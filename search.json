[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Probabilità per la psicologia",
    "section": "",
    "text": "Percorso e obiettivi\nQuesto sito è il modulo di richiamo sulla probabilità classica del progetto UTET a supporto del manuale Metodi bayesiani in psicologia.\nOffre una base teorica essenziale — variabili casuali, distribuzioni, valore atteso, varianza, dipendenza, campionamento — utile per leggere con agio l’inferenza bayesiana e i modelli del manuale principale.\nL’enfasi è operativa: formule essenziali, esempi minimi, diagrammi chiari. I capitoli rimandano, quando serve, ad approfondimenti nel companion e nel manuale.",
    "crumbs": [
      "Percorso e obiettivi"
    ]
  },
  {
    "objectID": "index.html#percorso-e-obiettivi",
    "href": "index.html#percorso-e-obiettivi",
    "title": "Probabilità per la psicologia",
    "section": "",
    "text": "Linguaggio della probabilità: eventi, misure di probabilità, indipendenza, condizionamento.\n\nVariabili casuali e distribuzioni: discrete e continue; funzioni di massa/densità e di ripartizione.\n\nMomentI e dipendenza: valore atteso, varianza, covarianza/correlazione.\n\nDistribuzioni fondamentali: Bernoulli, Binomiale, Poisson, Normale e derivate.\n\nCampionamento e verosimiglianza: dalla legge dei grandi numeri alla funzione di verosimiglianza come ponte verso l’inferenza.",
    "crumbs": [
      "Percorso e obiettivi"
    ]
  },
  {
    "objectID": "index.html#come-usare-il-modulo",
    "href": "index.html#come-usare-il-modulo",
    "title": "Probabilità per la psicologia",
    "section": "Come usare il modulo",
    "text": "Come usare il modulo\n\nProcedi in ordine: i concetti sono progressivi e si appoggiano l’uno sull’altro.\n\nRiduci la notazione al necessario: privilegiamo intuizioni e interpretazioni.\n\nCollega al bayesiano: tieni a mente come ogni concetto alimenta inferenza e modellazione (prior, verosimiglianza, posterior).",
    "crumbs": [
      "Percorso e obiettivi"
    ]
  },
  {
    "objectID": "index.html#prerequisiti-e-strumenti",
    "href": "index.html#prerequisiti-e-strumenti",
    "title": "Probabilità per la psicologia",
    "section": "Prerequisiti e strumenti",
    "text": "Prerequisiti e strumenti\n\nFamiliarità basilare con algebra e statistica descrittiva.\n\nRendering della matematica via MathJax (nessuna installazione richiesta).\n\nEsempi numerici riproducibili in \\(\\mathsf{R}\\) quando appropriato.",
    "crumbs": [
      "Percorso e obiettivi"
    ]
  },
  {
    "objectID": "index.html#licenza-duso",
    "href": "index.html#licenza-duso",
    "title": "Probabilità per la psicologia",
    "section": "Licenza d’uso",
    "text": "Licenza d’uso\nMateriali distribuiti con licenza\nCC BY-NC-ND 4.0. È consentita la condivisione con attribuzione, solo per usi non commerciali e senza modifiche.",
    "crumbs": [
      "Percorso e obiettivi"
    ]
  },
  {
    "objectID": "prefazione.html",
    "href": "prefazione.html",
    "title": "Prefazione",
    "section": "",
    "text": "A chi è destinato\nQuesto modulo di probabilità classica nasce come risorsa di supporto al manuale Metodi bayesiani in psicologia (UTET).\nIl suo scopo è fornire un lessico condiviso e alcune proprietà fondamentali utili a comprendere la logica dei modelli e dell’inferenza bayesiana, evitando sovraccarico teorico e duplicazioni.",
    "crumbs": [
      "Prefazione"
    ]
  },
  {
    "objectID": "prefazione.html#a-chi-è-destinato",
    "href": "prefazione.html#a-chi-è-destinato",
    "title": "Prefazione",
    "section": "",
    "text": "A chi desidera rinfrescare le basi di probabilità prima di affrontare l’inferenza bayesiana.\n\nA chi cerca un riferimento snello, con definizioni operative, esempi minimi e rimandi mirati.",
    "crumbs": [
      "Prefazione"
    ]
  },
  {
    "objectID": "prefazione.html#cosa-troverai",
    "href": "prefazione.html#cosa-troverai",
    "title": "Prefazione",
    "section": "Cosa troverai",
    "text": "Cosa troverai\n\nConcetti essenziali (eventi, indipendenza, probabilità condizionata).\n\nVariabili casuali e distribuzioni (discrete e continue).\n\nMomenti e dipendenza (valore atteso, varianza, covarianza/correlazione).\n\nDistribuzioni di lavoro in psicologia (Bernoulli, Binomiale, Poisson, Normale).\n\nCampionamento e verosimiglianza come ponte concettuale verso i modelli.\n\nOgni capitolo privilegia intuizioni e interpretazioni: la notazione viene tenuta al minimo necessario, mentre i collegamenti al companion e al manuale completano la prospettiva applicativa.",
    "crumbs": [
      "Prefazione"
    ]
  },
  {
    "objectID": "prefazione.html#come-leggere",
    "href": "prefazione.html#come-leggere",
    "title": "Prefazione",
    "section": "Come leggere",
    "text": "Come leggere\n\nProcedi in sequenza; quando un tema è noto, usa gli snodi (inizio/fine capitolo) per passare al successivo.\n\nQuando incontri un concetto inusuale nel manuale bayesiano (ad es. “verosimiglianza”), torna qui per la definizione operativa e un esempio numerico.",
    "crumbs": [
      "Prefazione"
    ]
  },
  {
    "objectID": "prefazione.html#ringraziamenti",
    "href": "prefazione.html#ringraziamenti",
    "title": "Prefazione",
    "section": "Ringraziamenti",
    "text": "Ringraziamenti\nQuesto modulo fa parte dell’ecosistema UTET dedicato all’analisi dei dati in psicologia.\nSi ringraziano i lettori che segnaleranno imprecisioni o suggerimenti tramite l’issue tracker del repository.",
    "crumbs": [
      "Prefazione"
    ]
  },
  {
    "objectID": "prefazione.html#licenza",
    "href": "prefazione.html#licenza",
    "title": "Prefazione",
    "section": "Licenza",
    "text": "Licenza\nMateriali rilasciati con licenza CC BY-NC-ND 4.0.\nCondivisione consentita con attribuzione; non è consentito l’uso commerciale né la creazione di opere derivate.",
    "crumbs": [
      "Prefazione"
    ]
  },
  {
    "objectID": "chapters/probability/introduction_probability.html",
    "href": "chapters/probability/introduction_probability.html",
    "title": "Elementi di teoria della probabilità",
    "section": "",
    "text": "Questo modulo raccoglie i concetti essenziali della probabilità classica, pensati come richiamo e supporto al manuale Metodi bayesiani in psicologia (UTET).\nLa probabilità fornisce il linguaggio con cui la scienza descrive l’incertezza: nessuna conclusione empirica è mai definitiva, ma può essere valutata in termini di gradi di plausibilità.\nIl formalismo matematico della probabilità è condiviso da tutte le principali prospettive inferenziali. Che si tratti dell’interpretazione frequentista (probabilità come frequenza relativa di un evento in ripetizioni ipotetiche) o di quella bayesiana (probabilità come misura di credenza razionale in una proposizione), le regole di base rimangono le stesse. Padroneggiarle è quindi indispensabile per comprendere sia i metodi classici sia l’approccio bayesiano sviluppato nel manuale.\nIn queste pagine troverai:\n\nle definizioni fondamentali di probabilità e le regole di calcolo di base;\n\nla probabilità condizionata e il teorema di Bayes, cardine dell’aggiornamento delle informazioni;\n\nle proprietà delle variabili casuali e delle loro distribuzioni, discrete e continue;\n\nla funzione di verosimiglianza, ponte concettuale che unisce inferenza bayesiana e frequentista.\n\nL’enfasi è operativa: fornire un vocabolario comune e strumenti minimi ma solidi, così da affrontare con maggiore sicurezza i capitoli del companion e del manuale principale.",
    "crumbs": [
      "Elementi di teoria della probabilità"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html",
    "href": "chapters/probability/01_intro_prob.html",
    "title": "2  Interpretazione della probabilità",
    "section": "",
    "text": "Introduzione\nIn questo capitolo esamineremo come la teoria della probabilità si sia affermata come uno strumento per descrivere e interpretare l’incertezza, muovendoci tra diverse concezioni (classica, frequentista e bayesiana) e riconoscendo il ruolo fondamentale della simulazione nel chiarire concetti probabilistici, come la legge dei grandi numeri. Prima, però, è utile soffermarsi sull’idea di casualità e sul nesso che la lega all’incertezza.",
    "crumbs": [
      "Elementi di teoria della probabilità",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Interpretazione della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#introduzione",
    "href": "chapters/probability/01_intro_prob.html#introduzione",
    "title": "2  Interpretazione della probabilità",
    "section": "",
    "text": "Panoramica del capitolo\n\nLe diverse interpretazioni della probabilità.\nIncertezza epistemica e ontologica.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere Why probability probably doesn’t exist (but it is useful to act like it does (Spiegelhalter, 2024).\nLeggere l’Appendice D.\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()",
    "crumbs": [
      "Elementi di teoria della probabilità",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Interpretazione della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#casualità-e-incertezza",
    "href": "chapters/probability/01_intro_prob.html#casualità-e-incertezza",
    "title": "2  Interpretazione della probabilità",
    "section": "\n2.1 Casualità e incertezza",
    "text": "2.1 Casualità e incertezza\nDavid Spiegelhalter, in un recente articolo pubblicato su Nature, sottolinea come la vita sia pervasa dall’incertezza: non sappiamo con certezza cosa è accaduto in passato, cosa avverrà in futuro né abbiamo una completa comprensione di ciò che ci circonda (Spiegelhalter, 2024). Questa condizione di ignoranza spinge a interpretare la casualità come un modello che, pur non fornendo previsioni deterministiche, rivela spesso regolarità statistiche. In altre parole, i singoli eventi possono apparire imprevedibili, ma l’osservazione di molti casi analoghi svela andamenti medi stabili e quantificabili.\nDa questa prospettiva nasce la teoria della probabilità, intesa come linguaggio matematico rigoroso per quantificare e modellare l’incertezza. Attraverso concetti quali valore atteso, distribuzioni di probabilità e frequenze relative, la probabilità permette di passare dalla nozione intuitiva di caso all’analisi formale dei fenomeni incerti. Anche nell’ambito psicologico, la probabilità supporta la ricerca, l’interpretazione di dati sperimentali e la presa di decisioni cliniche, fornendo una base teorica su cui costruire ipotesi e valutare rischi e benefici.",
    "crumbs": [
      "Elementi di teoria della probabilità",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Interpretazione della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#il-ruolo-della-probabilità-nello-studio-dei-fenomeni",
    "href": "chapters/probability/01_intro_prob.html#il-ruolo-della-probabilità-nello-studio-dei-fenomeni",
    "title": "2  Interpretazione della probabilità",
    "section": "\n2.2 Il ruolo della probabilità nello studio dei fenomeni",
    "text": "2.2 Il ruolo della probabilità nello studio dei fenomeni\nLa teoria della probabilità consente di trasformare le intuizioni sulla casualità in un linguaggio rigoroso. Tra le sue funzioni fondamentali si evidenziano:\n\nQuantificare l’incertezza\nAssegnare valori numerici agli esiti possibili rende esplicita la probabilità di ogni evento. Per esempio, nel lancio di un dado, dire che ogni faccia ha 1/6 di probabilità di uscire equivale a tradurre la casualità in un concetto misurabile.\nCombinare informazioni\nLe regole di somma e prodotto permettono di integrare probabilità relative a eventi diversi: la somma si utilizza per eventi mutualmente esclusivi (es. prendere o non prendere un voto specifico a un esame), mentre il prodotto si applica a eventi ritenuti indipendenti (es. risultati di più estrazioni da un’urna).\nAggiornare le credenze\nSecondo la prospettiva bayesiana, le probabilità non sono statiche, ma si modificano con il sopraggiungere di nuove evidenze. Un tipico esempio è la revisione di previsioni meteorologiche alla luce di dati più recenti, come la pressione atmosferica o l’umidità.\nOttimizzare le decisioni\nLa probabilità guida valutazioni di rischi e benefici, aiutando a scegliere in modo razionale quando l’esito di un’azione non è garantito. Questa idea si applica tanto in campo clinico, per decidere il protocollo di un trattamento sperimentale, quanto in ambito psicologico, per valutare il processo terapeutico per un disturbo alimentare.\n\nQueste funzioni costituiscono l’ossatura della teoria della probabilità e la rendono uno strumento essenziale per affrontare contesti in cui l’informazione è parziale o i fenomeni hanno una componente di casualità irriducibile.",
    "crumbs": [
      "Elementi di teoria della probabilità",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Interpretazione della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#due-tipi-di-incertezza-epistemica-e-ontologica",
    "href": "chapters/probability/01_intro_prob.html#due-tipi-di-incertezza-epistemica-e-ontologica",
    "title": "2  Interpretazione della probabilità",
    "section": "\n2.3 Due tipi di incertezza: epistemica e ontologica",
    "text": "2.3 Due tipi di incertezza: epistemica e ontologica\nL’analisi probabilistica si confronta con due tipologie di incertezza:\n\nEpistemica\nDipende dai limiti della conoscenza o dai dati a disposizione. Se in un esperimento non si controllano adeguatamente variabili importanti, la nostra misura di probabilità risente di queste lacune. L’incertezza epistemica può ridursi affinando il disegno sperimentale o ampliando il numero di osservazioni.\nOntologica\nInerente al fenomeno stesso, è indipendente dal grado di controllo o di osservazione possibile. Il lancio di un dado rimane imprevedibile anche se conoscessimo le leggi fisiche in gioco e le condizioni iniziali con incredibile precisione. Questo tipo di casualità è connaturato al sistema, e dunque impossibile da eliminare del tutto.\n\nUn celebre riferimento in questo contesto è Niels Bohr, secondo il quale la scienza non fornisce verità assolute, ma costruisce modelli che descrivono la realtà entro i limiti concettuali di cui disponiamo. In questa prospettiva, l’incertezza ontologica segna il confine tra ciò che è conoscibile e la complessità insita nella natura dei fenomeni.",
    "crumbs": [
      "Elementi di teoria della probabilità",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Interpretazione della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#cenni-storici",
    "href": "chapters/probability/01_intro_prob.html#cenni-storici",
    "title": "2  Interpretazione della probabilità",
    "section": "\n2.4 Cenni storici",
    "text": "2.4 Cenni storici\nLa teoria della probabilità affonda le sue radici nei giochi d’azzardo, pratiche antiche che stimolarono riflessioni sui meccanismi del caso. Fu però nel XVII secolo che iniziò a prendere forma una sistematizzazione scientifica, grazie al dialogo tra Blaise Pascal e Pierre de Fermat. I due matematici risposero alle questioni poste dal Chevalier de Méré, un aristocratico appassionato di scommesse. Tra i dilemmi più noti vi era il cosiddetto “problema della ripartizione equa”: come distribuire il premio di un torneo di dadi interrotto prematuramente, basandosi sulle chance residuali di vittoria dei giocatori?\n\nDue giocatori, A e B, stanno partecipando a un gioco in cui il primo a vincere sei round consecutivi ottiene il premio. Dopo sei round, A ha vinto cinque round e B uno. Poiché il gioco viene interrotto, come si dovrebbe dividere il premio in modo equo?\n\nQuesto problema spinse Pascal e Fermat a sviluppare i primi strumenti matematici per calcolare la probabilità degli eventi futuri, dando vita a un metodo rigoroso per affrontare l’incertezza. Stimando, ad esempio, che A avesse il 97% di probabilità di vincere e B il 3%, sembrava equo dividere il premio nella stessa proporzione. La soluzione, che prevedeva il calcolo degli esiti attesi e delle relative probabilità, segnò una svolta epocale, gettando le basi per la formalizzazione matematica della disciplina.\nChristian Huygens, con il trattato De Ratiociniis in Ludo Aleae (1657), approfondì le applicazioni nel gioco d’azzardo, mentre figure come Leibniz e John Graunt esplorarono rispettivamente la probabilità come strumento logico-giuridico e come frequenza statistica.\nJacob Bernoulli, nell’Ars Conjectandi (1713), formulò la legge dei grandi numeri, evidenziando come ripetute osservazioni empiriche rivelino regolarità nascoste, nonostante l’apparente imprevedibilità dei singoli eventi. Questo lavoro pose le basi per due visioni contrapposte: la probabilità come misura dell’incertezza epistemica (grado di fiducia razionale) e come proprietà oggettiva legata alla frequenza.",
    "crumbs": [
      "Elementi di teoria della probabilità",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Interpretazione della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#la-dualità-epistemologica-e-frequenziale",
    "href": "chapters/probability/01_intro_prob.html#la-dualità-epistemologica-e-frequenziale",
    "title": "2  Interpretazione della probabilità",
    "section": "\n2.5 La dualità epistemologica e frequenziale",
    "text": "2.5 La dualità epistemologica e frequenziale\nHacking (2006) ha sottolineato che, a partire dal contributo di Bernoulli, la probabilità si sviluppò storicamente lungo due assi: da un lato come misura della credibilità di un’ipotesi (prospettiva epistemologica), dall’altro come descrizione della frequenza con cui un evento compare in circostanze ripetute (prospettiva frequenziale). Questa tensione è tuttora visibile nella dicotomia fra metodi bayesiani e metodi frequentisti.\n\n2.5.1 Frequentismo\nIl frequentismo intende la probabilità come frequenza relativa dell’evento in un numero potenzialmente infinito di prove. I fondatori di questo approccio, tra cui Ronald A. Fisher e poi Jerzy Neyman ed Egon Pearson, hanno posto le basi dell’inferenza statistica classica (test di ipotesi, intervalli di confidenza, analisi di varianza).\nIl modello paradigmatico di questo approccio è il cosiddetto modello dell’urna. Si immagina di estrarre in modo casuale una pallina da un’urna contenente palline visivamente indistinguibili, ma numerate: ogni pallina ha la stessa probabilità di essere scelta, riproducendo così l’idea di eventi equiprobabili. Questa concezione si basa su una rappresentazione astratta e ideale della casualità che, nella realtà, trova riscontro in ambiti quali il campionamento statistico e gli studi clinici randomizzati (in cui ogni paziente ha la stessa probabilità di essere assegnato al gruppo sperimentale o di controllo). Il limite di questa visione emerge nei casi in cui non è possibile accumulare un gran numero di osservazioni o quando l’evento è unico e irripetibile.\n\n2.5.2 Bayesianesimo\nIl bayesianesimo si basa sull’idea di un continuo aggiornamento delle nostre credenze. Con il teorema di Bayes si parte da una conoscenza iniziale (detta prior) e la si aggiorna con i dati osservati (likelihood) per giungere a una stima a posteriori.\n\n2.5.2.1 Probabilità come costruzione soggettiva\nL’approccio bayesiano è basato su un’interpretazione soggettiva della probabilità, secondo cui tale concetto rappresenta il grado di fiducia (o credenza) che un individuo o un gruppo attribuisce al verificarsi di un evento, sulla base delle informazioni disponibili. Un esempio pratico è la previsione di pioggia al 70%: non si tratta di un fenomeno fisico oggettivo – come avverrebbe in un’ottica frequenzialista – bensì del risultato di dati storici, modelli climatici e continue rivalutazioni.\nBruno de Finetti ha spinto all’estremo questa prospettiva soggettivista, riassumendo il suo pensiero con la celebre affermazione: “La probabilità non esiste”. In altre parole, la probabilità non sarebbe una proprietà fisica intrinseca degli eventi, ma un indicatore di quanto “si è pronti a scommettere” sulla base delle informazioni e delle convinzioni possedute. Sebbene tali convinzioni debbano rispettare gli assiomi della probabilità per risultare logicamente coerenti, la definizione puntuale di quanto un evento sia “certo” o “probabile” dipende dalla prospettiva e dalle informazioni dell’osservatore.\nFrank Ramsey, nel 1926, fu uno dei primi a formalizzare questa idea, definendo la probabilità come grado di credenza individuale coerente con gli assiomi matematici (Ramsey, 1926). Pochi anni dopo, nel 1939, Jeffreys (1998) illustrò in “Theory of Probability” una tra le prime esposizioni moderne dei metodi bayesiani. Successivamente, Fishburn (1986) fornì una rigorosa formalizzazione matematica degli assiomi della probabilità soggettiva, mentre Press (2009) contribuì ad ampliare l’ambito di applicazione di questa prospettiva, dimostrando la sua importanza come strumento per affrontare l’incertezza in ambito scientifico. Per una panoramica storica sullo sviluppo del pensiero bayesiano, si vedano anche Bayesian Methods: General Background e Philosophy of Statistics.\nIn questo quadro, l’attenzione si sposta dalla realtà oggettiva alla costruzione umana della probabilità, ponendo in evidenza il ruolo dei giudizi, delle ipotesi e delle informazioni disponibili. La probabilità non è dunque una proprietà del mondo, ma una misura del grado di fiducia razionale che un soggetto idealizzato assegna all’affermazione di un evento, basandosi sulle conoscenze (spesso incomplete) di cui dispone. Questo soggetto ideale è concepito come privo di emozioni, pregiudizi o bias cognitivi, così da agire esclusivamente sulla base della logica e delle evidenze. Tale impostazione si applica in modo particolarmente efficace in contesti dove i dati sono limitati o l’incertezza è elevata, come spesso accade negli studi psicologici, in cui il comportamento umano mal si presta a una descrizione puramente frequenzialista.\n\n\n\n\n\n\nTerminologia\n\n\n\nIl termine probabilità soggettiva viene spesso frainteso come mancanza di rigore. Per questo motivo sono state proposte alternative:\n\n\nLindley (2013) adotta il termine probabilità personale, per sottolineare l’aspetto individuale (ma razionale) di tale definizione.\n\n\nHowson & Urbach (2006) preferisce probabilità epistemica, enfatizzando il legame con la conoscenza e l’incertezza dovuta a informazioni limitate.\n\nAutori come Kaplan (2023) utilizzano tali alternative terminologiche per evidenziare in modo più neutrale il ruolo fondamentale della probabilità come strumento scientifico.\n\n\nUn aspetto importante che ha contribuito a promuovere la diffusione contemporanea dell’approccio bayesiano è stata la scoperta, sul finire degli anni ’80, dei metodi Monte Carlo Markov chain (MCMC). Queste tecniche hanno reso computazionalmente accessibili modelli e calcoli altrimenti irrealizzabili, favorendo la rinascita e l’ulteriore evoluzione dei metodi bayesiani.",
    "crumbs": [
      "Elementi di teoria della probabilità",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Interpretazione della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#i-due-paradigmi-della-probabilità-in-psicologia",
    "href": "chapters/probability/01_intro_prob.html#i-due-paradigmi-della-probabilità-in-psicologia",
    "title": "2  Interpretazione della probabilità",
    "section": "\n2.6 I due paradigmi della probabilità in psicologia",
    "text": "2.6 I due paradigmi della probabilità in psicologia\nIn psicologia, entrambi i paradigmi hanno risvolti importanti. L’approccio frequentista è ancora dominante nell’analisi dei dati (si pensi al largo uso dei test di significatività), ma il bayesianesimo sta guadagnando terreno, poiché permette di integrare informazioni pregresse in modo trasparente e di esprimere in modo diretto la probabilità di un’ipotesi.",
    "crumbs": [
      "Elementi di teoria della probabilità",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Interpretazione della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#dalla-teoria-alla-pratica-simulazioni-con-r",
    "href": "chapters/probability/01_intro_prob.html#dalla-teoria-alla-pratica-simulazioni-con-r",
    "title": "2  Interpretazione della probabilità",
    "section": "\n2.7 Dalla teoria alla Pratica: simulazioni con R",
    "text": "2.7 Dalla teoria alla Pratica: simulazioni con R\nNello studio della probabilità e della statistica, l’analisi analitica può risultare complessa in contesti con modelli intricati o distribuzioni non standard. In questi casi, la simulazione al computer emerge come strumento didattico e metodologico essenziale. Utilizzando linguaggi di programmazione come R, è possibile replicare virtualmente un esperimento migliaia di volte, osservando empiricamente la distribuzione degli esiti e stimando probabilità attraverso il metodo Monte Carlo. Questo approccio non solo facilita la comprensione di concetti astratti, ma consente anche di validare risultati teorici in scenari reali.\n\n2.7.1 Legge dei Grandi Numeri\nUn principio fondamentale esplorabile attraverso simulazioni è la legge dei grandi numeri (LLN), pilastro dell’approccio frequentista. La LLN stabilisce che la frequenza relativa di un evento converge alla sua probabilità teorica all’aumentare del numero di prove, pur preservando l’imprevedibilità dei singoli esiti. Ad esempio, in una sequenza di lanci di una moneta equa, la proporzione di “teste” oscillerà inizialmente in modo marcato, ma tenderà progressivamente a stabilizzarsi attorno al 50%.\nQuesto fenomeno riflette due aspetti chiave:\n\n\nRiduzione della variabilità: la media campionaria diventa sempre più affidabile con l’aumentare della numerosità del campione.\n\n\nSeparazione tra singoli eventi e comportamento aggregato: la LLN non elimina l’incertezza nei casi singoli (es., il risultato del prossimo lancio), ma descrive un pattern prevedibile a livello di popolazione.\n\nLa simulazione seguente illustra questo principio generando quattro sequenze indipendenti di lanci di moneta e calcolando la proporzione cumulativa di “teste”:\n\n\n\n\n\n\n\n\nIl grafico evidenzia due fenomeni: la convergenza verso il valore teorico (linea tratteggiata) e la variabilità iniziale tra le sequenze, che si attenua progressivamente. Questo esempio dimostra come la LLN fornisca un ponte tra modelli teorici (es., “moneta equa”) e osservazioni empiriche, pur rimanendo valida solo in condizioni di ripetibilità (stesse probabilità in ogni prova) e assenza di bias sistematici.\nLe simulazioni trovano ampio utilizzo in psicologia sia nella formazione che nella ricerca:\n\n\nDidattica: visualizzare il comportamento di indicatori statistici (es., media campionaria) al variare della dimensione del campione, rendendo tangibili concetti come “potenza statistica” o “errore standard”.\n\n\nRicerca: testare la robustezza di modelli psicometrici in condizioni controllate, simulando dati con specifiche caratteristiche (es., correlazioni deboli, rumore sperimentale).\n\nQuesti strumenti favoriscono un apprendimento attivo, invitando gli studenti a manipolare parametri (es., probabilità di successo, numerosità campionaria) e osservarne gli effetti, consolidando così l’intuizione statistica. Tuttavia, è cruciale ricordare che le simulazioni non sostituiscono la teoria, ma la completano, evidenziandone limiti e presupposti applicativi.\n\n\n\n\n\n\nApprofondimento critico\n\n\n\nLa LLN non elimina sfide metodologiche come bias di campionamento, misurazione imperfetta o fenomeni non stazionari. In psicologia, dove molti costrutti (es., emozioni, attitudini) sono intrinsecamente dinamici, l’applicazione della LLN richiede particolare attenzione.",
    "crumbs": [
      "Elementi di teoria della probabilità",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Interpretazione della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#riflessioni-conclusive",
    "href": "chapters/probability/01_intro_prob.html#riflessioni-conclusive",
    "title": "2  Interpretazione della probabilità",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nLa teoria della probabilità, nata originariamente per analizzare il gioco d’azzardo, si è gradualmente trasformata nel corso dei secoli in un pilastro metodologico per affrontare l’incertezza in un’ampia gamma di contesti, compresa la psicologia. La sua evoluzione storica testimonia un confronto continuo fra interpretazioni epistemiche e frequenzialiste, contribuendo all’elaborazione di strumenti analitici e pratiche operative — dalle procedure inferenziali alla simulazione computerizzata — che consentono di modellizzare sistemi complessi.\nDa un punto di vista filosofico, la probabilità può essere intesa sia come proprietà del mondo (in chiave frequenzialista), sia come misura della nostra conoscenza (nell’ottica bayesiana e soggettivista). Nel primo caso, le frequenze relative e la legge dei grandi numeri mostrano come, da una moltitudine di eventi, possano emergere regolarità e pattern stabili. Nel secondo, l’enfasi è posta sulla dimensione umana e fallibile dell’inferenza: le credenze e le informazioni disponibili influenzano in modo diretto la nostra stima della probabilità di un evento.\nAl di là di queste differenze interpretative, la probabilità si rivela uno strumento insostituibile per pianificare esperimenti, analizzare dati e prendere decisioni in condizioni di incertezza – attività centrali nel campo della psicologia. Inoltre, la possibilità di integrare metodologie teoriche e simulazioni amplia ulteriormente le prospettive di ricerca e la capacità di comprendere i fenomeni studiati. Lungi dall’essere un semplice calcolo combinatorio, la probabilità abbraccia così la complessità della realtà e la ricchezza della conoscenza umana, mostrando una versatilità che la rende uno dei fondamenti del pensiero scientifico contemporaneo.\n\n\n\n\n\n\nPer chi desidera approfondire, il primo capitolo del testo Bernoulli’s Fallacy (Clayton, 2021) offre un’introduzione molto leggibile alle tematiche della definizione della probabilità nella storia della scienza.",
    "crumbs": [
      "Elementi di teoria della probabilità",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Interpretazione della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#esercizi",
    "href": "chapters/probability/01_intro_prob.html#esercizi",
    "title": "2  Interpretazione della probabilità",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\n\nQuali sono le principali concezioni della probabilità esplorate nel capitolo?\nCome viene definita l’incertezza secondo David Spiegelhalter?\nQual è il ruolo della casualità nella teoria della probabilità?\nCome funziona il modello dell’urna per rappresentare la casualità?\nQuali sono alcune applicazioni del modello della casualità?\nQuali sono le due principali fonti di incertezza nei fenomeni non deterministici?\nCome viene interpretata la probabilità secondo l’approccio soggettivista?\nQuali sono le due dimensioni principali del concetto di probabilità secondo Hacking?\nQual è stato il contributo di Pascal e Fermat alla teoria della probabilità?\nQuali sono le differenze tra l’approccio bayesiano e frequentista nella teoria della probabilità?\nQual è la Legge dei Grandi Numeri e come si applica?\nQuali sono i limiti dell’interpretazione frequentista della probabilità?\nCome ha influenzato Fisher lo sviluppo della statistica frequentista?\nQual è stato il ruolo di Jeffreys nella rinascita dell’approccio bayesiano?\nCome definisce Bruno de Finetti la probabilità?\nQuali sono i principi fondamentali della probabilità soggettivista secondo Jaynes?\nQuali sono le alternative terminologiche proposte per la “probabilità soggettiva”?\nQual è l’importanza della simulazione nella comprensione della probabilità?\nQuali sono le implicazioni filosofiche della dualità della probabilità?\nQuali sono i principali contributi storici alla teoria della probabilità?\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n\nLe principali concezioni della probabilità esplorate nel capitolo sono la visione classica, frequentista e bayesiana.\nSecondo David Spiegelhalter, l’incertezza è definita come la “consapevolezza cosciente dell’ignoranza”, riguardante eventi futuri o passati che non possiamo conoscere con certezza.\nLa casualità è un modello concettuale che aiuta a gestire e quantificare eventi imprevedibili, ma che seguono schemi regolari e riconoscibili.\nIl modello dell’urna rappresenta la casualità attraverso l’estrazione di palline numerate da un’urna, dove ogni pallina ha la stessa probabilità di essere estratta.\nAlcune applicazioni del modello della casualità includono indagini statistiche, sperimentazione scientifica e simulazioni in fisica e psicologia.\nLe due principali fonti di incertezza sono l’incertezza epistemica (derivante dalla conoscenza limitata) e l’incertezza ontologica (intrinseca al fenomeno stesso).\nSecondo l’approccio soggettivista, la probabilità è una misura del grado di fiducia o convinzione di un individuo riguardo al verificarsi di un evento, basata sulle informazioni disponibili.\nSecondo Hacking, le due dimensioni principali del concetto di probabilità sono quella epistemologica (misura della credibilità) e quella frequenziale (tendenza osservabile nei fenomeni aleatori).\nPascal e Fermat hanno sviluppato i primi strumenti matematici per calcolare la probabilità degli eventi futuri, risolvendo problemi legati al gioco d’azzardo.\nL’approccio bayesiano considera la probabilità come una misura soggettiva del grado di fiducia, mentre l’approccio frequentista la definisce come la frequenza relativa di un evento in una serie infinita di prove.\nLa Legge dei Grandi Numeri afferma che al crescere del numero di prove, la media dei risultati osservati si avvicina al valore atteso teorico.\nI limiti dell’interpretazione frequentista includono la difficoltà di applicarla a eventi singolari e non ripetibili, e la necessità di un numero infinito di prove per definire la probabilità.\nFisher ha introdotto concetti chiave come la massima verosimiglianza, i test di significatività e l’analisi della varianza, contribuendo allo sviluppo della statistica frequentista.\nJeffreys ha contribuito alla rinascita dell’approccio bayesiano con il suo libro “Theory of Probability”, che ha riportato l’attenzione sui metodi bayesiani.\nBruno de Finetti definisce la probabilità come una misura del grado di fiducia razionale basata su informazioni incomplete, affermando che “la probabilità non esiste” come proprietà oggettiva.\nSecondo Jaynes, i principi fondamentali della probabilità soggettivista includono l’intervallo numerico (0-1) e la coerenza logica, basandosi su informazioni disponibili.\nLe alternative terminologiche proposte per la “probabilità soggettiva” includono “probabilità personale” e “probabilità epistemica”.\nLa simulazione è importante per approssimare probabilità empiriche in contesti complessi, dove soluzioni analitiche non sono praticabili, e per comprendere fenomeni probabilistici attraverso modelli numerici.\nLe implicazioni filosofiche della dualità della probabilità riflettono la tensione tra una descrizione oggettiva della realtà e la soggettività del processo interpretativo.\nI principali contributi storici alla teoria della probabilità includono i lavori di Pascal, Fermat, Huygens, Bernoulli, Fisher, Jeffreys e de Finetti.",
    "crumbs": [
      "Elementi di teoria della probabilità",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Interpretazione della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#bibliografia",
    "href": "chapters/probability/01_intro_prob.html#bibliografia",
    "title": "2  Interpretazione della probabilità",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nClayton, A. (2021). Bernoulli’s Fallacy: Statistical Illogic and the Crisis of Modern Science. Columbia University Press.\n\n\nFishburn, P. C. (1986). The axioms of subjective probability. Statistical Science, 1(3), 335–345.\n\n\nHacking, I. (2006). The emergence of probability: A philosophical study of early ideas about probability, induction and statistical inference. Cambridge University Press.\n\n\nHowson, C., & Urbach, P. (2006). Scientific reasoning: the Bayesian approach. Open Court Publishing.\n\n\nJeffreys, H. (1998). The theory of probability. OuP Oxford.\n\n\nKaplan, D. (2023). Bayesian statistics for the social sciences. Guilford Publications.\n\n\nLindley, D. V. (2013). Understanding uncertainty. John Wiley & Sons.\n\n\nPress, S. J. (2009). Subjective and objective Bayesian statistics: Principles, models, and applications. John Wiley & Sons.\n\n\nRamsey, F. P. (1926). Truth and probability. In Readings in Formal Epistemology: Sourcebook (pp. 21–45). Springer.\n\n\nSpiegelhalter, D. (2024). Why probability probably doesn’t exist (but it is useful to act like it does). Nature, 636(8043), 560–563.",
    "crumbs": [
      "Elementi di teoria della probabilità",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Interpretazione della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html",
    "href": "chapters/probability/02_probability_models.html",
    "title": "3  Modelli probabilistici",
    "section": "",
    "text": "Introduzione\nDopo aver esaminato il significato filosofico della probabilità nel Capitolo 2, questo capitolo ne sviluppa una trattazione più formale, creando un collegamento tra la riflessione teorica e gli strumenti operativi. Partendo dalla definizione di esperimento casuale – come il lancio di una moneta o la somministrazione di un test psicologico – costruiremo un framework matematico per analizzare e quantificare le proprietà di tali esperimenti. In particolare, approfondiremo i concetti di spazio campionario, eventi e proprietà della probabilità, fornendo le basi per un’interpretazione rigorosa dei fenomeni complessi in psicologia e nelle scienze sociali.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#introduzione",
    "href": "chapters/probability/02_probability_models.html#introduzione",
    "title": "3  Modelli probabilistici",
    "section": "",
    "text": "Panoramica del capitolo\n\nNozioni di spazio campionario, eventi e operazioni su eventi.\nDefinizione di probabilità.\nSpazi discreti o continui.\nTeorema della somma.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere il capitolo Probability Models del testo di Chan & Kroese (2025).\nStudiare l’Appendice D.\nStudiare l’Appendice E.\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt;\n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(readr, VennDiagram)\n\n\n\n\n\n\n\n\n\n\nDomande introduttive\n\n\n\n\n\nPrima di esaminare in maniera più formale le basi della teoria della probabilità, consideriamo un classico problema della teoria della probabilità:\n“Quante persone servono in una stanza perché ci sia almeno il 50% di probabilità che due condividano lo stesso compleanno?”\nQuesto problema, noto come problema dei compleanni, fu introdotto dal matematico Richard von Mises nel 1932. La sua soluzione sfida l’intuizione e rivela quanto le probabilità combinatorie possano essere ingannevoli.\nRispondi alle seguenti domande.\n\nCon quante persone pensi si superi il 50% di probabilità? (23? 100? 180?)\nCon 30 persone, quale probabilità stimi? (10%? 50%? 70%?)\n\nScrivi le tue risposte su un foglietto senza condividere con i compagni.\nPer svolgere un esercizio in classe, compila il seguente modulo su Google Forms.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#esperimenti-casuali",
    "href": "chapters/probability/02_probability_models.html#esperimenti-casuali",
    "title": "3  Modelli probabilistici",
    "section": "\n3.1 Esperimenti casuali",
    "text": "3.1 Esperimenti casuali\nIl concetto fondamentale della probabilità è l’esperimento casuale, ovvero un procedimento il cui esito non può essere previsto con certezza, ma che può essere analizzato quantitativamente. Alcuni esempi di esperimenti casuali includono: lanciare un dado e osservare il numero ottenuto sulla faccia superiore; estrarre una carta a caso da un mazzo e registrarne il seme e il valore; misurare il livello di stress percepito da un gruppo di individui in un determinato contesto, come durante un esame o un evento stressante; contare il numero di risposte corrette fornite dai partecipanti a un test di memoria entro un tempo prestabilito; eccetera.\nL’analisi probabilistica ha lo scopo di comprendere il comportamento di tali esperimenti attraverso la costruzione di modelli matematici. Una volta formalizzato matematicamente un esperimento casuale, è possibile calcolare grandezze di interesse, come probabilità ed aspettative. Questi modelli possono essere implementati al computer per simulare l’esperimento e analizzarne i risultati. Inoltre, la modellizzazione matematica degli esperimenti casuali costituisce la base della statistica, disciplina che permette di confrontare diversi modelli e identificare quello più adeguato ai dati osservati.\n\n3.1.1 Il lancio di una moneta\nUno degli esperimenti casuali più semplici e fondamentali è il lancio ripetuto di una moneta. Molti concetti chiave della teoria della probabilità possono essere illustrati partendo da questo esperimento elementare. Per studiarne il comportamento, possiamo simularlo al computer utilizzando il linguaggio R.\nDi seguito, un semplice script in R simula 100 lanci di una moneta equa (cioè con probabilità uguali di ottenere Testa o Croce) e rappresenta graficamente la distribuzione dei risultati mediante un diagramma a barre.\n\nset.seed(123) # Imposta il seed per garantire la riproducibilità\nx &lt;- runif(100) &lt; 0.5 # Genera 100 numeri casuali e verifica se sono minori di 0.5\nx\n#&gt;   [1]  TRUE FALSE  TRUE FALSE FALSE  TRUE FALSE FALSE FALSE  TRUE FALSE  TRUE\n#&gt;  [13] FALSE FALSE  TRUE FALSE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE\n#&gt;  [25] FALSE FALSE FALSE FALSE  TRUE  TRUE FALSE FALSE FALSE FALSE  TRUE  TRUE\n#&gt;  [37] FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n#&gt;  [49]  TRUE FALSE  TRUE  TRUE FALSE  TRUE FALSE  TRUE  TRUE FALSE FALSE  TRUE\n#&gt;  [61] FALSE  TRUE  TRUE  TRUE FALSE  TRUE FALSE FALSE FALSE  TRUE FALSE FALSE\n#&gt;  [73] FALSE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE FALSE  TRUE FALSE\n#&gt;  [85]  TRUE  TRUE FALSE FALSE FALSE  TRUE  TRUE FALSE  TRUE FALSE  TRUE  TRUE\n#&gt;  [97] FALSE  TRUE  TRUE FALSE\n\nNel codice, la funzione runif genera 100 numeri casuali distribuiti uniformemente nell’intervallo [0, 1]. Confrontando ciascun numero con 0.5, otteniamo un vettore logico che rappresenta il risultato di ogni lancio: Testa (TRUE) o Croce (FALSE).\n\nt &lt;- 1:100 # Sequenza degli indici dei lanci\n\n# Creazione del dataframe per ggplot2\ndat &lt;- tibble(\n  Lancio = t,\n  Risultato = ifelse(x, \"Testa\", \"Croce\")\n)\nhead(dat)\n#&gt; # A tibble: 6 × 2\n#&gt;   Lancio Risultato\n#&gt;    &lt;int&gt; &lt;chr&gt;    \n#&gt; 1      1 Testa    \n#&gt; 2      2 Croce    \n#&gt; 3      3 Testa    \n#&gt; 4      4 Croce    \n#&gt; 5      5 Croce    \n#&gt; 6      6 Testa\n\nIl grafico a barre mostra la distribuzione osservata degli esiti.\n\n# Creazione del grafico a barre della distribuzione dei risultati\ndat |&gt;\n  ggplot(aes(x = Risultato)) +\n  geom_bar(aes(y = after_stat(prop), group = 1), width = 0.5) +\n  labs(\n    x = \"Risultato\",\n    y = \"Frequenza relativa\"\n  )\n\n\n\n\n\n\n\nUn aspetto rilevante di questo esperimento è l’andamento della proporzione osservata di esiti “Testa” in funzione del numero di lanci. Il grafico riportato di seguito illustra l’evoluzione della media cumulativa degli esiti “Testa”, che, in accordo con la legge dei grandi numeri, dovrebbe convergere al valore teorico di 0.5.\n\ny &lt;- cumsum(x) / t # Calcola la media cumulativa delle Teste\n\n# Creazione del dataframe per il grafico della media mobile\ndata_mean &lt;- tibble(\n  Lancio = t, \n  Media_Testa = y\n)\n\n# Creazione del grafico della media cumulativa\ndata_mean |&gt;\n  ggplot(\n    aes(x = Lancio, y = Media_Testa)\n  ) +\n  geom_line(linewidth = 1.5) +\n  geom_hline(yintercept = 0.5, linetype = \"dashed\", color = \"red\") +\n  labs(\n    x = \"Numero di lanci\",\n    y = \"Frequenza cumulativa di Teste\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nMedia cumulata\n\n\n\n\n\nLa media cumulata (o cumulativa) è una media che si calcola progressivamente, aggiungendo un nuovo dato alla volta e ricalcolando la media considerando tutti i valori precedenti insieme al nuovo.\nIn pratica, mostra come la media si evolve man mano che vengono inclusi nuovi dati nella serie.\nCome si calcola?\n\nAl primo dato, la media cumulata è il dato stesso.\n\nAl secondo dato, è la media tra il primo e il secondo.\n\nAl terzo dato, è la media tra il primo, il secondo e il terzo.\n\nE così via…\n\nFormula intuitiva:\n\\[\n\\text{Media cumulata al passo } n = \\frac{\\text{somma di tutti i dati fino al passo } n}{n}\n\\]\nEsempio pratico:\nSupponiamo di avere i voti di uno studente in 3 verifiche:\n\nVerifica 1: 7\n\nVerifica 2: 6\n\nVerifica 3: 8\n\nLe medie cumulate saranno:\n\nDopo la 1ª verifica: \\(\\frac{7}{1} = 7\\).\n\nDopo la 2ª verifica: \\(\\frac{7 + 6}{2} = 6.5\\).\n\nDopo la 3ª verifica: \\(\\frac{7 + 6 + 8}{3} = 7\\).\n\nA cosa serve?\n\n\nTracciare l’andamento nel tempo (es.: mostrare come la frequenza di “Testa” si avvicina gradualmente al 50% teorico man mano che aumentano i lanci).\n\n\nLisciare le fluttuazioni: riduce l’impatto di picchi temporanei, mostrando un trend più stabile.\n\n\nValutare prestazioni progressive (es.: un atleta che migliora gradualmente).\n\n\n\n\n\nIl grafico mostra come la media delle Teste oscilla inizialmente a causa della variabilità intrinseca dell’esperimento, ma tende progressivamente a stabilizzarsi intorno a 0.5. Questo fenomeno è un esempio della Legge dei Grandi Numeri, secondo cui, ripetendo un esperimento casuale un numero sempre maggiore di volte, la frequenza relativa di un evento si avvicina alla sua probabilità teorica.\n\n3.1.2 Domande di interesse\nL’esperimento casuale del lancio di una moneta porta a numerose domande, tra cui:\n\nQual è la probabilità di ottenere un certo numero \\(x\\) di Teste in 100 lanci?\nQual è il numero atteso di Teste in un esperimento di 100 lanci?\n\nDal punto di vista statistico, quando osserviamo i risultati di un esperimento reale (ad esempio, 100 lanci di una moneta), possiamo anche porci domande come:\n\nLa moneta è davvero equa o è sbilanciata?\nQual è il miglior metodo per stimare la probabilità \\(p\\) di ottenere Testa dalla sequenza osservata di lanci?\nQuanto è precisa la stima ottenuta e con quale livello di incertezza?\n\nQuesti interrogativi costituiscono la base della statistica inferenziale, che permette di testare ipotesi sulla probabilità di un evento e stimare parametri sconosciuti sulla base di dati osservati.\n\n3.1.3 Modellizzazione\nLa descrizione matematica di un esperimento casuale si basa su tre elementi fondamentali:\n\nLo spazio campionario: rappresenta l’insieme di tutti i possibili esiti dell’esperimento. Nel caso di esperimenti semplici, lo spazio campionario è immediato da individuare, mentre in situazioni più complesse è necessario applicare i principi del calcolo combinatorio.\nGli eventi: sono sottoinsiemi dello spazio campionario e rappresentano gli esiti di interesse. Per analizzare e manipolare gli eventi, utilizziamo gli strumenti della teoria degli insiemi.\nLa probabilità: assegna un valore numerico a ciascun evento, indicando la sua probabilità di verificarsi. L’assegnazione delle probabilità avviene secondo gli assiomi di Kolmogorov.\n\nNei paragrafi seguenti, analizzeremo ciascuna di queste componenti in dettaglio.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#spazio-campionario",
    "href": "chapters/probability/02_probability_models.html#spazio-campionario",
    "title": "3  Modelli probabilistici",
    "section": "\n3.2 Spazio campionario",
    "text": "3.2 Spazio campionario\nAnche se non possiamo prevedere con esattezza l’esito di un singolo esperimento casuale, possiamo comunque definire tutti i risultati che potrebbero verificarsi. L’insieme completo di questi esiti possibili si chiama spazio campionario.\n\nDefinizione 3.1 Lo spazio campionario \\(\\Omega\\) di un esperimento casuale è l’insieme di tutti i possibili esiti dell’esperimento.\n\n\n3.2.1 Esempi di spazi campionari\nConsideriamo lo spazio campionario di alcuni esperimenti casuali.\n\nLancio di due dadi consecutivi: \\[\n\\Omega = \\{(1,1), (1,2), \\dots, (6,6)\\}.\n\\]\nTempo di reazione a uno stimolo visivo: \\[\\Omega = \\mathbb{R}^+,\\] ovvero l’insieme dei numeri reali positivi.\nNumero di errori in un test di memoria a breve termine: \\[\\Omega = \\{0, 1, 2, \\dots\\}.\\]\nMisurazione delle altezze di dieci persone: \\[\\Omega = \\{(x_1, \\dots, x_{10}) : x_i \\ge 0, \\; i=1,\\dots,10\\} \\subset \\mathbb{R}^{10}.\\]",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#eventi",
    "href": "chapters/probability/02_probability_models.html#eventi",
    "title": "3  Modelli probabilistici",
    "section": "\n3.3 Eventi",
    "text": "3.3 Eventi\nSolitamente non siamo interessati a un singolo esito, ma a un insieme di essi. Un evento è un sottoinsieme dello spazio campionario a cui possiamo assegnare una probabilità.\n\nDefinizione 3.2 Un evento è un sottoinsieme \\(A \\subseteq \\Omega\\) al quale viene assegnata una probabilità. Indichiamo gli eventi con lettere maiuscole \\(A, B, C, \\dots\\). Diciamo che l’evento \\(A\\) si verifica se l’esito dell’esperimento appartiene a \\(A\\).\n\n\n3.3.1 Esempi di eventi\nConsideriamo alcuni possibili eventi definiti sugli spazi campionari descritti sopra.\n\nLancio di due dadi consecutivi.Evento: “La somma dei due dadi è uguale a 7”\\[\nA = \\{(1,6), (2,5), (3,4), (4,3), (5,2), (6,1)\\}.\n\\]\nTempo di reazione a uno stimolo visivo.Evento: “Il tempo di reazione è inferiore a 2 secondi”\\[\nA = [0, 2).\n\\]\nNumero di errori in un test di memoria a breve termine.Evento: “Il numero di errori è al massimo 3”\\[\nA = \\{0, 1, 2, 3\\}.\n\\]\nMisurazione delle altezze di dieci persone.Evento: “Almeno due persone hanno un’altezza superiore a 180 cm”\\[\nA = \\{(x_1, \\dots, x_{10}) : \\text{almeno due } x_i &gt; 180\\}.\n\\]\n\nQuesti esempi mostrano come gli eventi possano essere definiti in modo diverso a seconda della natura dello spazio campionario e del contesto di interesse.\n\n\n\n\n\n\nEsempio\n\n\n\n\n\nSupponiamo di lanciare una moneta tre volte e di annotare se esce Testa (\\(H\\)) o Croce (\\(T\\)) in ogni lancio. Lo spazio campionario è:\n\\[\n\\Omega = \\{HHH, HHT, HTH, HTT, THH, THT, TTH, TTT\\},\n\\]\ndove, ad esempio, \\(HTH\\) indica che il primo lancio dà Testa, il secondo Croce e il terzo Testa.\nUn’alternativa è rappresentare lo spazio campionario come l’insieme dei vettori binari di lunghezza 3, \\(\\{0,1\\}^3\\), dove Testa (\\(H\\)) corrisponde a 1 e Croce (\\(T\\)) a 0.\nL’evento \\(A\\) “il terzo lancio è Testa” si esprime come:\n\\[\nA = \\{HHH, HTH, THH, TTH\\}.\n\\]",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#operazioni-sugli-eventi",
    "href": "chapters/probability/02_probability_models.html#operazioni-sugli-eventi",
    "title": "3  Modelli probabilistici",
    "section": "\n3.4 Operazioni sugli eventi",
    "text": "3.4 Operazioni sugli eventi\nPoiché gli eventi sono definiti come insiemi, possiamo applicare loro le classiche operazioni insiemistiche.\nUnione (\\(\\cup\\)). L’unione di due eventi \\(A\\) e \\(B\\) è l’insieme di tutti gli esiti che appartengono almeno a uno dei due:\n\\[\nA \\cup B = \\{\\omega \\in \\Omega : \\omega \\in A \\text{ oppure } \\omega \\in B\\}.\n\\]\nIntersezione (\\(\\cap\\)). L’intersezione di due eventi è l’insieme degli esiti comuni:\n\\[\nA \\cap B = \\{\\omega \\in \\Omega : \\omega \\in A \\text{ e } \\omega \\in B\\}.\n\\]\nComplemento (\\(A^c\\)). Il complemento di un evento \\(A\\) è l’insieme di tutti gli esiti che non appartengono ad \\(A\\):\n\\[\nA^c = \\{\\omega \\in \\Omega : \\omega \\notin A\\}.\n\\]\nEventi mutuamente esclusivi. Due eventi sono mutuamente esclusivi se non hanno esiti in comune, ovvero:\n\\[\nA \\cap B = \\emptyset.\n\\]\n\n\n\n\n\n\nEsempio\n\n\n\n\n\n\n# Universo\nU &lt;- 1:10  \n\n# Definizione degli insiemi A e B\nA &lt;- c(1, 2, 3, 4, 5)\nB &lt;- c(4, 5, 6, 7, 8)\n\n# Calcolare l'unione, l'intersezione e il complemento relativo a un universo U\nunion_AB &lt;- union(A, B)\nintersect_AB &lt;- intersect(A, B)\ncomplement_A &lt;- setdiff(U, A)\ncomplement_B &lt;- setdiff(U, B)\n\n# Visualizzazione testuale\ncat(\"Unione A ∪ B:\", union_AB, \"\\n\")\n#&gt; Unione A ∪ B: 1 2 3 4 5 6 7 8\ncat(\"Intersezione A ∩ B:\", intersect_AB, \"\\n\")\n#&gt; Intersezione A ∩ B: 4 5\ncat(\"Complemento di A:\", complement_A, \"\\n\")\n#&gt; Complemento di A: 6 7 8 9 10\ncat(\"Complemento di B:\", complement_B, \"\\n\")\n#&gt; Complemento di B: 1 2 3 9 10\n\n\n# Visualizzazione con diagrammi di Venn\nvenn.plot &lt;- draw.pairwise.venn(\n  area1 = length(A),\n  area2 = length(B),\n  cross.area = length(intersect(A, B)),  # Corretto: usa intersect() invece di intersect_AB\n  category = c(\"A\", \"B\"),\n  fill = c(\"orange\", \"blue\"),\n  alpha = 0.5,\n  cat.col = c(\"orange\", \"blue\")  # Corretto: allineato con i colori di fill\n)\n\n# Visualizza il diagramma\ngrid.draw(venn.plot)\n\n\n\n\n\n\n\n\n# Esempio di eventi mutualmente esclusivi\nC &lt;- c(9, 10)  # Insieme disgiunto da A e B\nintersect_AC &lt;- intersect(A, C)  # Deve essere vuoto\n\ncat(\"Intersezione A ∩ C (eventi mutualmente esclusivi):\", intersect_AC, \"\\n\")\n#&gt; Intersezione A ∩ C (eventi mutualmente esclusivi):\n\n\n# Visualizzazione di eventi mutualmente esclusivi\nvenn.plot2 &lt;- draw.pairwise.venn(\n  area1 = length(A),\n  area2 = length(C),\n  cross.area = 0,  # Nessuna intersezione\n  category = c(\"A\", \"C\"),\n  fill = c(\"blue\", \"orange\"),\n  alpha = 0.5,\n  cat.col = c(\"blue\", \"orange\")\n)\ngrid.draw(venn.plot2)\n\n\n\n\n\n\n\n\n\n\n\n3.4.1 Proprietà fondamentali delle operazioni su eventi\n\nIdempotenza: \\[\nA \\cup A = A, \\quad A \\cap A = A.\n\\]\nLeggi di De Morgan: \\[\n(A \\cup B)^c = A^c \\cap B^c, \\quad (A \\cap B)^c = A^c \\cup B^c.\n\\]\nUnione e Intersezione con l’insieme vuoto: \\[\nA \\cup \\emptyset = A, \\quad A \\cap \\emptyset = \\emptyset.\n\\]\nUnione e Intersezione con lo spazio campionario: \\[\nA \\cup \\Omega = \\Omega, \\quad A \\cap \\Omega = A.\n\\]\n\nQueste operazioni forniscono la base per costruire e manipolare eventi in contesti probabilistici, permettendo di calcolare probabilità e prendere decisioni basate sull’analisi degli esiti possibili.\n\n\n\n\n\n\nEsempio\n\n\n\n\n\nPer gli insiemi definiti nell’esempio precedente, possiamo verificare la prima legge di De Morgan in R confrontando il complemento dell’unione con l’intersezione dei complementi:\n\ncomplemento dell’unione: \\((A \\cup B)^c\\),\nintersezione dei complementi: \\(A^c \\cap B^c\\).\n\nEseguiamo i calcoli in R:\n\n# Complemento dell'unione: (A ∪ B)^c\nsetdiff(U, union(A, B))\n#&gt; [1]  9 10\n\n\n# Intersezione dei complementi: A^c ∩ B^c\nintersect(setdiff(U, A), setdiff(U, B))\n#&gt; [1]  9 10\n\nSecondo la legge di De Morgan, i due risultati devono coincidere.\n\n\n\n\n\n\n\n\n\nEsempio\n\n\n\n\n\nConsideriamo l’esperimento del lancio di due dadi. Lo spazio campionario \\(\\Omega\\) è costituito da tutte le possibili coppie di risultati che possono verificarsi. Ogni dado ha 6 facce, quindi lo spazio campionario è:\n\\[\n\\Omega = \\{(1,1), (1,2), \\dots, (6,6)\\},\n\\]\nper un totale di \\(6 \\times 6 = 36\\) esiti possibili.\nSiamo interessati all’evento \\(A\\): “la somma dei due dadi è almeno 10”. Questo evento include tutte le coppie di risultati la cui somma è 10, 11 o 12. Gli esiti che soddisfano questa condizione sono:\n\\[\nA = \\{(4,6), (5,5), (5,6), (6,4), (6,5), (6,6)\\}.\n\\]\nEcco come generare lo spazio campionario in R in modo algoritmico e definire l’evento “la somma dei due dadi è almeno 10”:\nLo spazio campionario \\(\\Omega\\) è costituito da tutte le possibili coppie di risultati del lancio di due dadi. In R, possiamo generarlo utilizzando la funzione expand.grid, che crea tutte le combinazioni possibili tra i valori dei due dadi.\n\n# Generazione dello spazio campionario Omega\ndado &lt;- 1:6 # Facce di un dado\nOmega &lt;- expand.grid(Dado1 = dado, Dado2 = dado) # Tutte le combinazioni possibili\n\nL’output sarà una tabella con 36 righe, una per ogni combinazione possibile:\n\n# Visualizzazione dello spazio campionario\nprint(Omega)\n#&gt;    Dado1 Dado2\n#&gt; 1      1     1\n#&gt; 2      2     1\n#&gt; 3      3     1\n#&gt; 4      4     1\n#&gt; 5      5     1\n#&gt; 6      6     1\n#&gt; 7      1     2\n#&gt; 8      2     2\n#&gt; 9      3     2\n#&gt; 10     4     2\n#&gt; 11     5     2\n#&gt; 12     6     2\n#&gt; 13     1     3\n#&gt; 14     2     3\n#&gt; 15     3     3\n#&gt; 16     4     3\n#&gt; 17     5     3\n#&gt; 18     6     3\n#&gt; 19     1     4\n#&gt; 20     2     4\n#&gt; 21     3     4\n#&gt; 22     4     4\n#&gt; 23     5     4\n#&gt; 24     6     4\n#&gt; 25     1     5\n#&gt; 26     2     5\n#&gt; 27     3     5\n#&gt; 28     4     5\n#&gt; 29     5     5\n#&gt; 30     6     5\n#&gt; 31     1     6\n#&gt; 32     2     6\n#&gt; 33     3     6\n#&gt; 34     4     6\n#&gt; 35     5     6\n#&gt; 36     6     6\n\nL’evento \\(A\\) è definito come “la somma dei due dadi è almeno 10”. Per identificare queste combinazioni, aggiungiamo una colonna che calcola la somma dei due dadi e filtriamo le righe in cui la somma è maggiore o uguale a 10.\n\n# Aggiunta di una colonna per la somma dei due dadi\nOmega$Somma &lt;- Omega$Dado1 + Omega$Dado2\n\n# Definizione dell'evento A: somma dei due dadi almeno 10\nA &lt;- Omega[Omega$Somma &gt;= 10, ]\n\nL’output sarà un data frame con le combinazioni in cui la somma è almeno 10:\n\n# Visualizzazione dell'evento A\nprint(A)\n#&gt;    Dado1 Dado2 Somma\n#&gt; 24     6     4    10\n#&gt; 29     5     5    10\n#&gt; 30     6     5    11\n#&gt; 34     4     6    10\n#&gt; 35     5     6    11\n#&gt; 36     6     6    12\n\nIn sintesi,\n\nlo spazio campionario \\(\\Omega\\) è stato generato algoritmicamente utilizzando expand.grid;\nl’evento \\(A\\) è stato definito filtrando le combinazioni in cui la somma dei due dadi è almeno 10.\n\n\n\n\n\n\n\n\n\n\nEsempio\n\n\n\n\n\nConsideriamo un esperimento in cui lanciamo una moneta tre volte consecutivamente. Ogni lancio può risultare in Testa (H) o Croce (T). Lo spazio campionario \\(\\Omega\\) è costituito da tutte le possibili sequenze di risultati dei tre lanci. Ci sono \\(2^3 = 8\\) possibili esiti, che possono essere rappresentati come:\n\\[\n\\Omega = \\{\\text{HHH}, \\text{HHT}, \\text{HTH}, \\text{HTT}, \\text{THH}, \\text{THT}, \\text{TTH}, \\text{TTT}\\}.\n\\]\nVogliamo definire in R l’evento \\(A\\): “Il terzo lancio della moneta dia Testa (H)”. Questo evento include tutte le sequenze in cui il terzo carattere è “H”.\nIn R, possiamo rappresentare lo spazio campionario \\(\\Omega\\) come un vettore di stringhe, dove ogni stringa corrisponde a una sequenza di risultati.\n\n# Definizione dello spazio campionario Omega\nomega &lt;- c(\"HHH\", \"HHT\", \"HTH\", \"HTT\", \"THH\", \"THT\", \"TTH\", \"TTT\")\nomega\n#&gt; [1] \"HHH\" \"HHT\" \"HTH\" \"HTT\" \"THH\" \"THT\" \"TTH\" \"TTT\"\n\nL’evento \\(A\\) è costituito da tutte le sequenze in cui il terzo lancio è Testa (H). Per identificare queste sequenze, utilizziamo la funzione substr, che estrae il terzo carattere da ciascuna stringa e verifica se è uguale a “H”.\n\n# Definizione dell'evento A: terzo lancio è Testa (H)\nA &lt;- omega[substr(omega, 3, 3) == \"H\"]\n\nSpiegazione del codice:\n\n\nsubstr(omega, 3, 3) estrae il terzo carattere da ciascuna stringa nel vettore omega.\n\nsubstr(omega, 3, 3) == \"H\" crea un vettore logico (vero/falso) che indica se il terzo carattere è “H”.\n\nomega[...] filtra il vettore omega, mantenendo solo le sequenze che soddisfano la condizione.\n\nL’output sarà:\n\n# Visualizzazione dell'evento A\nA\n#&gt; [1] \"HHH\" \"HTH\" \"THH\" \"TTH\"\n\nQueste sono le sequenze in cui il terzo lancio è Testa (H).\nIn sintesi,\n\nlo spazio campionario \\(\\Omega\\) è stato definito come un vettore di stringhe in R;\nl’evento \\(A\\) è stato costruito filtrando le sequenze in cui il terzo carattere è “H”, utilizzando la funzione substr(x, start, stop);\nl’evento \\(A\\) corrisponde alle sequenze: HHH, HTH, THH, TTH.\n\nQuesto esercizio illustra come definire e manipolare eventi in R, utilizzando operazioni di base su stringhe e vettori.\n\n\n\n\n\n\n\n\n\nEsempio\n\n\n\n\n\nConsideriamo l’esperimento del lancio consecutivo di due dadi. Lo spazio campionario \\(\\Omega\\) è costituito da tutte le possibili coppie di risultati:\n\\[\n\\Omega = \\{(1, 1), (1, 2), \\dots, (6, 6)\\}.\n\\]\nDefiniamo due eventi:\n\nEvento \\(A\\): “Il primo dado mostra un 6”.\nQuesto evento include tutte le coppie in cui il primo dado è 6:\\[\nA = \\{(6, 1), (6, 2), (6, 3), (6, 4), (6, 5), (6, 6)\\}.\n\\]\nEvento \\(B\\): “Il secondo dado mostra un 6”.\nQuesto evento include tutte le coppie in cui il secondo dado è 6:\\[\nB = \\{(1, 6), (2, 6), (3, 6), (4, 6), (5, 6), (6, 6)\\}.\n\\]\n\nL’intersezione \\(A \\cap B\\) rappresenta l’evento in cui entrambi i dadi mostrano un 6:\n\\[\nA \\cap B = \\{(6, 6)\\}.\n\\]\nImplementazione in R\nPer analizzare gli eventi legati al lancio di due dadi, utilizziamo R per simulare lo spazio campionario e manipolare gli eventi.\n1. Generazione dello spazio campionario\nLa funzione expand.grid crea tutte le combinazioni possibili tra gli elementi di due vettori. Nel nostro caso, generiamo tutte le coppie (Dado1, Dado2):\n\n# Definizione delle facce dei dadi (1-6)\ndado &lt;- 1:6\n\n# Creazione di tutte le 36 combinazioni possibili\nOmega &lt;- expand.grid(\n  Dado1 = dado,\n  Dado2 = dado\n)\n\n# Visualizzazione delle prime 6 righe\nhead(Omega)\n#&gt;   Dado1 Dado2\n#&gt; 1     1     1\n#&gt; 2     2     1\n#&gt; 3     3     1\n#&gt; 4     4     1\n#&gt; 5     5     1\n#&gt; 6     6     1\n\n2. Definizione degli eventi\nEvento A - “Primo dado = 6”:\nFiltriamo le righe dove la colonna Dado1 è uguale a 6:\n\nA &lt;- Omega[Omega$Dado1 == 6, ] # Selezione condizionale\nprint(\"Evento A:\")\n#&gt; [1] \"Evento A:\"\nA\n#&gt;    Dado1 Dado2\n#&gt; 6      6     1\n#&gt; 12     6     2\n#&gt; 18     6     3\n#&gt; 24     6     4\n#&gt; 30     6     5\n#&gt; 36     6     6\n\nEvento B - “Secondo dado = 6”:\nFiltriamo le righe dove la colonna Dado2 è uguale a 6:\n\nB &lt;- Omega[Omega$Dado2 == 6, ]\nprint(\"Evento B:\")\n#&gt; [1] \"Evento B:\"\nB\n#&gt;    Dado1 Dado2\n#&gt; 31     1     6\n#&gt; 32     2     6\n#&gt; 33     3     6\n#&gt; 34     4     6\n#&gt; 35     5     6\n#&gt; 36     6     6\n\n3. Calcolo dell’intersezione A ∩ B\nMetodo 1: Funzione intersect()\nLa funzione base intersect() confronta intere righe tra due dataframe e restituisce quelle comuni:\n\nA_intersezione_B &lt;- intersect(A, B)\nprint(\"Intersezione con intersect():\")\n#&gt; [1] \"Intersezione con intersect():\"\nA_intersezione_B\n#&gt;   Dado1 Dado2\n#&gt; 1     6     6\n\nMetodo 2: Funzione merge()\nLa funzione base merge() esegue una join naturale sulle colonne con lo stesso nome:\n\nA_intersezione_B &lt;- merge(A, B)\nprint(\"Intersezione con merge():\")\n#&gt; [1] \"Intersezione con merge():\"\nA_intersezione_B\n#&gt;   Dado1 Dado2\n#&gt; 1     6     6\n\nMetodo 3: Pacchetto dplyr\nLa funzione inner_join() mantiene solo le righe presenti in entrambi i dataframe:\n\nA_intersezione_B &lt;- inner_join(A, B, by = c(\"Dado1\", \"Dado2\"))\nprint(\"Intersezione con dplyr:\")\n#&gt; [1] \"Intersezione con dplyr:\"\nA_intersezione_B\n#&gt;   Dado1 Dado2\n#&gt; 1     6     6\n\nIn sintesi,\n\nlo spazio campionario \\(\\Omega\\) è stato generato algoritmicamente in R;\ngli eventi \\(A\\) e \\(B\\) sono stati definiti filtrando lo spazio campionario;\nl’intersezione \\(A \\cap B\\) corrisponde all’evento in cui entrambi i dadi mostrano un 6: \\(\\{(6, 6)\\}.\\)",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#sec-probabilita",
    "href": "chapters/probability/02_probability_models.html#sec-probabilita",
    "title": "3  Modelli probabilistici",
    "section": "\n3.5 Probabilità",
    "text": "3.5 Probabilità\nIl terzo elemento fondamentale del modello probabilistico è la funzione di probabilità, che quantifica numericamente la possibilità di occorrenza degli eventi.\n\nDefinizione 3.3 Una probabilità \\(P\\) è una funzione \\(P: \\mathcal{F} \\to [0,1]\\) definita su una \\(\\sigma\\)-algebra \\(\\mathcal{F}\\) di sottoinsiemi di \\(\\Omega\\). A ogni evento \\(A \\in \\mathcal{F}\\), la funzione assegna un valore reale compreso tra 0 e 1, rispettando i seguenti assiomi di Kolmogorov:\n\nNon-negatività. Per ogni \\(A \\subseteq \\Omega\\), si richiede che \\(0 \\leq P(A) \\leq 1\\).\nNormalizzazione (evento certo). \\(P(\\Omega) = 1\\).\n\nAdditività numerabile. Se \\(A_1, A_2, \\dots\\) sono eventi mutuamente esclusivi (cioè \\(A_i \\cap A_j = \\emptyset\\) per \\(i \\neq j\\)), allora:\n\\[\nP\\!\\Bigl(\\bigcup_{i=1}^{\\infty} A_i\\Bigr) \\;=\\; \\sum_{i=1}^{\\infty} P(A_i).\n\\]\n\n\nIn altre parole, una misura di probabilità non solo assegna numeri nell’intervallo \\([0,1]\\) a ogni evento, ma richiede che l’evento “certo” \\(\\Omega\\) abbia probabilità 1 e che la probabilità di un’unione numerabile di eventi disgiunti sia la somma delle loro probabilità. Queste condizioni garantiscono la coerenza formale e l’interpretazione intuitiva del concetto di probabilità.\n\n\n3.5.1 Interpretazione degli assiomi di Kolmogorov\n\nAssioma 1 (Non-negatività e limiti 0–1)\nLa probabilità di un evento è sempre un numero reale compreso tra 0 e 1. Se la probabilità è 0, l’evento può considerarsi impossibile; se è 1, l’evento è certo.Esempio: Nel lancio di un dado a sei facce, l’evento “Esce 7” non può verificarsi e ha probabilità 0, mentre l’evento “Esce un numero tra 1 e 6” ha probabilità 1.\nAssioma 2 (Evento certo)\nLo spazio campionario \\(\\Omega\\) è l’insieme di tutti i possibili esiti dell’esperimento. Poiché in ogni prova deve accadere almeno uno degli esiti contenuti in \\(\\Omega\\), la probabilità di \\(\\Omega\\) è necessariamente 1.Esempio: Nel lancio di un dado, lo spazio campionario \\(\\Omega\\) è \\(\\{1,2,3,4,5,6\\}\\). L’evento “esce un numero tra 1 e 6” coincide con l’intero spazio campionario, quindi \\(P(\\Omega) = 1\\).\n\nAssioma 3 (Additività per eventi incompatibili)\nSe due o più eventi sono mutuamente esclusivi (o incompatibili) — cioè non possono verificarsi contemporaneamente — la probabilità della loro unione è la somma delle probabilità di ciascuno.Esempio: Con un dado, l’evento “esce un numero pari” e l’evento “esce un numero dispari” non possono verificarsi nello stesso lancio. Di conseguenza,\n\\[\nP(\\text{“pari”} \\cup \\text{“dispari”}) \\;=\\; P(\\text{“pari”}) + P(\\text{“dispari”})\\,.\n\\]\n\n\nQuesti assiomi assicurano che la probabilità, intesa come funzione che assegna valori tra 0 e 1 a ogni evento, rispetti la coerenza matematica e l’interpretazione intuitiva: non esistono eventi “negativi” o “più che certi”, e la probabilità totale dell’intero spazio dei possibili risultati deve sempre essere uguale a 1.\n\n3.5.2 Proprietà fondamentali\nDagli assiomi di Kolmogorov discendono alcune proprietà fondamentali che descrivono come la probabilità si comporti in varie situazioni. Le principali sono elencate di seguito.\n\nTeorema 3.1 Siano \\(A\\) e \\(B\\) eventi qualsiasi nello spazio campionario \\(\\Omega\\). Allora valgono le seguenti relazioni:\n\nProbabilità dell’evento impossibile\\[\nP(\\emptyset) = 0.\n\\] Poiché l’insieme vuoto non include alcun esito sperimentale, non può mai verificarsi.\nMonotonicità\\[\nA \\subseteq B \\quad \\Longrightarrow \\quad P(A) \\le P(B).\n\\] Se un evento è interamente contenuto in un altro, non può avere probabilità maggiore dell’evento che lo comprende.\nProbabilità del complementare\\[\nP(A^c) = 1 - P(A).\n\\] Poiché \\(A\\) e il suo complementare \\(A^c\\) coprono l’intero spazio \\(\\Omega\\), la probabilità di \\(A^c\\) è la parte “rimanente” fino a 1.\nRegola dell’inclusione–esclusione\\[\nP(A \\cup B) \\;=\\; P(A) + P(B) \\;-\\; P(A \\cap B).\n\\] Per calcolare la probabilità dell’unione di due eventi qualsiasi, si sommano le probabilità di ciascun evento e si sottrae la probabilità della loro intersezione (altrimenti verrebbe conteggiata due volte).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#case-discreto-continuo",
    "href": "chapters/probability/02_probability_models.html#case-discreto-continuo",
    "title": "3  Modelli probabilistici",
    "section": "\n3.6 Spazi discreti e continui",
    "text": "3.6 Spazi discreti e continui\nLa natura dello spazio campionario determina come definiamo e calcoliamo le probabilità. Distinguiamo i due casi fondamentali: lo spazio campionario discreto\n\\[\n\\Omega = \\{a_1, a_2, \\dots, a_n\\} \\quad \\text{oppure} \\quad \\Omega = \\{a_1, a_2, \\dots\\}\n\\]\ne lo spazio campionario continuo\n\\[\n\\Omega = \\mathbb{R} .\n\\]\n\n3.6.1 Spazi campionari discreti\nCaratteristiche:\n\nGli esiti sono numerabili (finiti o infiniti ma separabili).\n\nEsempi:\n\nLancio di un dado: \\(\\Omega = \\{1, 2, 3, 4, 5, 6\\}\\).\n\nNumero di clienti in un negozio in un’ora: \\(\\Omega = \\{0, 1, 2, \\dots\\}\\).\n\n\n\nDefinizione di Probabilità:\n\n\nAssegniamo una probabilità puntuale \\(p_i \\geq 0\\) a ogni esito \\(\\omega_i\\), con:\n\\[\n\\sum_{\\text{tutti gli } i} p_i = 1 \\quad \\text{(normalizzazione)}.\n\\]\n\n\nLa probabilità di un evento \\(A\\) si ottiene sommando le probabilità degli esiti in \\(A\\):\n\\[\nP(A) = \\sum_{\\omega_i \\in A} p_i.\n\\]\n\n\n\n\n\n\n\n\nEsempio\n\n\n\n\n\nLancio di un dado equilibrato.\n\nLa probabilità di ciascuna faccia è uniforme: \\(p_i = \\frac{1}{6}\\), con \\(i = 1, 2, \\dots, 6\\).\nConsideriamo l’evento \\(A = \\text{“Esce un numero pari\"}\\).\n\nPertanto, calcoliamo la probabilità di \\(A\\):\n\n\\[\nP(A) = p_2 + p_4 + p_6 = \\frac{1}{6} + \\frac{1}{6} + \\frac{1}{6} = \\frac{3}{6} = \\frac{1}{2}.\n\\]\nL’evento \\(A\\) ha dunque probabilità \\(\\frac{1}{2}\\).\n\n\n\n\n3.6.2 Spazi campionari continui\nCaratteristiche:\n\nGli esiti sono non numerabili (infiniti e “densi”).\n\nEsempi:\n\ntempo di attesa all’autobus: \\(\\Omega = [0, \\infty)\\);\n\naltezza di una persona: \\(\\Omega = [50\\, \\text{cm}, 250\\, \\text{cm}]\\).\n\n\n\nDefinizione di Probabilità:\n\nUsiamo una funzione di densità di probabilità (PDF) \\(f(x) \\geq 0\\), con:\\[\n\\int_{-\\infty}^{\\infty} f(x)\\, dx = 1 \\quad \\text{(normalizzazione)}.\n\\]\n\nLa probabilità di un evento \\(A\\) si ottiene integrando la PDF su \\(A\\):\\[\nP(A) = \\int_{A} f(x)\\, dx.\n\\]\n\n\n\n\n\n\n\n\nEsempio\n\n\n\n\n\nMisurazione dell’altezza degli uomini adulti, modellata come variabile aleatoria continua \\(X\\) (in cm) con distribuzione normale \\(\\mathcal{N}(170, 7^2)\\) (si veda la Sezione Capitolo 15):\nLa funzione di densità (PDF) corrispondente è:\n\\[\nf(x)\n= \\frac{1}{7\\sqrt{2\\pi}} \\exp\\!\\Bigl(-\\frac{(x - 170)^2}{2 \\cdot 7^2}\\Bigr),\n\\quad\nX \\sim \\mathcal{N}(170,\\, 7^2).\n\\]\nEvento di interesse:\\[\nA = \\text{“Altezza compresa tra 160 cm e 180 cm”}.\n\\]\nCalcolo della probabilità:\nLa probabilità di \\(A\\) è l’area sotto la curva della densità tra 160 cm e 180 cm:\n\\[\nP(A) \\;=\\; \\int_{160}^{180} \\frac{1}{7\\sqrt{2\\pi}}\n\\exp\\!\\Bigl(-\\frac{(x - 170)^2}{98}\\Bigr)\\,\\mathrm{d}x.\n\\]\nIn alternativa, si può scrivere:\n\\[\nP(160 \\leq X \\leq 180) \\;\\approx\\; 0.847 \\quad (84.7\\%).\n\\]\nPiù avanti vedremo come calcolare facilmente questa probabilità tramite R, ad esempio con il comando:\n\npnorm(180, 170, 7) - pnorm(160, 170, 7)\n#&gt; [1] 0.847\n\nQuesto codice restituisce la differenza tra le funzioni di ripartizione (CDF) a 180 e a 160, corrispondente proprio all’area desiderata sotto la PDF.\n\n\n\n\n3.6.3 Confronto chiave\n\n\n\n\n\n\n\nCaratteristica\nSpazio Discreto\nSpazio Continuo\n\n\n\nEsiti\nNumerabili (es: 1, 2, 3)\nNon numerabili (es: intervalli)\n\n\nProbabilità di un singolo punto\n\n\\(P(\\{\\omega_i\\}) = p_i\\) (\\(\\geq\\) 0)\n\n\\(P(\\{x\\}) = 0\\) (sempre zero)\n\n\nStrumento matematico\nSomma \\(\\sum\\)\n\nIntegrale \\(\\int\\)\n\n\n\nEsempi comuni\nDadi, monete, conteggi\nMisure fisiche, tempi, temperature\n\n\n\n\n\n\n\n\n\nProprietà della PDF\n\n\n\n\nNegli spazi continui, la PDF non è una probabilità (può essere &gt; 1), ma la sua area sottesa su un intervallo fornisce la probabilità.\n\nPer eventi continui, ha senso solo calcolare probabilità su intervalli (es: \\(P(160 \\leq X \\leq 180)\\)).\n\n\n\n\n\n3.6.4 Dai concetti base alle proprietà fondamentali della probabilità\nAbbiamo visto come un esperimento casuale possa essere formalizzato matematicamente attraverso tre elementi chiave:\n\n\nSpazio campionario (\\(\\Omega\\)): l’insieme di tutti i possibili esiti dell’esperimento.\n\nEventi: sottoinsiemi di \\(\\Omega\\) che rappresentano combinazioni di esiti di interesse.\n\nProbabilità: una funzione \\(P\\) che assegna a ogni evento un valore numerico compreso tra 0 e 1, misurandone il grado di verosimiglianza.\n\nPartendo da queste definizioni, è possibile derivare proprietà essenziali per il calcolo e l’analisi probabilistica. Queste proprietà consentono di determinare la probabilità di eventi complessi a partire da eventi elementari e di stabilire relazioni logiche tra di essi.\nIn questo corso, approfondiremo quattro teoremi fondamentali:\n\nteorema della somma;\nteorema del prodotto;\nteorema della probabilità totale;\nteorema di Bayes.\n\nL’introduzione di operazioni sugli eventi (unione, intersezione, complemento) e delle proprietà della probabilità (teorema della somma, probabilità condizionata, teorema della probabilità totale, …) ci consente di costruire modelli probabilistici più complessi e applicabili a problemi reali.\nQui di seguito, approfondiamo il teorema della somma.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#teorema-della-somma",
    "href": "chapters/probability/02_probability_models.html#teorema-della-somma",
    "title": "3  Modelli probabilistici",
    "section": "\n3.7 Teorema della somma",
    "text": "3.7 Teorema della somma\nIl teorema della somma (o regola additiva) permette di determinare la probabilità che si verifichi almeno uno tra due eventi \\(A\\) e \\(B\\). La sua formulazione dipende dalla relazione tra i due eventi:\nCaso 1: Eventi Mutuamente Esclusivi. Se \\(A\\) e \\(B\\) non possono verificarsi insieme (ossia \\(A \\cap B = \\emptyset\\)), la probabilità dell’unione è la somma delle singole probabilità:\n\\[\nP(A \\cup B) = P(A) + P(B).\n\\tag{3.1}\\]\nCaso 2: Eventi Non Esclusivi. Se \\(A\\) e \\(B\\) possono coesistere, è necessario evitare di contare due volte la loro intersezione:\n\\[\nP(A \\cup B) = P(A) + P(B) - P(A \\cap B).\n\\tag{3.2}\\]\nPerché questa differenza?\nLa probabilità è una funzione d’insieme coerente con le operazioni insiemistiche. L’addizione diretta \\(P(A) + P(B)\\) conteggia due volte gli esiti comuni a \\(A\\) e \\(B\\) (rappresentati da \\(A \\cap B\\)). La sottrazione di \\(P(A \\cap B)\\) garantisce che ogni esito sia considerato una sola volta.\nIl teorema della somma sottolinea come le operazioni logiche tra eventi (unione, intersezione) si riflettano in relazioni algebriche tra le loro probabilità, fornendo uno strumento operativo per modellare scenari reali.\n\n\n\n\n\n\nEsempio\n\n\n\n\n\nIn uno studio sulla salute mentale, supponiamo di avere i seguenti dati relativi a un campione di partecipanti:\n\nla probabilità che un individuo soffra di ansia è \\(P(A) = 0.30\\);\n\nla probabilità che un individuo soffra di depressione è \\(P(B) = 0.25\\);\nla probabilità che un individuo soffra contemporaneamente di ansia e depressione è \\(P(A \\cap B) = 0.15\\).\n\nVogliamo calcolare la probabilità che un individuo soffra di almeno uno dei due disturbi (ansia o depressione), ovvero \\(P(A \\cup B)\\).\nUtilizziamo la regola della somma per eventi non mutuamente esclusivi:\n\\[\nP(A \\cup B) = P(A) + P(B) - P(A \\cap B)\n\\]\nSvolgiamo questo calcolo in R:\n\n# Definiamo le probabilità\nP_A &lt;- 0.30 # Probabilità di soffrire di ansia\nP_B &lt;- 0.25 # Probabilità di soffrire di depressione\nP_A_intersect_B &lt;- 0.15 # Probabilità di soffrire di entrambi i disturbi\n\n# Applichiamo la formula della regola della somma\nP_A_union_B &lt;- P_A + P_B - P_A_intersect_B\nP_A_union_B\n#&gt; [1] 0.4\n\nInterpretazione: il 40% dei partecipanti soffre di almeno uno tra ansia e depressione. L’intersezione \\(P(A \\cap B) = 0.15\\) è fondamentale, poiché senza sottrarla avremmo contato due volte i soggetti che soffrono contemporaneamente di entrambi i disturbi.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#probabilità-calcolo-combinatorio-e-simulazioni",
    "href": "chapters/probability/02_probability_models.html#probabilità-calcolo-combinatorio-e-simulazioni",
    "title": "3  Modelli probabilistici",
    "section": "\n3.8 Probabilità, calcolo combinatorio e simulazioni",
    "text": "3.8 Probabilità, calcolo combinatorio e simulazioni\nIn molti problemi di probabilità, soprattutto quelli di taglio scolastico o introduttivo, si assume che ogni evento elementare abbia la stessa probabilità di verificarsi (equiprobabilità). In queste situazioni, il calcolo combinatorio risulta particolarmente utile per determinare la probabilità di un evento, poiché basta:\n\n\nDefinire gli eventi di successo: identificare tutte le configurazioni compatibili con l’evento di interesse.\n\n\nContare le possibilità: calcolare il numero di eventi di successo e rapportarlo al numero totale di eventi nello spazio campionario.\n\n\n\n\n\n\n\nEsempio\n\n\n\n\n\nEstrazione di una pallina da un’urna\nSupponiamo di avere un’urna con 10 palline numerate da 1 a 10, da cui estraiamo una sola pallina in modo casuale. Assumendo che ogni pallina abbia la stessa probabilità di essere estratta, calcoliamo la probabilità di estrarre un numero pari.\n\n\nEventi di successo: \\(\\{\\;2, 4, 6, 8, 10\\}\\) (5 casi)\n\n\nEventi totali: \\(\\{\\;1, 2, 3, 4, 5, 6, 7, 8, 9, 10\\}\\) (10 casi)\n\nLa probabilità cercata è quindi:\n\\[\nP(\\text{numero pari}) \\;=\\; \\frac{\\text{numero di eventi di successo}}{\\text{numero totale di eventi}}\n\\;=\\; \\frac{5}{10} \\;=\\; 0.5.\n\\]\n\n\n\nNelle applicazioni più complesse, come il calcolo della probabilità di ottenere una determinata combinazione di carte o il formare gruppi specifici partendo da una popolazione, utilizzeremo tecniche combinatorie più avanzate — ad esempio permutazioni e combinazioni (si veda la Sezione Appendice E) — che consentono di contare in modo sistematico gli eventi possibili e quelli di successo.\n\n3.8.1 Simulazioni Monte Carlo\nUno degli aspetti più impegnativi della probabilità è che molti problemi non si prestano a soluzioni immediate o intuitive. Per affrontarli, si possono adottare due approcci principali. Il primo consiste nell’applicare i teoremi della teoria della probabilità, un metodo rigoroso ma spesso controintuitivo. Il secondo approccio è quello della simulazione Monte Carlo, che permette di ottenere una soluzione approssimata, ma molto vicina al valore reale, seguendo una procedura più accessibile e intuitiva. Questo metodo prende il nome dal famoso Casinò di Monte Carlo a Monaco, anche se può essere semplicemente definito come “metodo di simulazione.”\nLa simulazione Monte Carlo appartiene a una classe generale di metodi stocastici che si contrappongono ai metodi deterministici. Questi metodi consentono di risolvere approssimativamente problemi analitici attraverso la generazione casuale delle quantità di interesse. Tra le tecniche comunemente utilizzate troviamo il campionamento con reinserimento, in cui la stessa unità può essere selezionata più volte, e il campionamento senza reinserimento, dove ogni unità può essere selezionata una sola volta. Questi strumenti rappresentano un mezzo potente e pratico per affrontare problemi complessi.\n\n\n\n\n\n\nIl problema dei complenni\n\n\n\n\n\nUn esempio classico di applicazione del metodo Monte Carlo è il calcolo delle probabilità relative a vari eventi definiti attraverso il modello dell’urna. Tra questi, abbiamo il celebre problema dei compleanni.\nIl problema dei compleanni esplora la probabilità che, in un gruppo di \\(n\\) persone, almeno due persone condividano la stessa data di nascita. Supponendo che i compleanni siano distribuiti uniformemente su 365 giorni (ignorando anni bisestili), il problema sorprende molte persone per il fatto che già con 23 persone la probabilità di una coincidenza è superiore al 50%.\n\n3.8.1.1 Soluzione analitica\nQuesto problema può essere risolto utilizzando il concetto di probabilità complementari. Infatti, il problema può essere visto da due prospettive complementari:\n\n\nCaso 1: tutti i compleanni sono diversi (nessuna persona condivide il compleanno con un’altra);\n\nCaso 2: almeno due persone condividono lo stesso compleanno.\n\nQuesti due casi sono mutuamente esclusivi (non possono verificarsi contemporaneamente) ed esaustivi (coprono tutte le possibilità). Pertanto, la somma delle loro probabilità deve essere uguale a 1:\n\\[\nP(\\text{almeno un compleanno in comune}) = 1 - P(\\text{nessun compleanno in comune}).\n\\]\nIn altre parole, per calcolare la probabilità che almeno due persone abbiano lo stesso compleanno, possiamo prima calcolare la probabilità che tutti i compleanni siano diversi e poi sottrarre questo valore da 1.\nCaso 1: probabilità che tutti i compleanni siano diversi.\nPer calcolare \\(P(\\text{nessun compleanno in comune})\\), seguiamo questo ragionamento:\n\nPrima persona: Può scegliere liberamente un giorno del calendario. Ci sono 365 possibilità (ignoriamo gli anni bisestili per semplicità).\nSeconda persona: Deve avere un compleanno diverso dalla prima persona. Quindi, ci sono 364 giorni disponibili.\nTerza persona: Deve avere un compleanno diverso dai primi due. Ci sono 363 giorni disponibili.\n\nQuesto processo continua fino alla \\(n\\)-esima persona, che avrà \\(365 - n + 1\\) giorni disponibili.\nLa probabilità che tutti i compleanni siano diversi si ottiene moltiplicando le probabilità individuali di ogni persona di avere un compleanno diverso dai precedenti. Poiché ogni scelta è indipendente, possiamo scrivere:\n\\[\nP(\\text{nessun compleanno in comune}) = \\frac{365}{365} \\cdot \\frac{364}{365} \\cdot \\frac{363}{365} \\cdot \\ldots \\cdot \\frac{365-n+1}{365}.\n\\]\nQuesto prodotto può essere espresso in forma compatta utilizzando il fattoriale:\n\\[\nP(\\text{nessun compleanno in comune}) = \\frac{365!}{(365-n)! \\cdot 365^n} ,\n\\]\ndove:\n\n\n\\(365!\\) è il fattoriale di 365 (il prodotto di tutti i numeri interi da 1 a 365).\n\n\\((365-n)!\\) è il fattoriale di \\(365 - n\\).\n\n\\(365^n\\) rappresenta tutte le possibili combinazioni di compleanni per \\(n\\) persone.\n\nCaso 2. Probabilità di almeno un compleanno in comune.\nOra che abbiamo calcolato la probabilità che tutti i compleanni siano diversi, possiamo trovare la probabilità che almeno due persone abbiano lo stesso compleanno come il complemento:\n\\[\nP(\\text{almeno un compleanno in comune}) = 1 - P(\\text{nessun compleanno in comune}).\n\\]\nSostituendo l’espressione precedente, otteniamo:\n\\[\nP(\\text{almeno un compleanno in comune}) = 1 - \\frac{365!}{(365-n)! \\cdot 365^n}.\n\\]\nOra che abbiamo le formule per i due eventi complementari, come funzione di \\(n\\), applichiamole al caso specifico in cui \\(n\\) = 23. Questo è un valore interessante perché, come vedremo, la probabilità che almeno due persone su 23 condividano lo stesso compleanno supera il 50%.\nLa formula per la probabilità che tutti i compleanni siano diversi è:\n\\[\nP(\\text{nessun compleanno in comune}) = \\frac{365!}{(365-n)! \\cdot 365^n}.\n\\]\nPer \\(n = 23\\), sostituiamo il valore nella formula:\n\\[\nP(\\text{nessun compleanno in comune}) = \\frac{365!}{(365-23)! \\cdot 365^{23}}.\n\\]\nSemplifichiamo:\n\\[\nP(\\text{nessun compleanno in comune}) = \\frac{365!}{342! \\cdot 365^{23}}.\n\\]\nUtilizzando R, troviamo:\n\n# Numero di persone\nn &lt;- 23\n\n# Calcolo della probabilità che tutti abbiano compleanni diversi\nnumeratore &lt;- prod(365:(365 - n + 1))\ndenominatore &lt;- 365^n\n\nP_diversi &lt;- numeratore / denominatore\nP_diversi  # stampa la probabilità\n#&gt; [1] 0.493\n\n\\[\nP(\\text{nessun compleanno in comune}) \\approx 0{,}4927.\n\\]\nCiò implica che la probabilità che 23 persone abbiano compleanni distinti sia approssimativamente 0.4927 (pari al 49.27%).\nLa probabilità che almeno due persone (su 23) condividano lo stesso compleanno corrisponde al complemento della probabilità appena calcolata:\n\\[\nP(\\text{almeno un compleanno in comune}) = 1 - P(\\text{nessun compleanno in comune}).\n\\]\nSostituendo il valore ottenuto:\n\\[\nP(\\text{almeno un compleanno in comune}) = 1 - 0{.}4927 = 0{.}5073.\n\\]\nRisultato finale:\nCon \\(n = 23\\), la probabilità che almeno una coppia condivida il compleanno supera il 50%, attestandosi intorno a 0.5073 (50.73%). Questo esito è spesso sorprendente, poiché intuitivamente si tende a sottostimare l’effetto della combinatoria: sebbene 23 possano sembrare poche, le \\(\\binom{23}{2} = 253\\) possibili coppie rendono statisticamente probabile una corrispondenza.\n\n3.8.1.2 Soluzione con simulazione in R\nPer risolvere il problema tramite simulazione, possiamo generare gruppi casuali di \\(n\\) persone, assegnando loro un compleanno casuale tra 1 e 365. Per ogni gruppo, verifichiamo se almeno due persone condividono lo stesso compleanno.\nEcco il codice R:\n\n# Numero di simulazioni\nnum_simulazioni &lt;- 10000\n\n# Funzione per simulare il problema del compleanno\nsimula_compleanno &lt;- function(n) {\n  # Conta il numero di successi (almeno un compleanno in comune)\n  successi &lt;- 0\n\n  # Loop per il numero di simulazioni\n  for (i in 1:num_simulazioni) {\n    # Genera n compleanni casuali\n    compleanni &lt;- sample(1:365, n, replace = TRUE)\n\n    # Verifica se ci sono duplicati\n    if (any(duplicated(compleanni))) {\n      successi &lt;- successi + 1\n    }\n  }\n\n  # Calcola la probabilità stimata\n  return(successi / num_simulazioni)\n}\n\nProviamo con diversi valori di n.\n\nset.seed(123) # Fissiamo il seme per la riproducibilità\nrisultati &lt;- sapply(1:50, simula_compleanno)\n\n# Creiamo un data frame con i risultati\ndf &lt;- data.frame(\n  n = 1:50,\n  prob = risultati\n)\n\n# Creiamo il grafico\nggplot(df, aes(x = n, y = prob)) +\n  geom_line(color = \"blue\") +\n  geom_point(color = \"blue\") +\n  geom_hline(yintercept = 0.5, color = \"red\", linetype = \"dashed\") +\n  labs(\n    x = \"Numero di persone (n)\",\n    y = \"Probabilità stimata\",\n    title = \"Problema del Compleanno (Simulazione)\"\n  )\n\n\n\n\n\n\n\n\n\nSimulazioni: Per ogni gruppo di \\(n\\), si eseguono 10000 simulazioni, in cui si generano \\(n\\) compleanni casuali tra 1 e 365.\n\nDuplicati: La funzione duplicated() verifica se ci sono compleanni ripetuti.\n\nCalcolo della probabilità: La proporzione di simulazioni in cui si verifica almeno un compleanno condiviso rappresenta la probabilità stimata.\n\nVisualizzazione: Si tracciano le probabilità per diversi valori di \\(n\\), evidenziando il punto in cui la probabilità supera il 50%.\n\nRisultati attesi:\n\ncon circa 23 persone, la probabilità stimata sarà superiore a 0.5;\nil grafico mostra una curva crescente con un rapido aumento della probabilità per \\(n\\) piccoli e un asintoto vicino a 1 per \\(n\\) grandi.\n\nQuesto approccio permette di comprendere intuitivamente il problema e di verificare i risultati teorici con la simulazione.\n\n3.8.1.3 Assunzioni\nIl problema dei compleanni evidenzia non solo l’efficacia dell’approccio simulativo nel semplificare la soluzione rispetto all’analisi formale, ma anche l’importanza delle assunzioni che entrambi i metodi condividono. In questo caso, l’assunzione è che la probabilità di nascita sia uniformemente distribuita nei 365 giorni dell’anno — un’ipotesi semplificativa che non rispecchia la realtà.\nQuesto esempio sottolinea un principio fondamentale dei modelli probabilistici (e scientifici in generale): ogni modello si basa su un insieme di assunzioni che ne delimitano la validità e l’applicabilità. Valutare criticamente la plausibilità di tali assunzioni è dunque essenziale per garantire che il modello fornisca una rappresentazione utile del fenomeno studiato.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#riflessioni-conclusive",
    "href": "chapters/probability/02_probability_models.html#riflessioni-conclusive",
    "title": "3  Modelli probabilistici",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nLa teoria della probabilità fornisce un quadro rigoroso per descrivere e analizzare fenomeni caratterizzati dall’incertezza. In questo capitolo abbiamo introdotto i concetti fondamentali del calcolo delle probabilità, evidenziando come la modellazione matematica degli esperimenti casuali consenta di quantificare e prevedere eventi incerti. Abbiamo esplorato strumenti essenziali come la definizione di spazio campionario, la nozione di evento e le regole della probabilità, illustrando il loro utilizzo sia attraverso esempi teorici sia mediante simulazioni computazionali.\nUn aspetto cruciale della modellazione probabilistica è il ruolo delle assunzioni su cui si basano i modelli. Ogni modello probabilistico si fonda su ipotesi specifiche riguardanti la natura del fenomeno studiato e il modo in cui gli esiti vengono generati. Queste ipotesi determinano non solo la validità del modello, ma anche il tipo di risposte che esso può fornire. Ad esempio, nel problema del compleanno, abbiamo ipotizzato che i compleanni siano distribuiti in modo uniforme nei 365 giorni dell’anno. Sebbene questa assunzione semplifichi notevolmente i calcoli, sappiamo che nella realtà esistono fluttuazioni stagionali nelle nascite che possono influenzare le probabilità effettive.\nQuesto ci porta a una considerazione più ampia: la probabilità non è solo un insieme di formule, ma uno strumento per rappresentare l’incertezza e prendere decisioni informate. Tuttavia, l’accuratezza di qualsiasi modello probabilistico dipende strettamente dalla plausibilità delle ipotesi adottate. Modelli diversi, basati su ipotesi differenti, possono portare a risultati diversi, e l’interpretazione dei risultati deve sempre tenere conto di queste assunzioni.\nIn definitiva, lo studio della probabilità non si limita alla manipolazione di formule, ma richiede un’attenta riflessione sulla relazione tra modelli teorici e fenomeni reali. Una comprensione critica delle assunzioni alla base di un modello è essenziale per applicare correttamente i concetti probabilistici in contesti pratici, sia in ambito scientifico che nelle decisioni quotidiane.\n\n\n\n\n\n\nRisposte alle domande iniziali\n\n\n\n\n\nIl 92% delle persone sovrastima il numero necessario per la prima domanda e sottostima la seconda probabilità. Questo problema mostra come l’intuizione umana fallisca con eventi apparentemente “rari”.\n\nLa risposta è 23 persone.\nLa probabilità è \\(\\sim 0.7\\)",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#esercizi",
    "href": "chapters/probability/02_probability_models.html#esercizi",
    "title": "3  Modelli probabilistici",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nQui di seguito sono presentati una serie di esercizi sbasati sulla Satisfaction with Life Scale (SWLS).\nEsercizi sullo Spazio Campionario e Eventi\n\n\nDefinizione dello Spazio Campionario\nSupponiamo che i punteggi della Satisfaction with Life Scale (SWLS) siano numeri interi compresi tra 5 e 35.\n\nQual è lo spazio campionario \\(\\Omega\\) per questo esperimento?\nSe hai raccolto i dati di 15 studenti, come potresti rappresentare lo spazio campionario con i loro punteggi osservati?\n\n\n\nDefinizione di un Evento\nConsideriamo l’evento A: “Uno studente ha un punteggio SWLS superiore a 25”.\n\nEsprimi l’evento A come un sottoinsieme dello spazio campionario.\nSe tra i 15 studenti osservati, 4 hanno punteggi superiori a 25, qual è la proporzione sperimentale per l’evento A?\n\n\n\nEventi Complementari\nDefiniamo l’evento B: “Uno studente ha un punteggio SWLS inferiore o uguale a 25”.\n\nScrivi l’evento B in relazione all’evento A.\nQual è la probabilità empirica di B, sapendo che 4 studenti hanno punteggi superiori a 25?\n\n\n\nEsercizi sulle Operazioni tra Eventi\n\n\nUnione di Eventi\nDefiniamo due eventi:\n\n\nA: “Il punteggio SWLS è superiore a 25”.\n\n\nC: “Il punteggio SWLS è inferiore a 15”.\n\nScrivi l’evento A ∪ C (“Lo studente ha un punteggio maggiore di 25 o minore di 15”).\nSe nel campione di 15 studenti, 4 studenti hanno punteggi superiori a 25 e 3 hanno punteggi inferiori a 15, qual è la proporzione empirica di A ∪ C?\n\n\n\nIntersezione di Eventi e Eventi Disgiunti\nSupponiamo che l’evento D sia: “Uno studente ha un punteggio pari a 20”.\n\nL’evento D e l’evento A sono disgiunti?\nSe nessuno degli studenti ha ottenuto esattamente 20, qual è la probabilità empirica di A ∩ D?\n\n\n\nEsercizi sulle Regole della Probabilità 6. Probabilità dell’Unione di Eventi\nSupponiamo di avere:\n\n\nP(A) = 0.3 (probabilità che un punteggio sia superiore a 25).\n\n\nP(C) = 0.2 (probabilità che un punteggio sia inferiore a 15).\n\n\nP(A ∩ C) = 0 (perché un punteggio non può essere contemporaneamente superiore a 25 e inferiore a 15).\n\nUsa la regola dell’unione per calcolare P(A ∪ C).\n\n\n\nProbabilità Condizionata\nConsideriamo:\n\n\nP(A) = 0.3 (probabilità che un punteggio sia superiore a 25).\n\n\nP(E) = 0.5 (probabilità che uno studente abbia più di 20 anni).\n\n\nP(A | E) = 0.4 (probabilità che un soggetto con più di 20 anni abbia un punteggio superiore a 25).\n\nUsa la formula della probabilità condizionata per calcolare P(A ∩ E).\n\n\n\nEsercizi su Permutazioni e Combinazioni\n\n\nSelezione Casuale di Studenti\nDal campione di 15 studenti, supponiamo di voler selezionare casualmente 3 studenti per partecipare a un’intervista sulla loro soddisfazione di vita.\n\nQuanti modi ci sono per selezionare 3 studenti su 15?\n\n\n\nOrdinare gli Studenti per Discussione\nSupponiamo di voler formare un piccolo gruppo di discussione con 3 studenti, scegliendoli in ordine di intervento.\n\nQuante diverse sequenze di 3 studenti possiamo ottenere?\n\n\nFormare Coppie di Studenti\nSe vogliamo formare coppie di studenti per un esercizio collaborativo, senza considerare l’ordine, quanti modi ci sono per farlo?\n\n\n\n\n\n\n\n\n\n\nSoluzione\n\n\n\n\n\n1. Definizione dello Spazio Campionario\n\n\nLo spazio campionario \\(\\Omega\\) per questo esperimento è l’insieme di tutti i possibili punteggi della Satisfaction with Life Scale (SWLS), quindi:\n\\[ \\Omega = \\{5, 6, 7, ..., 35\\} \\]\n\nSe abbiamo raccolto i dati di 15 studenti con punteggi osservati \\(\\{27, 21, 15, 30, 18, 23, 26, 35, 20, 22, 19, 25, 32, 29, 28\\}\\), possiamo considerare \\(\\Omega\\) come questo insieme specifico.\n\n2. Definizione di un Evento\n\n\nL’evento \\(A\\) “Uno studente ha un punteggio SWLS superiore a 25” è il sottoinsieme:\n\\[ A = \\{27, 30, 26, 35, 32, 29, 28\\}\\]\n\n\nSe 7 studenti su 15 hanno punteggi superiori a 25, la probabilità empirica è:\n\\[ P(A) = \\frac{7}{15} = 0.467 \\]\n\n\n3. Eventi Complementari\n\n\nL’evento complementare \\(B\\) “Uno studente ha un punteggio SWLS inferiore o uguale a 25” è:\n\\[ B = \\{21, 15, 18, 23, 20, 22, 19, 25\\}\\]\n\n\nSe 8 studenti su 15 rientrano in \\(B\\), la probabilità empirica è:\n\\[ P(B) = 1 - P(A) = \\frac{8}{15} = 0.533 \\]\n\n\nSoluzioni agli Esercizi sulle Operazioni tra Eventi\n4. Unione di Eventi\n\n\nL’evento \\(A \\cup C\\) (“Lo studente ha un punteggio maggiore di 25 o minore di 15”) è:\n\\[ A \\cup C = \\{27, 30, 26, 35, 32, 29, 28, 15\\}\\]\n\n\nSe 8 studenti su 15 appartengono a \\(A \\cup C\\), la probabilità empirica è:\n\\[ P(A \\cup C) = \\frac{8}{15} = 0.533 \\]\n\n\n5. Intersezione di Eventi e Eventi Disgiunti\n\nL’evento \\(D\\) “Uno studente ha un punteggio pari a 20” è \\(D = \\{20\\}\\).\n\nL’evento \\(A \\cap D\\) è l’insieme degli elementi comuni a \\(A\\) e \\(D\\), ma \\(D\\) non ha elementi in \\(A\\), quindi:\n\\[ A \\cap D = \\emptyset \\]\n\nEssendo \\(A \\cap D = \\emptyset\\), gli eventi sono disgiunti e \\(P(A \\cap D) = 0\\).\n\nSoluzioni agli Esercizi sulle Regole della Probabilità\n6. Probabilità dell’Unione di Eventi\nUsiamo la formula:\n\\[ P(A \\cup C) = P(A) + P(C) - P(A \\cap C) \\]\nDato che \\(P(A \\cap C) = 0\\), abbiamo:\n\\[ P(A \\cup C) = 0.3 + 0.2 - 0 = 0.5 \\]\n7. Probabilità Condizionata\nLa probabilità congiunta \\(P(A \\cap E)\\) si calcola con:\n\\[ P(A \\cap E) = P(A | E) \\cdot P(E) \\]\nSostituendo i valori:\n\\[ P(A \\cap E) = 0.4 \\times 0.5 = 0.2 \\]\nSoluzioni agli Esercizi su Permutazioni e Combinazioni\n8. Selezione Casuale di Studenti\nIl numero di modi per scegliere 3 studenti su 15 (combinazioni) è:\n\\[ C_{15,3} = \\frac{15!}{3!(15-3)!} = \\frac{15!}{3!12!} = \\frac{15 \\times 14 \\times 13}{3 \\times 2 \\times 1} = 455 \\]\n9. Ordinare gli Studenti per Discussione\nIl numero di modi per scegliere e ordinare 3 studenti su 15 (disposizioni) è:\n\\[ D_{15,3} = \\frac{15!}{(15-3)!} = \\frac{15!}{12!} = 15 \\times 14 \\times 13 = 2730 \\]\n10. Formare Coppie di Studenti\nIl numero di modi per formare coppie (combinazioni di 2 studenti su 15) è:\n\\[ C_{15,2} = \\frac{15!}{2!(15-2)!} = \\frac{15 \\times 14}{2 \\times 1} = 105 \\]",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#bibliografia",
    "href": "chapters/probability/02_probability_models.html#bibliografia",
    "title": "3  Modelli probabilistici",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nChan, J. C. C., & Kroese, D. P. (2025). Statistical Modeling and Computation (2ª ed.). Springer.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_sigma-algebra.html",
    "href": "chapters/probability/03_sigma-algebra.html",
    "title": "4  Dal Discreto al Continuo: la \\(\\sigma\\)-algebra",
    "section": "",
    "text": "Introduzione\nNel Capitolo 3 abbiamo visto come definire la probabilità su insiemi finiti, ossia in situazioni dove ci sono un numero limitato di esiti (ad esempio, i risultati di un lancio di dado). In quel contesto, la probabilità di ogni evento veniva spesso assegnata contando i casi favorevoli su quelli totali.\nTuttavia, in molti casi reali, lo spazio degli esiti non è finito, ma infinito (ad esempio, l’insieme degli interi, o addirittura la retta reale). In queste situazioni, la somma dei casi favorevoli su quelli totali non ha più senso o diventa tecnicamente inapplicabile. Per passare dal caso discreto a quello continuo, abbiamo quindi bisogno di strumenti più sofisticati.\nUno di questi strumenti è la \\(\\sigma\\)-algebra, che ci aiuta a definire in maniera rigorosa quali sottoinsiemi di uno spazio possiamo considerare “misurabili” e a cui possiamo assegnare una probabilità. In combinazione con gli assiomi di Kolmogorov, la \\(\\sigma\\)-algebra permette di estendere la teoria della probabilità dal caso discreto (discusso nel Capitolo 3) al caso continuo, dove la situazione è più delicata e non tutti i sottoinsiemi possono ricevere una probabilità.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Dal Discreto al Continuo: la $\\sigma$-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_sigma-algebra.html#introduzione",
    "href": "chapters/probability/03_sigma-algebra.html#introduzione",
    "title": "4  Dal Discreto al Continuo: la \\(\\sigma\\)-algebra",
    "section": "",
    "text": "Panoramica del capitolo\n\nPerché non possiamo sempre “misurare tutto” nello spazio continuo.\nCome la \\(\\sigma\\)-algebra ci fornisce un metodo per assegnare le probabilità negli spazi continui.\nIn che modo la \\(\\sigma\\)-algebra sia cruciale per soddisfare gli assiomi di Kolmogorov.\nLe differenze principali rispetto al caso discreto.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere il capitolo Probability Models del testo di Chan & Kroese (2025).\nLeggere il capitolo Probability and counting di Introduction to Probability (Blitzstein & Hwang, 2019).\nLeggere il Appendice E.\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(readr, lubridate, reshape2, VennDiagram)",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Dal Discreto al Continuo: la $\\sigma$-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_sigma-algebra.html#la-struttura-della-sigma-algebra",
    "href": "chapters/probability/03_sigma-algebra.html#la-struttura-della-sigma-algebra",
    "title": "4  Dal Discreto al Continuo: la \\(\\sigma\\)-algebra",
    "section": "\n4.1 La struttura della \\(\\sigma\\)-algebra",
    "text": "4.1 La struttura della \\(\\sigma\\)-algebra\nUna \\(\\sigma\\)-algebra \\(\\mathcal{F}\\) su uno spazio campionario \\(\\Omega\\) è una collezione di sottoinsiemi (eventi) che soddisfa le seguenti proprietà.\n\nInclusione dello spazio campionario:\\[\n  \\Omega \\in \\mathcal{F}.\n  \\]\nSignifica che l’evento “qualcosa accade” è sempre misurabile.\nChiusura rispetto al complemento:\\[\n\\text{Se } A \\in \\mathcal{F} \\text{ allora } A^c = \\Omega \\setminus A \\in \\mathcal{F}.\n\\]\nSe possiamo misurare la probabilità di un evento, dobbiamo anche poter misurare la probabilità che l’evento non accada.\nChiusura rispetto a unioni (anche numerabili):\\[\n\\text{Se } A_1, A_2, \\dots \\in \\mathcal{F}, \\text{ allora } \\bigcup_{i=1}^{\\infty} A_i \\in \\mathcal{F}.\n\\]\nSe possiamo misurare una collezione (anche infinita) di eventi, dobbiamo poter misurare anche l’evento “almeno uno di essi si verifica”.\n\nTali proprietà non sono un semplice dettaglio tecnico, ma garantiscono la coerenza del sistema probabilistico: ci assicurano che certe operazioni sugli eventi (complementi, unioni) non producano risultati “senza senso” per la probabilità.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Dal Discreto al Continuo: la $\\sigma$-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_sigma-algebra.html#relazione-tra-la-sigma-algebra-e-gli-assiomi-di-kolmogorov",
    "href": "chapters/probability/03_sigma-algebra.html#relazione-tra-la-sigma-algebra-e-gli-assiomi-di-kolmogorov",
    "title": "4  Dal Discreto al Continuo: la \\(\\sigma\\)-algebra",
    "section": "\n4.2 Relazione tra la \\(\\sigma\\)-algebra e gli assiomi di Kolmogorov",
    "text": "4.2 Relazione tra la \\(\\sigma\\)-algebra e gli assiomi di Kolmogorov\nL’introduzione della \\(\\sigma\\)-algebra è necessaria per garantire la coerenza del modello probabilistico. In sintesi:\n\nLa \\(\\sigma\\)-algebra delimita l’insieme degli eventi ammessi, ossia quegli insiemi per cui possiamo calcolare la probabilità.\nGli assiomi di Kolmogorov specificano le proprietà che la funzione di probabilità \\(P\\) deve rispettare su questi eventi.\nSenza la struttura di \\(\\sigma\\)-algebra, l’assioma di additività numerabile non sarebbe formulabile in modo rigoroso, poiché non avremmo garanzia che le operazioni di unione preservino l’appartenenza all’insieme degli eventi ammessi.\n\nIn conclusione, la costruzione formale della probabilità richiede non solo una funzione che assegni valori compresi tra 0 e 1 agli eventi, ma anche una struttura matematica che garantisca la coerenza di tali assegnazioni. La \\(\\sigma\\)-algebra assicura che ogni operazione insiemistica fondamentale per il calcolo della probabilità sia ben definita, permettendo agli assiomi di Kolmogorov di essere applicati senza ambiguità.\n\nEsempio 4.1 (Costruzione di una \\(\\sigma\\)-algebra discreta) Consideriamo lo spazio campionario discreto:\n\\[\n\\Omega = \\{1,2,3\\}.\n\\]\nDefinizione della \\(\\sigma\\)-algebra discreta. La \\(\\sigma\\)-algebra discreta corrisponde all’insieme di tutte le parti di \\(\\Omega\\), ovvero l’insieme di tutti i suoi sottoinsiemi:\n\\[\n\\mathcal{F} = \\bigl\\{\\varnothing, \\{1\\}, \\{2\\}, \\{3\\}, \\{1,2\\}, \\{1,3\\}, \\{2,3\\}, \\Omega \\bigr\\}.\n\\]\nVerifica delle proprietà della \\(\\sigma\\)-algebra. Per verificare che \\(\\mathcal{F}\\) sia effettivamente una \\(\\sigma\\)-algebra, controlliamo che soddisfi le seguenti proprietà:\n\n\nInclusione dell’insieme campionario e dell’insieme vuoto:\n\nPer definizione, \\(\\Omega \\in \\mathcal{F}\\) e \\(\\varnothing \\in \\mathcal{F}\\).\n\n\n\nChiusura rispetto ai complementi:\n\n\nSe un insieme \\(A\\) appartiene a \\(\\mathcal{F}\\), anche il suo complemento \\(A^c\\) rispetto a \\(\\Omega\\) deve appartenere a \\(\\mathcal{F}\\). Ad esempio:\n\nSe \\(\\{1,2\\} \\in \\mathcal{F}\\), allora \\(\\{1,2\\}^c = \\{3\\} \\in \\mathcal{F}\\).\nAnalogamente, per ogni altro sottoinsieme di \\(\\mathcal{F}\\) il complemento appartiene sempre a \\(\\mathcal{F}\\).\n\n\n\n\n\nChiusura rispetto alle unioni numerabili:\n\n\nNel caso discreto e finito, ogni unione di elementi in \\(\\mathcal{F}\\) appartiene ancora a \\(\\mathcal{F}\\). Ad esempio:\n\n\n\\(\\{1\\} \\cup \\{2\\} = \\{1,2\\} \\in \\mathcal{F}\\).\n\n\\(\\{1,3\\} \\cup \\{2\\} = \\{1,2,3\\} = \\Omega \\in \\mathcal{F}\\).\nPoiché \\(\\mathcal{F}\\) contiene tutti i possibili sottoinsiemi di \\(\\Omega\\), l’unione di qualsiasi collezione di elementi di \\(\\mathcal{F}\\) rimane in \\(\\mathcal{F}\\).\n\n\n\n\n\nInterpretazione intuitiva. Poiché ogni sottoinsieme di \\(\\Omega\\) appartiene a \\(\\mathcal{F}\\), tutti gli eventi possibili sono misurabili. Ad esempio:\n\nL’evento “esce 1 o 2” è rappresentato da \\(\\{1,2\\}\\).\nL’evento “non esce 3” è lo stesso evento \\(\\{1,2\\}\\), che è complementare a \\(\\{3\\}\\).\n\nEsempio di funzione di probabilità. Una possibile assegnazione di probabilità è quella di un dado equo a tre facce, dove ogni esito elementare ha la stessa probabilità:\n\\[\nP(\\{1\\}) = P(\\{2\\}) = P(\\{3\\}) = \\tfrac{1}{3}.\n\\]\nLe probabilità di eventi più complessi si ottengono sommando le probabilità degli esiti contenuti nell’evento:\n\\[\nP(\\{1,2\\}) = P(\\{1\\}) + P(\\{2\\}) = \\tfrac{1}{3} + \\tfrac{1}{3} = \\tfrac{2}{3}.\n\\]\nI valori fondamentali della funzione di probabilità rispettano gli assiomi di Kolmogorov:\n\\[\nP(\\Omega) = 1, \\quad P(\\varnothing) = 0.\n\\]",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Dal Discreto al Continuo: la $\\sigma$-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_sigma-algebra.html#dal-discreto-al-continuo",
    "href": "chapters/probability/03_sigma-algebra.html#dal-discreto-al-continuo",
    "title": "4  Dal Discreto al Continuo: la \\(\\sigma\\)-algebra",
    "section": "\n4.3 Dal discreto al continuo",
    "text": "4.3 Dal discreto al continuo\nDopo aver introdotto il concetto di \\(\\sigma\\)-algebra e il suo ruolo negli assiomi di Kolmogorov, analizziamo le differenze essenziali tra il caso discreto e quello continuo.\n\n4.3.1 Caso discreto\nQuando lo spazio campionario \\(\\Omega\\) è finito o numerabile (ad esempio, \\(\\{1, 2, 3, \\dots\\}\\)), la \\(\\sigma\\)-algebra può coincidere con l’insieme di tutte le parti di \\(\\Omega\\). In questo contesto:\n\nOgni sottoinsieme di \\(\\Omega\\) è misurabile.\nGli eventi possono essere definiti in modo esplicito senza ambiguità.\nGli assiomi di Kolmogorov si applicano direttamente.\nLa probabilità di ogni singolo punto può essere positiva.\n\n4.3.2 Caso continuo\nQuando lo spazio campionario è un insieme non numerabile come \\(\\Omega = [0,1]\\) o \\(\\mathbb{R}\\), la costruzione della \\(\\sigma\\)-algebra diventa più complessa. Non è possibile includere tutti i sottoinsiemi di \\(\\Omega\\) senza generare contraddizioni logiche. Un esempio classico è il paradosso di Vitali, che mostra come alcuni insiemi non possano essere misurati in modo coerente.\n\n4.3.3 La \\(\\sigma\\)-algebra di Borel\nPer evitare tali problemi, nel caso continuo si utilizza la \\(\\sigma\\)-algebra di Borel, che include solo i sottoinsiemi “ben misurabili” di \\(\\Omega\\), escludendo quelli che potrebbero portare a incoerenze matematiche. Ad esempio:\n\nIntervalli del tipo \\([a,b]\\), \\((-\\infty, 0]\\).\nUnioni numerabili di intervalli.\nComplementi di insiemi misurabili.\n\nInvece, insiemi come quello di Vitali non sono inclusi nella \\(\\sigma\\)-algebra di Borel perché non ammettono una misura coerente.\nConfronto tra il caso discreto e il caso continuo.\n\n\n\n\n\n\n\nCaratteristica\nCaso Discreto\nCaso Continuo\n\n\n\nStruttura di \\(\\Omega\\)\nFinito o numerabile (\\(\\{1,2,3,\\dots\\}\\))\nNon numerabile (\\(\\mathbb{R}\\), \\([0,1]\\), ecc.)\n\n\n\\(\\sigma\\)-algebra naturale\nInsieme di tutte le parti di \\(\\Omega\\)\n\n\n\\(\\sigma\\)-algebra di Borel\n\n\nEsempio di evento\n\n\\(\\{\\omega\\}\\), \\(\\{\\omega_1, \\omega_2\\}\\)\n\n\n\\([a,b]\\), \\((-\\infty, 0]\\), unione di intervalli\n\n\nProbabilità di un singolo punto\nPuò essere \\(&gt;0\\) (ad es. \\(P(\\{\\omega\\})=1/6\\))\nGeneralmente \\(0\\) se il fenomeno è continuo\n\n\nProblemi di misurabilità\nNon presenti\nNecessaria selezione di insiemi misurabili\n\n\n\nIn sintesi, nel caso discreto, la costruzione della \\(\\sigma\\)-algebra è immediata: includere tutti i sottoinsiemi non crea difficoltà, portando alla cosiddetta \\(\\sigma\\)-algebra discreta (o triviale se \\(\\Omega\\) ha un solo elemento).\nNel caso continuo, invece, la costruzione è più delicata. Non tutti i sottoinsiemi possono essere inclusi nella \\(\\sigma\\)-algebra senza compromettere la coerenza matematica. Per questo motivo, si utilizza la \\(\\sigma\\)-algebra di Borel, che permette di definire correttamente la misura di probabilità evitando paradossi.\n\n\n\n\n\n\nCostruzione della \\(\\sigma\\)-algebra di Borel\n\n\n\n\n\nPer costruire la \\(\\sigma\\)-algebra di Borel in \\([0,1]\\) o in \\(\\mathbb{R}\\), si parte dagli intervalli e si aggiungono tutte le unioni e intersezioni numerabili di questi intervalli. Questa procedura genera la più piccola collezione di sottoinsiemi che soddisfa le proprietà di una \\(\\sigma\\)-algebra.\n\n\nInclusi: Intervalli aperti, chiusi, segmenti, unioni di segmenti, ecc.\n\nEsclusi: Strutture “patologiche” come l’insieme di Vitali, che non possono essere misurate in modo coerente.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Dal Discreto al Continuo: la $\\sigma$-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_sigma-algebra.html#riflessioni-conclusive",
    "href": "chapters/probability/03_sigma-algebra.html#riflessioni-conclusive",
    "title": "4  Dal Discreto al Continuo: la \\(\\sigma\\)-algebra",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn questo capitolo, abbiamo esplorato come la probabilità possa essere estesa dal caso discreto, dove possiamo tranquillamente lavorare con insiemi finiti, al caso continuo, dove ci si confronta con spazi infinitamente densi. Abbiamo compreso che, in questa transizione, la \\(\\sigma\\)-algebra gioca un ruolo cruciale, definendo quali sottoinsiemi sono “misurabili”, ovvero a quali possiamo assegnare una probabilità senza incappare in contraddizioni logiche o matematiche.\nAttraverso la formalizzazione delle \\(\\sigma\\)-algebre e l’applicazione degli assiomi di Kolmogorov, abbiamo stabilito le basi per un sistema probabilistico coerente e completo. Nel caso discreto, la costruzione della \\(\\sigma\\)-algebra è diretta, potendo includere tutti i sottoinsiemi di uno spazio campionario finito o numerabile. Tuttavia, nel caso continuo, abbiamo appreso che non tutti i sottoinsiemi possono essere misurati con coerenza. La \\(\\sigma\\)-algebra di Borel emerge come uno strumento essenziale per navigare questo terreno più complesso.\nLa distinzione tra il caso discreto e il continuo ci dimostra come la matematica possa affrontare con eleganza problemi di diversa natura. Nel discreto, ogni evento può avere una probabilità positiva e ogni sottoinsieme è misurabile. Nel continuo, invece, dobbiamo procedere con cautela, selezionando gli insiemi che possiamo “misurare” in modo coerente. In conclusione, la \\(\\sigma\\)-algebra non è soltanto un artificio tecnico, ma un elemento fondamentale che permette di costruire un ponte tra il discreto e il continuo, garantendo la coerenza della teoria della probabilità.\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nConsidera i seguenti esercizi basati sulla Satisfaction with Life Scale (SWLS).\n\n\nQuali sottoinsiemi sono eventi ammissibili?\nSupponiamo che i punteggi SWLS raccolti siano numeri interi tra 5 e 35.\n\nTra i seguenti insiemi, quali potrebbero essere inclusi in una \\(\\sigma\\)-algebra su questo spazio campionario?\n\n\nA: Tutti gli studenti con punteggio pari o superiore a 25.\n\n\nB: Studenti con punteggio pari.\n\n\nC: Studenti con punteggio multiplo di 3.\n\n\nD: Studenti con punteggio superiore all’altezza media degli unicorni.\n\n\n\nQuale criterio potremmo usare per decidere se un insieme è ammissibile in una \\(\\sigma\\)-algebra?\n\n\n\nChiusura rispetto al complemento\nSe l’evento A rappresenta gli studenti con punteggio SWLS ≥ 25, quale sarà l’evento complementare Aᶜ?\n\nEsprimilo in termini di punteggi.\n\nSe il 40% degli studenti ha punteggi ≥ 25, qual è la probabilità empirica dell’evento Aᶜ?\n\n\n\nEsercizi sulle Operazioni tra Eventi 3. Unione di Eventi\nConsideriamo i seguenti eventi:\n\n\nB: “Studente ha un punteggio SWLS pari”.\n\n\nC: “Studente ha un punteggio multiplo di 3”.\n\nElenca i punteggi che appartengono a B ∪ C (cioè lo studente ha un punteggio pari o multiplo di 3).\n\nSe nel campione di 15 studenti, 8 hanno un punteggio in B e 5 in C, e 3 di essi appartengono a entrambi gli insiemi, calcola la probabilità empirica di B ∪ C usando la formula dell’unione.\n\n\n\nIntersezione e additività numerabile\n\nSe un evento D rappresenta gli studenti con punteggio ≥20 e ≤30, possiamo dire che è incluso nella \\(\\sigma\\)-algebra se B e C lo sono? Perché?\nCalcola l’intersezione B ∩ C e verifica se i dati raccolti rispettano l’additività.\n\n\n\nEsercizi sugli Assiomi di Kolmogorov 5. Assioma della Normalizzazione\n\nSupponiamo di assegnare probabilità a eventi definiti sui punteggi SWLS dei 15 studenti.\n\nSe la somma delle probabilità di tutti gli eventi possibili non è 1, cosa significa?\n\nDai un esempio di una distribuzione di probabilità su SWLS che rispetti la normalizzazione.\n\n\n\nAssioma dell’Additività\n\nSupponiamo che P(A) = 0.4 e P(Aᶜ) = 0.6.\n\nVerifica se questa distribuzione soddisfa l’assioma di Kolmogorov.\n\nSe introduciamo un terzo evento E (punteggi tra 15 e 20), come possiamo calcolare P(A ∪ E) rispettando gli assiomi?\n\n\n\nEsercizi su Spazi Misurabili e Applicazioni\n\n\nDefinire uno Spazio Misurabile\n\n\nConsideriamo lo spazio campionario \\(\\Omega\\) dei punteggi SWLS e la \\(\\sigma\\)-algebra \\(\\mathcal{F}\\) formata dai sottoinsiemi:\n\n{Punteggi pari}\n\n{Punteggi multipli di 5}\n\n{Punteggi ≥ 25}\n\n\n\nQuesta collezione rispetta le condizioni di una \\(\\sigma\\)-algebra? Perché?\n\n\n\nEsempio di Probabilità in un Caso Continuo\n\nSe invece di punteggi discreti avessimo misurato il tempo di risposta a un questionario SWLS (espresso in secondi con valori reali), il modello discreto funzionerebbe?\n\nProva a descrivere un possibile evento misurabile in un caso continuo e spiega perché sarebbe più complesso da gestire rispetto al caso discreto.\n\n\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n1. Quali sottoinsiemi sono eventi ammissibili?\n\nGli insiemi che possono essere inclusi in una \\(\\sigma\\)-algebra devono essere chiusi rispetto a unioni, intersezioni e complementi.\n\nA (punteggi ≥ 25), B (punteggi pari), e C (punteggi multipli di 3) possono essere inclusi in una \\(\\sigma\\)-algebra, perché sono definiti su criteri chiari e permettono operazioni insiemistiche.\n\nD (punteggi superiori alla media degli unicorni) non è un evento misurabile, poiché dipende da valori soggettivi e non da una regola fissa applicabile all’intero spazio campionario.\n\n2. Chiusura rispetto al complemento\n\nL’evento complementare di A (punteggi ≥ 25) è Aᶜ (punteggi &lt; 25).\nSe la probabilità empirica di A è 0.4, la probabilità empirica di Aᶜ è: \\[ P(Aᶜ) = 1 - P(A) = 1 - 0.4 = 0.6 \\]\n\n\nSoluzioni agli Esercizi sulle Operazioni tra Eventi\n3. Unione di Eventi\n\nI punteggi in B sono {6, 8, 10, 12, …, 34} e quelli in C sono {6, 9, 12, …, 33}.\n\nB ∪ C è l’insieme {6, 8, 9, 10, 12, …, 34}.\nApplicando la formula dell’unione: \\[ P(B ∪ C) = P(B) + P(C) - P(B ∩ C) \\] \\[ P(B ∪ C) = \\frac{8}{15} + \\frac{5}{15} - \\frac{3}{15} = \\frac{10}{15} = 0.667 \\]\n\n\n4. Intersezione e additività numerabile\n\nL’evento D (20 ≤ SWLS ≤ 30) è un sottoinsieme di B ∪ C, quindi se B e C sono inclusi in una \\(\\sigma\\)-algebra, anche D lo sarà.\n\nB ∩ C (punteggi pari e multipli di 3) = {6, 12, 18, …}.\nDalla distribuzione empirica, P(B ∩ C) = \\(\\frac{3}{15} = 0.2\\).\n\nSoluzioni agli Esercizi sugli Assiomi di Kolmogorov\n5. Assioma della Normalizzazione\n\nSe la somma delle probabilità degli eventi possibili non è 1, significa che il sistema di probabilità è mal definito.\nEsempio corretto di distribuzione: \\[ P(A) = 0.4, P(B) = 0.3, P(Aᶜ) = 0.6, P(Bᶜ) = 0.7 \\] Tutti gli eventi coprono l’intero spazio campionario senza sovrapposizioni non gestite.\n\n6. Assioma dell’Additività\n\nSe P(A) = 0.4 e P(Aᶜ) = 0.6, allora: \\[ P(A) + P(Aᶜ) = 1 \\] Quindi gli assiomi di Kolmogorov sono rispettati.\nSe introduciamo un evento E (SWLS tra 15 e 20) con P(E) = 0.2, possiamo usare la formula dell’unione per calcolare P(A ∪ E) se A ed E non sono disgiunti.\n\nSoluzioni agli Esercizi su Spazi Misurabili e Applicazioni\n7. Definire uno Spazio Misurabile\n\nL’insieme \\(\\mathcal{F}\\) con {Punteggi pari, Punteggi multipli di 5, Punteggi ≥ 25} rispetta:\n\nInclusione di \\(\\Omega\\).\nChiusura rispetto al complemento.\nChiusura rispetto all’unione.\n\n\nQuindi è una \\(\\sigma\\)-algebra valida.\n\n8. Probabilità nel Caso Continuo\n\nSe misurassimo tempo di risposta al questionario SWLS in secondi (con valori reali), avremmo bisogno di una densità di probabilità anziché probabilità discrete.\nUn evento misurabile potrebbe essere: “Tempo di risposta compreso tra 10 e 15 secondi”.\nLa probabilità di un singolo valore (es. esattamente 12 secondi) sarebbe zero nel caso continuo.\n\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] grid      stats     graphics  grDevices utils     datasets  methods  \n#&gt; [8] base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] VennDiagram_1.7.3     futile.logger_1.4.3   reshape2_1.4.4       \n#&gt;  [4] lubridate_1.9.4       readr_2.1.5           pillar_1.11.0        \n#&gt;  [7] tinytable_0.13.0      patchwork_1.3.2       ggdist_3.3.3         \n#&gt; [10] tidybayes_3.0.7       bayesplot_1.14.0      ggplot2_3.5.2        \n#&gt; [13] reliabilitydiag_0.2.1 priorsense_1.1.1      posterior_1.6.1      \n#&gt; [16] loo_2.8.0             rstan_2.32.7          StanHeaders_2.32.10  \n#&gt; [19] brms_2.22.0           Rcpp_1.1.0            sessioninfo_1.2.3    \n#&gt; [22] conflicted_1.2.0      janitor_2.2.1         matrixStats_1.5.0    \n#&gt; [25] modelr_0.1.11         tibble_3.3.0          dplyr_1.1.4          \n#&gt; [28] tidyr_1.3.1           rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] formatR_1.14          gridExtra_2.3         inline_0.3.21        \n#&gt;  [4] sandwich_3.1-1        rlang_1.1.6           magrittr_2.0.3       \n#&gt;  [7] multcomp_1.4-28       snakecase_0.11.1      compiler_4.5.1       \n#&gt; [10] systemfonts_1.2.3     vctrs_0.6.5           stringr_1.5.1        \n#&gt; [13] pkgconfig_2.0.3       arrayhelpers_1.1-0    fastmap_1.2.0        \n#&gt; [16] backports_1.5.0       rmarkdown_2.29        tzdb_0.5.0           \n#&gt; [19] ragg_1.5.0            purrr_1.1.0           xfun_0.53            \n#&gt; [22] cachem_1.1.0          jsonlite_2.0.0        broom_1.0.9          \n#&gt; [25] parallel_4.5.1        R6_2.6.1              stringi_1.8.7        \n#&gt; [28] RColorBrewer_1.1-3    estimability_1.5.1    knitr_1.50           \n#&gt; [31] zoo_1.8-14            pacman_0.5.1          Matrix_1.7-4         \n#&gt; [34] splines_4.5.1         timechange_0.3.0      tidyselect_1.2.1     \n#&gt; [37] abind_1.4-8           codetools_0.2-20      curl_7.0.0           \n#&gt; [40] pkgbuild_1.4.8        lattice_0.22-7        plyr_1.8.9           \n#&gt; [43] withr_3.0.2           bridgesampling_1.1-2  coda_0.19-4.1        \n#&gt; [46] evaluate_1.0.5        lambda.r_1.2.4        survival_3.8-3       \n#&gt; [49] RcppParallel_5.1.11-1 tensorA_0.36.2.1      checkmate_2.3.3      \n#&gt; [52] stats4_4.5.1          distributional_0.5.0  generics_0.1.4       \n#&gt; [55] rprojroot_2.1.1       hms_1.1.3             rstantools_2.5.0     \n#&gt; [58] scales_1.4.0          xtable_1.8-4          glue_1.8.0           \n#&gt; [61] emmeans_1.11.2-8      tools_4.5.1           mvtnorm_1.3-3        \n#&gt; [64] QuickJSR_1.8.0        colorspace_2.1-1      nlme_3.1-168         \n#&gt; [67] cli_3.6.5             textshaping_1.0.3     futile.options_1.0.1 \n#&gt; [70] svUnit_1.0.8          Brobdingnag_1.2-9     V8_7.0.0             \n#&gt; [73] gtable_0.3.6          digest_0.6.37         TH.data_1.1-4        \n#&gt; [76] htmlwidgets_1.6.4     farver_2.1.2          memoise_2.0.1        \n#&gt; [79] htmltools_0.5.8.1     lifecycle_1.0.4       MASS_7.3-65",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Dal Discreto al Continuo: la $\\sigma$-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_sigma-algebra.html#bibliografia",
    "href": "chapters/probability/03_sigma-algebra.html#bibliografia",
    "title": "4  Dal Discreto al Continuo: la \\(\\sigma\\)-algebra",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlitzstein, J. K., & Hwang, J. (2019). Introduction to probability. CRC Press.\n\n\nChan, J. C. C., & Kroese, D. P. (2025). Statistical Modeling and Computation (2ª ed.). Springer.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Dal Discreto al Continuo: la $\\sigma$-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html",
    "href": "chapters/probability/04_conditional_prob.html",
    "title": "5  Probabilità condizionata",
    "section": "",
    "text": "Introduzione\nLa probabilità condizionata esprime la probabilità di un evento tenendo conto del verificarsi di un altro evento. Questo concetto è fondamentale perché riflette il modo in cui aggiorniamo le nostre credenze alla luce di nuove informazioni. Ad esempio, la probabilità che piova domani può essere diversa a seconda delle condizioni atmosferiche di oggi: osservare un cielo nuvoloso modifica la nostra valutazione della probabilità di pioggia. In questo senso, ogni nuova informazione può confermare, rafforzare o mettere in discussione le credenze preesistenti.\nLa probabilità condizionata ha un ruolo centrale non solo nella teoria della probabilità, ma anche nelle applicazioni quotidiane e scientifiche. In molti contesti, le probabilità sono implicitamente condizionate da informazioni preesistenti, anche quando non lo esplicitiamo formalmente. Comprendere e quantificare questo processo di aggiornamento delle credenze ci consente di gestire in modo più efficace l’incertezza, rendendo la probabilità uno strumento dinamico per la decisione e l’inferenza.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#introduzione",
    "href": "chapters/probability/04_conditional_prob.html#introduzione",
    "title": "5  Probabilità condizionata",
    "section": "",
    "text": "Panoramica del capitolo\n\nConcetti di probabilità congiunta, marginale e condizionata.\nApplicazione dei principi di indipendenza e probabilità condizionata.\nIl paradosso di Simpson;\nIl teorema del prodotto e della probabilità totale.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere il capitolo Conditional probability di Introduction to Probability (Blitzstein & Hwang, 2019).\nLeggere il capitolo Conditional Probability (Schervish & DeGroot, 2014).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#indipendenza-stocastica",
    "href": "chapters/probability/04_conditional_prob.html#indipendenza-stocastica",
    "title": "5  Probabilità condizionata",
    "section": "\n5.1 Indipendenza stocastica",
    "text": "5.1 Indipendenza stocastica\nUn caso particolare di aggiornamento delle probabilità si verifica quando due eventi non si influenzano a vicenda. In tal caso, la probabilità congiunta di più eventi si calcola in modo molto più semplice, grazie alla proprietà di indipendenza.\n\n5.1.1 Indipendenza di due eventi\n\nDefinizione 5.1 Due eventi \\(A\\) e \\(B\\) si dicono indipendenti se la probabilità che si verifichino entrambi è uguale al prodotto delle probabilità dei singoli eventi:\n\\[\nP(A \\cap B) \\;=\\; P(A)\\, P(B).\n\\tag{5.1}\\]\n\nIn altre parole, sapere che \\(A\\) si è verificato non influisce sul valore di \\(P(B)\\), e viceversa. Quando questa condizione è soddisfatta, si scrive \\(A \\perp B\\) per indicare l’indipendenza dei due eventi.\n\n\n\n\n\n\nEsempio\n\n\n\n\n\nSupponiamo di lanciare due monete distinte e di considerare i seguenti eventi:\n\n\n\\(A\\) = “La prima moneta mostra Testa”\n\n\n\\(B\\) = “La seconda moneta mostra Testa”\n\nPoiché il risultato della prima moneta non influisce in alcun modo su quello della seconda, i due eventi sono indipendenti. In particolare, la probabilità di ottenere “Testa” su una moneta è:\n\\[\nP(A) \\;=\\; P(B) \\;=\\; \\frac{1}{2}.\n\\]\nLa probabilità che entrambe le monete mostrino Testa (cioè che si verifichino contemporaneamente gli eventi \\(A\\) e \\(B\\)) è data dal prodotto delle loro probabilità:\n\\[\nP(A \\cap B) \\;=\\; P(A)\\,P(B)\n\\;=\\; \\frac{1}{2} \\times \\frac{1}{2}\n\\;=\\; \\frac{1}{4}.\n\\]\nPoiché questa relazione è soddisfatta, possiamo concludere che \\(A\\) e \\(B\\) sono eventi indipendenti.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#indipendenza-di-un-insieme-di-eventi",
    "href": "chapters/probability/04_conditional_prob.html#indipendenza-di-un-insieme-di-eventi",
    "title": "5  Probabilità condizionata",
    "section": "\n5.2 Indipendenza di un insieme di eventi",
    "text": "5.2 Indipendenza di un insieme di eventi\nIl concetto di indipendenza non si limita a due soli eventi, ma può estendersi a un insieme arbitrario di eventi. In generale, diciamo che \\(\\{A_i : i \\in I\\}\\) è un insieme di eventi indipendente se, per ogni sottoinsieme finito \\(J \\subseteq I\\), la probabilità dell’intersezione degli eventi in \\(J\\) coincide con il prodotto delle probabilità di ciascun evento:\n\\[\nP \\Bigl(\\bigcap_{i \\in J} A_i\\Bigr)\n\\;=\\;\n\\prod_{i \\in J} P(A_i).\n\\tag{5.2}\\]\nQuesta condizione richiede che ogni combinazione di eventi presenti la stessa proprietà di non influenzarsi a vicenda. L’indipendenza può essere:\n\nun’assunzione semplificante in molti modelli (ad esempio, ipotizzare che le variabili di un questionario misurino proprietà “indipendenti” dei partecipanti);\n\nuna caratteristica empirica emersa dai dati, da verificare attraverso analisi apposite.\n\n\n\n\n\n\n\nEsempio\n\n\n\n\n\nConsideriamo una sequenza di tre lanci di una moneta equilibrata e definiamo gli eventi:\n\n\n\\(A_1\\) = “Il primo lancio mostra Testa”.\n\n\\(A_2\\) = “Il secondo lancio mostra Testa”.\n\n\\(A_3\\) = “Il terzo lancio mostra Testa”.\n\nCiascuno di questi eventi ha probabilità \\(1/2\\). Poiché ogni lancio non influenza gli altri, l’insieme \\(\\{A_1, A_2, A_3\\}\\) è indipendente nel senso più ampio: non solo \\(P(A_1 \\cap A_2) = P(A_1)P(A_2)\\) e simili per coppie, ma vale anche\n\\[\nP(A_1 \\cap A_2 \\cap A_3)\n\\;=\\;\nP(A_1)\\,P(A_2)\\,P(A_3)\n\\;=\\;\n\\left(\\tfrac12\\right)\\left(\\tfrac12\\right)\\left(\\tfrac12\\right)\n\\;=\\;\n\\tfrac18.\n\\]\nIn effetti, per qualunque combinazione di Testa e Croce (ad esempio, “Testa al primo e terzo lancio, Croce al secondo”), la probabilità risulta sempre il prodotto delle probabilità dei singoli esiti, confermando l’indipendenza.\n\n\n\n\n5.2.1 Quando gli eventi non sono indipendenti\nSe per due eventi \\(A\\) e \\(B\\) si ha \\(P(A \\cap B) \\neq P(A) P(B)\\), essi non sono indipendenti. In tal caso, conoscere l’esito di uno fornisce informazioni sul probabile verificarsi dell’altro, e occorre tenere conto di questa dipendenza nei calcoli (ad esempio, usando la probabilità condizionata).\n\n5.2.2 Differenza tra indipendenza ed eventi disgiunti\nUn errore frequente è confondere “indipendenti” con “disgiunti (o mutuamente esclusivi)”. Due eventi sono disgiunti se non possono avvenire contemporaneamente, cioè\n\\[\nP(A \\cap B) \\;=\\; 0.\n\\]\nSe \\(P(A)&gt;0\\) e \\(P(B)&gt;0\\) e gli eventi sono disgiunti, non possono essere indipendenti. Infatti, l’indipendenza richiederebbe\n\\[\nP(A \\cap B) \\;=\\; P(A)\\,P(B),\n\\]\nma, poiché \\(P(A \\cap B)=0\\) e \\(P(A) P(B)\\) sarebbe positivo, la relazione non può valere. Quindi, la disgiunzione implica l’esclusione reciproca, mentre l’indipendenza significa che la probabilità di uno non risente in alcun modo dell’altro.\n\n\n\n\n\n\nEsempio\n\n\n\n\n\nNel lancio di un dado a sei facce:\n\n\n\\(C\\) = “Esce un numero pari” \\(\\{\\;2,4,6\\}\\).\n\n\\(D\\) = “Esce un numero dispari” \\(\\{\\;1,3,5\\}\\).\n\nI due eventi sono disgiunti, poiché un numero non può essere contemporaneamente pari e dispari; dunque \\(P(C \\cap D)=0\\).\nTuttavia, non sono indipendenti: se lo fossero, si dovrebbe avere \\(P(C \\cap D) = P(C)P(D)\\). Invece,\n\\[\n0 \\;\\neq\\; \\tfrac12 \\,\\times\\, \\tfrac12 \\;=\\; \\tfrac14,\n\\]\nda cui segue che \\(C\\) e \\(D\\) non sono eventi indipendenti.\n\n\n\nIn sintesi, gli eventi disgiunti non possono verificarsi insieme, mentre gli eventi indipendenti non influiscono uno sulla probabilità dell’altro. Entrambe le proprietà sono importanti ma rispondono a concetti nettamente diversi.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#probabilità-condizionata",
    "href": "chapters/probability/04_conditional_prob.html#probabilità-condizionata",
    "title": "5  Probabilità condizionata",
    "section": "\n5.3 Probabilità condizionata",
    "text": "5.3 Probabilità condizionata\nLa probabilità condizionata esprime la probabilità di un evento \\(A\\) una volta che si sappia che un altro evento \\(B\\) è già avvenuto.\n\nDefinizione 5.2 Se \\(P(B) &gt; 0\\), si definisce:\n\\[\nP(A \\mid B)\n\\;=\\;\n\\frac{P(A \\cap B)}{P(B)}.\n\\tag{5.3}\\]\n\nQuesta formula può essere letta come un “ricalcolo” della probabilità di \\(A\\) limitandosi al sottoinsieme di esiti in cui \\(B\\) è vero.\n\n5.3.1 Interpretazione della probabilità condizionata\nLa probabilità condizionata funge da meccanismo di aggiornamento delle nostre conoscenze. Inizialmente, si dispone di una stima di \\(P(A)\\); dopo aver appreso che un evento correlato \\(B\\) si è verificato, si “restringe” il campo agli esiti compatibili con \\(B\\) e si riassegna la probabilità di \\(A\\) su questa base.\n\n\nEsempio intuitivo: Se si sa che una persona ha la febbre (\\(B\\)), la probabilità che abbia l’influenza (\\(A\\)) aumenta rispetto a quella calcolata sull’intera popolazione.\n\nQuesta capacità di “aggiornare le credenze” fa della probabilità condizionata uno strumento fondamentale in:\n\n\ninferenze statistiche, per gestire informazioni parziali o acquisite progressivamente;\n\n\nteoria dell’apprendimento, quando si valutano ipotesi o modelli a fronte di nuovi dati;\n\n\nmodellizzazione delle dipendenze tra eventi, in cui la conoscenza di un evento influenza la probabilità di un altro.\n\n\n\n\n\n\n\nEsempio\n\n\n\n\n\nLanciamo due dadi equilibrati consecutivamente. Dato che la somma dei dadi è 10, qual è la probabilità che uno dei due dadi mostri un 6?\nDefiniamo:\n\n\nB come l’evento che la somma sia 10:\\[ B = \\{(4, 6), (5, 5), (6, 4)\\}. \\]\n\n\nA come l’evento che uno dei due dadi mostri un 6:\\[ A = \\{(1, 6), \\dots, (5, 6), (6, 1), \\dots, (6, 5)\\}. \\]\n\n\nL’intersezione tra A e B è:\\[ A \\cap B = \\{(4, 6), (6, 4)\\}. \\]\nPoiché in questo esperimento tutti gli eventi elementari sono equiprobabili, la probabilità condizionata \\(P(A | B)\\) è data da:\\[\nP(A | B) = \\frac{P(A \\cap B)}{P(B)} = \\frac{\\frac{2}{36}}{\\frac{3}{36}} = \\frac{2}{3}.\n\\]\nQuindi, la probabilità che uno dei due dadi mostri un 6, sapendo che la somma è 10, è \\(\\frac{2}{3}\\).\n\n\n\n\n\n\n\n\n\nEsempio\n\n\n\n\n\nSomma di due dadi\nConsideriamo il lancio di due dadi equilibrati e calcoliamo la probabilità che la somma dei punteggi risulti minore di 8.\n\n\nSenza informazioni aggiuntive\n\nOgni dado può assumere valori da 1 a 6, per un totale di 36 possibili combinazioni \\((6 \\times 6)\\).\n\nTra queste 36, esistono 21 combinazioni in cui la somma è minore di 8.\n\nDunque la probabilità iniziale è: \\[\nP(\\text{Somma} &lt; 8)\n\\;=\\;\n\\frac{21}{36}\n\\;\\approx\\; 0{.}58.\n\\]\n\n\n\n\nCon informazione aggiuntiva\nSupponiamo di sapere che la somma uscita è dispari. Questa nuova informazione restringe lo spazio degli esiti possibili:\n\nSolo 18 combinazioni su 36 producono un risultato dispari.\n\nTra queste 18, 12 combinazioni hanno somma minore di 8.\n\nPertanto, la probabilità condizionata diventa: \\[\nP(\\text{Somma} &lt; 8 \\,\\mid\\, \\text{Somma dispari})\n\\;=\\;\n\\frac{12}{18}\n\\;=\\;\n0{.}67.\n\\]\n\n\n\n\nConfrontando i due risultati (\\(0{,}58\\) senza informazioni contro \\(0{,}67\\) con l’informazione “somma dispari”), osserviamo come la probabilità di un evento possa cambiare una volta ottenuta un’informazione aggiuntiva.\nCodice in R.\nNel codice R che segue, utilizziamo l’insieme di tutte le combinazioni di lanci per verificare numericamente i risultati:\n\n# 1. Definiamo i possibili valori di un dado\nr &lt;- 1:6  \n\n# 2. Costruiamo tutte le combinazioni possibili (i, j)\n#    in cui i e j vanno da 1 a 6.\n#    In totale ci aspettiamo 36 combinazioni (6 x 6).\nsample &lt;- expand.grid(i = r, j = r)  \nnrow(sample)  # Contiamo quante sono: dovrebbero essere 36\n#&gt; [1] 36\n\n# 3. Selezioniamo solo le coppie (i, j) in cui la somma è minore di 8.\n#    Verifichiamo quante sono e le confrontiamo con il totale.\nevent &lt;- subset(sample, i + j &lt; 8)\ncat(nrow(event), \"/\", nrow(sample), \"\\n\")  # Dovrebbe stampare 21 / 36\n#&gt; 21 / 36\n\n# 4. Selezioniamo ora solo le coppie con somma dispari.\n#    %% è l’operatore \"modulo\": (i + j) %% 2 != 0 verifica se la somma è dispari.\nsample_odd &lt;- subset(sample, (i + j) %% 2 != 0)\nnrow(sample_odd)  # Dovrebbe essere 18\n#&gt; [1] 18\n\n# 5. Calcoliamo quante coppie hanno somma minore di 8 tra quelle con somma dispari.\nevent_odd &lt;- subset(sample_odd, i + j &lt; 8)\ncat(nrow(event_odd), \"/\", nrow(sample_odd), \"\\n\")  # Dovrebbe stampare 12 / 18\n#&gt; 12 / 18\n\nSecondo la Equazione 5.3, se definiamo\n\n\n\\(A\\) = “Somma &lt; 8”\n\n\n\\(B\\) = “Somma dispari”,\n\nallora \\(P(A \\cap B) = 12/36\\) e \\(P(B) = 18/36\\). Di conseguenza,\n\\[\nP(A \\mid B)\n\\;=\\;\n\\frac{P(A \\cap B)}{P(B)}\n\\;=\\;\n\\frac{12/36}{18/36}\n\\;=\\;\n\\frac{12}{18}\n\\;=\\;\n0{.}67.\n\\]\nQuesto esempio dimostra come la probabilità condizionata consenta di aggiornare la stima di un evento alla luce di nuove informazioni.\n\n\n\n\n\n\n\n\n\nScreening per la diagnosi precoce del tumore mammario\n\n\n\n\n\nSupponiamo di utilizzare un test diagnostico con le seguenti caratteristiche:\n\n\nSensibilità (probabilità di test positivo fra le donne malate): 90%.\n\n\nSpecificità (probabilità di test negativo fra le donne sane): 90%.\n\n\nPrevalenza (percentuale di donne effettivamente malate nella popolazione): 1%.\n\n1. Esempio con 1000 donne.\nPer semplificare i calcoli, immaginiamo di sottoporre a screening 1000 donne a caso:\n\n\nDonne malate (1%): 10 su 1000.\n\nCon una sensibilità del 90%, circa 9 di queste 10 donne avranno un esito positivo al test (vere positive).\n\nCirca 1 donna avrà invece un risultato negativo (falso negativo).\n\n\n\nDonne sane (99%): 990 su 1000.\n\nCon una specificità del 90%, circa 891 di queste 990 risulteranno negative al test (vere negative).\n\nLe restanti 99 donne avranno un esito positivo (false positive).\n\n\n\nQuesto ci permette di costruire uno schema riassuntivo (spesso rappresentato sotto forma di tabella o diagramma a blocchi):\n\n\npositive: \\(9\\) (vere positive) + \\(99\\) (false positive) = 108,\n\n\nnegative: \\(1\\) (falso negativo) + \\(891\\) (vero negativo) = 892.\n\n2. Probabilità non condizionata di un test positivo.\nLa probabilità che una donna, scelta a caso, risulti positiva allo screening (indipendentemente dal fatto che sia malata o sana) si ottiene rapportando il numero di test positivi al totale:\n\\[\nP(\\text{Test positivo})\n\\;=\\;\n\\frac{108}{1000}\n\\;=\\;\n0{.}108\n\\;\\; (10{.}8\\%).\n\\]\nQuesta è una probabilità non condizionata, in quanto considera l’intera popolazione delle 1000 donne, senza ulteriori informazioni.\n3. Probabilità condizionata di essere malate dato un test positivo.\nCi interessa ora sapere: Se una donna ha appena ricevuto un risultato positivo, qual è la probabilità che abbia davvero il cancro al seno?\nMatematicamente, riformuliamo la domanda come:\\[\nP(\\text{Cancro} \\mid \\text{Test positivo}).\n\\]\nOsservando il nostro esempio di 1000 donne:\n\nAbbiamo 108 test positivi in tutto.\n\nSolo 9 di questi test positivi provengono effettivamente da donne malate.\n\nPertanto,\n\\[\nP(\\text{Cancro} \\mid \\text{Test positivo})\n\\;=\\;\n\\frac{9}{108}\n\\;=\\;\n0{.}083\n\\;\\; (8{.}3\\%).\n\\]\nQuesta è una probabilità condizionata, poiché riguarda soltanto quelle donne già selezionate in base all’esito positivo del test.\n4. Confronto fra probabilità non condizionata e condizionata.\n\n\nProbabilità non condizionata (esito positivo): \\(0{.}108\\) (10.8%).\n\n\nProbabilità condizionata (avere un tumore, sapendo che il test è positivo): \\(0{.}083\\) (8.3%).\n\nNotiamo come l’informazione aggiuntiva (“il test è risultato positivo”) riduca il numero di casi osservati, focalizzando l’attenzione su un sottoinsieme della popolazione. In altre parole, la conoscenza di un test positivo aggiorna la nostra stima della probabilità di avere la malattia, mostrandoci che, nonostante l’alta sensibilità e specificità, la maggior parte dei test positivi riguarda donne sane (false positive), a causa della bassa prevalenza (1%).\nQuesto esempio illustra in modo tangibile la distinzione fra:\n\n\nprobabilità non condizionata: la probabilità di un evento considerando l’intera popolazione,\n\n\nprobabilità condizionata: la probabilità di un evento una volta appresa un’informazione aggiuntiva (qui, l’esito positivo del test).\n\nQuesta differenza è fondamentale nell’interpretazione dei test diagnostici, specialmente quando la malattia è relativamente rara.\n\n\n\n\n\n\n\n\n\nIl Problema di Monty Hall\n\n\n\n\n\nIl problema di Monty Hall è un famoso quesito di teoria della probabilità che illustra in modo efficace il concetto di probabilità condizionata. Questo problema è diventato celebre grazie a una rubrica tenuta da Marilyn vos Savant nella rivista Parade, in cui rispose a una lettera pubblicata il 9 settembre 1990:\n\n“Supponiamo di partecipare a un quiz televisivo e di dover scegliere tra tre porte. Dietro una di esse c’è un’auto, mentre dietro le altre due ci sono delle capre. Scegli una porta, ad esempio la numero 1, e il conduttore, che sa cosa c’è dietro ogni porta, ne apre un’altra, diciamo la numero 3, rivelando una capra. A questo punto, ti chiede se vuoi cambiare la tua scelta e passare alla porta numero 2. È vantaggioso cambiare porta?” Craig. F. Whitaker, Columbia, MD\n\nLa situazione descritta ricorda quella del popolare quiz televisivo degli anni ’70 Let’s Make a Deal, condotto da Monty Hall e Carol Merrill. Marilyn vos Savant rispose che il concorrente dovrebbe cambiare porta, poiché la probabilità di vincere l’auto raddoppia passando da 1/3 a 2/3. Tuttavia, la sua risposta suscitò un acceso dibattito, con molte persone, inclusi alcuni matematici, che sostenevano che cambiare porta non avrebbe offerto alcun vantaggio. Questo episodio ha reso il problema di Monty Hall uno dei più famosi esempi di come l’intuizione possa portare a conclusioni errate in ambito probabilistico.\nChiarire il Problema.\nLa lettera originale di Craig Whitaker è piuttosto vaga, quindi per analizzare il problema in modo rigoroso è necessario fare alcune ipotesi:\n\n\nPosizione dell’auto: L’auto è nascosta in modo casuale ed equiprobabile dietro una delle tre porte.\n\nScelta iniziale del giocatore: Il giocatore sceglie una porta in modo casuale, indipendentemente dalla posizione dell’auto.\n\nAzione del conduttore: Dopo la scelta del giocatore, il conduttore apre una delle due porte rimanenti, rivelando una capra, e offre al giocatore la possibilità di cambiare porta.\n\nScelta del conduttore: Se il conduttore ha la possibilità di scegliere tra due porte (entrambe con capre), ne apre una in modo casuale.\n\nCon queste assunzioni, possiamo rispondere alla domanda: Qual è la probabilità che il giocatore vinca l’auto se decide di cambiare porta?\nDi seguito, esploreremo tre metodi per risolvere il problema di Monty Hall: il diagramma ad albero, l’analisi delle probabilità e una simulazione.\nMetodo 1: diagramma ad albero.\nIl diagramma ad albero è uno strumento utile per visualizzare tutti i possibili esiti di un esperimento probabilistico. Nel caso del problema di Monty Hall, possiamo suddividere il processo in tre fasi:\n\n\nPosizione dell’auto: L’auto può trovarsi dietro una delle tre porte (A, B o C), ciascuna con probabilità 1/3.\n\nScelta del giocatore: Il giocatore sceglie una porta in modo casuale, indipendentemente dalla posizione dell’auto.\n\nAzione del conduttore: Il conduttore apre una delle due porte rimanenti, rivelando una capra.\n\nIl diagramma ad albero mostra tutte le possibili combinazioni di questi eventi. Ad esempio, se l’auto è dietro la porta A e il giocatore sceglie la porta B, il conduttore aprirà la porta C (l’unica porta rimanente con una capra).\nPasso 1: Identificare lo spazio campionario\nLo spazio campionario è composto da 12 esiti possibili, rappresentati dalle combinazioni di:\n\nPosizione dell’auto (A, B, C).\nScelta iniziale del giocatore (A, B, C).\nPorta aperta dal conduttore (una delle due rimanenti con una capra).\n\nEcco un diagramma ad albero che rappresenta questa situazione:\n\n\n\n\n\nFigura 5.1: Il diagramma ad albero per il Problema di Monty Hall mostra le probabilità associate a ogni possibile esito. I pesi sugli archi rappresentano la probabilità di seguire quel particolare percorso, dato che ci troviamo nel nodo padre. Ad esempio, se l’auto si trova dietro la porta A, la probabilità che il giocatore scelga inizialmente la porta B è pari a 1/3. La colonna più a destra del diagramma mostra la probabilità di ciascun esito finale. Ogni probabilità di esito è calcolata moltiplicando le probabilità lungo il percorso che parte dalla radice (auto dietro una certa porta) e termina alla foglia (esito finale) (Figura tratta da Lehman, Leighton e Meyer, 2018).\n\n\nPasso 2: Definire l’evento di interesse\nL’evento di interesse è “il giocatore vince cambiando porta”. Questo si verifica quando la porta inizialmente scelta dal giocatore non nasconde l’auto, e il giocatore decide di cambiare porta.\nGli esiti che soddisfano questa condizione sono:\n\n(Auto A, Scelta B, Apertura C)\n(Auto A, Scelta C, Apertura B)\n(Auto B, Scelta A, Apertura C)\n(Auto B, Scelta C, Apertura A)\n(Auto C, Scelta A, Apertura B)\n(Auto C, Scelta B, Apertura A)\n\nQuesti esiti sono in totale 6.\nPasso 3: Calcolare le probabilità degli esiti\nOgni esito ha una probabilità specifica, calcolata moltiplicando le probabilità lungo il percorso nel diagramma ad albero.\nEsempio di calcolo per l’esito (Auto A, Scelta B, Apertura C):\n\nLa probabilità che l’auto sia dietro la porta A è \\(\\frac{1}{3}\\).\nLa probabilità che il giocatore scelga la porta B è \\(\\frac{1}{3}\\).\nLa probabilità che il conduttore apra la porta C (che contiene una capra) è \\(1\\) (poiché il conduttore deve aprire una porta con una capra, e la porta C è l’unica possibile).\n\nLa probabilità totale per questo esito è:\n\\[\nP(\\text{Auto A, Scelta B, Apertura C}) = \\frac{1}{3} \\times \\frac{1}{3} \\times 1 = \\frac{1}{9}.\n\\]\nProcedendo in modo simile per tutti gli altri esiti, otteniamo le probabilità per tutti i 12 esiti.\nPasso 4: Calcolare la probabilità dell’evento\nLa probabilità di vincere cambiando porta è la somma delle probabilità degli esiti favorevoli.\n\\[\n\\begin{aligned}\nP&(\\text{vincere cambiando porta}) = \\notag \\\\\n&\\quad P(\\text{Auto A, Scelta B, Apertura C}) + P(\\text{Auto A, Scelta C, Apertura B}) + \\notag\\\\  \n&\\quad P(\\text{Auto B, Scelta A, Apertura C}) + \\dots \\notag\n\\end{aligned}\n\\]\n\\[\n= \\frac{1}{9} + \\frac{1}{9} + \\frac{1}{9} + \\frac{1}{9} + \\frac{1}{9} + \\frac{1}{9} = \\frac{6}{9} = \\frac{2}{3}.\n\\]\nLa probabilità di vincere mantenendo la scelta originale è il complemento:\n\\[\nP(\\text{vincere mantenendo la scelta}) = 1 - P(\\text{vincere cambiando porta}) = 1 - \\frac{2}{3} = \\frac{1}{3}.\n\\]\nLa conclusione è che il giocatore ha una probabilità di vincere pari a \\(\\frac{2}{3}\\) se cambia porta, contro una probabilità di \\(\\frac{1}{3}\\) se mantiene la sua scelta iniziale. Cambiare porta è quindi la strategia vincente.\nMetodo 2: analisi delle probabilità.\nIl problema di Monty Hall può essere chiarito analizzando i tre scenari possibili, immaginando di essere osservatori esterni che sanno cosa si nasconde dietro ogni porta:\n\n\nPrimo scenario:\n\nIl giocatore sceglie inizialmente la porta con una capra (chiamiamola “capra 1”).\n\nIl conduttore apre l’altra porta con la “capra 2”.\n\nSe il giocatore cambia porta, vince l’automobile.\n\n\n\nSecondo scenario:\n\nIl giocatore sceglie inizialmente la porta con l’altra capra (“capra 2”).\n\nIl conduttore apre la porta con la “capra 1”.\n\nSe il giocatore cambia porta, vince l’automobile.\n\n\n\nTerzo scenario:\n\nIl giocatore sceglie inizialmente la porta con l’automobile.\n\nIl conduttore apre una delle due porte con una capra (non importa quale).\n\nSe il giocatore cambia porta, perde l’automobile.\n\n\n\nAll’inizio del gioco, il giocatore ha:\n\n\n1/3 di probabilità di scegliere l’automobile.\n\n\n2/3 di probabilità di scegliere una capra.\n\nDopo la scelta iniziale, il conduttore apre una porta con una capra, ma questa azione non altera le probabilità iniziali. Il giocatore si trova quindi con due porte chiuse: quella scelta inizialmente e una rimanente.\n\nSe il giocatore ha scelto l’automobile inizialmente (1/3 di probabilità), cambiando porta perde.\n\nSe il giocatore ha scelto una capra inizialmente (2/3 di probabilità), cambiando porta vince l’automobile.\n\nIn sintesi, cambiando porta, il giocatore ha 2/3 di probabilità di vincere l’automobile, mentre mantenendo la scelta iniziale ha solo 1/3 di probabilità. Pertanto, la strategia migliore è cambiare porta per massimizzare le possibilità di vittoria.\nMetodo 3: simulazione.\nPer confermare il risultato, possiamo eseguire una simulazione. Ripetendo il gioco migliaia di volte, possiamo confrontare la frequenza con cui il giocatore vince cambiando porta rispetto a quando mantiene la scelta iniziale.\nEcco un esempio di codice in R per la simulazione:\n\n# Numero di simulazioni da effettuare.\n# Più è grande B, più precisa sarà la stima.\nB &lt;- 10000  \n\n# Definiamo una funzione \"monty_hall\" che\n# a) simula un gioco\n# b) restituisce TRUE/FALSE a seconda che il giocatore vinca l'auto o no.\nmonty_hall &lt;- function(strategy){\n  \n  # 1. Dichiariamo le porte possibili, in forma di stringhe.\n  doors &lt;- c(\"1\", \"2\", \"3\")\n  \n  # 2. Stabiliamo dove si trova il premio (auto) e le capre.\n  #    \"prize\" sarà un vettore con dentro \"car\" per la porta con l’auto \n  #    e \"goat\" per quelle con la capra.\n  #    La funzione sample() crea una distribuzione casuale di \"car\" e \"goat\".\n  prize &lt;- sample(c(\"car\", \"goat\", \"goat\"))\n  \n  # 3. Troviamo qual è la porta che ha la macchina.\n  prize_door &lt;- doors[ prize == \"car\" ]\n  \n  # 4. Il giocatore fa la sua prima scelta, pescando a caso fra le 3 porte.\n  my_pick &lt;- sample(doors, 1)\n  \n  # 5. Il conduttore deve aprire una porta che:\n  #    - non sia la mia (my_pick)\n  #    - non abbia la macchina (prize_door)\n  #    Così facendo, rivela una porta con la capra.\n  #    Se ci sono due porte con capra, ne sceglie una a caso.\n  show &lt;- sample(doors[!doors %in% c(my_pick, prize_door)], 1)\n  \n  # 6. La strategia \"stick\" significa: RESTARE sulla scelta iniziale (my_pick).\n  #    La strategia \"switch\" significa: CAMBIARE porta, passando a quella\n  #    rimasta tra le due che NON sono state aperte.\n  stick &lt;- my_pick\n  switch &lt;- doors[!doors %in% c(my_pick, show)]\n  \n  # 7. Se la strategia scelta (in input) è \"stick\", la mia scelta finale è \"stick\".\n  #    Altrimenti, è \"switch\".\n  final_choice &lt;- ifelse(strategy == \"stick\", stick, switch)\n  \n  # 8. La funzione restituisce TRUE se la scelta finale coincide con la porta premiata,\n  #    altrimenti FALSE.\n  return(final_choice == prize_door)\n}\n\nNel codice qui sopra:\n\n\nmy_pick è la porta che il giocatore sceglie subito.\n\nshow è la porta che il conduttore mostra, rivelando la capra.\n\nstick rimane la scelta iniziale (quindi è my_pick).\n\nswitch è la porta che rimane fra le non aperte e non scelte inizialmente.\n\nAl termine, la funzione monty_hall() stabilisce se, con la strategia considerata, si vince (TRUE) o si perde (FALSE).\n\n# Simuliamo B volte la strategia \"stick\" (non cambiare mai la scelta iniziale).\nstick_results &lt;- replicate(B, monty_hall(\"stick\"))\n\n# stick_results è un vettore di TRUE/FALSE lungo B.\n# Per scoprire la percentuale di vittorie, calcoliamo la media dei TRUE.\nmean(stick_results)\n#&gt; [1] 0.328\n\n\n# Simuliamo B volte la strategia \"switch\" (cambiare sempre la scelta iniziale).\nswitch_results &lt;- replicate(B, monty_hall(\"switch\"))\n\n# Anche qui, calcoliamo la media per sapere quante volte abbiamo vinto l’auto.\nmean(switch_results)\n#&gt; [1] 0.668\n\n\nLa media di un vettore di TRUE/FALSE in R è pari alla frazione di TRUE.\nIn questo modo, mean(stick_results) ci dice la probabilità di vincere restando sulla scelta iniziale.\n\nmean(switch_results) ci dice la probabilità di vincere se si cambia sempre porta dopo l’intervento del conduttore.\n\nRisultati attesi:\n\n\nMantenere la Scelta Iniziale: La frequenza di vittoria dovrebbe essere circa 1/3 (33.3%).\n\nCambiare Porta: La frequenza di vittoria dovrebbe essere circa 2/3 (66.6%).\n\nLa simulazione conferma che cambiare porta aumenta la probabilità di vincere da 1/3 a 2/3, dimostrando che la strategia ottimale nel problema di Monty Hall è quella di cambiare porta dopo che il conduttore ha rivelato una capra.\nIn sintesi, il problema di Monty Hall mette in luce come l’intuizione possa trarci in inganno quando ci confrontiamo con scenari probabilistici. Attraverso l’uso del diagramma ad albero, un’analisi delle probabilità e l’esecuzione di simulazioni, abbiamo dimostrato che cambiare porta raddoppia le possibilità di vincita, facendole passare da 1/3 a 2/3. Questo risultato, in apparente contrasto con ciò che potrebbe sembrare intuitivo, costituisce un esempio emblematico dell’importanza di adottare un approccio formale nella valutazione delle probabilità, anziché affidarsi esclusivamente a impressioni iniziali che spesso si rivelano fuorvianti.\n\n\n\n\n\n\n\n\n\nIl paradosso di Simpson\n\n\n\n\n\nNel contesto della probabilità condizionata, un fenomeno particolarmente interessante e, al tempo stesso, controintuitivo è il paradosso di Simpson. Questo paradosso si verifica quando una tendenza osservata in diversi gruppi di dati separati scompare o addirittura si inverte una volta che i gruppi vengono combinati.\nIl paradosso di Simpson evidenzia l’importanza di considerare le variabili confondenti e di analizzare i dati con grande attenzione per evitare di trarre conclusioni errate o fuorvianti. È un esempio emblematico di come l’interpretazione dei dati statistici richieda non solo strumenti matematici, ma anche una profonda comprensione del contesto e delle relazioni tra le variabili coinvolte.\nUn caso storico di paradosso di Simpson riguarda l’applicazione della pena di morte negli Stati Uniti (Radelet & Pierce, 1991). Questo studio analizza 674 processi per omicidio in Florida tra il 1976 e il 1987, esaminando l’influenza della razza dell’imputato e della vittima sulla probabilità di ricevere la pena di morte. I dati riportano il numero di condannati alla pena di morte in base alla razza dell’imputato e della vittima:\n\n\n\n\n\n\n\n\n\nRazza dell’imputato\nRazza della vittima\nPena di morte\nNo pena di morte\nTasso di condanna\n\n\n\nBianco\nBianco\n19\n132\n19 / 151 ≈ 12.6%\n\n\nBianco\nNero\n11\n52\n11 / 63 ≈ 17.5%\n\n\nNero\nBianco\n6\n37\n6 / 43 ≈ 14.0%\n\n\nNero\nNero\n1\n9\n1 / 10 = 10.0%\n\n\n\nSe analizziamo i dati separatamente per la razza della vittima, emerge che la probabilità di ricevere la pena di morte è più alta per gli imputati bianchi rispetto agli imputati neri, sia nei casi in cui la vittima era bianca (12.6% vs 14.0%) sia nei casi in cui la vittima era nera (17.5% vs 10.0%).\nTuttavia, quando i dati vengono aggregati senza tenere conto della razza della vittima, si osserva una tendenza opposta:\n\n\n\n\n\n\n\n\nRazza dell’imputato\nPena di morte\nNo pena di morte\nTasso di condanna\n\n\n\nBianco\n30\n184\n30 / 214 ≈ 14.0%\n\n\nNero\n7\n46\n7 / 53 ≈ 13.2%\n\n\n\nAggregando i dati, sembra che gli imputati neri abbiano meno probabilità di ricevere la pena di morte rispetto agli imputati bianchi (13.2% vs 14.0%).\nQuesta apparente contraddizione è il risultato del paradosso di Simpson. La variabile confondente in questo caso è la razza della vittima: gli omicidi con vittime bianche avevano una probabilità molto più alta di portare alla pena di morte rispetto agli omicidi con vittime nere. Poiché gli imputati bianchi erano più spesso accusati di aver ucciso vittime bianche (per cui la probabilità di pena di morte era maggiore), il loro tasso di condanna complessivo risultava più alto. Viceversa, gli imputati neri erano più spesso accusati di aver ucciso vittime nere (per cui la probabilità di pena di morte era inferiore), abbassando il loro tasso di condanna complessivo.\nQuesto caso dimostra come l’aggregazione dei dati senza considerare una variabile confondente (in questo caso, la razza della vittima) possa portare a una conclusione errata e fuorviante. È essenziale analizzare i dati in modo stratificato per evitare interpretazioni distorte e per comprendere i reali meccanismi sottostanti un fenomeno.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#indipendenza-e-probabilità-condizionata",
    "href": "chapters/probability/04_conditional_prob.html#indipendenza-e-probabilità-condizionata",
    "title": "5  Probabilità condizionata",
    "section": "\n5.4 Indipendenza e probabilità condizionata",
    "text": "5.4 Indipendenza e probabilità condizionata\nL’indipendenza tra due eventi \\(A\\) e \\(B\\) può essere interpretata intuitivamente attraverso la probabilità condizionata. Due eventi sono indipendenti se il verificarsi di uno non influenza la probabilità di verificarsi dell’altro. In altre parole, conoscere che \\(B\\) è accaduto non modifica la probabilità di \\(A\\), e viceversa.\nQuesta relazione può essere formalizzata con le seguenti equazioni:\n\\[\nP(A \\mid B) = \\frac{P(A \\cap B)}{P(B)} = P(A),\n\\]\n\\[\nP(B \\mid A) = \\frac{P(A \\cap B)}{P(A)} = P(B).\n\\]\nPertanto, \\(A\\) e \\(B\\) sono indipendenti se e solo se:\n\\[\nP(A \\mid B) = P(A),\n\\]\n\\[\nP(B \\mid A) = P(B).\n\\]\nQueste condizioni significano che la probabilità di \\(A\\) non cambia, indipendentemente dal fatto che \\(B\\) sia accaduto, e lo stesso vale per \\(B\\).\n\n5.4.1 Indipendenza di tre eventi\nLa definizione di indipendenza si estende naturalmente a tre eventi \\(A\\), \\(B\\), e \\(C\\), ma con condizioni aggiuntive. Tre eventi sono indipendenti se:\n\n\nOgni coppia di eventi è indipendente:\n\\[\n\\begin{aligned}\nP(A \\cap B) &= P(A) P(B), \\\\\nP(A \\cap C) &= P(A) P(C), \\\\\nP(B \\cap C) &= P(B) P(C).\n\\end{aligned}\n\\]\n\n\nLa probabilità congiunta di tutti e tre gli eventi è uguale al prodotto delle loro probabilità individuali:\n\\[\nP(A \\cap B \\cap C) = P(A) P(B) P(C).\n\\]\n\n\nLe prime tre condizioni verificano l’indipendenza a coppie (indipendenza a due a due), mentre l’ultima condizione garantisce che i tre eventi siano completamente indipendenti. È importante notare che l’indipendenza a due a due non implica necessariamente l’indipendenza completa: per essere indipendenti nel senso completo, tutte e quattro le condizioni devono essere soddisfatte.\nIn sintesi, l’indipendenza tra eventi implica che il verificarsi di uno di essi non fornisce alcuna informazione sulla probabilità del verificarsi degli altri. Nel caso di due eventi, questa proprietà si traduce nell’invarianza della probabilità condizionata. Per tre o più eventi, l’indipendenza richiede sia l’indipendenza a coppie sia la condizione più forte sull’intersezione di tutti gli eventi.\nQuesti concetti sono fondamentali nella probabilità e nella statistica, poiché semplificano molti calcoli e forniscono una base per modelli più complessi.\n\n\n\n\n\n\nEsempio\n\n\n\n\n\nIndipendenza tra Eventi in un Mazzo di Carte\nScenario 1: Mazzo Completo (52 Carte)\nConsideriamo un mazzo standard di 52 carte. Ogni seme (picche, cuori, quadri, fiori) contiene 13 carte, e nel mazzo ci sono 4 Regine in totale. Definiamo i seguenti eventi:\n\n\n\\(A\\) = “Pescare una carta di picche”,\n\n\n\\(B\\) = “Pescare una carta Regina”.\n\n\nProbabilità di \\(A\\). Poiché ci sono 13 picche in un mazzo di 52 carte, \\[\nP(A) = \\frac{13}{52} = \\frac{1}{4}.\n\\]\nProbabilità di \\(B\\). Ci sono 4 Regine su 52 carte, quindi \\[\nP(B) = \\frac{4}{52} = \\frac{1}{13}.\n\\]\nProbabilità congiunta \\(P(A \\cap B)\\). L’unica carta che è contemporaneamente “picche” e “Regina” è la Regina di picche, perciò: \\[\nP(A \\cap B) = \\frac{1}{52}.\n\\]\n\nPer verificare l’indipendenza di \\(A\\) e \\(B\\), confrontiamo \\(P(A \\cap B)\\) con \\(P(A)\\,P(B)\\):\n\\[\nP(A)\\,P(B)\n= \\frac{1}{4} \\times \\frac{1}{13}\n= \\frac{1}{52},\n\\] \\[\nP(A \\cap B)\n= \\frac{1}{52}.\n\\]\nPoiché \\(P(A \\cap B) = P(A)\\,P(B)\\), i due eventi sono indipendenti quando il mazzo è completo.\nScenario 2: Mazzo Ridotto (51 Carte)\nOra rimuoviamo una carta qualunque dal mazzo — ad esempio il “2 di quadri” — portando il totale a 51 carte. Notiamo che la Regina di picche non è stata rimossa, ma il cambio di composizione potrebbe comunque influire sulle probabilità.\n\nProbabilità di \\(A \\cap B\\). Poiché la Regina di picche è ancora presente, pescare quella carta specifica ha ora probabilità \\[\nP(A \\cap B) = \\frac{1}{51}.\n\\]\nProbabilità di \\(A\\). Il seme di picche non è stato modificato (restano 13 picche), ma il denominatore è passato a 51 carte: \\[\nP(A) = \\frac{13}{51}.\n\\]\nProbabilità di \\(B\\). Nel mazzo restano ancora 4 Regine (nessuna è stata rimossa), su 51 carte totali: \\[\nP(B) = \\frac{4}{51}.\n\\]\nProdotto \\(P(A)\\,P(B)\\). Calcolando: \\[\nP(A)\\,P(B)\n= \\frac{13}{51} \\times \\frac{4}{51}\n= \\frac{52}{2601}.\n\\]\n\nConfrontando:\n\\[\nP(A \\cap B)\n= \\frac{1}{51},\n\\quad\\text{mentre}\\quad\nP(A)\\,P(B)\n= \\frac{52}{2601}.\n\\]\nSi verifica che\n\\[\n\\frac{1}{51}\n\\;\\neq\\;\n\\frac{52}{2601}.\n\\]\nPertanto, \\(A\\) e \\(B\\) non sono più indipendenti nel mazzo ridotto.\nIn sintesi, questo esempio mostra come l’indipendenza tra due eventi dipenda dal contesto:\n\ncon un mazzo completo (52 carte), “pescare picche” e “pescare una Regina” sono eventi indipendenti;\nbasta rimuovere una carta qualunque (anche non correlata direttamente a “picche” o “Regine”) perché le probabilità cambino e gli stessi eventi cessino di essere indipendenti.\n\nIn altre parole, ogni modifica alla composizione del mazzo può influire sulle probabilità dei singoli eventi e, di conseguenza, sulle loro relazioni di dipendenza o indipendenza.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#teorema-del-prodotto",
    "href": "chapters/probability/04_conditional_prob.html#teorema-del-prodotto",
    "title": "5  Probabilità condizionata",
    "section": "\n5.5 Teorema del prodotto",
    "text": "5.5 Teorema del prodotto\nA partire dalla definizione di probabilità condizionata, possiamo derivare quello che viene chiamato Teorema del Prodotto, noto anche come teorema della probabilità composta, regola moltiplicativa o regola della catena. Questo risultato permette di esprimere la probabilità congiunta di due o più eventi come il prodotto di probabilità condizionate.\n\n5.5.1 Caso di due eventi\nPer due eventi \\(A\\) e \\(B\\), il Teorema del Prodotto asserisce che:\n\\[\nP(A \\cap B)\n\\;=\\;\nP(B) \\,\\cdot\\, P(A \\mid B)\n\\;=\\;\nP(A) \\,\\cdot\\, P(B \\mid A).\n\\tag{5.4}\\]\nIn altre parole, la probabilità che \\(A\\) e \\(B\\) si verifichino contemporaneamente può essere calcolata in due modi equivalenti:\n\n\nprimo modo: prendi la probabilità di \\(B\\), quindi moltiplicala per la probabilità di \\(A\\), sapendo già che \\(B\\) è accaduto;\n\nsecondo modo: prendi la probabilità di \\(A\\), quindi moltiplicala per la probabilità di \\(B\\), sapendo già che \\(A\\) è accaduto.\n\nL’ordine degli eventi in cui si applica la condizione è arbitrario, a patto di rispettare la formula e scegliere la condizione corrispondente.\n\n5.5.2 Generalizzazione a \\(n\\) eventi\nIl Teorema del Prodotto si estende naturalmente al caso di più di due eventi. Se consideriamo \\(n\\) eventi \\(A_1, A_2, \\dots, A_n\\), e assumiamo che\n\\[\nP(A_1 \\cap A_2 \\cap \\cdots \\cap A_{n-1}) \\;&gt;\\; 0,\n\\]\nallora la probabilità che tutti questi eventi si verifichino è data da:\n\\[\n\\begin{aligned}\nP(A_1 \\,\\cap\\, A_2 \\,\\cap\\, \\cdots \\,\\cap\\, A_n)\n&= P(A_1)\n\\;\\times\\; P(A_2 \\mid A_1)\n\\;\\times\\; P(A_3 \\mid A_1 \\cap A_2)\n\\;\\times\\; \\cdots \\\\\n&\\quad \\cdots \\times\\; P(A_n \\mid A_1 \\cap A_2 \\cap \\cdots \\cap A_{n-1}).\n\\end{aligned}\n\\tag{5.5}\\]\nIn pratica, ciascun fattore si ottiene considerando la probabilità dell’evento successivo, condizionata sul verificarsi di tutti gli eventi precedenti. Questa formulazione è cruciale, ad esempio, nelle analisi di sequenze di eventi o in modelli statistici in cui le probabilità vengono “aggiornate” gradualmente mano a mano che si verificano nuove condizioni.\nIl Teorema del Prodotto rappresenta uno dei fondamenti teorici più importanti della probabilità e trova applicazioni in numerosi contesti, quali:\n\nla modellazione di processi sequenziali o temporali;\nla scomposizione di problemi complessi in calcoli più semplici e gestibili;\nla teoria delle reti bayesiane e l’analisi della probabilità condizionata.\n\nGrazie a questo teorema, è possibile affrontare problemi complessi suddividendoli in passaggi progressivi, in cui ogni probabilità condizionata contribuisce alla costruzione della soluzione complessiva in maniera sistematica.\n\n5.5.2.1 Procedura di calcolo\nPer applicare la regola:\n\n\nparti dal primo evento: usa la probabilità incondizionata \\(P(A_1)\\);\n\n\ncondiziona progressivamente: moltiplica per \\(P(A_2 \\mid A_1)\\), poi per \\(P(A_3 \\mid A_1 \\cap A_2)\\), e così via;\n\ntermina con l’ultimo evento: includi \\(P(A_n \\mid A_1 \\cap \\cdots \\cap A_{n-1})\\).\n\n\n\n\n\n\n\nEsempio\n\n\n\n\n\nDa un’urna contenente 6 palline bianche e 4 nere si estrae una pallina per volta, senza reintrodurla nell’urna. Indichiamo con \\(B_i\\) l’evento: “esce una pallina bianca alla \\(i\\)-esima estrazione” e con \\(N_i\\) l’estrazione di una pallina nera. L’evento: “escono due palline bianche nelle prime due estrazioni” è rappresentato dalla intersezione \\(\\{B_1 \\cap B_2\\}\\) e, per l’Equazione 5.4, la sua probabilità vale\n\\[\nP(B_1 \\cap B_2) = P(B_1)P(B_2 \\mid B_1).\n\\]\n\\(P(B_1)\\) vale 6/10, perché nella prima estrazione \\(\\Omega\\) è costituito da 10 elementi: 6 palline bianche e 4 nere. La probabilità condizionata \\(P(B_2 \\mid B_1)\\) vale 5/9, perché nella seconda estrazione, se è verificato l’evento \\(B_1\\), lo spazio campionario consiste di 5 palline bianche e 4 nere. Si ricava pertanto:\n\\[\nP(B_1 \\cap B_2) = \\frac{6}{10} \\cdot \\frac{5}{9} = \\frac{1}{3}.\n\\]\nIn modo analogo si ha che\n\\[\nP(N_1 \\cap N_2) = P(N_1)P(N_2 \\mid N_1) = \\frac{4}{10} \\cdot \\frac{3}{9} = \\frac{4}{30}.\n\\]\nSe l’esperimento consiste nell’estrazione successiva di 3 palline, la probabilità che queste siano tutte bianche, per l’Equazione 5.5, vale\n\\[\n\\begin{aligned}\nP(B_1 \\cap B_2 \\cap B_3) &=P(B_1)P(B_2 \\mid B_1)P(B_3 \\mid B_1 \\cap B_2) \\notag\\\\\n&=\\frac{6}{10}\\cdot\\frac{5}{9} \\cdot\\frac{4}{8} \\notag\\\\\n&= \\frac{1}{6}.\n\\end{aligned}\n\\]\nLa probabilità dell’estrazione di tre palline nere è invece:\n\\[\n\\begin{aligned}\nP(N_1 \\cap N_2 \\cap N_3) &= P(N_1)P(N_2 \\mid N_1)P(N_3 \\mid N_1 \\cap N_2)\\notag\\\\\n&= \\frac{4}{10} \\cdot \\frac{3}{9} \\cdot \\frac{2}{8} \\notag\\\\\n&= \\frac{1}{30}.\\notag\n\\end{aligned}\n\\]",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#teorema-della-probabilità-totale",
    "href": "chapters/probability/04_conditional_prob.html#teorema-della-probabilità-totale",
    "title": "5  Probabilità condizionata",
    "section": "\n5.6 Teorema della probabilità totale",
    "text": "5.6 Teorema della probabilità totale\nIl Teorema della Probabilità Totale — anche detto legge della probabilità totale — permette di calcolare la probabilità di un evento \\(A\\) scomponendola rispetto a una partizione di sottoinsiemi che coprono l’intero spazio campionario. È particolarmente utile quando si affrontano situazioni con più scenari, categorie o gruppi nei quali ripartire il calcolo di probabilità.\n\n5.6.1 Enunciato generale\n\nDefinizione 5.3 Supponiamo che lo spazio campionario \\(\\Omega\\) sia suddiviso in una partizione di eventi \\(B_1, B_2, \\dots, B_n\\), ossia:\n\n\nmutua esclusività: \\(B_i \\cap B_j = \\varnothing\\) per \\(i \\neq j\\);\n\n\ncopertura totale: \\(\\bigcup_{i=1}^n B_i = \\Omega\\).\n\nAllora, per un qualsiasi evento \\(A \\subseteq \\Omega\\) vale:\n\\[\nP(A)\n\\;=\\;\n\\sum_{i=1}^n P(A \\cap B_i)\n\\;=\\;\n\\sum_{i=1}^n P(A \\mid B_i)\\, P(B_i).\n\\tag{5.6}\\]\nIn altre parole, \\(P(A)\\) può essere visto come una media pesata delle probabilità condizionate \\(P(A \\mid B_i)\\), con pesi \\(P(B_i)\\).\n\n\n5.6.2 Caso di due partizioni\nQuando lo spazio campionario è ripartito in due soli eventi, \\(B\\) e il suo complementare \\(B^c\\), la formula si semplifica in:\n\\[\n\\begin{aligned}\nP(A)\n&= P(A \\cap B) + P(A \\cap B^c) \\\\\n&= P(A \\mid B)\\,P(B) \\;+\\; P(A \\mid B^c)\\,P(B^c).\n\\end{aligned}\n\\tag{5.7}\\]\n\n\n\n\n\n\nEsempio\n\n\n\n\n\nTest medico\nAbbiamo:\n\n\n\\(B\\): “Una persona è malata”;\n\n\\(B^c\\): “Una persona è sana”;\n\n\n\\(A\\): “Test positivo”.\n\nSecondo il Teorema della Probabilità Totale, la probabilità di un risultato positivo si ottiene sommando:\n\\[\nP(A)\n= P(\\text{Positivo} \\mid \\text{Malato}) \\,P(\\text{Malato})\n\\;+\\;\nP(\\text{Positivo} \\mid \\text{Sano}) \\,P(\\text{Sano}).\n\\]\n\n\n\n\n5.6.3 Applicazioni principali\n\nAnalisi per Categorie\nQuando la popolazione è divisa in gruppi \\(B_1, \\dots, B_n\\) (ad esempio, fasce d’età o regioni), la probabilità di un evento \\(A\\) si ottiene sommando le probabilità di \\(A\\) condizionate a ciascun gruppo, moltiplicate per la frequenza di quel gruppo.\nTeorema di Bayes\nIl denominatore della formula di Bayes è la somma \\(\\sum_{j=1}^n P(E \\mid H_j)\\,P(H_j)\\), che è appunto un’applicazione della probabilità totale. Qui, \\(H_1, \\dots, H_n\\) rappresentano ipotesi alternative (partizione) e \\(E\\) un dato osservato.\n\nIn breve, il teorema della probabilità totale “scompone” un problema globale in sotto-problemi più specifici, ciascuno condizionato su una porzione dello spazio campionario, permettendo di sommare i risultati finali per ottenere \\(P(A)\\).\n\n\n\n\n\n\nEsempio\n\n\n\n\n\nUrne con Palline di Colori Diversi\nAbbiamo 3 urne, ciascuna con 100 palline:\n\nUrna 1: 75 rosse, 25 blu\n\nUrna 2: 60 rosse, 40 blu\n\nUrna 3: 45 rosse, 55 blu\n\nL’urna viene scelta a caso (probabilità \\(1/3\\) per ciascuna). Qual è la probabilità di estrarre una pallina rossa?\nDefinisco:\n\n\n\\(R\\): “Estraggo una pallina rossa”;\n\n\n\\(U_i\\): “Seleziono l’Urna \\(i\\)”.\n\nLe urne \\(U_1, U_2, U_3\\) costituiscono una partizione (disgiunte e coprenti \\(\\Omega\\)). Sappiamo:\n\\[\nP(R \\mid U_1)=0.75,\n\\quad\nP(R \\mid U_2)=0.60,\n\\quad\nP(R \\mid U_3)=0.45.\n\\]\nApplicando la probabilità totale:\n\\[\n\\begin{aligned}\nP(R)\n&= P(R \\mid U_1)\\,P(U_1) + P(R \\mid U_2)\\,P(U_2) + P(R \\mid U_3)\\,P(U_3)\\\\\n&= 0.75 \\times \\tfrac13 + 0.60 \\times \\tfrac13 + 0.45 \\times \\tfrac13\n= 0.60.\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\n\n\nEsempio\n\n\n\n\n\nProbabilità della Depressione in Diverse Fasce d’Età\nUna popolazione è suddivisa in 3 gruppi:\n\ngiovani (30%),\nadulti (40%),\n\nanziani (30%).\n\nLe probabilità condizionate di soffrire di depressione sono:\n\\[\nP(D \\mid \\text{Giovane}) = 0.10, \\quad\nP(D \\mid \\text{Adulto}) = 0.20, \\quad\nP(D \\mid \\text{Anziano}) = 0.35.\n\\]\nUsando la probabilità totale:\n\\[\nP(D)\n= 0.10\\times0.30 + 0.20\\times0.40 + 0.35\\times0.30\n= 0.215.\n\\]\nDunque, circa il 21.5% della popolazione totale soffre di depressione, combinando i tassi per ciascuna fascia.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#riflessioni-conclusive",
    "href": "chapters/probability/04_conditional_prob.html#riflessioni-conclusive",
    "title": "5  Probabilità condizionata",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nLa probabilità condizionata è uno dei concetti più importanti in statistica, poiché fornisce il quadro teorico per:\n\ncomprendere e formalizzare l’indipendenza tra eventi o variabili (assenza di ogni tipo di relazione);\nespandere e generalizzare il calcolo delle probabilità (ad esempio, la legge della probabilità totale, che scompone in modo sistematico eventi complessi);\n\nalimentare metodi inferenziali avanzati, come il Teorema di Bayes.\n\nIn particolare, il Teorema di Bayes rappresenta uno strumento cardine dell’inferenza statistica: grazie alla probabilità condizionata, è possibile “aggiornare” in modo continuo le credenze sulle ipotesi (o sui parametri di un modello) alla luce di nuove osservazioni. Tale caratteristica di “apprendimento” graduale rende l’inferenza bayesiana flessibile e potente, ideale per affrontare situazioni in cui vengono resi disponibili dati aggiuntivi o in cui le condizioni iniziali possono cambiare.\nIn definitiva, la probabilità condizionata non solo chiarisce la nozione di indipendenza e getta le fondamenta di metodi inferenziali evoluti, ma soprattutto rappresenta il “motore” di modelli che si adattano dinamicamente alle nuove informazioni. Questa prospettiva “attiva” nell’aggiornamento delle probabilità è ciò che rende l’analisi statistica uno strumento versatile per descrivere e interpretare il mondo reale.\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nEsercizio 1: Soddisfazione con la Vita e Stress Accademico\nUn gruppo di studenti ha compilato la Satisfaction with Life Scale (SWLS) e un questionario sullo stress accademico. Dai dati raccolti emerge che:\n\nIl 40% degli studenti ha riportato un alto livello di stress accademico.\nIl 60% degli studenti ha riportato un basso livello di stress accademico.\nTra gli studenti con alto stress, il 30% ha riportato una soddisfazione con la vita elevata.\nTra gli studenti con basso stress, il 70% ha riportato una soddisfazione con la vita elevata.\n\nCalcola la probabilità che uno studente scelto a caso abbia:\n\nUn alto livello di stress e una soddisfazione elevata.\nUna soddisfazione elevata.\nUn alto livello di stress, dato che ha una soddisfazione elevata.\n\nEsercizio 2: Studio del Paradosso di Simpson\nUn’università vuole valutare la relazione tra la frequenza di partecipazione alle lezioni e il successo negli esami finali. I dati raccolti mostrano che:\n\n\n\n\n\n\n\n\nGruppo\nStudenti con alta frequenza\nSuperano l’esame\nNon superano l’esame\n\n\n\nA\n40\n30\n10\n\n\nB\n60\n20\n40\n\n\n\n\nCalcola la probabilità di superare l’esame per ciascun gruppo separatamente.\nCalcola la probabilità totale di superare l’esame.\nSpiega se il Paradosso di Simpson si manifesta in questi dati.\n\nEsercizio 3: Il Problema di Monty Hall\nIn un quiz televisivo, un concorrente deve scegliere tra tre porte: dietro una c’è un’auto e dietro le altre due ci sono capre. Dopo la scelta iniziale, il conduttore, che sa cosa c’è dietro ogni porta, apre una delle due porte rimanenti rivelando una capra. Il concorrente ha ora la possibilità di cambiare la sua scelta.\n\nQual è la probabilità di vincere l’auto se il concorrente non cambia la sua scelta?\nQual è la probabilità di vincere l’auto se il concorrente cambia la sua scelta?\nSpiega perché cambiare porta è la strategia migliore.\n\nEsercizio 4: Teorema della Probabilità Totale\nUn’università ha tre dipartimenti: Psicologia, Economia e Ingegneria. Le proporzioni di studenti iscritti sono:\n\nPsicologia: 40%\nEconomia: 35%\nIngegneria: 25%\n\nLa probabilità di laurearsi in tempo varia per ogni dipartimento:\n\nPsicologia: 70%\nEconomia: 60%\nIngegneria: 80%\n\nCalcola la probabilità che uno studente scelto a caso si laurei in tempo.\nEsercizio 5: Urne e Palline\nUn’urna contiene 5 palline rosse e 7 blu. Si estrae una pallina, si osserva il colore e poi la pallina viene rimessa nell’urna. Quindi si estrae una seconda pallina.\n\nQual è la probabilità di estrarre due palline rosse?\nQual è la probabilità di estrarre almeno una pallina blu?\nQual è la probabilità di estrarre una pallina rossa alla seconda estrazione, dato che la prima estratta era blu?\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\nEsercizio 1: Soddisfazione con la Vita e Stress Accademico\n\n\nLa probabilità che uno studente abbia alto stress e soddisfazione elevata si calcola moltiplicando la probabilità condizionata di avere soddisfazione elevata dato l’alto stress per la probabilità di avere alto stress:\n\\[\nP(S \\cap V) = P(V | S) P(S) = 0.30 \\times 0.40 = 0.12.\n\\]\n\n\nLa probabilità che uno studente abbia una soddisfazione elevata, indipendentemente dal livello di stress, si ottiene applicando la legge della probabilità totale:\n\\[\nP(V) = P(V | S) P(S) + P(V | \\neg S) P(\\neg S)\n\\]\n\\[\n= (0.30 \\times 0.40) + (0.70 \\times 0.60) = 0.12 + 0.42 = 0.54.\n\\]\n\n\nLa probabilità che uno studente abbia alto stress sapendo che ha una soddisfazione elevata si calcola utilizzando la formula della probabilità condizionata:\n\\[\nP(S | V) = \\frac{P(S \\cap V)}{P(V)} = \\frac{0.12}{0.54} \\approx 0.22.\n\\]\n\n\nEsercizio 2: Studio del Paradosso di Simpson\n\n\n\\(P(E | A) = \\frac{30}{40} = 0.75\\), \\(P(E | B) = \\frac{20}{60} = 0.33\\)\n\n\\(P(E) = P(E | A) P(A) + P(E | B) P(B) = (0.75 \\times 0.40) + (0.33 \\times 0.60) = 0.30 + 0.198 = 0.498\\)\nSe i tassi di successo aggregati mostrano una relazione invertita, il Paradosso di Simpson si manifesta.\n\nEsercizio 3: Il Problema di Monty Hall\n\n\\(P(V | S) = \\frac{1}{3}\\)\n\\(P(V | C) = \\frac{2}{3}\\)\nCambiare porta aumenta le probabilità di vincita da \\(1/3\\) a \\(2/3\\), quindi conviene sempre cambiare.\n\nEsercizio 4: Teorema della Probabilità Totale\n\\(P(L) = (0.70 \\times 0.40) + (0.60 \\times 0.35) + (0.80 \\times 0.25) = 0.28 + 0.21 + 0.20 = 0.69\\)\nEsercizio 5: Urne e Palline\n\n\\(P(R_1 \\cap R_2) = (5/12) \\times (5/12) = 25/144\\)\n\\(1 - P(R_1 \\cap R_2) = 1 - 25/144 = 119/144\\)\n\\(P(R_2 | B_1) = 5/12\\)\n\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt;  [4] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt;  [7] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [10] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [13] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [16] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [25] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.8          tidyselect_1.2.1      farver_2.1.2         \n#&gt;  [4] fastmap_1.2.0         TH.data_1.1-4         tensorA_0.36.2.1     \n#&gt;  [7] digest_0.6.37         timechange_0.3.0      estimability_1.5.1   \n#&gt; [10] lifecycle_1.0.4       survival_3.8-3        magrittr_2.0.3       \n#&gt; [13] compiler_4.5.1        rlang_1.1.6           tools_4.5.1          \n#&gt; [16] knitr_1.50            bridgesampling_1.1-2  htmlwidgets_1.6.4    \n#&gt; [19] curl_7.0.0            pkgbuild_1.4.8        RColorBrewer_1.1-3   \n#&gt; [22] abind_1.4-8           multcomp_1.4-28       withr_3.0.2          \n#&gt; [25] purrr_1.1.0           grid_4.5.1            stats4_4.5.1         \n#&gt; [28] colorspace_2.1-1      xtable_1.8-4          inline_0.3.21        \n#&gt; [31] emmeans_1.11.2-8      scales_1.4.0          MASS_7.3-65          \n#&gt; [34] cli_3.6.5             mvtnorm_1.3-3         rmarkdown_2.29       \n#&gt; [37] ragg_1.5.0            generics_0.1.4        RcppParallel_5.1.11-1\n#&gt; [40] cachem_1.1.0          stringr_1.5.1         splines_4.5.1        \n#&gt; [43] parallel_4.5.1        vctrs_0.6.5           V8_7.0.0             \n#&gt; [46] Matrix_1.7-4          sandwich_3.1-1        jsonlite_2.0.0       \n#&gt; [49] arrayhelpers_1.1-0    systemfonts_1.2.3     glue_1.8.0           \n#&gt; [52] codetools_0.2-20      distributional_0.5.0  lubridate_1.9.4      \n#&gt; [55] stringi_1.8.7         gtable_0.3.6          QuickJSR_1.8.0       \n#&gt; [58] htmltools_0.5.8.1     Brobdingnag_1.2-9     R6_2.6.1             \n#&gt; [61] textshaping_1.0.3     rprojroot_2.1.1       evaluate_1.0.5       \n#&gt; [64] lattice_0.22-7        backports_1.5.0       memoise_2.0.1        \n#&gt; [67] broom_1.0.9           snakecase_0.11.1      rstantools_2.5.0     \n#&gt; [70] coda_0.19-4.1         gridExtra_2.3         nlme_3.1-168         \n#&gt; [73] checkmate_2.3.3       xfun_0.53             zoo_1.8-14           \n#&gt; [76] pkgconfig_2.0.3",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#bibliografia",
    "href": "chapters/probability/04_conditional_prob.html#bibliografia",
    "title": "5  Probabilità condizionata",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlitzstein, J. K., & Hwang, J. (2019). Introduction to probability. CRC Press.\n\n\nRadelet, M. L., & Pierce, G. L. (1991). Choosing Those Who Will Die: Race and the Death Penalty in Florida. Florida Law Review, 43(1), 1–34.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_bayes_theorem.html",
    "href": "chapters/probability/05_bayes_theorem.html",
    "title": "6  Il teorema di Bayes",
    "section": "",
    "text": "Introduzione\nIl teorema di Bayes costituisce un metodo matematico ottimale per risolvere problemi di inferenza induttiva, ovvero situazioni in cui si deducono cause sottostanti, principi generali o strutture complesse a partire da dati parziali e incerti. Trova applicazione in scenari disparati: dalla ricostruzione della percezione tridimensionale basata su segnali retinici all’interpretazione degli stati mentali altrui attraverso il comportamento osservabile, fino alla stima di parametri fisici in condizioni sperimentali rumorose (Baker et al., 2011; Ma et al., 2023). La sua efficacia emerge soprattutto in contesti dove le evidenze disponibili non permettono di discriminare univocamente tra ipotesi concorrenti.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_bayes_theorem.html#introduzione",
    "href": "chapters/probability/05_bayes_theorem.html#introduzione",
    "title": "6  Il teorema di Bayes",
    "section": "",
    "text": "Panoramica del capitolo\n\nL’importanza dell teorema di Bayes.\nl’utilizzo del teorema di Bayes per analizzare e interpretare i test diagnostici, tenendo in considerazione la prevalenza della malattia in questione.\nSoluzione di problemi di probabilità discreta che necessitano dell’applicazione del teorema di Bayes.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere Everything is Predictable: How Bayesian Statistics Explain Our World (Chivers, 2024). Questo libro offre una descrizione chiara e accessibile dell’impatto che il teorema di Bayes ha avuto sulla vita moderna.\nLeggere Bayesian Models of Cognition di Thomas L. Griffiths, una voce della Open Encyclopedia of Cognitive Science.\nLeggere il capitolo Conditional Probability (Schervish & DeGroot, 2014).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n\n\n\n\n6.0.1 Incertezza come fondamento dell’inferenza\nUn principio cardine del ragionamento bayesiano è il riconoscimento dell’incertezza intrinseca a qualsiasi processo conoscitivo. Anche in un universo deterministico, la complessità dei sistemi e i limiti dei nostri sensi rendono impossibile una conoscenza completa. Ad esempio, non possiamo determinare con esattezza infiniti dettagli (come posizione e stato di ogni neurone nel cervello di un interlocutore) né accedere direttamente a variabili latenti (come emozioni o intenzioni). Di conseguenza, ogni inferenza conserva un margine probabilistico, che Bayes quantifica e trasforma in uno strumento operativo.\n\n6.0.2 Dinamica bayesiana: aggiornare le credenze\nLa realtà può essere paragonata a una partita di poker più che a una di scacchi: operiamo sempre in condizioni di informazione imperfetta. Le decisioni si basano su un bilanciamento tra conoscenze pregresse (prior) e nuovi indizi (likelihood), in un processo dinamico formalizzato dall’equazione:\n\\[\nP(H \\mid E) = \\frac{P(E \\mid H) \\cdot P(H)}{P(E)} ,\n\\]\ndove:\n\n\n\\(P(H \\mid E)\\) (posterior): plausibilità rivista dell’ipotesi \\(H\\) dopo aver osservato l’evidenza \\(E\\);\n\n\n\\(P(E \\mid H)\\) (likelihood): probabilità di osservare \\(E\\) se \\(H\\) fosse vera;\n\n\n\\(P(H)\\) (prior): fiducia iniziale in \\(H\\);\n\n\n\\(P(E)\\): fattore di normalizzazione.\n\nQuesto meccanismo permette di ricalibrare razionalmente le convinzioni, riducendo l’incertezza man mano che nuovi dati vengono integrati.\n\n6.0.3 Inferenza induttiva e razionalità adattiva\nL’inferenza induttiva bayesiana rappresenta un pilastro della razionalità scientifica e quotidiana. A differenza della logica deduttiva (dove le conclusioni derivano necessariamente dalle premesse), Bayes riconcilia teoria ed evidenza empirica, consentendo previsioni robuste nonostante dati incompleti. Le applicazioni spaziano:\n\nin psicologia cognitiva, modellando come il cervello interpreta segnali ambigui (Caudek & Bruno, 2024; Domini & Caudek, 2003);\n\nnell’intelligenza artificiale, guidando algoritmi di apprendimento automatico (Chivers, 2024);\n\nnelle scienze sociali, per stimare preferenze nascoste da comportamenti osservati.\n\nIl teorema non elimina l’incertezza, ma fornisce un protocollo formale per gestirla, trasformando l’induzione da atto intuitivo a procedura rigorosa. In questo senso, incarna un principio di razionalità adattiva, dove l’ottimalità non richiede onniscienza, bensì un aggiornamento coerente delle credenze in risposta all’esperienza.\n\n\n\n\n\n\n\n\n\n\n\n\n6.0.4 Una rivoluzione nel pensiero probabilistico\nPer comprendere appieno il teorema di Bayes, è necessario delineare le sue origini storiche. Nel XVIII secolo, Thomas Bayes (1701-1761), ecclesiastico presbiteriano e matematico britannico, pose le basi di una rivoluzione concettuale nel campo della probabilità e della statistica. Il suo contributo teorico, passato alla storia come teorema di Bayes, ha plasmato in modo decisivo lo sviluppo scientifico e tecnologico dei secoli successivi, influenzando discipline che spaziano dalla medicina all’intelligenza artificiale (Chivers, 2024).\n\n6.0.4.1 La figura di Thomas Bayes\nBayes proveniva da una famiglia benestante e studiò teologia a Edimburgo, preparandosi al ministero religioso. Come ricorda il biografo David Bellhouse, Bayes non era un accademico nel senso moderno del termine, ma un erudito libero, interessato alla conoscenza per passione personale (Bellhouse, 2004).\nDurante la sua vita, Bayes pubblicò due testi:\n\n\nUn trattato di teologia: Divine Benevolence: Or, an Attempt to Prove that the Principal End of the Divine Providence and Government is the Happiness of His Creatures (1731), una teodicea che cerca di spiegare come la legge naturale possa ottimizzare il benessere universale.\n\n\nUna difesa del calcolo infinitesimale: An Introduction to the Doctrine of Fluxions (1736), in risposta alle critiche di George Berkeley sugli infinitesimi e i concetti fondamentali del calcolo newtoniano (Jesseph, 1993).\n\nIl lavoro che segnò la svolta nella teoria della probabilità fu però pubblicato postumo, nel 1763, sulle Philosophical Transactions of the Royal Society: An Essay towards Solving a Problem in the Doctrine of Chances. Per la prima volta, si formalizzava un metodo per aggiornare le ipotesi probabilistiche alla luce di nuove evidenze, ponendo le fondamenta dell’inferenza bayesiana (Stigler, 1990).\n\n6.0.4.2 Bayes e il ruolo culturale della scienza\nCome sottolinea ancora Bellhouse, nel XVIII secolo era comune, tra le élite colte, dedicarsi allo studio di discipline scientifiche per prestigio sociale. Per Bayes, la matematica era dunque una passione coltivata con spirito libero. Il suo merito straordinario fu di spingere l’interpretazione della probabilità verso una prospettiva epistemologica innovativa, dove la probabilità diventa espressione quantitativa della nostra ignoranza sul mondo.\nIn contrapposizione alla visione “classica”, che vedeva la probabilità come frequenza osservabile in eventi ripetuti, Bayes propose che essa potesse rappresentare il grado di fiducia di un osservatore, inevitabilmente influenzato da conoscenze pregresse e da pregiudizi individuali. In questo senso, la probabilità assume un carattere dinamico e soggettivo, configurandosi come uno strumento di conoscenza che si aggiorna di continuo al variare dei dati (Spiegelhalter, 2019).\n\n6.0.4.3 Un esperimento mentale illuminante\nPer illustrare la sua idea, Bayes propose un semplice esempio: immagina di lanciare alcune palline su un tavolo da biliardo. Dopo aver segnato con una linea il punto in cui si ferma una pallina bianca (e averla poi rimossa), si lanciano altre palline rosse e si conta quante cadono a destra e quante a sinistra di quella linea. Sulla base di queste osservazioni, come si può “indovinare” la posizione della linea? E con quale probabilità la prossima pallina rossa cadrà a sinistra di essa?\nLa soluzione di Bayes combina i dati osservati (numero di palline cadute a sinistra o a destra) con le convinzioni iniziali dell’osservatore (il cosiddetto “prior”), delineando un processo di apprendimento graduale che guida la revisione critica delle ipotesi.\n\n6.0.4.4 Il ruolo di Richard Price\nDopo la morte di Bayes, fu un altro ecclesiastico, Richard Price (1723-1791), a dare impulso alla diffusione del saggio bayesiano. Price aveva un’ottima reputazione negli ambienti intellettuali dell’epoca, grazie anche alle sue relazioni con figure di spicco come Benjamin Franklin, Thomas Jefferson e John Adams.\nPrice prese in carico il manoscritto di Bayes, lo sottopose al fisico John Canton e ne curò la pubblicazione postuma, operando modifiche significative. Rispetto alla versione originale di Bayes, concentrata quasi esclusivamente sugli aspetti teorici, Price aggiunse una parte dedicata alle applicazioni pratiche, rendendo il testo più fruibile a un pubblico più ampio. Per questo motivo, lo storico Stephen Stigler lo definisce «il primo bayesiano della storia».\n\n6.0.4.5 Dal silenzio alla riscoperta\nPer oltre cinquant’anni, il lavoro di Bayes rimase in ombra, oscurato dall’opera pionieristica di Pierre-Simon Laplace. Già nel 1774, Laplace pervenne indipendentemente a principi analoghi, e successivamente li sistematizzò nella monumentale Théorie analytique des probabilités (1812). Solo in tempi più recenti, con l’avvento dei metodi di calcolo moderno e dell’informatica, la statura del teorema di Bayes è emersa in tutta la sua importanza.\nOggi, il teorema di Bayes è considerato un cardine della statistica moderna: formalizza il modo in cui aggiorniamo le nostre credenze alla luce di nuovi dati. Questo schema è cruciale in ogni disciplina scientifica e tecnologica che debba fare i conti con incertezza e dati incompleti. Dalla genomica all’econometria, dalla fisica delle particelle alle scienze cognitive, il paradigma bayesiano risulta prezioso per gestire e interpretare informazioni in continuo aggiornamento.\n\n6.0.4.6 L’eredità di Bayes nell’era digitale\nNell’intelligenza artificiale, le idee bayesiane sono alla base di sistemi di apprendimento automatico e modelli probabilistici complessi. Strumenti come i moderni modelli linguistici (ad esempio ChatGPT e Claude) sfruttano strategie di inferenza bayesiana – anche se in forme estremamente avanzate – per generare risposte, fare previsioni e adattarsi costantemente agli input degli utenti.\nLa parabola storica di questo teorema, nato dalle speculazioni di un pastore presbiteriano del Settecento, mostra chiaramente il potenziale trasformativo delle idee matematiche. Come sottolinea Tom Chivers nel suo Everything Is Predictable: How Bayesian Statistics Explain Our World, la statistica bayesiana è diventata una sorta di “grammatica universale” per interpretare la realtà, permettendoci di affrontare con metodo situazioni complesse, modellare l’incertezza e formulare previsioni in contesti dove l’informazione è inevitabilmente limitata (Chivers, 2024).\nIn sintesi, la forza del teorema di Bayes non risiede soltanto nella sua eleganza formale, ma soprattutto nella sua portata epistemologica: esso traduce in termini matematici la nostra naturale tendenza ad apprendere da ciò che osserviamo e a rivedere continuamente ciò che crediamo. Per questo rimane, ancora oggi, un punto di riferimento fondamentale in qualunque disciplina che affronti il problema della conoscenza in condizioni di incertezza.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_bayes_theorem.html#la-regola-di-bayes-e-linferenza-probabilistica",
    "href": "chapters/probability/05_bayes_theorem.html#la-regola-di-bayes-e-linferenza-probabilistica",
    "title": "6  Il teorema di Bayes",
    "section": "\n6.1 La regola di Bayes e l’inferenza probabilistica",
    "text": "6.1 La regola di Bayes e l’inferenza probabilistica\nL’inferenza bayesiana utilizza un principio centrale della teoria delle probabilità noto come regola di Bayes. Questo principio consente di aggiornare in modo razionale le nostre credenze sulla base di nuovi dati osservati, integrandoli con conoscenze pregresse.\n\n6.1.1 Derivazione della regola di Bayes\nConsideriamo due eventi casuali, \\(A\\) e \\(B\\). La probabilità congiunta \\(P(A, B)\\), ossia la probabilità che entrambi gli eventi accadano simultaneamente, può essere espressa in due modi equivalenti:\n\nTramite la regola della catena, possiamo scrivere: \\[\nP(A, B) = P(A \\mid B)P(B).\n\\] Qui, \\(P(A \\mid B)\\) è la probabilità condizionata che si verifichi l’evento \\(A\\) sapendo che l’evento \\(B\\) è avvenuto, mentre \\(P(B)\\) è la probabilità marginale di \\(B\\), indipendente da \\(A\\).\nUtilizzando la simmetria della probabilità congiunta, possiamo invertire gli eventi: \\[\nP(A, B) = P(B \\mid A)P(A).\n\\]\n\nDato che entrambe le espressioni rappresentano la stessa probabilità congiunta, possiamo eguagliarle:\n\\[\nP(A \\mid B)P(B) = P(B \\mid A)P(A).\n\\]\nRisolvendo per \\(P(B \\mid A)\\) otteniamo la regola di Bayes:\n\\[\nP(B \\mid A) = \\frac{P(A \\mid B) P(B)}{P(A)}.\n\\tag{6.1}\\]\n\n6.1.2 Interpretazione dei termini della regola di Bayes\nLa regola di Bayes permette di aggiornare la nostra credenza sulla probabilità di un’ipotesi o evento (\\(B\\)), dopo aver osservato un dato o evidenza (\\(A\\)):\n\n\n\\(P(B)\\) (prior): è la probabilità iniziale assegnata all’evento \\(B\\) prima di osservare il dato \\(A\\). Rappresenta la nostra conoscenza pregressa o il nostro grado iniziale di fiducia.\n\n\\(P(A \\mid B)\\) (verosimiglianza): è la probabilità di osservare il dato \\(A\\) nell’ipotesi che \\(B\\) sia vero. Indica quanto il dato sia compatibile con l’ipotesi.\n\n\\(P(B \\mid A)\\) (posterior): è la probabilità aggiornata, cioè la nostra nuova credenza sull’evento \\(B\\) dopo aver osservato il dato \\(A\\).\n\n\\(P(A)\\) (evidenza): è la probabilità marginale del dato osservato, calcolata sommando o integrando su tutte le possibili ipotesi alternative che potrebbero aver generato tale dato. Agisce da termine di normalizzazione per garantire che la somma delle probabilità a posteriori sia uguale a 1.\n\n6.1.3 Applicazioni della regola di Bayes\nNella pratica, l’inferenza bayesiana si svolge tipicamente nel seguente modo:\n\nSi parte da uno spazio delle ipotesi \\(\\mathcal{H}\\), ovvero un insieme di tutte le possibili spiegazioni o modelli che potrebbero aver generato i dati osservati \\(D\\).\nA ciascuna ipotesi \\(H \\in \\mathcal{H}\\) viene assegnata una probabilità a priori \\(P(H)\\) che riflette la nostra fiducia iniziale.\nUna volta raccolti i dati \\(D\\), aggiorniamo le probabilità delle ipotesi usando la formula:\n\n\\[\nP(H \\mid D) = \\frac{P(D \\mid H) \\, P(H)}{P(D)},\n\\tag{6.2}\\]\ndove:\n\n\n\\(P(D \\mid H)\\) è la verosimiglianza, cioè la probabilità che l’ipotesi \\(H\\) abbia generato i dati \\(D\\);\n\n\\(P(D)\\) è la probabilità marginale (evidenza), calcolata considerando tutte le possibili ipotesi:\n\n\\[\nP(D) = \\sum_{H' \\in \\mathcal{H}} P(D \\mid H')P(H'),\n\\]\nnel caso discreto, oppure:\n\\[\nP(D) = \\int_{\\mathcal{H}} P(D \\mid H')P(H') \\, dH',\n\\]\nnel caso continuo.\n\n\n\n\n\n\nEsempio\n\n\n\n\n\nImmagina di avere ricevuto un messaggio anonimo sul tuo cellulare con scritto solo “Ci vediamo stasera!”. Vuoi capire chi può essere stato a mandartelo. In questo esempio, il tuo “spazio delle ipotesi” sarà rappresentato da tre persone possibili: Alice, Bruno e Carla.\nQuindi, hai un insieme di ipotesi molto semplice:\n\\[\n\\mathcal{H} = \\{\\text{Alice},\\, \\text{Bruno},\\, \\text{Carla}\\} .\n\\]\n1. Probabilità a priori (prima di guardare i dati).\nSupponi che ciascuna persona abbia una probabilità diversa di scriverti:\n\n\nIpotesi\n\\(P(H)\\)\n\n\n\nAlice\n0.5\n\n\nBruno\n0.3\n\n\nCarla\n0.2\n\n\n\nQueste sono le tue probabilità a priori, basate sulla tua esperienza o conoscenza passata (ad esempio, Alice tende a scriverti spesso, Carla raramente).\n2. Come le ipotesi generano i dati (informazioni aggiuntive).\nOra raccogli alcune informazioni utili (i tuoi dati \\(D\\)):\n\nIl messaggio dice “Ci vediamo stasera!”.\n\nRifletti sul fatto che ciascuna delle tre persone usa questa frase con frequenze diverse (sai, ad esempio, che Alice usa spesso frasi brevi come questa, mentre Bruno e Carla la usano meno spesso, ovvero tendono a scrivere messaggi più lunghi):\n\n\n\n\n\n\nIpotesi\nProbabilità di inviare questa specifica frase (\\(P(D \\mid H)\\))\n\n\n\nAlice\n0.7\n\n\nBruno\n0.4\n\n\nCarla\n0.1\n\n\n\nQueste probabilità rappresentano il “meccanismo generatore dei dati”, ovvero come ciascuna persona (ipotesi) potrebbe generare proprio il messaggio che hai ricevuto.\n3. Aggiornamento delle probabilità a posteriori (dopo aver osservato il messaggio).\nOra applichiamo la formula di Bayes per aggiornare la nostra fiducia iniziale:\n\\[\nP(H \\mid D) = \\frac{P(D \\mid H) \\, P(H)}{P(D)} .\n\\]\nPrima calcoliamo la probabilità totale di ricevere quello specifico messaggio, indipendentemente da chi l’ha inviato. Usiamo il teorema della probabilità totale:\n\\[\nP(D) = P(D\\mid\\text{Alice})P(\\text{Alice}) + P(D\\mid\\text{Bruno})P(\\text{Bruno}) + P(D\\mid\\text{Carla})P(\\text{Carla}) .\n\\]\nCioè:\n\\[\nP(D) = (0.7 \\times 0.5) + (0.4 \\times 0.3) + (0.1 \\times 0.2)\n= 0.35 + 0.12 + 0.02\n= 0.49 .\n\\]\nOra aggiorniamo ciascuna ipotesi:\n\nAlice:\n\n\\[\nP(\\text{Alice}\\mid D) = \\frac{0.7\\times0.5}{0.49} = \\frac{0.35}{0.49} \\approx 0.714 .\n\\]\n\nBruno:\n\n\\[\nP(\\text{Bruno}\\mid D) = \\frac{0.4\\times0.3}{0.49} = \\frac{0.12}{0.49} \\approx 0.245 .\n\\]\n\nCarla:\n\n\\[\nP(\\text{Carla}\\mid D) = \\frac{0.1\\times0.2}{0.49} = \\frac{0.02}{0.49} \\approx 0.041 .\n\\]\n4. Interpretazione finale (intuizione bayesiana).\nDopo aver osservato il messaggio (“dati”), la tua fiducia si è aggiornata rispetto alle probabilità iniziali:\n\n\nIpotesi\nProbabilità a priori\nProbabilità a posteriori\n\n\n\nAlice\n0.5\n0.714\n\n\nBruno\n0.3\n0.245\n\n\nCarla\n0.2\n0.041\n\n\n\nOra credi molto più fortemente che sia stata Alice a scriverti.\nIn sintesi, in questo esempio semplice, lo spazio delle ipotesi era costituito da tre persone possibili. Ciascuna ipotesi poteva “generare” (cioè produrre o inviare) lo specifico messaggio che hai ricevuto con una diversa probabilità (“meccanismo generatore dei dati”). Prima dei dati avevi delle credenze su chi poteva averti scritto (“probabilità a priori”), poi lo specifico messaggio osservato (“i dati”) ha modificato le tue convinzioni (“probabilità a posteriori”), secondo la logica della Regola di Bayes.\nQuesto esempio chiarisce intuitivamente il significato di:\n\n\nspazio delle ipotesi (le possibili spiegazioni);\n\nmeccanismo generatore dei dati (la probabilità con cui ciascuna ipotesi produce il dato osservato);\n\naggiornamento bayesiano (come cambia la fiducia nelle ipotesi dopo aver visto i dati).\n\n\n\n\n\n6.1.4 Il processo iterativo dell’aggiornamento bayesiano\nL’inferenza bayesiana è intrinsecamente iterativa. Ogni volta che emergono nuovi dati, la distribuzione a posteriori \\(P(H \\mid D)\\) ottenuta diventa il nuovo prior per aggiornamenti successivi. Questo permette un affinamento continuo delle credenze, adattando la nostra comprensione del mondo in modo dinamico e coerente con le nuove evidenze.\n\n6.1.4.1 Considerazioni pratiche\nSpesso, il calcolo diretto della probabilità marginale \\(P(D)\\) — corrispondente, nell’esempio precedente, alla probabilità di osservare lo specifico messaggio ricevuto sul dispositivo mobile — risulta computazionalmente oneroso, in particolare quando lo spazio delle ipotesi è discreto o continuo di alta dimensionalità. Per ovviare a questa limitazione, vengono impiegati metodi numerici approssimativi come il Campionamento Monte Carlo o le inferenze variazionali, tecniche che permettono di stimare in modo efficiente tali grandezze probabilistiche anche in scenari reali complessi, senza ricorrere a calcoli analitici esatti.\nIn sintesi, la regola di Bayes fornisce uno schema formale e razionale per integrare informazioni pregresse con nuove osservazioni. Questa capacità di aggiornare continuamente le nostre credenze rappresenta il cuore del ragionamento probabilistico e rende l’approccio bayesiano uno strumento fondamentale in molte discipline scientifiche e applicazioni pratiche.\n\n\n\n\n\n\nEsempio\n\n\n\n\n\nImmaginiamo questo scenario: sospettiamo che una moneta possa essere truccata e vogliamo verificarlo attraverso due lanci. Utilizzeremo il ragionamento bayesiano per combinare le nostre convinzioni iniziali con i dati osservati.\nLe Due Ipotesi.\nSupponiamo che la moneta possa essere:\n\n\nbilanciata (pari probabilità di Testa e Croce: 50% ciascuna);\n\ntruccata (sbilanciata, con probabilità di Testa del 80% e Croce del 20%).\n\nIl nostro obiettivo è capire quale ipotesi sia più plausibile dopo ogni lancio.\nFase 1: credenze iniziali (prior).\nPrima di lanciare la moneta, abbiamo una certa idea di quanto sia probabile ciascuna ipotesi:\n\\[\nP(\\text{Bilanciata}) = 0.85 \\quad\\text{e}\\quad P(\\text{Truccata}) = 0.15.\n\\]\nQueste probabilità rappresentano il prior, ovvero le nostre convinzioni iniziali prima di osservare qualunque risultato.\nFase 2: primo lancio - esce Testa.\nLanciamo la moneta una volta e osserviamo il risultato: esce Testa.\nCi chiediamo: “Quanto è probabile osservare Testa se ciascuna delle due ipotesi fosse vera?”\n\nSe la moneta è bilanciata, la probabilità di osservare Testa è 0.5 (50%).\nSe la moneta è truccata, la probabilità di osservare Testa è 0.8 (80%).\n\nQueste due probabilità rappresentano la verosimiglianza:\n\\[\nP(\\text{Testa} \\mid \\text{Bilanciata}) = 0.5 \\quad\\text{e}\\quad P(\\text{Testa} \\mid \\text{Truccata}) = 0.8.\n\\]\nEvidenza: Probabilità Complessiva dell’Evento Osservato.\nVogliamo ora sapere quanto sia probabile osservare Testa in generale, considerando entrambe le ipotesi possibili. Per calcolarlo, usiamo la probabilità totale, che tiene conto di tutte le possibili ipotesi:\n\\[\nP(\\text{Testa}) = P(\\text{Testa} \\mid \\text{Bilanciata}) \\times P(\\text{Bilanciata}) + P(\\text{Testa} \\mid \\text{Truccata}) \\times P(\\text{Truccata}).\n\\]\nSostituiamo i valori numerici:\n\\[\nP(\\text{Testa}) = (0.5 \\times 0.85) + (0.8 \\times 0.15) = 0.425 + 0.12 = 0.545.\n\\]\nQuesta è la probabilità marginale o evidenza del risultato osservato.\nPosterior: Aggiornamento delle Credenze dopo l’Evidenza.\nOra possiamo usare il Teorema di Bayes per aggiornare le nostre credenze iniziali alla luce dell’evento osservato (Testa):\n\\[\n\\begin{aligned}\nP(\\text{Bilanciata} \\mid \\text{Testa}) &= \\frac{P(\\text{Testa} \\mid \\text{Bilanciata}) \\times P(\\text{Bilanciata})}{P(\\text{Testa})}\\notag\\\\\n&= \\frac{0.5 \\times 0.85}{0.545} \\notag\\\\\n&= 0.7798 \\quad (77.98\\%).\n\\end{aligned} \\notag\n\\]\n\\[\n\\begin{aligned}\nP(\\text{Truccata} \\mid \\text{Testa}) &= \\frac{P(\\text{Testa} \\mid \\text{Truccata}) \\times P(\\text{Truccata})}{P(\\text{Testa})} \\notag\\\\\n&= \\frac{0.8 \\times 0.15}{0.545} \\notag\\\\\n&= 0.2202 \\quad (22.02\\%). \\notag\n\\end{aligned}\n\\]\nInterpretazione Intuitiva.\nPrima del lancio, eravamo abbastanza sicuri (85%) che la moneta fosse bilanciata. Dopo aver osservato un singolo lancio che mostra Testa, questa certezza diminuisce (passa a circa 77.98%), mentre la probabilità che la moneta sia truccata aumenta (passa da 15% a circa 22.02%).\nQuesto esempio mostra come il prior, la verosimiglianza e l’evidenza si combinino nel ragionamento bayesiano per produrre un aggiornamento razionale e coerente delle credenze.\nFase 3: secondo Lancio - esce Testa.\nSupponiamo ora di lanciare la moneta una seconda volta, osservando ancora Testa. Usiamo le nuove probabilità ottenute (posterior) come prior aggiornati:\n\\[\nP(\\text{Bilanciata}) = 0.7798 \\quad\\text{e}\\quad P(\\text{Truccata}) = 0.2202.\n\\]\nCalcoliamo nuovamente l’evidenza:\n\\[\nP(\\text{Testa}) = (0.5 \\times 0.7798) + (0.8 \\times 0.2202) = 0.3899 + 0.1762 = 0.5661.\n\\]\nAggiorniamo quindi le credenze con il teorema di Bayes:\n\\[\nP(\\text{Bilanciata} \\mid \\text{Testa}) = \\frac{0.5 \\times 0.7798}{0.5661} = 0.6887 \\quad (68.87\\%).\n\\]\n\\[\nP(\\text{Truccata} \\mid \\text{Testa}) = \\frac{0.8 \\times 0.2202}{0.5661} = 0.3113 \\quad (31.13\\%).\n\\]\nInterpretazione del Secondo Aggiornamento.\nDopo il secondo lancio che mostra ancora Testa, la probabilità che la moneta sia bilanciata scende ulteriormente da 0.7798 a 0.6887, mentre la probabilità che la moneta sia truccata sale a 0.3113. Questo esempio mostra come l’aggiornamento bayesiano consenta di modificare progressivamente le nostre credenze, adattandole coerentemente a ogni nuova evidenza osservata.\n\n\n\n\n6.1.5 Applicazioni in psicologia\nNegli ultimi anni, i modelli bayesiani hanno acquisito un ruolo centrale nello studio della cognizione umana, fornendo una struttura formale per comprendere come il cervello costruisca rappresentazioni del mondo e prenda decisioni sulla base di dati incerti. Come discusso da Griffiths et al. (2024), questi modelli sono stati applicati a una vasta gamma di processi cognitivi, tra cui:\n\n\nApprendimento e generalizzazione: i modelli bayesiani descrivono come gli individui apprendano nuove categorie e concetti sulla base di dati limitati e rumorosi (Tenenbaum, Griffiths, & Kemp, 2006).\n\nPercezione e interpretazione sensoriale: la percezione visiva e il riconoscimento di oggetti possono essere spiegati come un’inferenza bayesiana sulla base di segnali sensoriali ambigui (Domini & Caudek, 2003; Yuille & Kersten, 2006).\n\nControllo motorio: il sistema motorio umano sembra ottimizzare i movimenti attraverso una combinazione di modelli interni e aggiornamenti bayesiani (Kording & Wolpert, 2006).\n\nMemoria e recupero delle informazioni: i processi mnemonici, come il richiamo della memoria semantica, possono essere modellati come inferenze bayesiane basate su conoscenze pregresse (Steyvers, Griffiths, & Dennis, 2006).\n\nAcquisizione del linguaggio: l’apprendimento del linguaggio nei bambini può essere descritto attraverso processi probabilistici che permettono di inferire le strutture grammaticali sulla base di dati linguistici limitati (Chater & Manning, 2006; Xu & Tenenbaum, in press).\n\nApprendimento causale: la capacità di inferire relazioni causali dagli eventi osservati è coerente con un modello bayesiano, in cui la mente valuta la probabilità di una relazione causale sulla base dell’evidenza disponibile (Griffiths & Tenenbaum, 2005, 2007).\n\nRagionamento e decisione: il ragionamento simbolico e il processo decisionale possono essere formalizzati come un aggiornamento bayesiano delle credenze sulla base di nuove informazioni (Oaksford & Chater, 2001).\n\nCognizione sociale: le inferenze sulle intenzioni e credenze altrui possono essere modellate attraverso processi bayesiani, permettendo di spiegare come le persone comprendano il comportamento altrui (Baker, Tenenbaum, & Saxe, 2007).\n\n\n6.1.5.1 L’inferenza bayesiana nella cognizione umana\nUn tema centrale che emerge da questi programmi di ricerca è la seguente domanda: come fa la mente umana ad andare oltre i dati dell’esperienza? In altre parole, come riesce il cervello a costruire modelli complessi del mondo a partire da informazioni limitate e spesso ambigue?\nL’approccio bayesiano propone che il cervello utilizzi un processo di inferenza probabilistica per aggiornare continuamente le proprie credenze, combinando informazioni pregresse con nuove osservazioni per affinare le proprie rappresentazioni mentali. Questo meccanismo consente di spiegare molte delle capacità cognitive umane, dall’apprendimento rapido di nuove categorie alla capacità di adattarsi a un ambiente mutevole, fino alla formulazione di inferenze sociali e alla presa di decisioni in condizioni di incertezza.\nL’adozione dei modelli bayesiani nella psicologia cognitiva ha portato a una nuova comprensione della mente come sistema predittivo, in grado di formulare ipotesi probabilistiche sugli eventi futuri e di correggerle dinamicamente sulla base dell’esperienza. Questo approccio ha profonde implicazioni per lo studio del comportamento umano e per lo sviluppo di nuove tecniche di modellizzazione nei campi della psicologia, delle neuroscienze e dell’intelligenza artificiale.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_bayes_theorem.html#test-medici",
    "href": "chapters/probability/05_bayes_theorem.html#test-medici",
    "title": "6  Il teorema di Bayes",
    "section": "\n6.2 Test medici",
    "text": "6.2 Test medici\nUno degli esempi più comuni per comprendere il teorema di Bayes riguarda i test diagnostici.\n\n\n\n\n\n\nEsempio\n\n\n\n\n\nConsideriamo un test di mammografia utilizzato per diagnosticare il cancro al seno che abbiamo già discusso nel Capitolo 5. Definiamo le seguenti ipotesi:\n\n\n\\(M^+\\): la persona ha il cancro al seno;\n\n\\(M^-\\): la persona non ha il cancro al seno.\n\nL’evidenza è il risultato positivo del test, indicato con \\(T^+\\). Il nostro obiettivo è calcolare la probabilità che una persona abbia il cancro al seno, dato un risultato positivo al test, ovvero \\(P(M^+ \\mid T^+)\\).\nDefinizione dei termini nella regola di Bayes.\nIl teorema di Bayes afferma che:\n\\[\nP(M^+ \\mid T^+) = \\frac{P(T^+ \\mid M^+) P(M^+)}{P(T^+)} ,\n\\]\ndove:\n\n\n\\(P(T^+ \\mid M^+)\\) è la sensibilità del test, cioè la probabilità che il test risulti positivo se la persona ha effettivamente il cancro. Nel nostro caso, \\(P(T^+ \\mid M^+) = 0.90\\).\n\n\\(P(M^+)\\) è la probabilità a priori di avere il cancro al seno, ovvero la prevalenza della malattia nella popolazione. Supponiamo che sia \\(P(M^+) = 0.01\\) (1%).\n\n\\(P(T^+ \\mid M^-)\\) è la probabilità di un falso positivo, cioè la probabilità che il test risulti positivo anche in assenza di malattia. Questa è complementare alla specificità del test:\n\n\\[\n  P(T^+ \\mid M^-) = 1 - \\text{Specificità} = 1 - 0.90 = 0.10.\n\\]\n\n\n\\(P(M^-)\\) è la probabilità a priori che una persona non abbia il cancro, ovvero:\n\n\\[\n  P(M^-) = 1 - P(M^+) = 1 - 0.01 = 0.99.\n\\]\n\n\n\\(P(T^+)\\) è la probabilità marginale che il test risulti positivo, calcolata considerando entrambe le possibilità (cioè che la persona abbia o non abbia il cancro):\n\n\\[\n  P(T^+) = P(T^+ \\mid M^+) P(M^+) + P(T^+ \\mid M^-) P(M^-).\n\\]\nSostituendo i valori numerici:\n\\[\n  P(T^+) = (0.90 \\cdot 0.01) + (0.10 \\cdot 0.99) = 0.009 + 0.099 = 0.108.\n\\]\nApplicazione della Regola di Bayes.\nOra possiamo calcolare la probabilità a posteriori \\(P(M^+ \\mid T^+)\\):\n\\[\nP(M^+ \\mid T^+) = \\frac{0.90 \\cdot 0.01}{0.108} = \\frac{0.009}{0.108} = 0.0833.\n\\]\nInterpretazione del Risultato.\nQuesto risultato indica che, nonostante il test abbia una sensibilità e una specificità del 90%, la probabilità che una persona con un test positivo abbia effettivamente il cancro è solo dell’8.3%. Questo effetto è dovuto alla bassa prevalenza della malattia: anche se il test è relativamente accurato, il numero di falsi positivi è ancora alto rispetto ai veri positivi. Tale risultato conferma quanto precedentemente ottenuto nel Capitolo 5, attraverso un metodo di calcolo alternativo.\nQuesta formulazione mostra come la regola di Bayes permetta di aggiornare la probabilità di avere la malattia dopo aver osservato il risultato del test, combinando la sensibilità, la specificità e la prevalenza della malattia nella popolazione.\n\n\n\nIn un secondo esempio, vogliamo valutare l’affidabilità di un test per l’HIV e capire come la nostra stima di infezione cambia dopo due test consecutivi positivi. Utilizzeremo la regola di Bayes per aggiornare la probabilità di avere l’HIV man mano che otteniamo nuovi risultati.\n\n\n\n\n\n\nEsempio\n\n\n\n\n\nImmaginiamo che una persona esegua due volte un test per l’HIV.\nNotazione e dati iniziali.\nIndichiamo con:\n\n\n\\(M^+\\): la persona ha l’HIV;\n\n\\(M^-\\): la persona non ha l’HIV;\n\n\\(T^+\\): il test è positivo;\n\n\\(T^-\\): il test è negativo.\n\nAbbiamo inoltre i seguenti dati:\n\nPrevalenza (probabilità a priori di avere l’HIV):\\[\nP(M^+) = 0.003 \\quad (0.3\\%).\n\\]\nSensibilità del test (probabilità che il test sia positivo se la persona è malata):\\[\nP(T^+ \\mid M^+) = 0.95.\n\\]\nSpecificità del test (probabilità che il test sia negativo se la persona è sana):\\[\nP(T^- \\mid M^-) = 0.9928 \\quad \\Longrightarrow \\quad P(T^+ \\mid M^-) = 0.0072.\n\\]\n\nPasso 1: dopo il primo test positivo.\nUsiamo la regola di Bayes per aggiornare la probabilità di essere malati, dopo un primo risultato positivo:\n\\[\nP(M^+ \\mid T^+) = \\frac{P(T^+ \\mid M^+)P(M^+)}{P(T^+)}.\n\\]\nCalcoliamo la probabilità marginale di un test positivo, considerando entrambe le ipotesi:\n\\[\nP(T^+) = P(T^+ \\mid M^+)P(M^+) + P(T^+ \\mid M^-)P(M^-).\n\\]\nSostituendo i valori noti, otteniamo:\n\\[\nP(T^+) = (0.95 \\times 0.003) + (0.0072 \\times 0.997) = 0.00285 + 0.00718 = 0.01003.\n\\]\nLa probabilità aggiornata (posterior) diventa quindi:\n\\[\nP(M^+ \\mid T^+) = \\frac{0.00285}{0.01003} \\approx 0.2844 \\quad (28.44\\%).\n\\]\nDopo un primo test positivo, la probabilità che la persona sia effettivamente HIV-positiva sale da un valore iniziale molto basso (0.3%) a 28.44%, aumentando notevolmente ma senza ancora garantire la certezza.\nPasso 2: aggiornamento dopo un secondo test positivo.\nAdesso immaginiamo di ripetere il test e ottenere nuovamente un risultato positivo. La nuova probabilità si calcola applicando ancora la regola di Bayes, utilizzando come prior il risultato appena trovato:\n\\[\nP(M^+ \\mid T_1^+, T_2^+) = \\frac{P(T_2^+ \\mid M^+, T_1^+)P(M^+ \\mid T_1^+)}{P(T_2^+ \\mid T_1^+)}.\n\\]\nAssumendo che i risultati dei test siano indipendenti dato lo stato di malattia o meno, possiamo semplificare:\n\n\\(P(T_2^+ \\mid M^+, T_1^+) = P(T^+ \\mid M^+) = 0.95\\)\n\\(P(T_2^+ \\mid M^-, T_1^+) = P(T^+ \\mid M^-) = 0.0072\\)\n\nLa probabilità di ottenere un secondo test positivo diventa quindi:\n\\[\nP(T_2^+ \\mid T_1^+) = P(T^+ \\mid M^+)P(M^+ \\mid T_1^+) + P(T^+ \\mid M^-)P(M^- \\mid T_1^+).\n\\]\nSostituendo i valori numerici calcolati in precedenza:\n\\[\nP(T_2^+ \\mid T_1^+) = (0.95 \\times 0.2844) + (0.0072 \\times 0.7156) = 0.2702 + 0.00515 = 0.27535.\n\\]\nOra calcoliamo la nuova probabilità a posteriori dopo due test positivi:\n\\[\nP(M^+ \\mid T_1^+, T_2^+) = \\frac{0.95 \\times 0.2844}{0.27535} \\approx 0.981 \\quad (98.1\\%).\n\\]\nInterpretazione finale.\n\nDopo il primo test positivo, la probabilità passa dallo 0.3% iniziale a circa il 28.44%, aumentando notevolmente ma restando incerta.\nDopo il secondo test positivo, la probabilità sale drasticamente al 98.1%, rendendo quasi certa la diagnosi.\n\nQuesto esempio dimostra chiaramente il valore dell’aggiornamento bayesiano: un singolo risultato positivo incrementa la probabilità, ma in presenza di una bassa prevalenza non basta per una diagnosi certa. Ripetere il test e ottenere conferme successive permette invece di raggiungere una certezza diagnostica molto elevata.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_bayes_theorem.html#la-fallacia-del-procuratore",
    "href": "chapters/probability/05_bayes_theorem.html#la-fallacia-del-procuratore",
    "title": "6  Il teorema di Bayes",
    "section": "\n6.3 La fallacia del procuratore",
    "text": "6.3 La fallacia del procuratore\nIl teorema di Bayes non trova applicazione solo in campo medico, ma è essenziale anche nei procedimenti giudiziari. Infatti, fraintendimenti nell’interpretazione di probabilità e statistiche possono portare a gravi errori di giudizio. Uno degli errori più comuni in questo contesto è la fallacia del procuratore.\n\n\n\n\n\n\nEsempio\n\n\n\n\n\nChe cos’è la fallacia del procuratore?\nLa fallacia del procuratore consiste nel confondere la probabilità di osservare una certa evidenza se una persona è innocente, \\(P(T^+ \\mid I)\\), con la probabilità che una persona sia innocente dopo aver osservato quella evidenza, \\(P(I \\mid T^+)\\).\n\nIn termini giudiziari, questo equivale a dire: “Poiché è estremamente improbabile ottenere un certo riscontro (ad es. un test positivo) se la persona è innocente, allora è estremamente improbabile che la persona sia innocente se si è ottenuto un esito positivo”.\nIn realtà, per stabilire se la persona è innocente o colpevole dopo aver visto il risultato, occorre considerare sia la bassa frequenza delle persone effettivamente colpevoli nella popolazione (prevalenza) sia la possibilità di falsi positivi. Il teorema di Bayes fornisce lo strumento formale per integrare questi elementi.\n\nConsideriamo il seguente esempio. Supponiamo di utilizzare un test del DNA per identificare un sospetto tra 65 milioni di persone. Il test ha:\n\n\nSensibilità (\\(P(T^+ \\mid C)\\)) = 99%\\(\\rightarrow\\) Se la persona è effettivamente colpevole, il test risulta positivo il 99% delle volte.\n\nSpecificità (\\(P(T^- \\mid I)\\)) = 99.99997%\\(\\rightarrow\\) Se la persona è innocente, il test risulta negativo il 99.99997% delle volte.\nDa cui segue che il tasso di falso positivo è \\(1 - 0.9999997 = 0.0000003 = 0.00003\\%\\).\n\nPrevalenza (\\(P(C)\\)) = \\(1/65{,}000{,}000 \\approx 1.54 \\times 10^{-8}\\)\\(\\rightarrow\\) Un individuo scelto a caso ha una probabilità di circa \\(1.54 \\times 10^{-8}\\) (cioè 1 su 65 milioni) di essere il vero colpevole.\n\nUn campione di DNA coincide con quello di una persona trovata nel database e il test dà risultato positivo. Qual è la probabilità che costui sia davvero colpevole? Formalmente, vogliamo \\(P(C \\mid T^+)\\).\nPasso 1: Calcolare \\(P(T^+)\\), la probabilità di un test positivo.\nLa probabilità complessiva di un esito positivo deriva da due scenari alternativi:\n\n\nLa persona è colpevole e il test è positivo:\\(P(T^+ \\mid C) \\times P(C)\\).\n\nLa persona è innocente e il test è positivo per errore (falso positivo):\\(P(T^+ \\mid I) \\times P(I)\\).\n\nPerciò, usando la regola della probabilità totale:\n\\[\nP(T^+)\n= P(T^+ \\mid C) \\, P(C) \\;+\\; P(T^+ \\mid I) \\, P(I).\n\\]\nAssegniamo i valori numerici:\n\n\n\\(P(T^+ \\mid C) = 0.99\\) (sensibilità).\n\n\\(P(C) = 1.54 \\times 10^{-8}\\).\n\n\\(P(T^+ \\mid I) = 1 - P(T^- \\mid I) = 1 - 0.9999997 = 0.0000003\\).\n\n\\(P(I) = 1 - P(C) \\approx 0.99999998\\).\n\nEseguiamo il calcolo:\n\\[\n\\begin{aligned}\nP(T^+)\n&= (0.99 \\times 1.54 \\times 10^{-8}) + (0.0000003 \\times 0.99999998)\\\\\n&= 1.5231 \\times 10^{-8} + 2.9999994 \\times 10^{-7}\\\\\n&= 3.1523 \\times 10^{-7}.\n\\end{aligned}\n\\]\nPasso 2: Applicare la regola di Bayes per \\(P(C \\mid T^+)\\).\nOra possiamo calcolare la probabilità di essere colpevoli dato che il test è positivo:\n\\[\nP(C \\mid T^+)\n= \\frac{P(T^+ \\mid C)\\,P(C)}{P(T^+)}.\n\\]\nInseriamo i valori:\n\\[\n\\begin{aligned}\nP(C \\mid T^+)\n&= \\frac{(0.99 \\times 1.54 \\times 10^{-8})}{3.1523 \\times 10^{-7}}\\\\\n&= \\frac{1.5231 \\times 10^{-8}}{3.1523 \\times 10^{-7}}\\\\\n&\\approx 0.0483 \\quad (\\text{cioè } 4.83\\%).\n\\end{aligned}\n\\]\nInterpretazione: perché è “solo” il 4.83%?\nSebbene sensibilità e specificità del test siano entrambe molto alte, la prevalenza estremamente bassa del colpevole (1 su 65 milioni) riduce notevolmente la probabilità a posteriori \\(P(C \\mid T^+)\\). In una popolazione di 65 milioni di individui, anche un esiguo tasso di falsi positivi (\\(0.0000003\\)) genera un numero assoluto di risultati positivi fra gli innocenti molto più grande del numero di colpevoli reali.\nIn pratica, pur avendo un test positivo, la probabilità che la persona sia davvero colpevole resta modesta (circa 4.83%), perché i “falsi allarmi” nella massa di individui innocenti superano di gran lunga i (pochi) veri positivi.\nEvitare la fallacia del procuratore.\nLa fallacia del procuratore consiste nel confondere:\n\n\n\\(P(T^+ \\mid I)\\): la probabilità che un innocente risulti positivo (falso positivo),\n\n\\(P(I \\mid T^+)\\): la probabilità di essere innocenti dopo un test positivo.\n\nQuesta confusione porta a sovrastimare la colpevolezza di un individuo basandosi su una singola evidenza statistica. Applicando il teorema di Bayes, invece, si comprende che un test positivo non implica automaticamente colpevolezza, soprattutto quando la malattia (o il reato, in questo caso) è molto raro. Nei processi giudiziari, ciò significa che un dato probabilistico deve sempre essere contestualizzato alla popolazione di riferimento: la corretta interpretazione delle prove è fondamentale per evitare errori giudiziari.\nConclusione epistemologica.\nL’impiego di test probabilistici in ambito giudiziario richiede un’applicazione rigorosa del teorema di Bayes per evitare distorsioni interpretative. Solo un corretto aggiornamento delle credenze, integrando:\n\n\nla probabilità pre-test (\\(P(C)\\), prevalenza del colpevole nella popolazione investigata),\n\n\nla potenza diagnostica del test (sensibilità e specificità),\n\n\nil tasso di errore strumentale (falsi positivi e falsi negativi),\n\nconsente di ridurre il rischio di errori giudiziari sistematici. In assenza di questa integrazione, anche test estremamente precisi possono condurre a ingiuste condanne, trasformando strumenti scientifici affidabili in fonti di distorsione probatoria.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_bayes_theorem.html#la-probabilità-inversa",
    "href": "chapters/probability/05_bayes_theorem.html#la-probabilità-inversa",
    "title": "6  Il teorema di Bayes",
    "section": "\n6.4 La probabilità inversa",
    "text": "6.4 La probabilità inversa\nGli esempi precedenti mostrano due tipi di domande probabilistiche fondamentali:\n\n\nProbabilità diretta\n\n“Qual è la probabilità di osservare un certo risultato, supponendo che l’ipotesi sia vera?”\n\n\n\nProbabilità inversa\n\n“Qual è la probabilità che un’ipotesi sia vera, dati i risultati osservati?”\n\n\n\nQuesta distinzione è cruciale per comprendere il teorema di Bayes e le differenze tra l’approccio frequentista e quello bayesiano alla probabilità.\n\n6.4.1 Esempi\nPrendiamo come esempio il lancio di una moneta:\n\nProbabilità diretta:\nSe riteniamo che la moneta sia equa (cioè \\(P(\\text{Testa}) = 0{.}5\\)), qual è la probabilità di osservare zero teste in cinque lanci? In questo caso, stiamo calcolando \\[\nP(D \\mid H) = (0.5)^5 = 0.03125,\n\\] dove \\(D\\) rappresenta il dato (“zero teste in cinque lanci”) e \\(H\\) l’ipotesi (“la moneta è equa”).\nProbabilità inversa:\nOra poniamo la domanda opposta. Abbiamo lanciato una moneta cinque volte e osservato zero teste. Quanto è probabile che la moneta sia davvero equa? Qui vogliamo conoscere \\(\\displaystyle P(H \\mid D)\\) (l’ipotesi “la moneta è equa” dopo aver visto il risultato) anziché \\(P(D \\mid H)\\). Per rispondere correttamente, ci occorre il teorema di Bayes, che combina la probabilità dei dati (\\(P(D \\mid H)\\)) con una stima iniziale (il prior) su quanto riteniamo probabile l’ipotesi prima dell’osservazione.\n\n6.4.2 Dalla probabilità diretta alla probabilità inversa: il contributo di Bayes\nPer lungo tempo, la teoria della probabilità si è occupata quasi esclusivamente di probabilità diretta: “se l’ipotesi è vera, qual è la probabilità di osservare un certo esito?”. Nel XVIII secolo, Thomas Bayes capovolse la prospettiva, concentrandosi su come determinare la probabilità dell’ipotesi a partire dalle evidenze disponibili, introdusse cioè l’idea di probabilità inversa. Questa svolta ha aperto la strada a ciò che oggi chiamiamo inferenza bayesiana, permettendo di aggiornare in modo sistematico e rigoroso la credibilità di un’ipotesi dopo aver osservato nuovi dati.\n\n6.4.3 L’impatto della probabilità inversa\nLa possibilità di stimare \\(\\displaystyle P(H \\mid D)\\), cioè la probabilità di un’ipotesi data l’evidenza osservata, si è rivelata fondamentale in molti ambiti:\n\n\nScienza e sperimentazione: quanto è probabile che un’ipotesi sia vera dopo aver raccolto i dati di un esperimento?\n\n\nMedicina: quanto è probabile che un paziente abbia una certa malattia, se il test diagnostico è positivo?\n\n\nGiustizia: quanto è probabile che una persona sia colpevole, se il DNA trovato sulla scena del crimine combacia col suo?\n\nIn tutti questi casi non basta calcolare la probabilità dei dati “dato un’ipotesi” \\(\\bigl(P(D \\mid H)\\bigr)\\); occorre invece aggiornare la stima della probabilità dell’ipotesi alla luce dei dati \\(\\bigl(P(H \\mid D)\\bigr)\\).\nIn sintesi, l’inferenza bayesiana risponde appunto a questa seconda domanda, passando dalla probabilità diretta alla probabilità inversa in modo rigoroso. Grazie al teorema di Bayes, possiamo combinare in modo coerente le nostre conoscenze pregresse (il cosiddetto prior) con le evidenze raccolte, ottenendo una probabilità a posteriori che rappresenta la nostra nuova convinzione. Senza questa prospettiva, gran parte dei problemi scientifici e delle decisioni pratiche resterebbe priva di un metodo per collegare razionalmente le evidenze empiriche alle ipotesi da verificare.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_bayes_theorem.html#riflessioni-conclusive",
    "href": "chapters/probability/05_bayes_theorem.html#riflessioni-conclusive",
    "title": "6  Il teorema di Bayes",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn questo capitolo abbiamo esplorato vari esempi, principalmente nel campo medico e forense, per illustrare come il teorema di Bayes permetta di combinare le informazioni derivate dalle osservazioni con le conoscenze precedenti (priori), aggiornando così il nostro grado di convinzione rispetto a un’ipotesi. Il teorema di Bayes fornisce un meccanismo razionale, noto come “aggiornamento bayesiano”, che ci consente di ricalibrare le nostre convinzioni iniziali alla luce di nuove evidenze.\nUna lezione fondamentale che il teorema di Bayes ci insegna, sia nella ricerca scientifica che nella vita quotidiana, è che spesso non ci interessa tanto conoscere la probabilità che qualcosa accada assumendo vera un’ipotesi, quanto piuttosto la probabilità che un’ipotesi sia vera, dato che abbiamo osservato una certa evidenza. In altre parole, la forza del teorema di Bayes sta nella sua capacità di affrontare direttamente il problema inverso, cioè come dedurre la verità di un’ipotesi a partire dalle osservazioni.\nIl framework bayesiano per l’inferenza probabilistica offre un approccio generale per comprendere come i problemi di induzione possano essere risolti in linea di principio e, forse, anche come possano essere affrontati dalla mente umana.\nIn questo capitolo ci siamo concentrati sull’applicazione del teorema di Bayes utilizzando probabilità puntuali. Tuttavia, il teorema esprime pienamente il suo potenziale quando sia l’evidenza che i gradi di certezza a priori delle ipotesi sono rappresentati attraverso distribuzioni di probabilità continue. Questo sarà l’argomento centrale nella prossima sezione della dispensa, dove approfondiremo il flusso di lavoro bayesiano e l’uso di distribuzioni continue nell’aggiornamento bayesiano.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_bayes_theorem.html#esercizi",
    "href": "chapters/probability/05_bayes_theorem.html#esercizi",
    "title": "6  Il teorema di Bayes",
    "section": "Esercizi",
    "text": "Esercizi\nÈ facile trovare online esercizi sull’applicazione del teorema di Bayes. Ad esempio, consiglio gli esercizi 1–6 disponibili sulla seguente pagina web.\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt;  [4] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt;  [7] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [10] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [13] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [16] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [25] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.8          tidyselect_1.2.1      farver_2.1.2         \n#&gt;  [4] fastmap_1.2.0         TH.data_1.1-4         tensorA_0.36.2.1     \n#&gt;  [7] digest_0.6.37         timechange_0.3.0      estimability_1.5.1   \n#&gt; [10] lifecycle_1.0.4       survival_3.8-3        magrittr_2.0.3       \n#&gt; [13] compiler_4.5.1        rlang_1.1.6           tools_4.5.1          \n#&gt; [16] knitr_1.50            bridgesampling_1.1-2  htmlwidgets_1.6.4    \n#&gt; [19] curl_7.0.0            pkgbuild_1.4.8        RColorBrewer_1.1-3   \n#&gt; [22] abind_1.4-8           multcomp_1.4-28       withr_3.0.2          \n#&gt; [25] purrr_1.1.0           grid_4.5.1            stats4_4.5.1         \n#&gt; [28] colorspace_2.1-1      xtable_1.8-4          inline_0.3.21        \n#&gt; [31] emmeans_1.11.2-8      scales_1.4.0          MASS_7.3-65          \n#&gt; [34] cli_3.6.5             mvtnorm_1.3-3         rmarkdown_2.29       \n#&gt; [37] ragg_1.5.0            generics_0.1.4        RcppParallel_5.1.11-1\n#&gt; [40] cachem_1.1.0          stringr_1.5.1         splines_4.5.1        \n#&gt; [43] parallel_4.5.1        vctrs_0.6.5           V8_7.0.0             \n#&gt; [46] Matrix_1.7-4          sandwich_3.1-1        jsonlite_2.0.0       \n#&gt; [49] arrayhelpers_1.1-0    systemfonts_1.2.3     glue_1.8.0           \n#&gt; [52] codetools_0.2-20      distributional_0.5.0  lubridate_1.9.4      \n#&gt; [55] stringi_1.8.7         gtable_0.3.6          QuickJSR_1.8.0       \n#&gt; [58] htmltools_0.5.8.1     Brobdingnag_1.2-9     R6_2.6.1             \n#&gt; [61] textshaping_1.0.3     rprojroot_2.1.1       evaluate_1.0.5       \n#&gt; [64] lattice_0.22-7        backports_1.5.0       memoise_2.0.1        \n#&gt; [67] broom_1.0.9           snakecase_0.11.1      rstantools_2.5.0     \n#&gt; [70] coda_0.19-4.1         gridExtra_2.3         nlme_3.1-168         \n#&gt; [73] checkmate_2.3.3       xfun_0.53             zoo_1.8-14           \n#&gt; [76] pkgconfig_2.0.3",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_bayes_theorem.html#bibliografia",
    "href": "chapters/probability/05_bayes_theorem.html#bibliografia",
    "title": "6  Il teorema di Bayes",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBaker, C., Saxe, R., & Tenenbaum, J. (2011). Bayesian theory of mind: Modeling joint belief-desire attribution. Proceedings of the annual meeting of the cognitive science society, 33.\n\n\nBellhouse, D. R. (2004). The Reverend Thomas Bayes, FRS: a biography to celebrate the tercentenary of his birth.\n\n\nCaudek, C., & Bruno, N. (2024). Fenomeni stereocinetici, teorie della percezione e sociologia della scienza. Giornale italiano di psicologia, 51(3), 451–466.\n\n\nChivers, T. (2024). Everything is Predictable: How Bayesian Statistics Explain Our World. Simon; Schuster.\n\n\nDomini, F., & Caudek, C. (2003). 3-D structure perceived from dynamic information: A new theory. Trends in Cognitive Sciences, 7(10), 444–449.\n\n\nGriffiths, T. L., Chater, N., & Tenenbaum, J. B. (2024). Bayesian models of cognition: reverse engineering the mind. MIT Press.\n\n\nJesseph, D. M. (1993). Berkeley’s philosophy of mathematics. University of Chicago Press.\n\n\nMa, W. J., Kording, K. P., & Goldreich, D. (2023). Bayesian models of perception and action: An introduction. MIT press.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:\n\n\nSpiegelhalter, D. (2019). The art of statistics: Learning from data. Penguin UK.\n\n\nStigler, S. M. (1990). The history of statistics: The measurement of uncertainty before 1900. Harvard University Press.\n\n\nYuille, A., & Kersten, D. (2006). Vision as Bayesian inference: analysis by synthesis? Trends in cognitive sciences, 10(7), 301–308.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_random_var.html",
    "href": "chapters/probability/06_random_var.html",
    "title": "7  Variabili casuali",
    "section": "",
    "text": "Introduzione\nFino ad ora abbiamo studiato le probabilità associate a eventi, come la possibilità di vincere il gioco di Monty Hall o di avere una rara condizione medica in seguito a un test positivo. Tuttavia, in molte situazioni pratiche vogliamo conoscere aspetti più dettagliati. Ad esempio, potremmo chiederci:\nPer rispondere a tali domande è necessario lavorare con le variabili casuali. In questo capitolo introdurremo il concetto di variabile casuale e ne analizzeremo le proprietà fondamentali.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_random_var.html#introduzione",
    "href": "chapters/probability/06_random_var.html#introduzione",
    "title": "7  Variabili casuali",
    "section": "",
    "text": "quanti tentativi occorrono affinché, in un gioco simile a Monty Hall, un concorrente vinca?\nquanto durerà un determinato evento o condizione?\nqual è la perdita attesa giocando d’azzardo con un dado sbilanciato per molte ore?\n\n\nPanoramica del capitolo\n\nLe definizioni e le caratteristiche delle variabili casuali discrete e continue, e le relative distribuzioni di probabilità;\nCome calcolare e interpretare il valore atteso di variabili casuali, sia discrete che continue.\nDeterminare e comprendere la varianza e la deviazione standard di variabili casuali.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\nPer seguire al meglio questo capitolo, è consigliato aver letto i seguenti riferimenti:\n\nl’appendice Appendice F;\nil capitolo Random Variables and Probability Distributions in Chan & Kroese (2025);\nil capitolo Random variables and their distributions in Blitzstein & Hwang (2019);\n\nil capitolo Random Variables and Distributions in Schervish & DeGroot (2014).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_random_var.html#definizione-di-variabile-casuale",
    "href": "chapters/probability/06_random_var.html#definizione-di-variabile-casuale",
    "title": "7  Variabili casuali",
    "section": "\n7.1 Definizione di variabile casuale",
    "text": "7.1 Definizione di variabile casuale\nUna variabile casuale è una funzione che associa ogni elemento di uno spazio campionario a un valore numerico. Questo strumento permette di trasformare esiti qualitativi (ad esempio, il risultato di un lancio di carte, come cuori, quadri, fiori, picche) in valori numerici, facilitando così l’analisi matematica.\n\nDefinizione 7.1 Sia \\(S\\) lo spazio campionario di un esperimento aleatorio. Una variabile casuale \\(X\\) è una funzione\\[\nX: S \\longrightarrow \\mathbb{R},\n\\] che associa ad ogni esito \\(s \\in S\\) un numero reale \\(X(s)\\).\n\n\n\n\n\n\n\nEsempio\n\n\n\n\n\nLanciamo due dadi equilibrati e annotiamo la somma dei valori delle loro facce. Ogni lancio genera una coppia di valori \\((i,j)\\), dove \\(i\\) è il risultato del primo dado e \\(j\\) il risultato del secondo dado. Lo spazio campionario completo dei possibili esiti è:\n\\[\n\\Omega = \\{(1,1), (1,2), \\dots, (6,5), (6,6)\\}.\n\\]\nDefiniamo una variabile casuale \\(X\\) che associa ciascun esito \\((i,j)\\) alla somma dei valori ottenuti dai due dadi, cioè:\n\\[\nX(i,j) = i + j.\n\\]\nAd esempio, se il primo dado mostra 4 e il secondo dado mostra 4, allora l’esito è \\((4,4)\\) e la variabile casuale \\(X\\) assume il valore 8.\n\n\nLa variabile aleatoria \\(X\\) rappresenta la somma di due dadi (figura tratta da Chan & Kroese, 2025).\n\nConsideriamo il valore specifico \\(X=8\\): questo valore può essere ottenuto attraverso cinque diversi esiti dello spazio campionario: \\((2,6), (3,5), (4,4), (5,3), (6,2)\\). Indichiamo con \\(\\{X=8\\}\\) l’insieme di questi esiti. Poiché tutti gli esiti in \\(\\Omega\\) sono equiprobabili, possiamo calcolare la probabilità di ottenere una somma pari a 8 come:\n\\[\nP(X=8) = \\frac{5}{36}.\n\\]",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_random_var.html#tipologie-di-variabili-casuali",
    "href": "chapters/probability/06_random_var.html#tipologie-di-variabili-casuali",
    "title": "7  Variabili casuali",
    "section": "\n7.2 Tipologie di variabili casuali",
    "text": "7.2 Tipologie di variabili casuali\nLe variabili casuali si dividono in due categorie principali:\n\n7.2.1 Variabili casuali discrete\nUna variabile casuale discreta assume un insieme finito o numerabile di valori. Gli esempi includono il numero di teste ottenute in lanci di moneta o la somma dei risultati di due dadi. Per queste variabili, la funzione di massa di probabilità (PMF) assegna a ciascun valore \\(x\\) la probabilità \\(P(X = x)\\).\n\nEsempio 7.1 Nel lancio di due dadi, la variabile \\(X\\) (somma dei punti) può assumere valori interi da 2 a 12. La distribuzione di \\(X\\) si ottiene contando i casi favorevoli per ciascun valore e dividendo per il numero totale di esiti (36).\n\n\n7.2.2 Variabili casuali continue\nUna variabile casuale continua può assumere infiniti valori in un intervallo (ad esempio, l’altezza di una persona). In questo caso non si assegna una probabilità a un singolo valore (che risulterebbe essere zero), ma si definisce una funzione di densità di probabilità (PDF), tale che l’integrale della funzione su un intervallo fornisce la probabilità che la variabile cada in quell’intervallo.\n\nEsempio 7.2 Considera una variabile \\(X\\) che rappresenta l’altezza in centimetri. Invece di \\(P(X = 170)\\), calcoliamo probabilità come \\(P(170 \\leq X \\leq 180)\\) mediante l’integrale della PDF in quell’intervallo.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_random_var.html#notazione-convenzionale",
    "href": "chapters/probability/06_random_var.html#notazione-convenzionale",
    "title": "7  Variabili casuali",
    "section": "\n7.3 Notazione convenzionale",
    "text": "7.3 Notazione convenzionale\nNella teoria della probabilità si adotta una convenzione chiara per distinguere una variabile casuale dal suo valore osservato o realizzato:\n\nla variabile casuale viene indicata con lettere maiuscole (es. \\(X\\));\nil valore specifico assunto dalla variabile casuale viene indicato con lettere minuscole (es. \\(x\\)).\n\nQuesta convenzione aiuta a evitare ambiguità, soprattutto quando si definiscono:\n\nprobabilità cumulative: \\(P(X \\leq x)\\);\nvalore atteso: \\(E[X]\\);\nfunzioni di densità o massa di probabilità: \\(f_X(x)\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_random_var.html#variabili-casuali-multiple",
    "href": "chapters/probability/06_random_var.html#variabili-casuali-multiple",
    "title": "7  Variabili casuali",
    "section": "\n7.4 Variabili casuali multiple",
    "text": "7.4 Variabili casuali multiple\nIn molti esperimenti, è utile considerare contemporaneamente più variabili casuali. Ad esempio, supponiamo di lanciare una moneta equilibrata tre volte. Definiamo tre variabili casuali indipendenti \\(X_1\\), \\(X_2\\) e \\(X_3\\), ciascuna associata all’esito di un lancio:\n\\[\nP(X_n = 1) = 0.5 \\quad (\\text{testa}), \\qquad P(X_n = 0) = 0.5 \\quad (\\text{croce}), \\quad n = 1, 2, 3.\n\\]\nPossiamo poi definire una nuova variabile casuale derivata, ad esempio:\n\\[\nZ = X_1 + X_2 + X_3,\n\\]\nche rappresenta il numero totale di teste ottenute nei tre lanci. In questo scenario, \\(Z\\) è una variabile casuale discreta che può assumere esclusivamente i valori 0, 1, 2 o 3.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_random_var.html#distribuzione-di-probabilità",
    "href": "chapters/probability/06_random_var.html#distribuzione-di-probabilità",
    "title": "7  Variabili casuali",
    "section": "\n7.5 Distribuzione di probabilità",
    "text": "7.5 Distribuzione di probabilità\n\nDefinizione 7.2 La distribuzione di probabilità di una variabile casuale descrive come le probabilità sono assegnate ai possibili valori (o intervalli di valori) della variabile.\n\n\n7.5.1 Funzione di massa di probabilità (PMF) per variabili discrete\nPer una variabile casuale discreta \\(X\\), la distribuzione è definita tramite la funzione di massa di probabilità (PMF), indicata con \\(f(x)\\), dove:\n\\[\nf(x) = P(X = x).\n\\]\nNota la PMF, è possibile calcolare la probabilità di qualsiasi evento associato a \\(X\\). Ad esempio, per un insieme \\(B\\) di valori:\n\\[\nP(X \\in B) = \\sum_{x \\in B} f(x).\n\\]\n\n\n\n\n\n\nEsempio\n\n\n\n\n\nConsideriamo nuovamente il lancio di due dadi, definendo \\(X\\) come la somma dei loro valori. La tabella seguente mostra chiaramente tutti i casi possibili, il numero di combinazioni per ogni somma, e la relativa probabilità:\n\n\n\n\n\n\n\n\n\\(X\\)\nCasi Favorevoli\nNumero di Casi\n\\(P(X = x)\\)\n\n\n\n2\n\\((1,1)\\)\n1\n\\(\\frac{1}{36}\\)\n\n\n3\n\\((1,2), (2,1)\\)\n2\n\\(\\frac{2}{36} = \\frac{1}{18}\\)\n\n\n4\n\\((1,3), (2,2), (3,1)\\)\n3\n\\(\\frac{3}{36} = \\frac{1}{12}\\)\n\n\n5\n\\((1,4), (2,3), (3,2), (4,1)\\)\n4\n\\(\\frac{4}{36} = \\frac{1}{9}\\)\n\n\n6\n\\((1,5), (2,4), (3,3), (4,2), (5,1)\\)\n5\n\\(\\frac{5}{36}\\)\n\n\n7\n\\((1,6), (2,5), (3,4), (4,3), (5,2), (6,1)\\)\n6\n\\(\\frac{6}{36} = \\frac{1}{6}\\)\n\n\n8\n\\((2,6), (3,5), (4,4), (5,3), (6,2)\\)\n5\n\\(\\frac{5}{36}\\)\n\n\n9\n\\((3,6), (4,5), (5,4), (6,3)\\)\n4\n\\(\\frac{4}{36} = \\frac{1}{9}\\)\n\n\n10\n\\((4,6), (5,5), (6,4)\\)\n3\n\\(\\frac{3}{36} = \\frac{1}{12}\\)\n\n\n11\n\\((5,6), (6,5)\\)\n2\n\\(\\frac{2}{36} = \\frac{1}{18}\\)\n\n\n12\n\\((6,6)\\)\n1\n\\(\\frac{1}{36}\\)\n\n\n\nPer esempio, la probabilità di ottenere una somma pari a 7 è \\(\\frac{1}{6}\\) perché ci sono 6 combinazioni favorevoli su 36 possibili.\n\n\n\n\n7.5.2 Funzione di distribuzione cumulativa (CDF)\n\nDefinizione 7.3 La funzione di distribuzione cumulativa (CDF) di una variabile casuale \\(X\\) è definita come: \\[\nF(x) = P(X \\leq x).\n\\] La CDF indica la probabilità che \\(X\\) assuma valori minori o uguali a un valore specifico \\(x\\).\n\n\n7.5.3 Proprietà della CDF (funzione di ripartizione)\nLa CDF descrive la probabilità che una variabile casuale \\(X\\) assuma un valore minore o uguale a \\(x\\). Per capirla in psicologia (ad esempio, per analizzare dati di test, questionari, o esperimenti), bastano tre idee chiave:\n\n\nNon diminuisce mai:\nSe consideriamo valori \\(x\\) sempre più grandi, la probabilità cumulata non può diminuire.\n\n\nEsempio: Se la CDF a \\(x = 50\\) in un test è \\(0.7\\), a \\(x = 60\\) sarà almeno \\(0.7\\) (potrebbe salire, ma non scendere).\n\n\nPerché? Aggiungendo nuovi risultati (es.: punteggi più alti), la probabilità totale può solo aumentare o restare uguale.\n\n\n\nEstremi prevedibili:\n\nPer valori molto bassi (es.: \\(x \\to -\\infty\\)), la probabilità cumulata è 0: non esistono punteggi infinitamente bassi.\n\nPer valori molto alti (es.: \\(x \\to +\\infty\\)), la probabilità cumulata è 1: tutti i possibili risultati sono inclusi.\n\n\nEsempio: In una scala Likert da 1 a 5, la CDF a \\(x = 0\\) è 0, e a \\(x = 10\\) è 1.\n\n\n\nNiente salti “a sorpresa” verso destra:\nLa CDF è costruita in modo che, se ci spostiamo di pochissimo a destra di un punto \\(x\\), la probabilità cumulata non crolla improvvisamente.\n\n\nEsempio:\nSupponiamo che in un questionario, il punteggio \\(x = 10\\) corrisponda a una certa probabilità cumulata (es.: \\(0.8\\)). Se ci spostiamo di un millesimo a destra (es.: \\(x = 10.001\\)), la probabilità rimane \\(0.8\\), a meno che \\(10.001\\) non sia un punteggio valido.\n\n\nA cosa serve? Garantisce coerenza: se un punteggio \\(x\\) ha una certa probabilità, questa non viene “persa” spostandosi di poco a destra.\n\n\n\n7.5.4 CDF per variabili discrete\nIn psicologia, spesso lavoriamo con dati discreti (es.: risposte a item di un test, come “1 = Mai” a “5 = Sempre”). In questi casi:\n\nLa CDF si calcola sommando le probabilità di tutti i valori \\(\\leq x\\).\n\n\nEsempio: Se in una scala da 1 a 5, il 30% degli studenti risponde 1 o 2, allora \\(F(2) = 0.3\\).\n\n\nGraficamente: La CDF avrà “gradini” nei punti corrispondenti ai valori possibili (es.: 1, 2, 3, 4, 5).\n\n\n7.5.4.1 Perché serve saperlo?\nQueste proprietà aiutano a:\n\nInterpretare grafici cumulativi (es.: quanto è probabile che un partecipante abbia un punteggio \\(\\leq\\) 20?).\n\nEvitare errori logici (es.: non ha senso aspettarsi un calo della probabilità cumulata all’aumentare di \\(x\\)).\n\nLeggere correttamente salti nei dati discreti (es.: un gradino in \\(x = 4\\) indica un accumulo di probabilità in quel punto).\n\n\n\n\n\n\n\nEsempio\n\n\n\n\n\nRiprendendo l’esempio della variabile casuale \\(X\\) definita come la somma di due dadi, possiamo riassumere PMF e CDF in una tabella unica:\n\n\n\\(x\\)\n\\(P(X = x)\\)\n\\(F(x)\\)\n\n\n\n2\n\\(\\frac{1}{36}\\)\n\\(\\frac{1}{36}\\)\n\n\n3\n\\(\\frac{2}{36}\\)\n\\(\\frac{3}{36}\\)\n\n\n4\n\\(\\frac{3}{36}\\)\n\\(\\frac{6}{36}\\)\n\n\n5\n\\(\\frac{4}{36}\\)\n\\(\\frac{10}{36}\\)\n\n\n6\n\\(\\frac{5}{36}\\)\n\\(\\frac{15}{36}\\)\n\n\n7\n\\(\\frac{6}{36}\\)\n\\(\\frac{21}{36}\\)\n\n\n8\n\\(\\frac{5}{36}\\)\n\\(\\frac{26}{36}\\)\n\n\n9\n\\(\\frac{4}{36}\\)\n\\(\\frac{30}{36}\\)\n\n\n10\n\\(\\frac{3}{36}\\)\n\\(\\frac{33}{36}\\)\n\n\n11\n\\(\\frac{2}{36}\\)\n\\(\\frac{35}{36}\\)\n\n\n12\n\\(\\frac{1}{36}\\)\n\\(1\\)\n\n\n\n\n\n\n\n7.5.5 Simulazione della distribuzione di probabilità\nSpesso, anche se è possibile calcolare analiticamente la distribuzione di probabilità (come nel caso dei due dadi), può essere utile ottenere una stima empirica attraverso la simulazione. Questo approccio prevede di ripetere l’esperimento molte volte e di analizzare le frequenze relative dei risultati ottenuti.\n\n\n\n\n\n\nEsempio\n\n\n\n\n\nSimulazione del lancio di due dadi in R.\n1. Simulare il lancio di un singolo dado\n\n# Funzione per simulare un dado a sei facce\nlancia_dado &lt;- function() {\n  sample(1:6, 1)\n}\n\n2. Simulare il lancio di due dadi\n\n# Funzione per simulare il lancio di due dadi ripetuto n volte\nlancia_due_dadi &lt;- function(n) {\n  risultati &lt;- numeric(n)\n  \n  for (i in 1:n) {\n    risultati[i] &lt;- lancia_dado() + lancia_dado()\n  }\n  \n  risultati\n}\n\n3. Eseguire la simulazione\n\n# Numero totale di simulazioni\nnumero_lanci &lt;- 100000\n\n# Simulazione dei lanci\nrisultati_simulazione &lt;- lancia_due_dadi(numero_lanci)\n\n# Visualizza i primi 20 risultati\ncat(\"Primi 20 risultati:\", risultati_simulazione[1:20], \"\\n\")\n#&gt; Primi 20 risultati: 8 6 7 9 8 10 5 6 9 10 7 4 7 12 8 7 6 4 4 4\n\n4. Calcolare e visualizzare la distribuzione empirica\n\n# Calcola la frequenza assoluta per ciascuna somma\nfrequenze_assolute &lt;- table(risultati_simulazione)\nfrequenze_assolute\n#&gt; risultati_simulazione\n#&gt;     2     3     4     5     6     7     8     9    10    11    12 \n#&gt;  2837  5540  8349 10945 13924 16831 13894 11034  8295  5559  2792\n\n# Calcola direttamente le frequenze relative (probabilità empiriche)\nprobabilita_empiriche &lt;- frequenze_assolute / numero_lanci\nprobabilita_empiriche\n#&gt; risultati_simulazione\n#&gt;      2      3      4      5      6      7      8      9     10     11     12 \n#&gt; 0.0284 0.0554 0.0835 0.1095 0.1392 0.1683 0.1389 0.1103 0.0829 0.0556 0.0279\n\n# Crea una tabella finale chiara e semplice\ndistribuzione_empirica &lt;- data.frame(\n  Somma = as.numeric(names(probabilita_empiriche)),\n  Probabilita = as.vector(probabilita_empiriche)\n)\n\n# Mostra la distribuzione empirica\nprint(distribuzione_empirica)\n#&gt;    Somma Probabilita\n#&gt; 1      2      0.0284\n#&gt; 2      3      0.0554\n#&gt; 3      4      0.0835\n#&gt; 4      5      0.1095\n#&gt; 5      6      0.1392\n#&gt; 6      7      0.1683\n#&gt; 7      8      0.1389\n#&gt; 8      9      0.1103\n#&gt; 9     10      0.0829\n#&gt; 10    11      0.0556\n#&gt; 11    12      0.0279\n\nChiarimento sintetico dei concetti chiave.\n\nCos’è una simulazione?\nÈ un esperimento realizzato al computer che replica più volte un evento casuale per osservare i possibili risultati e la loro frequenza.\nDistribuzione empirica\nÈ la frequenza con cui ogni risultato (in questo caso, la somma di due dadi) appare nella simulazione. Con più simulazioni, questa distribuzione si avvicina sempre di più a quella prevista dalla teoria.\nProbabilità teorica ed empirica\nLa probabilità teorica è calcolata matematicamente: ad esempio, la somma “7” è teoricamente più frequente perché ci sono più modi di ottenerla (6+1, 5+2, 4+3, ecc.).\nLa probabilità empirica, invece, si ottiene dalla simulazione pratica, ed è una buona approssimazione della probabilità teorica quando il numero di prove è grande.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_random_var.html#distribuzioni-per-variabili-continue",
    "href": "chapters/probability/06_random_var.html#distribuzioni-per-variabili-continue",
    "title": "7  Variabili casuali",
    "section": "\n7.6 Distribuzioni per variabili continue",
    "text": "7.6 Distribuzioni per variabili continue\n\nDefinizione 7.4 Una variabile casuale continua è una variabile aleatoria \\(X\\) caratterizzata da una distribuzione di probabilità continua. Formalmente, \\(X\\) si definisce continua se soddisfa le seguenti proprietà:\n\n\nEsistenza della funzione di densità (pdf):\nEsiste una funzione non negativa \\(f(x)\\), detta funzione di densità di probabilità (pdf, dall’inglese probability density function), tale che:\n\n\n\\(f(x) \\geq 0\\) per ogni \\(x \\in \\mathbb{R}\\);\n\nL’area totale sotto la curva di \\(f(x)\\) è pari a 1:\\[\n\\int_{-\\infty}^{+\\infty} f(x) \\, dx = 1.\n\\]\n\n\n\n\nCalcolo delle probabilità tramite integrazione:\nPer ogni intervallo \\((a, b] \\subseteq \\mathbb{R}\\) (con \\(a &lt; b\\)), la probabilità che \\(X\\) assuma valori in \\((a, b]\\) è data dall’integrale della pdf su tale intervallo:\n\\[\nP(a &lt; X \\leq b) = \\int_{a}^{b} f(x) \\, dx.\n\\]\nQuesta probabilità coincide anche con la differenza della funzione di ripartizione (CDF, cumulative distribution function) \\(F(x) = P(X \\leq x)\\) agli estremi dell’intervallo:\n\\[\nP(a &lt; X \\leq b) = F(b) - F(a).\n\\]\n\n\n\n\n7.6.1 Proprietà chiave delle variabili continue\n\n\nProbabilità in un punto nulla:\nA differenza delle variabili discrete, per una variabile continua la probabilità di assumere un valore esatto \\(x_0\\) è sempre zero:\n\\[\nP(X = x_0) = 0.\n\\]\nQuesto avviene perché la probabilità è legata all’area sotto la curva \\(f(x)\\), e un singolo punto ha “larghezza zero”, risultando in un’area nulla. Di conseguenza, per variabili continue:\n\\[\nP(a \\leq X \\leq b) = P(a &lt; X \\leq b) = P(a \\leq X &lt; b) = P(a &lt; X &lt; b).\n\\]\n\nInterpretazione della densità:\nLa funzione \\(f(x)\\) non rappresenta direttamente una probabilità, ma descrive come la probabilità si distribuisce nello spazio campionario. Valori maggiori di \\(f(x)\\) indicano regioni in cui è più probabile che \\(X\\) assuma valori (densità di probabilità).\nModellizzazione di fenomeni continui:\nLe distribuzioni continue sono utilizzate per rappresentare grandezze misurabili con precisione arbitraria, come tempo, lunghezze, o temperature. Esempi comuni includono la distribuzione normale, esponenziale e uniforme continua.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_random_var.html#riflessioni-conclusive",
    "href": "chapters/probability/06_random_var.html#riflessioni-conclusive",
    "title": "7  Variabili casuali",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn questo capitolo abbiamo introdotto e approfondito il concetto fondamentale di variabile casuale, illustrando come questo strumento permetta di formalizzare e analizzare matematicamente fenomeni casuali complessi. Attraverso esempi intuitivi, come il lancio di dadi o la simulazione di situazioni reali, abbiamo osservato come le variabili casuali consentano di tradurre domande astratte in analisi concrete e interpretabili.\nAbbiamo esaminato le due principali tipologie di variabili casuali—discrete e continue—e discusso le relative distribuzioni di probabilità. Le distribuzioni discrete, caratterizzate da una funzione di massa di probabilità (PMF), si prestano particolarmente bene a modellare situazioni in cui gli eventi possono essere enumerati (come punteggi in test psicologici o risultati di giochi). Al contrario, le distribuzioni continue, descritte dalla funzione di densità di probabilità (PDF), sono essenziali per modellare misure precise, come l’altezza o il tempo, dove il numero di possibili valori è teoricamente infinito.\nUn aspetto importante trattato è la funzione di distribuzione cumulativa (CDF), che fornisce una descrizione completa della distribuzione di una variabile casuale, facilitando la comprensione intuitiva della probabilità che un evento accada entro certi limiti. Conoscere le proprietà della CDF aiuta a prevenire errori comuni nella sua interpretazione e a trarre conclusioni più affidabili dai dati empirici.\nInfine, attraverso l’utilizzo della simulazione, abbiamo mostrato come sia possibile avvicinarsi empiricamente a una distribuzione teorica, confermando e visualizzando in modo pratico e immediato concetti astratti. Questa capacità di simulare e verificare empiricamente le distribuzioni è estremamente utile, soprattutto quando i modelli teorici diventano troppo complessi da risolvere analiticamente.\nNei prossimi capitoli approfondiremo ulteriormente questi concetti, esaminando alcune distribuzioni di probabilità specifiche che sono comunemente usate nella ricerca psicologica e nelle applicazioni pratiche. Questo ci permetterà di passare da una conoscenza teorica delle variabili casuali a una competenza concreta nel loro utilizzo e nella loro interpretazione, sviluppando strumenti che miglioreranno le nostre capacità di analisi e di decisione in ambito psicologico e statistico.\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\nConsiglio gli esercizi di base disponibili nella seguente pagina web.\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nEsercizi sulla distribuzione normale, risolvibili usando R, sono disponibili sulla seguente pagina web.\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt;  [4] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt;  [7] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [10] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [13] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [16] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [25] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.8          tidyselect_1.2.1      farver_2.1.2         \n#&gt;  [4] fastmap_1.2.0         TH.data_1.1-4         tensorA_0.36.2.1     \n#&gt;  [7] digest_0.6.37         timechange_0.3.0      estimability_1.5.1   \n#&gt; [10] lifecycle_1.0.4       survival_3.8-3        magrittr_2.0.3       \n#&gt; [13] compiler_4.5.1        rlang_1.1.6           tools_4.5.1          \n#&gt; [16] knitr_1.50            bridgesampling_1.1-2  htmlwidgets_1.6.4    \n#&gt; [19] curl_7.0.0            pkgbuild_1.4.8        RColorBrewer_1.1-3   \n#&gt; [22] abind_1.4-8           multcomp_1.4-28       withr_3.0.2          \n#&gt; [25] purrr_1.1.0           grid_4.5.1            stats4_4.5.1         \n#&gt; [28] colorspace_2.1-1      xtable_1.8-4          inline_0.3.21        \n#&gt; [31] emmeans_1.11.2-8      scales_1.4.0          MASS_7.3-65          \n#&gt; [34] cli_3.6.5             mvtnorm_1.3-3         rmarkdown_2.29       \n#&gt; [37] ragg_1.5.0            generics_0.1.4        RcppParallel_5.1.11-1\n#&gt; [40] cachem_1.1.0          stringr_1.5.1         splines_4.5.1        \n#&gt; [43] parallel_4.5.1        vctrs_0.6.5           V8_7.0.0             \n#&gt; [46] Matrix_1.7-4          sandwich_3.1-1        jsonlite_2.0.0       \n#&gt; [49] arrayhelpers_1.1-0    systemfonts_1.2.3     glue_1.8.0           \n#&gt; [52] codetools_0.2-20      distributional_0.5.0  lubridate_1.9.4      \n#&gt; [55] stringi_1.8.7         gtable_0.3.6          QuickJSR_1.8.0       \n#&gt; [58] htmltools_0.5.8.1     Brobdingnag_1.2-9     R6_2.6.1             \n#&gt; [61] textshaping_1.0.3     rprojroot_2.1.1       evaluate_1.0.5       \n#&gt; [64] lattice_0.22-7        backports_1.5.0       memoise_2.0.1        \n#&gt; [67] broom_1.0.9           snakecase_0.11.1      rstantools_2.5.0     \n#&gt; [70] coda_0.19-4.1         gridExtra_2.3         nlme_3.1-168         \n#&gt; [73] checkmate_2.3.3       xfun_0.53             zoo_1.8-14           \n#&gt; [76] pkgconfig_2.0.3",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_random_var.html#bibliografia",
    "href": "chapters/probability/06_random_var.html#bibliografia",
    "title": "7  Variabili casuali",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlitzstein, J. K., & Hwang, J. (2019). Introduction to probability. CRC Press.\n\n\nChan, J. C. C., & Kroese, D. P. (2025). Statistical Modeling and Computation (2ª ed.). Springer.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_prob_distributions.html",
    "href": "chapters/probability/07_prob_distributions.html",
    "title": "8  Distribuzioni di massa e di densità",
    "section": "",
    "text": "Introduzione\nNel Capitolo 7 abbiamo introdotto il concetto di variabile casuale, distinguendo tra variabili casuali discrete e continue. Per le prime, abbiamo descritto formalmente come assegnare una distribuzione di massa di probabilità, mentre per le seconde abbiamo introdotto la nozione di funzione di densità di probabilità. Fino a questo punto, i concetti di distribuzione di massa e densità sono stati trattati in termini prevalentemente formali e matematici.\nLo scopo di questo capitolo è quello di approfondire queste idee, fornendo un’interpretazione più intuitiva e concreta di tali concetti. Attraverso esempi ed analisi pratiche, cercheremo di chiarire il significato sottostante alle distribuzioni di probabilità, rendendo più accessibili queste fondamentali strutture della teoria delle probabilità.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Distribuzioni di massa e di densità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_prob_distributions.html#introduzione",
    "href": "chapters/probability/07_prob_distributions.html#introduzione",
    "title": "8  Distribuzioni di massa e di densità",
    "section": "",
    "text": "Panoramica del capitolo\n\nLa variabilità di variabili discrete e continue.\n\nLa differenza tra massa di probabilità (distribuzioni discrete) e densità di probabilità (distribuzioni continue).\n\nPerché, per una variabile continua, la probabilità di osservare un valore esatto è pari a zero.\n\nDagli istogrammi alle funzioni di densità di probabilità.\n\nLa funzione di ripartizione.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere il capitolo Random variables and their distributions del testo di Blitzstein & Hwang (2019).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Distribuzioni di massa e di densità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_prob_distributions.html#variabili-casuali-discrete-e-continue",
    "href": "chapters/probability/07_prob_distributions.html#variabili-casuali-discrete-e-continue",
    "title": "8  Distribuzioni di massa e di densità",
    "section": "\n8.1 Variabili casuali discrete e continue",
    "text": "8.1 Variabili casuali discrete e continue\nUn elemento fondamentale nella comprensione delle distribuzioni di probabilità è la distinzione tra variabili casuali discrete e continue, poiché le distribuzioni di probabilità associate differiscono in modo sostanziale.\n\n\nVariabili casuali discrete: assumono un numero finito o numerabile di valori. Ad esempio, il numero di successi in una serie di esperimenti o il risultato del lancio di un dado.\n\nVariabili casuali continue: possono assumere un numero infinito di valori all’interno di un intervallo. Esempi includono il tempo di attesa per un evento o il quoziente intellettivo (QI) di una persona.\n\nQuesta distinzione è fondamentale perché le relative distribuzioni probabilistiche si comportano in modi diversi.\n\n8.1.1 Distribuzioni di probabilità discrete\nLe distribuzioni di probabilità discrete descrivono fenomeni aleatori con un numero finito o numerabile di esiti possibili. Queste distribuzioni sono rappresentate da una funzione di massa di probabilità (PMF), che assegna una probabilità a ciascun valore della variabile casuale.\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nConsideriamo un dado sbilanciato con la seguente distribuzione di probabilità:\n\n\nValore di \\(X\\)\n\nProbabilità \\(p(x)\\)\n\n\n\n\n1\n0.10\n\n\n2\n0.15\n\n\n3\n0.20\n\n\n4\n0.25\n\n\n5\n0.20\n\n\n6\n0.10\n\n\n\nQuesta tabella rappresenta la funzione di massa di probabilità (PMF).\nPer visualizzare questa distribuzione, possiamo simulare 1000 lanci del dado e creare un diagramma a barre che rappresenta le frequenze relative osservate. In R:\n\n# Dati\nset.seed(123)\nprob &lt;- c(0.10, 0.15, 0.20, 0.25, 0.20, 0.10)\nlanci &lt;- sample(1:6, size = 1000, replace = TRUE, prob = prob)\n\n# Creazione di un data frame\ndf &lt;- data.frame(Valore = factor(lanci))\n\n# Creazione del diagramma a barre\nggplot(df, aes(x = Valore)) +\n  geom_bar(aes(y = after_stat(count) / sum(after_stat(count))), fill = \"lightblue\", color=\"black\") +\n  labs(\n    x = \"Valore\",\n    y = \"Frequenza relativa\"\n  )\n\n\n\n\n\n\n\nQuando il numero di lanci aumenta, le frequenze relative si avvicinano sempre più alle probabilità teoriche.\n\n\n\n\n8.1.2 Distribuzioni di probabilità continue\nLe distribuzioni di probabilità continue descrivono variabili casuali che possono assumere un numero infinito di valori in un intervallo. In questo caso, la probabilità è rappresentata da una funzione di densità di probabilità (PDF), che descrive la probabilità che la variabile assuma valori in un dato intervallo.\n\n8.1.2.1 Probabilità come area sotto la curva\nLe distribuzioni continue sono descritte dalla funzione di densità di probabilità (PDF). Per una variabile casuale continua \\(X\\), la probabilità che \\(X\\) assuma un valore compreso tra \\(a\\) e \\(b\\) è data dall’area sotto la curva della PDF tra \\(a\\) e \\(b\\):\n\\[\nP(a \\leq X \\leq b) = \\int_a^b f(x) \\, dx.\n\\]\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nIl quoziente intellettivo (QI) è spesso modellato come una variabile casuale continua con distribuzione normale, con media \\(\\mu = 100\\) e deviazione standard \\(\\sigma = 15\\). Possiamo simulare questa distribuzione e confrontare l’istogramma dei dati con la PDF teorica.\nSimulazione con 50 osservazioni.\n\n# Parametri della distribuzione normale\nmu &lt;- 100\nsigma &lt;- 15\nsize &lt;- 50\n\n# Generare i dati\nset.seed(123)\nx &lt;- rnorm(size, mean = mu, sd = sigma)\n\n# Istogramma e densità\ndata_frame &lt;- data.frame(X = x)\nxmin &lt;- min(x)\nxmax &lt;- max(x)\ndensity_data &lt;- data.frame(\n  X = seq(xmin, xmax, length.out = 100),\n  Density = dnorm(seq(xmin, xmax, length.out = 100), mean = mu, sd = sigma)\n)\n\nggplot(data_frame, aes(x = X)) +\n  geom_histogram(\n    aes(y = after_stat(density)),\n    bins = 25,\n    fill = \"lightblue\", color = \"black\"\n  ) +\n  geom_line(\n    data = density_data,\n    aes(x = X, y = Density),\n    color = \"black\",\n    size = 1\n  ) +\n  labs(\n    x = \"Valori del QI\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\nCon un campione piccolo, l’istogramma non corrisponde perfettamente alla PDF teorica. Tuttavia, aumentando il numero di osservazioni, l’approssimazione migliora.\nSimulazione con 20000 osservazioni.\n\n# Generare un campione più grande\nsize &lt;- 20000\nset.seed(123)\nx &lt;- rnorm(size, mean = mu, sd = sigma)\n\n# Aggiornare media e deviazione standard\nmu &lt;- mean(x)\nsigma &lt;- sd(x)\n\n# Creare il grafico\ndata_frame &lt;- data.frame(X = x)\nxmin &lt;- min(x)\nxmax &lt;- max(x)\ndensity_data &lt;- data.frame(\n  X = seq(xmin, xmax, length.out = 100),\n  Density = dnorm(seq(xmin, xmax, length.out = 100), mean = mu, sd = sigma)\n)\n\nggplot(data_frame, aes(x = X)) +\n  geom_histogram(\n    aes(y = after_stat(density)),\n    bins = 25,\n    fill = \"lightblue\",\n    color = \"black\"\n  ) +\n  geom_line(\n    data = density_data,\n    aes(x = X, y = Density),\n    color = \"black\",\n    size = 1\n  ) +\n  labs(\n    x = \"Valori del QI\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\nCon un campione di grandi dimensioni, l’istogramma riflette molto meglio la PDF teorica.\n\n\n\n\n8.1.2.2 Interpretazione della funzione di densità\nLa funzione di densità di probabilità (PDF) rappresenta un’astrazione continua dell’istogramma. Quando il numero di osservazioni tende a infinito e la larghezza degli intervalli tende a zero, il profilo dell’istogramma si avvicina alla PDF.\n\n8.1.2.3 Proprietà della PDF\n\n\nArea Totale: L’area totale sotto la curva della PDF è uguale a 1, poiché rappresenta la probabilità totale.\n\nProbabilità per Intervalli: La probabilità che la variabile assuma un valore in un intervallo \\([a, b]\\) è data dall’area sotto la curva tra \\(a\\) e \\(b\\).\n\nProbabilità per Singoli Valori: Per una variabile continua, la probabilità di un singolo valore è sempre zero, poiché corrisponde all’area sotto la curva in un punto.\n\n8.1.2.4 Parametri delle distribuzioni di probabilità\nLe distribuzioni di probabilità, sia discrete che continue, sono definite da parametri che ne determinano le proprietà fondamentali. Questi parametri consentono di adattare il modello probabilistico ai dati osservati.\n\n8.1.2.5 Proprietà influenzate dai parametri\n\n\nPosizione (Tendenza Centrale): Indica il valore attorno al quale si concentra la distribuzione. Ad esempio, nella distribuzione normale, la media (\\(\\mu\\)) rappresenta il centro della distribuzione.\n\nDispersione: Misura quanto i valori della distribuzione si allontanano dalla posizione centrale. Nella distribuzione normale, la deviazione standard (\\(\\sigma\\)) controlla la larghezza della curva.\n\nForma: Determina l’asimmetria o la curtosi della distribuzione. Alcune distribuzioni, come quella gamma o beta, hanno parametri specifici per regolare la forma.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Distribuzioni di massa e di densità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_prob_distributions.html#il-paradosso-delle-variabili-casuali-continue",
    "href": "chapters/probability/07_prob_distributions.html#il-paradosso-delle-variabili-casuali-continue",
    "title": "8  Distribuzioni di massa e di densità",
    "section": "\n8.2 Il paradosso delle variabili casuali continue",
    "text": "8.2 Il paradosso delle variabili casuali continue\nUn aspetto controintuitivo delle variabili casuali continue è che la probabilità di osservare esattamente un determinato valore è sempre pari a zero. Per esempio, se consideriamo una variabile continua che rappresenta l’altezza di una persona, la probabilità che l’altezza sia esattamente 170 cm è espressa da\n\\[\nP(X = 170) = 0.\n\\]\nPerché accade questo? La risposta sta nel concetto di “esattezza”. Se riscriviamo 170 cm come 170.00000000000000000000000000000000000 cm (con infiniti decimali), diventa chiaro che stiamo cercando un singolo punto in un continuum infinito.\nQuesto non significa che l’evento sia impossibile, ma che nelle variabili continue la probabilità ha senso solo se riferita a intervalli di valori. Infatti, se sommiamo infinite probabilità diverse da zero, supereremmo 1, cosa impossibile.\n\n8.2.1 Due implicazioni importanti\nQuesto modo di definire la probabilità nelle variabili continue comporta due implicazioni chiave:\n\n\nCalcolo della probabilità su intervalli:\nNelle variabili continue, le probabilità si calcolano solo su intervalli (es.: tra 169.5 cm e 170.5 cm). Questo perché, se ogni singolo valore avesse probabilità &gt; 0, la somma di infiniti valori supererebbe 1 (il che è impossibile).\n\nEventi con probabilità zero:\nIl fatto che un evento (ad esempio, \\(X = 170\\)) abbia probabilità zero non implica che l’evento sia impossibile. È come cercare un granello di sabbia specifico su una spiaggia infinita: tecnicamente possibile, ma praticamente improbabile.\n\n8.2.2 Il paradosso della probabilità zero\nQuesto ragionamento porta a un apparente paradosso: se la probabilità che l’altezza di una persona sia esattamente 170 è zero, come possiamo mai osservare un valore specifico, come 170 (o un qualsiasi altro valore), nella realtà?\nUna metafora utile per comprendere questo fenomeno è data dal celebre paradosso di Zenone della freccia. Nel paradosso, si sostiene che, in ogni istante, la freccia sia immobile, e dunque non si dovrebbe mai muovere. Analogamente, ogni singolo valore (es.: 170 cm) ha probabilità zero, ma l’insieme di infiniti valori in un intervallo crea un’area sotto la curva (probabilità) misurabile.\n\n8.2.3 La prospettiva degli infinitesimi\nNegli anni ’60, il matematico Abraham Robinson sviluppò una teoria matematica rigorosa degli infinitesimi, ovvero numeri infinitamente piccoli, diversi da zero. In questo quadro, possiamo reinterpretare la probabilità dei singoli punti nel seguente modo:\n\n\nProbabilità infinitesimale:\nUn singolo valore puntuale non ha probabilità strettamente zero, bensì infinitamente piccola (un infinitesimo). Pur essendo praticamente indistinguibile da zero nella teoria classica, l’aggregazione (tramite integrazione) di infiniti eventi con probabilità infinitesimali può produrre un valore di probabilità finito e positivo per un intervallo. In altre parole, infiniti punti infinitamente piccoli sommati insieme generano un intervallo di probabilità misurabile e significativa.\n\nIn conclusione, il cosiddetto “paradosso della probabilità zero” non rappresenta un vero paradosso, ma evidenzia piuttosto i limiti delle nostre intuizioni quando affrontiamo concetti inerenti variabili continue. La chiave per la comprensione risiede nella distinzione tra il contributo di un singolo punto (infinitesimale o zero, nell’analisi classica) e l’area complessiva calcolata mediante l’integrazione.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Distribuzioni di massa e di densità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_prob_distributions.html#la-funzione-di-ripartizione-per-una-variabile-casuale-continua",
    "href": "chapters/probability/07_prob_distributions.html#la-funzione-di-ripartizione-per-una-variabile-casuale-continua",
    "title": "8  Distribuzioni di massa e di densità",
    "section": "\n8.3 La funzione di ripartizione per una variabile casuale continua",
    "text": "8.3 La funzione di ripartizione per una variabile casuale continua\nLa funzione di ripartizione, nota anche come distribuzione cumulativa, è uno strumento fondamentale per descrivere il comportamento di una variabile casuale, sia essa discreta o continua. Per una variabile casuale continua \\(\\Theta\\), la funzione di ripartizione \\(F_{\\Theta}(\\theta)\\) è definita come:\n\\[\nF_{\\Theta}(\\theta) = P(\\Theta \\leq \\theta).\n\\]\nIn altre parole, \\(F_{\\Theta}(\\theta)\\) rappresenta la probabilità che la variabile \\(\\Theta\\) assuma un valore minore o uguale a \\(\\theta\\). Questa definizione è identica a quella utilizzata per le variabili casuali discrete, ma nel caso continuo assume un significato particolare a causa della natura continua della variabile.\n\n8.3.1 Proprietà della funzione di ripartizione\nLa funzione di ripartizione per una variabile casuale continua gode di alcune proprietà importanti:\n\n\nMonotonicità Crescente: \\(F_{\\Theta}(\\theta)\\) è una funzione non decrescente. Ciò significa che, all’aumentare di \\(\\theta\\), la probabilità \\(P(\\Theta \\leq \\theta)\\) non diminuisce.\n\nLimiti agli Estremi:\n\nQuando \\(\\theta \\to -\\infty\\), \\(F_{\\Theta}(\\theta) \\to 0\\).\nQuando \\(\\theta \\to +\\infty\\), \\(F_{\\Theta}(\\theta) \\to 1\\).\n\n\n\nContinuità: Per una variabile casuale continua, \\(F_{\\Theta}(\\theta)\\) è una funzione continua. Questo differisce dal caso discreto, dove la funzione di ripartizione è a gradini.\n\n8.3.2 Calcolo delle probabilità per intervalli\nUna delle applicazioni più utili della funzione di ripartizione è il calcolo della probabilità che la variabile casuale \\(\\Theta\\) assuma valori all’interno di un intervallo specifico. Dati due valori \\(\\theta_1\\) e \\(\\theta_2\\) (con \\(\\theta_1 &lt; \\theta_2\\)), la probabilità che \\(\\Theta\\) sia compreso tra \\(\\theta_1\\) e \\(\\theta_2\\) è data da:\n\\[\nP(\\theta_1 &lt; \\Theta \\leq \\theta_2) = F_{\\Theta}(\\theta_2) - F_{\\Theta}(\\theta_1).\n\\]\nQuesta formula è particolarmente utile perché, nel caso delle variabili continue, la probabilità di un singolo punto è sempre zero. Pertanto, per calcolare probabilità significative, è necessario considerare intervalli di valori.\n\n8.3.3 Relazione con la funzione di densità di probabilità (PDF)\nLa funzione di ripartizione è strettamente legata alla funzione di densità di probabilità (PDF), \\(f(\\theta)\\). Mentre la PDF descrive la densità di probabilità in ogni punto, la funzione di ripartizione rappresenta l’area sotto la curva della PDF fino a un certo valore \\(\\theta\\). Formalmente, la funzione di ripartizione si ottiene integrando la PDF:\n\\[\nF_{\\Theta}(\\theta) = \\int_{-\\infty}^{\\theta} f(t) \\, dt.\n\\]\nQuesta relazione evidenzia come la funzione di ripartizione sia una rappresentazione cumulativa della probabilità, ottenuta sommando (o integrando) i contributi della densità di probabilità fino al valore \\(\\theta\\).\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nConsideriamo una variabile casuale \\(\\Theta\\) con distribuzione normale standard (media \\(\\mu = 0\\) e deviazione standard \\(\\sigma = 1\\)). La PDF è data da:\n\\[\nf(\\theta) = \\frac{1}{\\sqrt{2\\pi}} e^{-\\theta^2 / 2}.\n\\]\nLa funzione di ripartizione \\(F_{\\Theta}(\\theta)\\) è l’integrale di questa funzione da \\(-\\infty\\) a \\(\\theta\\):\n\\[\nF_{\\Theta}(\\theta) = \\int_{-\\infty}^{\\theta} \\frac{1}{\\sqrt{2\\pi}} e^{-t^2 / 2} \\, dt.\n\\]\nQuesta funzione non ha una forma chiusa semplice, ma può essere calcolata numericamente o consultata in tabelle statistiche. Ad esempio, per \\(\\theta = 1\\), \\(F_{\\Theta}(1) \\approx 0.8413\\), il che significa che la probabilità che \\(\\Theta\\) sia minore o uguale a 1 è circa l’84.13%.\n\n\n\n\n8.3.4 Interpretazione grafica\nGraficamente, la funzione di ripartizione rappresenta l’area sotto la curva della PDF a sinistra del valore \\(\\theta\\). Ad esempio, se consideriamo la distribuzione normale standard:\n\nPer \\(\\theta = 0\\), \\(F_{\\Theta}(0) = 0.5\\), poiché la media della distribuzione è 0 e la curva è simmetrica.\nPer \\(\\theta = 1\\), \\(F_{\\Theta}(1) \\approx 0.8413\\), come visto sopra.\nPer \\(\\theta = -1\\), \\(F_{\\Theta}(-1) \\approx 0.1587\\), poiché la coda sinistra della distribuzione contiene il 15.87% della probabilità.\n\n\n\n\n\n\n\n\n\nIn conclusione, la funzione di ripartizione è uno strumento essenziale per comprendere e lavorare con variabili casuali continue. Essa non solo fornisce una rappresentazione cumulativa della probabilità, ma permette anche di calcolare probabilità per intervalli e di collegare la PDF alla distribuzione complessiva della variabile. Attraverso la sua relazione con la PDF, la funzione di ripartizione offre un ponte tra la descrizione locale (densità) e quella globale (probabilità cumulativa) di una variabile casuale continua.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Distribuzioni di massa e di densità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_prob_distributions.html#interpretazioni-bayesiana-e-frequentista-della-pdf",
    "href": "chapters/probability/07_prob_distributions.html#interpretazioni-bayesiana-e-frequentista-della-pdf",
    "title": "8  Distribuzioni di massa e di densità",
    "section": "\n8.4 Interpretazioni bayesiana e frequentista della PDF",
    "text": "8.4 Interpretazioni bayesiana e frequentista della PDF\nIn questo capitolo, abbiamo introdotto la funzione di densità di probabilità come limite del profilo di un istogramma, una descrizione intuitiva e utile per comprendere il concetto di densità. Questa interpretazione corrisponde, tuttavia, alla visione frequentista della densità di probabilità. Nella statistica Bayesiana, l’interpretazione è diversa e merita una spiegazione separata.\n\n8.4.1 Interpretazione frequentista\nConcetto di ripetizione degli esperimenti:\n\nIdea di frequenza relativa:\nNel paradigma frequentista la probabilità è intesa come il limite della frequenza relativa di un evento ottenuto al ripetere un esperimento un numero molto elevato di volte. Immaginiamo di eseguire un esperimento molte volte, ad ogni ripetizione si ottiene un valore di \\(x\\). Se costruiamo un istogramma di questi valori, questo istogramma diventa sempre più “liscio” man mano che il numero delle ripetizioni aumenta, fino a convergere alla PDF \\(p(x)\\).\nPDF come istogramma limite:\nLa PDF rappresenta la distribuzione dei valori osservati in una serie di ripetizioni dell’esperimento. In altre parole, essa descrive quanto frequentemente, in una ipotetica serie infinita di esperimenti, il valore \\(x\\) assume un determinato intervallo.\nEsempio intuitivo:\nSe misuriamo l’altezza degli individui in una popolazione, nel contesto frequentista, la PDF ci dice quale frazione di individui cade in un certo intervallo di altezza se potessimo misurare ogni possibile individuo (o eseguire ripetutamente misurazioni indipendenti in una popolazione “ideale”).\n\n8.4.2 Interpretazione bayesiana\nConcetto di incertezza e credenza:\n\n\nParametro come variabile casuale:\nIn statistica bayesiana, i parametri non sono visti come quantità fisse, ma come incerti. Si assume che ogni parametro (o dato osservato) abbia una propria distribuzione che riflette la nostra incertezza su di esso.\n\nAd esempio, se stiamo stimando un parametro \\(\\theta\\) (ad esempio la media di una distribuzione), in un approccio bayesiano attribuiamo a \\(\\theta\\) una distribuzione di probabilità che esprime quanto sia plausibile ciascun valore di \\(\\theta\\), dati i dati osservati e le nostre conoscenze pregresse.\n\n\n\nPDF come distribuzione di credenze:\nLa PDF, in questo contesto, non descrive una frequenza relativa osservabile sperimentalmente (perché l’esperimento non viene ripetuto infinite volte, o perché \\(x\\) è un valore fisso ma incerto), ma esprime il grado di fiducia o la plausibilità che il valore “vero” di \\(x\\) (o di un parametro) si trovi in un certo intervallo.\n\nÈ come “spalmare” la nostra incertezza su tutti i valori possibili: la sfumatura lungo l’asse \\(x\\) rappresenta la distribuzione delle nostre credenze.\n\n\nAnalogia con la densità di materia:\nUn’utile analogia è quella della densità di materia \\(\\rho(x)\\) in meccanica classica: la densità non descrive la posizione precisa di ogni atomo, ma come la materia (o, in questo caso, la probabilità) è distribuita lungo l’asse \\(x\\). Allo stesso modo, in una PDF bayesiana, non sono i “valori di \\(x\\)” ad essere distribuiti (in termini di frequenza osservabile), ma è la nostra “incertezza” a essere distribuita sui possibili valori.\nEsempio intuitivo:\nImmagina di dover stimare la probabilità che una certa ipotesi sia vera, ad esempio la media dell’altezza in una popolazione. Invece di pensare a misurazioni ripetute, consideri il valore medio come fisso ma incerto. La PDF bayesiana esprime il grado di credenza per ciascun possibile valore della media, in base ai dati raccolti e alle informazioni a priori.\n\n8.4.3 Confronto\n\n\nFrequentista:\n\n\nFocus: Distribuzione dei dati.\n\nInterpretazione: La PDF descrive come i valori di \\(x\\) sarebbero distribuiti se ripetessimo l’esperimento infinite volte.\n\nEsempio: L’istogramma dei dati osservati in una lunga serie di esperimenti.\n\n\n\nBayesiano:\n\n\nFocus: Distribuzione della nostra incertezza o credenza.\n\nInterpretazione: La PDF riflette quanto sia plausibile ciascun valore di \\(x\\) (o di un parametro) dato l’informazione disponibile, senza necessità di ripetere l’esperimento.\n\nEsempio: La distribuzione a posteriori di un parametro dopo aver combinato dati osservati e informazioni a priori.\n\n\n\n\n\n\n\n\nFigura 8.1: Interpretazioni frequentista e bayesiana di una PDF (curva blu) per una quantità reale \\(x\\). A sinistra: interpretazione frequentista come istogramma limite dei valori di \\(x\\) nelle ripetizioni; i valori di \\(x\\) sono distribuiti secondo la PDF. A destra: interpretazione bayesiana, con \\(x\\) che assume un valore fisso ma incerto per il caso specifico (rappresentato dal punto sull’asse \\(x\\)), con la probabilità distribuita sui valori possibili (raffigurata con una sfumatura lungo l’asse \\(x\\)). (Figura tratta da Loredo & Wolpert, 2024)\n\n\nIn sintesi, questa distinzione tra interpretazioni non è solo una questione di semantica, ma ha implicazioni pratiche nella formulazione di modelli statistici e nell’interpretazione dei risultati. Mentre l’approccio frequentista è spesso utilizzato quando si può concettualmente pensare a ripetizioni infinite dell’esperimento, l’approccio bayesiano è particolarmente utile quando si vuole esprimere e aggiornare la propria incertezza su una quantità basandosi sia su dati che su conoscenze pregresse.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Distribuzioni di massa e di densità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_prob_distributions.html#riflessioni-conclusive",
    "href": "chapters/probability/07_prob_distributions.html#riflessioni-conclusive",
    "title": "8  Distribuzioni di massa e di densità",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nLa funzione di densità di probabilità (PDF) costituisce il fondamento per la descrizione delle variabili casuali continue, consentendo di associare le probabilità ad intervalli, tramite il calcolo dell’area sottesa alla curva. In questo contesto, la probabilità di osservare un valore esatto risulta zero, non per impossibilità dell’evento, ma perché in un insieme continuo ogni singolo punto contribuisce con un’area infinitesimale.\nIl paradosso apparente, secondo cui la somma di infiniti contributi nulli porta a una probabilità totale positiva, si risolve grazie alla teoria dell’integrazione. Integrando i contributi infinitesimali lungo un intervallo, si ottiene una quantità finita che rappresenta la probabilità complessiva dell’evento. Un’interpretazione alternativa, fornita dalla teoria degli infinitesimi di Abraham Robinson, consente di attribuire a tali eventi probabilità infinitesimali, distinguendo tra diverse “grandezze” e chiarendo ulteriormente il processo di aggregazione verso un valore unitario.\nNel campo della data science, le distribuzioni di probabilità—formalmente rappresentate da \\(p(x)\\)—sono strumenti indispensabili per modellare la variabilità osservabile in una popolazione. Queste distribuzioni non mirano a riprodurre in maniera dettagliata ogni aspetto della realtà, ma offrono un modello semplificato che consente di generalizzare i dati osservati e di formulare previsioni rigorose sui fenomeni futuri. In altre parole, \\(p(x)\\) non rappresenta la popolazione nel suo complesso, bensì un’astrazione matematica che cattura l’incertezza e la variabilità del fenomeno studiato.\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nEsercizio 1: Variabili Casuali Discrete e Continue\nUtilizzando i dati raccolti sulla Satisfaction with Life Scale (SWLS) e sulla Scala della Rete Sociale di Lubben a 6 item (LSNS-6), classifica le seguenti variabili come discrete o continue:\n\nIl punteggio totale della SWLS.\nIl numero di amici con cui uno studente si sente a proprio agio nel parlare di questioni personali.\nIl tempo (in minuti) che uno studente trascorre con amici durante una settimana.\nIl numero di volte che uno studente ha contattato un parente nell’ultimo mese.\nIl livello di soddisfazione della vita misurato su una scala da 1 a 7.\n\nSpiega il motivo della tua classificazione per ciascuna variabile.\nEsercizio 2: Distribuzioni di Probabilità Discrete\nConsideriamo la distribuzione del numero di amici con cui uno studente si sente a proprio agio nel parlare di questioni personali, misurata attraverso la LSNS-6. Supponiamo che la distribuzione sia la seguente (ma nell’esercizio usa le frequenze relative trovate nel campione di dati raccolto):\n\n\nNumero di amici\nProbabilità\n\n\n\n0\n0.05\n\n\n1\n0.15\n\n\n2\n0.25\n\n\n3\n0.30\n\n\n4\n0.15\n\n\n5\n0.10\n\n\n\n\nVerifica che questa sia una distribuzione di probabilità valida.\nQual è la probabilità che uno studente abbia almeno 3 amici con cui si sente a proprio agio nel parlare di questioni personali?\nQual è la probabilità che abbia meno di 2 amici?\nCalcola il valore atteso (media) e la varianza di questa distribuzione.\n\nEsercizio 3: Distribuzioni di Probabilità Continue\nIl punteggio totale della SWLS può essere approssimato da una distribuzione normale con media 20 e deviazione standard 5.\n\nQual è la probabilità che un individuo scelto a caso abbia un punteggio superiore a 25?\nQual è la probabilità che un individuo abbia un punteggio compreso tra 15 e 25?\nQual è il valore del punteggio che delimita il 10% superiore della distribuzione?\n\n(Suggerimento: utilizza la funzione di ripartizione della distribuzione normale standard per calcolare queste probabilità.)\nEsercizio 4: Legge della Probabilità Totale\nSi sa che il 60% degli studenti proviene da un ambiente con un forte supporto sociale, mentre il 40% ha un supporto sociale limitato. Inoltre, si sa che: - La probabilità che uno studente con forte supporto sociale abbia un punteggio SWLS superiore a 20 è 0.75. - La probabilità che uno studente con supporto sociale limitato abbia un punteggio SWLS superiore a 20 è 0.50.\nQual è la probabilità che uno studente scelto a caso abbia un punteggio SWLS superiore a 20?\nEsercizio 5: Teorema di Bayes e Supporto Sociale\nRiprendendo l’esercizio precedente, calcola la probabilità che uno studente provenga da un ambiente con forte supporto sociale dato che il suo punteggio SWLS è superiore a 20.\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\nEsercizio 1: Variabili Casuali Discrete e Continue\nUtilizzando i dati raccolti sulla Satisfaction with Life Scale (SWLS) e sulla Scala della Rete Sociale di Lubben a 6 item (LSNS-6), classifica le seguenti variabili come discrete o continue:\n\nIl punteggio totale della SWLS. (Continuo)\nIl numero di amici con cui uno studente si sente a proprio agio nel parlare di questioni personali. (Discreto)\nIl tempo (in minuti) che uno studente trascorre con amici durante una settimana. (Continuo)\nIl numero di volte che uno studente ha contattato un parente nell’ultimo mese. (Discreto)\nIl livello di soddisfazione della vita misurato su una scala da 1 a 7. (Discreto)\n\nEsercizio 2: Distribuzioni di Probabilità Discrete\nConsideriamo la distribuzione del numero di amici con cui uno studente si sente a proprio agio nel parlare di questioni personali, misurata attraverso la LSNS-6. Supponiamo che la distribuzione sia la seguente:\n\n\nNumero di amici\nProbabilità\n\n\n\n0\n0.05\n\n\n1\n0.15\n\n\n2\n0.25\n\n\n3\n0.30\n\n\n4\n0.15\n\n\n5\n0.10\n\n\n\n\n\nVerifica della distribuzione: La somma delle probabilità deve essere 1:\n\\[ 0.05 + 0.15 + 0.25 + 0.30 + 0.15 + 0.10 = 1.00 \\]\nPoiché la somma è 1, la distribuzione è valida.\n\n\nProbabilità di almeno 3 amici:\n\\[ P(X \\geq 3) = P(3) + P(4) + P(5) = 0.30 + 0.15 + 0.10 = 0.55 \\]\n\n\nProbabilità di meno di 2 amici:\n\\[ P(X &lt; 2) = P(0) + P(1) = 0.05 + 0.15 = 0.20 \\]\n\n\nValore atteso e varianza:\n\\[ E(X) = \\sum x P(x) = (0 \\times 0.05) + (1 \\times 0.15) + (2 \\times 0.25) + (3 \\times 0.30) + (4 \\times 0.15) + (5 \\times 0.10) = 2.65 \\]\n\\[ Var(X) = E(X^2) - (E(X))^2 \\]\n\\[ E(X^2) = (0^2 \\times 0.05) + (1^2 \\times 0.15) + (2^2 \\times 0.25) + (3^2 \\times 0.30) + (4^2 \\times 0.15) + (5^2 \\times 0.10) = 8.05 \\]\n\\[ Var(X) = 8.05 - (2.65)^2 = 1.06 \\]\n\n\nEsercizio 3: Distribuzioni di Probabilità Continue\nIl punteggio totale della SWLS può essere approssimato da una distribuzione normale con media 20 e deviazione standard 5.\n\n\nProbabilità che il punteggio sia superiore a 25:\n\\[ P(X &gt; 25) = 1 - P(X \\leq 25) \\]\nStandardizziamo:\n\\[ Z = \\frac{25 - 20}{5} = 1 \\]\nUsando le tabelle della distribuzione normale:\n\\[ P(Z \\leq 1) = 0.8413 \\Rightarrow P(X &gt; 25) = 1 - 0.8413 = 0.1587 \\]\n\n\nProbabilità che il punteggio sia tra 15 e 25:\n\\[ P(15 \\leq X \\leq 25) = P(Z \\leq 1) - P(Z \\leq -1) \\]\n\\[ = 0.8413 - 0.1587 = 0.6826 \\]\n\n\nPercentile 90 della distribuzione:\nIl valore di Z per il 90% è 1.28.\n\\[ X = 20 + (1.28 \\times 5) = 26.4 \\]\n\n\nEsercizio 4: Legge della Probabilità Totale\n\\[ P(SWLS &gt; 20) = P(SWLS &gt; 20 | S) P(S) + P(SWLS &gt; 20 | \\neg S) P(\\neg S) \\]\n\\[ = (0.75 \\times 0.60) + (0.50 \\times 0.40) \\]\n\\[ = 0.45 + 0.20 = 0.65 \\]\nEsercizio 5: Teorema di Bayes e Supporto Sociale\n\\[ P(S | SWLS &gt; 20) = \\frac{P(SWLS &gt; 20 | S) P(S)}{P(SWLS &gt; 20)} \\]\n\\[ = \\frac{(0.75 \\times 0.60)}{0.65} \\]\n\\[ = \\frac{0.45}{0.65} = 0.6923 \\]\nQuindi, la probabilità che uno studente provenga da un ambiente con forte supporto sociale dato che il suo punteggio SWLS è superiore a 20 è circa 69.2%.\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt;  [4] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt;  [7] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [10] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [13] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [16] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [25] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.8          tidyselect_1.2.1      farver_2.1.2         \n#&gt;  [4] fastmap_1.2.0         TH.data_1.1-4         tensorA_0.36.2.1     \n#&gt;  [7] digest_0.6.37         timechange_0.3.0      estimability_1.5.1   \n#&gt; [10] lifecycle_1.0.4       survival_3.8-3        magrittr_2.0.3       \n#&gt; [13] compiler_4.5.1        rlang_1.1.6           tools_4.5.1          \n#&gt; [16] yaml_2.3.10           knitr_1.50            labeling_0.4.3       \n#&gt; [19] bridgesampling_1.1-2  htmlwidgets_1.6.4     curl_7.0.0           \n#&gt; [22] pkgbuild_1.4.8        RColorBrewer_1.1-3    abind_1.4-8          \n#&gt; [25] multcomp_1.4-28       withr_3.0.2           purrr_1.1.0          \n#&gt; [28] grid_4.5.1            stats4_4.5.1          colorspace_2.1-1     \n#&gt; [31] xtable_1.8-4          inline_0.3.21         emmeans_1.11.2-8     \n#&gt; [34] scales_1.4.0          MASS_7.3-65           cli_3.6.5            \n#&gt; [37] mvtnorm_1.3-3         rmarkdown_2.29        ragg_1.5.0           \n#&gt; [40] generics_0.1.4        RcppParallel_5.1.11-1 cachem_1.1.0         \n#&gt; [43] stringr_1.5.1         splines_4.5.1         parallel_4.5.1       \n#&gt; [46] vctrs_0.6.5           V8_7.0.0              Matrix_1.7-4         \n#&gt; [49] sandwich_3.1-1        jsonlite_2.0.0        arrayhelpers_1.1-0   \n#&gt; [52] systemfonts_1.2.3     glue_1.8.0            codetools_0.2-20     \n#&gt; [55] distributional_0.5.0  lubridate_1.9.4       stringi_1.8.7        \n#&gt; [58] gtable_0.3.6          QuickJSR_1.8.0        htmltools_0.5.8.1    \n#&gt; [61] Brobdingnag_1.2-9     R6_2.6.1              textshaping_1.0.3    \n#&gt; [64] rprojroot_2.1.1       evaluate_1.0.5        lattice_0.22-7       \n#&gt; [67] backports_1.5.0       memoise_2.0.1         broom_1.0.9          \n#&gt; [70] snakecase_0.11.1      rstantools_2.5.0      coda_0.19-4.1        \n#&gt; [73] gridExtra_2.3         nlme_3.1-168          checkmate_2.3.3      \n#&gt; [76] xfun_0.53             zoo_1.8-14            pkgconfig_2.0.3",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Distribuzioni di massa e di densità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_prob_distributions.html#bibliografia",
    "href": "chapters/probability/07_prob_distributions.html#bibliografia",
    "title": "8  Distribuzioni di massa e di densità",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlitzstein, J. K., & Hwang, J. (2019). Introduction to probability. CRC Press.\n\n\nLoredo, T. J., & Wolpert, R. L. (2024). Bayesian inference: more than Bayes’s theorem. Frontiers in Astronomy and Space Sciences, 11, 1326926.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Distribuzioni di massa e di densità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_expval_var.html",
    "href": "chapters/probability/08_expval_var.html",
    "title": "9  Proprietà delle variabili casuali",
    "section": "",
    "text": "Introduzione\nSpesso è molto utile sintetizzare la distribuzione di una variabile casuale attraverso indicatori caratteristici. Questi indicatori consentono di cogliere le principali proprietà della distribuzione, come la posizione centrale (ovvero il “baricentro”) e la variabilità (ossia la dispersione attorno al centro). In questo modo, è possibile ottenere una descrizione sintetica e significativa della distribuzione di probabilità della variabile casuale.\nIn questo capitolo, introdurremo i concetti fondamentali di valore atteso e varianza di una variabile casuale, che sono strumenti essenziali per comprendere e riassumere le proprietà di una distribuzione probabilistica.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_expval_var.html#introduzione",
    "href": "chapters/probability/08_expval_var.html#introduzione",
    "title": "9  Proprietà delle variabili casuali",
    "section": "",
    "text": "Panoramica del capitolo\n\nConcetti di valore atteso e varianza per variabili casuali discrete.\nProprietà del valore atteso e della varianza.\nValore atteso e varianza per variabili casuali continue.\nUtilizzare R per calcolare valore atteso e varianza.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\nPer affrontare al meglio questo capitolo, assicurati di avere familiarità con i seguenti argomenti:\n\nÈ fondamentale aver letto la sezione Appendice F.\nSi consiglia la lettura del capitolo Expectation in Schervish & DeGroot (2014).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_expval_var.html#tendenza-centrale",
    "href": "chapters/probability/08_expval_var.html#tendenza-centrale",
    "title": "9  Proprietà delle variabili casuali",
    "section": "\n9.1 Tendenza centrale",
    "text": "9.1 Tendenza centrale\nQuando vogliamo comprendere il comportamento tipico di una variabile casuale, ci interessa spesso determinare il suo “valore tipico”. Tuttavia, questa nozione può essere interpretata in diversi modi:\n\n\nMedia: La somma dei valori divisa per il numero dei valori.\n\nMediana: Il valore centrale della distribuzione, quando i dati sono ordinati in senso crescente o decrescente.\n\nModa: Il valore che si verifica con maggiore frequenza.\n\nAd esempio, per il set di valori \\(\\{3, 1, 4, 1, 5\\}\\), la media è \\(\\frac{3+1+4+1+5}{5} = 2.8\\), la mediana è 3, e la moda è 1. Tuttavia, quando ci occupiamo di variabili casuali, anziché di semplici sequenze di numeri, diventa necessario chiarire cosa intendiamo per “valore tipico” in questo contesto. Questo ci porta alla definizione formale del valore atteso.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_expval_var.html#valore-atteso",
    "href": "chapters/probability/08_expval_var.html#valore-atteso",
    "title": "9  Proprietà delle variabili casuali",
    "section": "\n9.2 Valore atteso",
    "text": "9.2 Valore atteso\n\nDefinizione 9.1 Sia \\(X\\) una variabile casuale discreta che assume i valori \\(x_1, \\dots, x_n\\) con probabilità \\(P(X = x_i) = p(x_i)\\). Il valore atteso di \\(X\\), denotato con \\(\\mathbb{E}(X)\\), è definito come:\n\\[\n\\mathbb{E}(X) = \\sum_{i=1}^n x_i \\cdot p(x_i).\n\\]\n\nIn altre parole, il valore atteso (noto anche come speranza matematica o aspettazione) di una variabile casuale è la somma di tutti i valori che la variabile può assumere, ciascuno ponderato dalla probabilità con cui esso si verifica.\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nCalcoliamo il valore atteso della variabile casuale \\(X\\) corrispondente al lancio di una moneta equilibrata, dove testa corrisponde a \\(X = 1\\) e croce corrisponde a \\(X = 0\\):\n\\[\n\\mathbb{E}(X) = \\sum_{i=1}^{2} x_i \\cdot P(x_i) = 0 \\cdot \\frac{1}{2} + 1 \\cdot \\frac{1}{2} = 0.5.\n\\]\n\n\n\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nCalcoliamo il valore atteso della variabile casuale \\(X\\) che rappresenta la somma dei punti ottenuti dal lancio di due dadi equilibrati a sei facce.\nLa variabile casuale \\(X\\) può assumere i seguenti valori:\n\\[\n\\{2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12\\}.\n\\]\nLa probabilità associata a ciascun valore è data dalla distribuzione di massa di probabilità. Ad esempio, il valore \\(X = 2\\) si ottiene solo se entrambi i dadi mostrano 1, quindi ha probabilità:\n\\[\nP(X = 2) = \\frac{1}{36}.\n\\]\nAnalogamente, \\(X = 7\\) può essere ottenuto con sei combinazioni diverse: (1,6), (2,5), (3,4), (4,3), (5,2), (6,1), quindi:\n\\[\nP(X = 7) = \\frac{6}{36}.\n\\]\nLa distribuzione di massa di probabilità completa è:\n\\[\nP(X) = \\left\\{\\frac{1}{36}, \\frac{2}{36}, \\frac{3}{36}, \\frac{4}{36}, \\frac{5}{36}, \\frac{6}{36}, \\frac{5}{36}, \\frac{4}{36}, \\frac{3}{36}, \\frac{2}{36}, \\frac{1}{36}\\right\\}.\n\\]\nIl valore atteso \\(\\mathbb{E}[X]\\) è definito come:\n\\[\n\\mathbb{E}[X] = \\sum_{x} x \\cdot P(X = x).\n\\]\nApplicando questa formula:\n\\[\n\\mathbb{E}[X] = 2 \\cdot \\frac{1}{36} + 3 \\cdot \\frac{2}{36} + 4 \\cdot \\frac{3}{36} + \\cdots + 12 \\cdot \\frac{1}{36} = 7.\n\\]\nEcco come calcolarlo utilizzando R:\n\n# Valori di X e le loro probabilità\nvalori &lt;- 2:12\nprob &lt;- c(1, 2, 3, 4, 5, 6, 5, 4, 3, 2, 1) / 36\n\n# Calcolo del valore atteso\nvalore_atteso &lt;- sum(valori * prob)\nvalore_atteso\n#&gt; [1] 7\n\nIl risultato sarà: \\[\n\\mathbb{E}[X] = 7.\n\\]\nPer rappresentare graficamente la distribuzione di massa di probabilità:\n\n# Creazione di un data frame\ndati &lt;- data.frame(Valore = valori, Probabilità = prob)\n\n# Plot\nggplot(dati, aes(x = Valore, y = Probabilità)) +\n  geom_col(fill = \"lightblue\") +\n  labs(\n    title = \"Distribuzione di Massa di Probabilità per X\",\n    x = \"Valore della Somma (X)\",\n    y = \"Probabilità\"\n  ) \n\n\n\n\n\n\n\n\n\n\nNel suo Ars conjectandi, Bernoulli introduce la nozione di valore atteso con le seguenti parole:\n\nil termine “aspettativa” non deve essere inteso nel suo significato comune […], bensì come la speranza di ottenere il meglio diminuita dalla paura di ottenere il peggio. Pertanto, il valore della nostra aspettativa rappresenta sempre qualcosa di intermedio tra il meglio che possiamo sperare e il peggio che possiamo temere (Hacking, 2006).\n\nIn termini moderni, questa intuizione può essere rappresentata in modo più chiaro attraverso una simulazione. Possiamo affermare, infatti, che il valore atteso di una variabile casuale corrisponde alla media aritmetica di un gran numero di realizzazioni indipendenti della variabile stessa.\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nPer fare un esempio concreto, consideriamo nuovamente il caso del lancio di due dadi bilanciati a sei facce, dove la variabile casuale \\(X\\) rappresenta la “somma dei due dadi”. Simuliamo un numero elevato di realizzazioni indipendenti di \\(X\\).\n\nset.seed(123)  \nx_samples &lt;- sample(valori, size = 1e6, replace = TRUE, prob = prob)\n\nL’istruzione sample(x, size = 1e6, replace = TRUE, prob = px)) utilizza R per generare un array di 1.000.000 di elementi (specificato dal parametro size), selezionati casualmente dall’array x secondo le probabilità specificate nell’array px.\nQuando il numero di realizzazioni indipendenti è sufficientemente grande, la media aritmetica dei campioni generati si avvicina al valore atteso della variabile casuale:\n\nmean(x_samples)\n#&gt; [1] 7\n\nQuesto risultato conferma che il valore atteso \\(\\mathbb{E}[X] = 7\\) rappresenta la somma media dei punti ottenuti nel lancio di due dadi equilibrati su un numero elevato di prove. Anche se ogni singola somma può variare tra 2 e 12, in media ci aspettiamo una somma di 7.\nL’aspettativa può anche essere interpretata come un centro di massa. Immagina che delle masse puntiformi con pesi \\(p_1, p_2, \\dots, p_n\\) siano posizionate alle posizioni \\(x_1, x_2, \\dots, x_n\\) sulla retta reale. Il centro di massa—il punto in cui i pesi sono bilanciati—è dato da:\n\\[\n\\text{centro di massa} = x_1 p_1 + x_2 p_2 + \\dots + x_n p_n,\n\\]\nche corrisponde esattamente all’aspettativa della variabile discreta \\(X\\), che assume valori \\(x_1, \\dots, x_n\\) con probabilità \\(p_1, \\dots, p_n\\). Una conseguenza ovvia di questa interpretazione è che, per una funzione di densità di probabilità (pdf) simmetrica, l’aspettativa coincide con il punto di simmetria (a patto che l’aspettativa esista).\n\n\n\n\n\nFigura 9.1: L’aspettativa come centro di massa (figura tratta da Chan & Kroese, 2025).\n\n\n\n\n\n\n9.2.1 Proprietà del valore atteso\nUna delle proprietà più importanti del valore atteso è la sua linearità: il valore atteso della somma di due variabili casuali è uguale alla somma dei loro rispettivi valori attesi:\n\\[\n\\mathbb{E}(X + Y) = \\mathbb{E}(X) + \\mathbb{E}(Y).\n\\tag{9.1}\\]\nQuesta proprietà, espressa dalla formula sopra, è intuitiva quando \\(X\\) e \\(Y\\) sono variabili casuali indipendenti, ma è valida anche nel caso in cui \\(X\\) e \\(Y\\) siano correlate.\nInoltre, se moltiplichiamo una variabile casuale per una costante \\(c\\), il valore atteso del prodotto è uguale alla costante moltiplicata per il valore atteso della variabile casuale:\n\\[\n\\mathbb{E}(cY) = c \\mathbb{E}(Y).\n\\tag{9.2}\\]\nQuesta proprietà ci dice che una costante può essere “estratta” dall’operatore di valore atteso, e si applica a qualunque numero di variabili casuali.\nUn’altra proprietà significativa riguarda il prodotto di variabili casuali indipendenti. Se \\(X\\) e \\(Y\\) sono indipendenti, allora il valore atteso del loro prodotto è uguale al prodotto dei loro valori attesi:\n\\[\n\\mathbb{E}(XY) = \\mathbb{E}(X) \\mathbb{E}(Y).\n\\tag{9.3}\\]\nInfine, consideriamo la media aritmetica \\(\\bar{X} = \\frac{X_1 + \\ldots + X_n}{n}\\) di \\(n\\) variabili casuali indipendenti con la stessa distribuzione e con valore atteso \\(\\mu\\). Il valore atteso della media aritmetica è:\n\\[\n\\mathbb{E}(\\bar{X}) = \\frac{1}{n} \\left(\\mathbb{E}(X_1) + \\dots + \\mathbb{E}(X_n)\\right) = \\frac{1}{n} \\cdot n \\cdot \\mathbb{E}(X) = \\mu.\n\\]\nQuesto risultato conferma che la media aritmetica di un campione di variabili casuali indipendenti ha lo stesso valore atteso della distribuzione originaria, rendendo il valore atteso uno strumento cruciale per l’analisi statistica e probabilistica.\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nConsideriamo il seguente esperimento casuale. Sia \\(Y\\) il numero che si ottiene dal lancio di un dado equilibrato a sei facce e \\(Y\\) il numero di teste prodotto dal lancio di una moneta equilibrata (0 oppure 1). Troviamo il valore atteso di \\(X+Y\\).\nPer risolvere il problema iniziamo a costruire lo spazio campione dell’esperimento casuale.\n\n\n\n\n\n\n\n\n\n\n\n\\(x /\\ y\\)\n1\n2\n3\n4\n5\n6\n\n\n\n0\n(0, 1)\n(0, 2)\n(0, 3)\n(0, 4)\n(0, 5)\n(0, 6)\n\n\n1\n(1, 1)\n(1, 2)\n(1, 3)\n(1, 4)\n(1, 5)\n(1, 6)\n\n\n\novvero\n\n\n\\(x /\\ y\\)\n1\n2\n3\n4\n5\n6\n\n\n\n0\n1\n2\n3\n4\n5\n6\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\nIl risultato del lancio del dado è indipendente dal risultato del lancio della moneta. Pertanto, ciascun evento elementare dello spazio campione avrà la stessa probabilità di verificarsi, ovvero \\(P(\\omega) = \\frac{1}{12}\\). Il valore atteso di \\(X+Y\\) è dunque uguale a:\n\\[\n\\mathbb{E}(X+Y) = 1 \\cdot \\frac{1}{12} + 2 \\cdot \\frac{1}{12} + \\dots + 7 \\cdot \\frac{1}{12} = 4.0.\n\\]\nSi ottiene lo stesso risultato usando l’Equazione 9.1:\n\\[\n\\mathbb{E}(X+Y) = \\mathbb{E}(X) + E(Y) = 3.5 + 0.5 = 4.0.\n\\]\n\n\n\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nSvolgiamo ora l’esercizio in R\n\ncoin &lt;- 0:1  # Valori della moneta: testa (0) e croce (1)\ndie &lt;- 1:6   # Valori del dado: da 1 a 6\n\n# Creazione del campione come combinazione di valori (moneta, dado)\nsample &lt;- expand.grid(coin = coin, die = die)\nprint(sample)\n#&gt;    coin die\n#&gt; 1     0   1\n#&gt; 2     1   1\n#&gt; 3     0   2\n#&gt; 4     1   2\n#&gt; 5     0   3\n#&gt; 6     1   3\n#&gt; 7     0   4\n#&gt; 8     1   4\n#&gt; 9     0   5\n#&gt; 10    1   5\n#&gt; 11    0   6\n#&gt; 12    1   6\n\n\npx &lt;- numeric()  # Vettore per memorizzare le probabilità\n\nfor (i in 1:7) {\n  # Filtrare le combinazioni in cui la somma è uguale a 'i'\n  event &lt;- subset(sample, coin + die == i)\n  # Calcolare la probabilità\n  prob &lt;- nrow(event) / nrow(sample)\n  px &lt;- c(px, prob)\n  \n  # Stampare la probabilità\n  cat(sprintf(\"P(X + Y = %d) = %d / %d\\n\", i, nrow(event), nrow(sample)))\n}\n#&gt; P(X + Y = 1) = 1 / 12\n#&gt; P(X + Y = 2) = 2 / 12\n#&gt; P(X + Y = 3) = 2 / 12\n#&gt; P(X + Y = 4) = 2 / 12\n#&gt; P(X + Y = 5) = 2 / 12\n#&gt; P(X + Y = 6) = 2 / 12\n#&gt; P(X + Y = 7) = 1 / 12\n\n\nx &lt;- 1:7  # Valori della variabile casuale (somma di moneta e dado)\nexpected_value &lt;- sum(x * px)\nexpected_value\n#&gt; [1] 4\n\n\n\n\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nConsideriamo le variabili casuali \\(X\\) e \\(Y\\) definite nel caso del lancio di tre monete equilibrate, dove \\(X\\) conta il numero delle teste nei tre lanci e \\(Y\\) conta il numero delle teste al primo lancio. Si calcoli il valore atteso di \\(Z = X \\cdot Y\\).\nLa distribuzione di probabilità congiunta \\(P(X, Y)\\) è fornita nella tabella seguente.\n\n\n\\(x /\\ y\\)\n0\n1\n\\(p(Y)\\)\n\n\n\n0\n1/8\n0\n1/8\n\n\n1\n2/8\n1/8\n3/8\n\n\n2\n1/8\n2/8\n3/8\n\n\n3\n0\n1/8\n1/8\n\n\n\\(p(y)\\)\n4/8\n4/8\n1.0\n\n\n\nIl calcolo del valore atteso di \\(XY\\) si riduce a\n\\[\n\\mathbb{E}(Z) = 1 \\cdot \\frac{1}{8} + 2 \\cdot \\frac{2}{8} + 3 \\cdot \\frac{1}{8} = 1.0.\n\\]\nSi noti che le variabili casuali \\(Y\\) e \\(Y\\) non sono indipendenti. Dunque non possiamo usare l’Equazione 9.3. Infatti, il valore atteso di \\(X\\) è\n\\[\n\\mathbb{E}(X) = 1 \\cdot \\frac{3}{8} + 2 \\cdot \\frac{3}{8} + 3 \\cdot \\frac{1}{8} = 1.5\n\\]\ne il valore atteso di \\(Y\\) è\n\\[\n\\mathbb{E}(Y) = 0 \\cdot \\frac{4}{8} + 1 \\cdot \\frac{4}{8} = 0.5.\n\\]\nPerciò\n\\[\n1.5 \\cdot 0.5 \\neq 1.0.\n\\]\n\n\n\n\n9.2.2 Valore atteso di una variabile casuale continua\nNel caso di una variabile casuale continua \\(X\\), il valore atteso è definito come:\n\\[\n\\mathbb{E}(X) = \\int_{-\\infty}^{+\\infty} x \\cdot p(x) \\, \\mathrm{d}x.\n\\]\nAnche in questo contesto, il valore atteso rappresenta una media ponderata dei valori di \\(x\\), dove ogni possibile valore di \\(x\\) è ponderato in base alla densità di probabilità \\(p(x)\\).\nL’integrale può essere interpretato analogamente a una somma continua, in cui \\(x\\) rappresenta la posizione delle barre infinitamente strette di un istogramma, e \\(p(x)\\) rappresenta l’altezza di tali barre. La notazione \\(\\int_{-\\infty}^{+\\infty}\\) indica che si sta sommando il contributo di ogni valore possibile di \\(x\\) lungo l’intero asse reale.\nQuesta interpretazione rende chiaro come l’integrale calcoli una somma ponderata che si estende su tutti i possibili valori di \\(x\\), fornendo una misura centrale della distribuzione della variabile casuale continua. Per ulteriori dettagli sulla notazione dell’integrale, si veda l’?sec-calculus.\n\n9.2.2.1 Moda\nUn’altra misura di tendenza centrale delle variabili casuali continue è la moda. La moda di \\(Y\\) individua il valore \\(y\\) più plausibile, ovvero il valore \\(y\\) che massimizza la funzione di densità \\(p(y)\\):\n\\[\nMo(Y) = \\text{argmax}_y p(y).\n\\tag{9.4}\\]\n\n\n\n\n\n\nLa notazione \\(\\text{argmax}_y p(y)\\) significa: il valore \\(y\\) tale per cui la funzione \\(p(y)\\) assume il suo valore massimo.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_expval_var.html#varianza",
    "href": "chapters/probability/08_expval_var.html#varianza",
    "title": "9  Proprietà delle variabili casuali",
    "section": "\n9.3 Varianza",
    "text": "9.3 Varianza\nDopo il valore atteso, la seconda proprietà più importante di una variabile casuale è la varianza.\n\nDefinizione 9.2 Se \\(X\\) è una variabile casuale discreta con distribuzione \\(p(x)\\), la varianza di \\(X\\), denotata con \\(\\mathbb{V}(X)\\), è definita come:\n\\[\n\\mathbb{V}(X) = \\mathbb{E}\\Big[\\big(X - \\mathbb{E}(X)\\big)^2\\Big].\n\\tag{9.5}\\]\n\nIn altre parole, la varianza misura la deviazione media quadratica dei valori della variabile rispetto alla sua media. Se denotiamo il valore atteso di \\(X\\) con \\(\\mu = \\mathbb{E}(X)\\), la varianza \\(\\mathbb{V}(X)\\) diventa il valore atteso di \\((X - \\mu)^2\\).\nLa varianza rappresenta una misura della “dispersione” dei valori di \\(X\\) intorno al suo valore atteso. Quando calcoliamo la varianza, stiamo effettivamente misurando quanto i valori di \\(X\\) tendono a differire dalla media \\(\\mu\\).\nPer capire meglio, consideriamo la variabile casuale \\(X - \\mathbb{E}(X)\\), detta scarto o deviazione dalla media. Questa variabile rappresenta le “distanze” tra i valori di \\(X\\) e il valore atteso \\(\\mathbb{E}(X)\\). Tuttavia, poiché lo scarto può essere positivo o negativo, la media dello scarto è sempre zero, il che lo rende inadatto a quantificare la dispersione.\nPer risolvere questo problema, eleviamo al quadrato gli scarti, ottenendo \\((X - \\mathbb{E}(X))^2\\), che rende tutte le deviazioni positive. La varianza è quindi la media di questi scarti al quadrato, fornendo una misura efficace della dispersione complessiva dei valori di \\(X\\) rispetto alla sua media.\nQuesto concetto è fondamentale per comprendere la variabilità di una distribuzione e per applicare strumenti statistici che richiedono una conoscenza approfondita della distribuzione dei dati.\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nPosta \\(S\\) uguale alla somma dei punti ottenuti nel lancio di due dadi equilibrati, si calcoli la varianza di \\(S\\).\nLa variabile casuale \\(S\\) ha la seguente distribuzione di probabilità:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(s\\)\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\\(P(S = s)\\)\n\\(\\frac{1}{36}\\)\n\\(\\frac{2}{36}\\)\n\\(\\frac{3}{36}\\)\n\\(\\frac{4}{36}\\)\n\\(\\frac{5}{36}\\)\n\\(\\frac{6}{36}\\)\n\\(\\frac{5}{36}\\)\n\\(\\frac{4}{36}\\)\n\\(\\frac{3}{36}\\)\n\\(\\frac{2}{36}\\)\n\\(\\frac{1}{36}\\)\n\n\nEssendo \\(\\mathbb{E}(S) = 7\\), la varianza diventa\n\\[\n\\begin{aligned}\n\\mathbb{V}(S) &= \\sum \\left(s - \\mathbb{E}(S)\\right)^2 \\cdot P(s) \\notag\\\\\n&= (2 - 7)^2 \\cdot \\frac{1}{36} + (3-7)^2 \\cdot \\frac{3}{36} + \\dots + (12 - 7)^2 \\cdot \\frac{1}{36} \\notag\\\\\n&= 5.8333.\\notag\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nSvolgiamo l’esercizio in R\n\n# Definire i valori di x e le loro probabilità px\nx &lt;- 2:12\npx &lt;- c(\n  1 / 36, 2 / 36, 3 / 36, 4 / 36, 5 / 36, 6 / 36,\n  5 / 36, 4 / 36, 3 / 36, 2 / 36, 1 / 36\n)\n\n# Calcolare il valore atteso\nex &lt;- sum(x * px)\nex\n#&gt; [1] 7\n\nApplichiamo l’Equazione 9.5:\n\n# Calcolo della varianza utilizzando la definizione\nvariance &lt;- sum((x - ex)^2 * px)\nvariance\n#&gt; [1] 5.83\n\nUsiamo la funzione var() di rv_discrete:\n\n# Calcolo della varianza con pesi\nvariance_check &lt;- weighted.mean((x - ex)^2, w = px)\nvariance_check\n#&gt; [1] 5.83\n\n\n\n\n\n9.3.1 Formula alternativa per la varianza\nLa varianza di una variabile casuale \\(X\\), indicata come \\(\\mathbb{V}(X)\\), misura la dispersione dei valori attorno alla media. La definizione classica è:\n\\[\n\\mathbb{V}(X) = \\mathbb{E}\\Big[\\big(X - \\mathbb{E}(X)\\big)^2\\Big].\n\\]\nEsiste però una formula alternativa che semplifica il calcolo.\n\nDimostrazione. \n\nEspansione del quadrato\nConsideriamo la varianza, definita come \\(\\mathbb{V}(X) = \\mathbb{E}\\big[(X - \\mathbb{E}(X))^2\\big]\\).\nEspandiamo il quadrato \\((X - \\mathbb{E}(X))^2\\) utilizzando la regola \\((a - b)^2 = a^2 - 2ab + b^2\\): \\[\n(X - \\mathbb{E}(X))^2 = X^2 - 2\\,X\\,\\mathbb{E}(X) + \\big(\\mathbb{E}(X)\\big)^2.\n\\]\nApplicazione dell’aspettativa\nApplichiamo \\(\\mathbb{E}[\\cdot]\\) a ciascun termine, ricordando che l’aspettativa è un operatore lineare: \\[\n\\mathbb{E}\\big[(X - \\mathbb{E}(X))^2\\big]\n= \\mathbb{E}\\big[X^2\\big]\n  \\;-\\; 2 \\,\\mathbb{E}\\big[X\\,\\mathbb{E}(X)\\big]\n  \\;+\\; \\mathbb{E}\\big[\\big(\\mathbb{E}(X)\\big)^2\\big].\n\\]\n\nGestione dei termini costanti\nL’aspettativa \\(\\mathbb{E}(X)\\) è una costante (indipendente da \\(X\\)). Indichiamola con \\(\\mu\\). Quindi:\n\n\n\\(\\mathbb{E}(X^2)\\) resta com’è.\n\n\\(\\mathbb{E}[X \\cdot \\mu] = \\mu \\, \\mathbb{E}[X] = \\mu \\cdot \\mu = \\mu^2\\).\n\n\\(\\mathbb{E}\\big(\\mu^2\\big) = \\mu^2\\).\n\n\n\nSostituzione e semplificazione\nRimpiazzando i risultati nel secondo passaggio si ottiene: \\[\n\\mathbb{E}(X^2) \\;-\\; 2\\,\\mu^2 \\;+\\; \\mu^2\n\\;=\\; \\mathbb{E}(X^2) - \\mu^2.\n\\]\nPoiché \\(\\mu = \\mathbb{E}(X)\\), la varianza può quindi essere scritta come:\n\\[\n\\boxed{\n\\mathbb{V}(X) = \\mathbb{E}(X^2) \\;-\\; \\bigl(\\mathbb{E}(X)\\bigr)^2.\n}\n\\tag{9.6}\\]\n\n\n\nQuesta forma risulta molto utile per ragioni di efficienza computazionale: invece di calcolare gli scarti \\((X - \\mu)\\) per ogni osservazione, è sufficiente trovare \\(\\mathbb{E}(X^2)\\) e poi sottrarre \\(\\mu^2\\). In tal modo si riducono i passaggi intermedi e, di conseguenza, si minimizzano gli errori pratici. Inoltre, nelle dimostrazioni che richiedono manipolazioni algebriche – come quelle tipiche della Teoria Classica dei Test – questa espressione semplifica notevolmente le trasformazioni.\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nConsideriamo la variabile casuale \\(X\\) che corrisponde al numero di teste che si osservano nel lancio di una moneta truccata con probabilità di testa uguale a 0.8. Si trovi la varianza di \\(Y\\).\nIl valore atteso di \\(X\\) è\n\\[\n\\mathbb{E}(X) = 0 \\cdot 0.2 + 1 \\cdot 0.8 = 0.8.\n\\]\nUsando la formula tradizionale della varianza otteniamo:\n\\[\n\\mathbb{V}(X) = (0 - 0.8)^2 \\cdot 0.2 + (1 - 0.8)^2 \\cdot 0.8 = 0.16.\n\\]\nLo stesso risultato si trova con la formula alternativa della varianza. Il valore atteso di \\(X^2\\) è\n\\[\n\\mathbb{E}(X^2) = 0^2 \\cdot 0.2 + 1^2 \\cdot 0.8 = 0.8.\n\\]\ne la varianza diventa\n\\[\n\\mathbb{V}(X) = \\mathbb{E}(X^2) - \\big(\\mathbb{E}(Y) \\big)^2 = 0.8 - 0.8^2 = 0.16.\n\\]\n\n\n\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nSvolgiamo l’esercizio in R:\n\n# Definire i valori di x e le probabilità px\nx &lt;- c(0, 1)\npx &lt;- c(0.2, 0.8)\n\n# Calcolare il risultato\nresult &lt;- sum(x^2 * px) - (sum(x * px))^2\nresult\n#&gt; [1] 0.16\n\n\n\n\n\n9.3.2 Proprietà\nSegno della varianza. La varianza di una variabile aleatoria non è mai negativa, ed è zero solamente quando la variabile assume un solo valore.\nInvarianza per traslazione. La varianza è invariante per traslazione, che lascia fisse le distanze dalla media, e cambia quadraticamente per riscalamento:\n\\[\n\\mathbb{V}(a + bX) = b^2\\mathbb{V}(X).\n\\]\nDimostrazione. Iniziamo a scrivere\n\\[\n(aX+b)-{\\mathbb{E}}[aX+b]=aX+b-a{\\mathbb{E}}[X]-b=a(X-{\\mathbb  {E}}[X]).\n\\]\nQuindi\n\\[\n\\sigma _{{aX+b}}^{2}={\\mathbb{E}}[a^{2}(X-{\\mathbb  {E}}[X])^{2}]=a^{2}\\sigma _{X}^{2}.\n\\]\nEsaminiamo una dimostrazione numerica.\n\n# Definire i valori di x\nx &lt;- c(2, 1, 4, 7)\n\n# Calcolare y\ny &lt;- 100 + 2 * x\n\n# Verificare la relazione tra le varianze\nresult &lt;- var(y) == 2^2 * var(x)\nresult\n#&gt; [1] TRUE\n\nVarianza della somma di due variabili indipendenti. La varianza della somma di due variabili indipendenti o anche solo incorrelate è pari alla somma delle loro varianze:\n\\[\n\\mathbb{V}(X+Y) = \\mathbb{V}(X) + \\mathbb{V}(Y).\n\\]\nDimostrazione. Se \\(\\mathbb{E}(X) = \\mathbb{E}(Y) = 0\\), allora \\(\\mathbb{E}(X+Y) = 0\\) e\n\\[\\mathbb{V}(X+Y) = \\mathbb{E}((X+Y)^2) = \\mathbb{E}(X^2) + 2 \\mathbb{E}(XY) + \\mathbb{E}(Y^2).\\]\nSiccome le variabili sono indipendenti risulta \\(\\mathbb{E}(XY) = \\mathbb{E}(X)\\mathbb{E}(Y) = 0\\).\nVarianza della differenza di due variabili indipendenti. La varianza della differenza di due variabili indipendenti è pari alla somma delle loro varianze:\n\\[\n\\mathbb{V}(X-Y) = \\mathbb{V}(X) + \\mathbb{V}(Y).\n\\]\nDimostrazione.\n\\[\n\\mathbb{V}(X-Y) = \\mathbb{V}(X +(-Y)) = \\mathbb{V}(X) + \\mathbb{V}(-Y) = \\mathbb{V}(X) + \\mathbb{V}(Y).\n\\]\nVarianza della somma di due variabili non indipendenti. Se \\(X\\) e \\(Y\\) non sono indipendenti, la formula viene corretta dalla loro covarianza:\n\\[\n\\mathbb{V}(X+Y) = \\mathbb{V}(X) + \\mathbb{V}(Y) + 2 Cov(X,Y),\n\\]\ndove \\(Cov(X,Y) = \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y)\\).\nUna dimostrazione numerica di questo principio è fornita sotto.\n\n# Definire i valori di x e y\nx &lt;- c(2, 1, 4, 7)\ny &lt;- c(1, 3, 5, 11)\n\n# Calcolare la varianza di x + y con ddof = 0\nvar_x_y &lt;- mean((x + y - mean(x + y))^2)\nvar_x_y\n#&gt; [1] 35.2\n\n\n# Definire i valori di x e y\nx &lt;- c(2, 1, 4, 7)\ny &lt;- c(1, 3, 5, 11)\n\n# Calcolo della varianza combinata\nresult &lt;- mean((x - mean(x))^2) + \n          mean((y - mean(y))^2) + \n          2 * cov(x, y) * (length(x) - 1) / length(x)\nresult\n#&gt; [1] 35.2\n\nVarianza della media di variabili indipendenti. La media aritmetica \\(\\textstyle {\\bar  {X}}={\\frac  {X_{1}+\\ldots +X_{n}}{n}}\\) di \\(n\\) variabili casuali indipendenti aventi la medesima distribuzione, ha varianza\n\\[\n\\mathbb{V}(\\bar{X}) = \\frac{1}{n^2} \\mathbb{V}(X_1)+ \\dots \\mathbb{V}(X_n) = \\frac{1}{n^2} n \\mathbb{V}(X) = \\frac{1}{n} \\mathbb{V}(X).\n\\]\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nIl principio precedente è illustrato dalla seguente simulazione.\n\n# Creare la popolazione\nset.seed(123)  # Per riproducibilità\npopulation &lt;- rnorm(10000, mean = 50, sd = 10)\n\n# Definire dimensione del campione e numero di campioni\nsample_size &lt;- 30\nnum_samples &lt;- 100000\n\n# Creare un vettore per memorizzare le medie campionarie\nsample_means &lt;- numeric(num_samples)\n\n# Generare i campioni e calcolare le medie\nfor (i in 1:num_samples) {\n  sample &lt;- sample(population, size = sample_size, replace = TRUE)\n  sample_means[i] &lt;- mean(sample)\n}\n\n# Calcolare la varianza delle medie campionarie\nsampling_dist_mean_var &lt;- var(sample_means) * ((num_samples - 1) / num_samples)  # ddof = 0\nsampling_dist_mean_var\n#&gt; [1] 3.33\n\nIl valore teorico della varianza della distribuzione campionaria della media è\n\n10^2 / 30\n#&gt; [1] 3.33\n\n\n\n\n\n9.3.3 Varianza di una variabile casuale continua\nPer una variabile casuale continua \\(X\\), la varianza è definita come:\n\\[\n\\mathbb{V}(X) = \\int_{-\\infty}^{+\\infty} \\large[x - \\mathbb{E}(X)\\large]^2 p(x) \\,\\operatorname {d}\\!x.\n\\tag{9.7}\\]\nAnalogamente al caso discreto, la varianza di una variabile casuale continua \\(X\\) una misura della dispersione, ovvero la “distanza” media quadratica attesa dei valori \\(x\\) rispetto alla loro media \\(\\mathbb{E}(X)\\). In altre parole, la varianza quantifica quanto i valori della variabile casuale si discostano tipicamente dal loro valore medio.\n\n9.3.4 Deviazione standard\nQuando si lavora con le varianze, i valori sono elevati al quadrato, il che può rendere i numeri significativamente più grandi (o più piccoli) rispetto ai dati originali. Per riportare questi valori all’unità di misura della scala originale, si prende la radice quadrata della varianza. Il risultato ottenuto è chiamato deviazione standard ed è comunemente indicato con la lettera greca \\(\\sigma\\).\n\nDefinizione 9.3 La deviazione standard, o scarto quadratico medio, è definita come la radice quadrata della varianza:\n\\[\n\\sigma_X = \\sqrt{\\mathbb{V}(X)}.\n\\tag{9.8}\\]\n\nCome nella statistica descrittiva, la deviazione standard di una variabile casuale fornisce una misura della dispersione, ossia la “distanza” tipica o prevista dei valori \\(x\\) rispetto alla loro media.\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nPer i dadi equilibrati dell’esempio precedente, la deviazione standard della variabile casuale \\(S\\) è pari a \\(\\sqrt{5.833} = 2.415\\). Questo valore indica quanto i risultati della somma dei due dadi tendono a variare attorno alla loro media.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_expval_var.html#standardizzazione",
    "href": "chapters/probability/08_expval_var.html#standardizzazione",
    "title": "9  Proprietà delle variabili casuali",
    "section": "\n9.4 Standardizzazione",
    "text": "9.4 Standardizzazione\n\nDefinizione 9.4 Data una variabile casuale \\(X\\), si dice variabile standardizzata di \\(X\\) l’espressione\n\\[\nZ = \\frac{X - \\mathbb{E}(X)}{\\sigma_X}.\n\\tag{9.9}\\]\n\nSolitamente, una variabile standardizzata viene denotata con la lettera \\(Z\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_expval_var.html#il-teorema-di-chebyshev",
    "href": "chapters/probability/08_expval_var.html#il-teorema-di-chebyshev",
    "title": "9  Proprietà delle variabili casuali",
    "section": "\n9.5 Il teorema di Chebyshev",
    "text": "9.5 Il teorema di Chebyshev\nIl Teorema di Chebyshev ci permette di stimare la probabilità che una variabile aleatoria si discosti dal suo valore atteso (media) di una certa quantità. In altre parole, ci fornisce un limite superiore alla probabilità che una variabile aleatoria assuma valori “estremi”.\nIl teorema di Chebyshev afferma che, per qualsiasi variabile aleatoria X con media E(X) e varianza Var(X), e per qualsiasi numero reale k &gt; 0, si ha:\n\\[\nP(\\mid X - E(X)\\mid \\geq k \\sigma) \\leq 1/k^2,\n\\tag{9.10}\\]\ndove:\n\n\n\\(P(\\mid X - E(X)\\mid \\geq k \\sigma)\\) è la probabilità che lo scarto assoluto tra X e la sua media sia maggiore o uguale a k volte la deviazione standard (σ).\nσ è la radice quadrata della varianza, ovvero la deviazione standard.\n\nCosa ci dice questo teorema?\n\n\nLimite superiore: Il teorema ci fornisce un limite superiore alla probabilità che una variabile aleatoria si discosti dalla sua media di più di k deviazioni standard.\n\nQualsiasi distribuzione: La bellezza di questo teorema è che vale per qualsiasi distribuzione di probabilità, a patto che la media e la varianza esistano.\n\nUtilizzo: Il teorema di Chebyshev è molto utile quando non conosciamo la distribuzione esatta di una variabile aleatoria, ma conosciamo la sua media e la sua varianza.\n\nIn sintesi, il teorema di Chebyshev ci fornisce un limite superiore alla probabilità che una variabile aleatoria si discosti dalla sua media di una certa quantità, in base alla sua varianza. Il teorema di Chebyshev ci permette quindi di fare inferenze sulla distribuzione di una variabile aleatoria anche quando abbiamo informazioni limitate.\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nSupponiamo di avere una variabile aleatoria \\(X\\) con media 100 e varianza 25. Vogliamo stimare la probabilità che \\(X\\) assuma valori al di fuori dell’intervallo [90, 110].\nIn questo caso, \\(k\\) = 2 (poiché 10 è uguale a 2 volte la deviazione standard, che è 5). Applicando il teorema di Chebyshev, otteniamo:\n\\[\nP(\\mid X - 100 \\mid \\geq 10) \\leq \\left( \\frac{1}{2} \\right)^2 = 0.25\n\\]\nQuindi, possiamo affermare con certezza che al massimo il 25% dei valori di X saranno al di fuori dell’intervallo [90, 110].",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_expval_var.html#momenti-di-variabili-casuali",
    "href": "chapters/probability/08_expval_var.html#momenti-di-variabili-casuali",
    "title": "9  Proprietà delle variabili casuali",
    "section": "\n9.6 Momenti di variabili casuali",
    "text": "9.6 Momenti di variabili casuali\n\nDefinizione 9.5 Si chiama momento di ordine \\(q\\) di una v.c. \\(X\\), dotata di densità \\(p(x)\\), la quantità\n\\[\n\\mathbb{E}(X^q) = \\int_{-\\infty}^{+\\infty} x^q p(x) \\; dx.\n\\tag{9.11}\\]\nSe \\(X\\) è una v.c. discreta, i suoi momenti valgono:\n\\[\n\\mathbb{E}(X^q) = \\sum_i x_i^q P(x_i),\n\\tag{9.12}\\]\ndove:\n\n\n\\(E(X^q)\\) rappresenta il valore atteso di \\(X\\) elevato alla \\(q\\)-esima potenza.\n\n\\(x_i\\) sono i possibili valori della variabile discreta.\n\n\\(P(x_i)\\) è la probabilità associata a ciascun valore discreto.\n\n\nI momenti sono parametri statistici che forniscono informazioni importanti sulle caratteristiche di una variabile casuale. Tra questi, i più noti e utilizzati sono:\n\nIl momento del primo ordine (\\(q\\) = 1): corrisponde al valore atteso (o media) della variabile casuale \\(X\\).\nIl momento del secondo ordine (\\(q\\) = 2): quando calcolato rispetto alla media, corrisponde alla varianza.\n\nPer i momenti di ordine superiore al primo, è comune calcolarli rispetto al valore medio di \\(X\\). Questo si ottiene applicando una traslazione: \\(x_0 = x − \\mathbb{E}(X)\\), dove \\(x_0\\) rappresenta lo scarto dalla media. In particolare, il momento centrale del secondo ordine, calcolato con questa traslazione, corrisponde alla definizione di varianza.\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nIn R, possiamo calcolare il valore atteso e la varianza di variabili casuali discrete utilizzando vettori di valori e probabilità.\nConsideriamo una variabile casuale \\(X\\) che rappresenta i valori ottenuti dal lancio di un dado non equilibrato, con valori possibili da 0 a 6, e con la seguente distribuzione di massa di probabilità: 0.1, 0.2, 0.3, 0.1, 0.1, 0.0, 0.2.\nIniziamo a definire un vettore che contiene i valori della v.c.:\n\nx &lt;- 0:6\nprint(x)\n#&gt; [1] 0 1 2 3 4 5 6\n\nIl vettore px conterrà le probabilità associate ai valori x:\n\npx &lt;- c(0.1, 0.2, 0.3, 0.1, 0.1, 0.0, 0.2)\nprint(px)\n#&gt; [1] 0.1 0.2 0.3 0.1 0.1 0.0 0.2\n\nControlliamo che la somma sia 1:\n\nsum(px)\n#&gt; [1] 1\n\nCalcoliamo il valore atteso di \\(X\\) implementando la formula del valore atteso utilizzando i vettori x e px:\n\nx_ev &lt;- sum(x * px)\nx_ev\n#&gt; [1] 2.7\n\nCalcoliamo la varianza di \\(X\\) usando i vettori x e px:\n\nx_var &lt;- sum((x - x_ev)^2 * px)\nx_var\n#&gt; [1] 3.81\n\nCalcoliamo la deviazione standard di \\(X\\) prendendo la radice quadrata della varianza:\n\nx_sd &lt;- sqrt(x_var)\nx_sd\n#&gt; [1] 1.95\n\nPer rappresentare graficamente la distribuzione di massa, possiamo usare ggplot2:\n\ndf &lt;- data.frame(x = x, pmf = px)\nggplot(df, aes(x = x, y = pmf)) +\n  geom_point(color = \"#832F2B\", size = 3) +\n  geom_segment(aes(xend = x, yend = 0), linewidth = 1) +\n  labs(title = \"Distribuzione di massa di probabilità\", \n       x = \"Valori\", y = \"Probabilità\")\n\n\n\n\n\n\n\nQuesto codice calcola il valore atteso, la varianza e la deviazione standard di una variabile casuale discreta e rappresenta graficamente la distribuzione di massa, tutto in R.\n\n\n\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nUn esempio pratico dell’uso del valore atteso e della varianza in psicologia è rappresentato dagli studi sulla memoria episodica, in particolare attraverso il paradigma sperimentale delle risposte “Remember-Know”. Questo paradigma permette di esplorare come le persone riconoscano eventi passati, distinguendo tra ricordi dettagliati e semplici sensazioni di familiarità.\nIl Paradigma “Remember-Know”\nIn un tipico esperimento di memoria episodica:\n\nAi partecipanti viene presentata una lista di stimoli (es. parole o immagini).\nDopo un intervallo di tempo, viene mostrata una nuova lista contenente elementi precedentemente visti (old) e elementi nuovi (new).\n\nPer ogni stimolo old riconosciuto, i soggetti devono specificare se:\n\n\nRemember (R): Ricordano consapevolmente dettagli contestuali dell’episodio di encoding (es. “Ricordo che questa parola era scritta in rosso”).\n\nKnow (K): Avvertono familiarità con lo stimolo, ma senza accesso a dettagli specifici (es. “Sembra conosciuto, ma non so perché”).\n\n\nMiss: Non riconoscono lo stimolo.\n\n\n\nLa variabile in gioco è quindi categorica e discreta, con tre possibili esiti per gli stimoli old: {R, K, Miss}.\nModelli Teorici e Previsioni Statistiche\nDue importanti teorie cercano di spiegare come avviene questo riconoscimento:\nTeoria del Processo Unico (Strength Theory) (e.g., Wixted & Mickes, 2010)\n\n\nIpotesi centrale:\nC’è una sola dimensione continua (la “forza mnemonica”) che determina il tipo di risposta.\n\nLe risposte Remember derivano da tracce molto forti, quelle Know da tracce di forza intermedia, e i Miss da tracce troppo deboli.\n\n\n\nImplicazioni statistiche: molte risposte Know, meno risposte Remember, bassa varianza.\n\nTeoria del Doppio Processo (Dual-Process) (e.g., Yonelinas, 2002)\n\n\nIpotesi centrale:\nCi sono due processi indipendenti:\n\n\nRecollection (R): Processo qualitativo e binario (presente/assente), legato al ricordo consapevole di dettagli contestuali.\n\n\nFamiliarità (K): Processo continuo, basato su una sensazione generica di familiarità.\n\n\n\nImplicazioni statistiche: numero simile di risposte Remember e Know, alta varianza.\n\nQui entrano in gioco i concetti statistici: ogni teoria formula previsioni diverse sul valore atteso (es. proporzione attesa di risposte R o K) e sulla varianza (dispersione dei dati attorno a questi valori). Confrontando le osservazioni sperimentali con le aspettative teoriche, è possibile testare quale modello sia più coerente con i dati empirici, illustrando come strumenti probabilistici possano chiarire meccanismi cognitivi complessi.\nConfronto Statistico: Previsioni Teoriche\nPer confrontare quantitativamente le previsioni dei due modelli, consideriamo un esperimento ipotetico con 100 stimoli old. Assegniamo punteggi numerici alle categorie di risposta per trasformarle in una variabile discreta, facilitando il calcolo di valore atteso e varianza:\n\n\nRemember (R) = 2\n\n\nKnow (K) = 1\n\nMiss = 0\n\nQuesta codifica riflette l’intensità mnemonica associata a ciascuna risposta, permettendo di quantificare le differenze teoriche tra i modelli.\n1. Modello Single-Process (Forza continua)\nSecondo questa teoria, la distribuzione attesa delle risposte è:\n\n\nCategoria\nR\nK\nMiss\n\n\n% Prevista\n25%\n60%\n15%\n\n\nCalcoli statistici:\n- Valore atteso (media ponderata):\\[\n  E(X) = (2 \\cdot 0.25) + (1 \\cdot 0.60) + (0 \\cdot 0.15) = 1.10\n  \\]\n- Varianza (dispersione attorno alla media):\\[\n  \\begin{aligned}\n  Var(X) &= (2-1.10)^2 \\cdot 0.25 + (1-1.10)^2 \\cdot 0.60 + (0-1.10)^2 \\cdot 0.15 \\\\\n  &= 0.2025 + 0.006 + 0.1815 = 0.39\n  \\end{aligned}\n  \\]\n2. Modello Dual-Process (Recollection e Familiarità)\nLa teoria prevede una distribuzione basata su due meccanismi indipendenti:\n\n\nCategoria\nR\nK\nMiss\n\n\n% Prevista\n40%\n40%\n20%\n\n\nCalcoli statistici:\n- Valore atteso:\\[\n  E(X) = (2 \\cdot 0.40) + (1 \\cdot 0.40) + (0 \\cdot 0.20) = 1.20\n  \\]\n- Varianza:\\[\n  \\begin{aligned}\n  Var(X) &= (2-1.20)^2 \\cdot 0.40 + (1-1.20)^2 \\cdot 0.40 + (0-1.20)^2 \\cdot 0.20 \\\\\n  &= 0.256 + 0.016 + 0.288 = 0.56\n  \\end{aligned}\n  \\]\nSintesi del Confronto\nI due modelli generano previsioni distinte, riassunte nella tabella seguente:\n\n\n\n\n\n\n\n\nModello\nValore Atteso\nVarianza\nInterpretazione\n\n\n\nSingle-Process\n1.10\n0.39\nMedia più bassa, varianza ridotta (distribuzione concentrata attorno a K).\n\n\nDual-Process\n1.20\n0.56\nMedia più alta, varianza elevata (effetto della miscela tra due processi).\n\n\n\n\n\nValore atteso: Il modello dual-process predice una media superiore, coerente con la maggiore proporzione attesa di risposte Remember.\n\n\nVarianza: La differenza nella dispersione (0.39 vs. 0.56) riflette l’eterogeneità introdotta dalla separazione tra recollection e familiarità nel modello duale.\n\nApplicazione a Dati Empirici\nSupponiamo ora di aver raccolto dati reali da 100 soggetti che hanno prodotto questa distribuzione:\n\n\nR\nK\nMiss\n\n\n38%\n42%\n20%\n\n\nCalcoliamo il valore atteso e la varianza empiriche:\n\\[\n  E(X) = 2 \\cdot 0.38 + 1 \\cdot 0.42 + 0 \\cdot 0.20 = 1.18\n  \\]\n\\[\n  Var(X) = (2-1.18)^2 \\cdot 0.38 + (1-1.18)^2 \\cdot 0.42 + (0-1.18)^2 \\cdot 0.20 = 0.55\n  \\]\nRisultati:\n\n\nDati\nValore Atteso\nVarianza\n\n\nEmpirici\n1.18\n0.55\n\n\nConfrontando questi risultati con le previsioni teoriche, notiamo che i dati empirici si avvicinano molto più al modello dual-process (valore atteso: 1.20 vs. 1.18; varianza: 0.56 vs. 0.55).\nImplicazioni Psicologiche e Cliniche\n\nTeoriche: Il confronto tra distribuzioni osservate e teoriche, usando valore atteso e varianza, consente di identificare quale teoria cognitiva spieghi meglio i dati.\nCliniche: In contesti clinici (es. valutazione di deficit cognitivi), questo approccio consente di identificare se un paziente mostra un profilo riconducibile a un danno selettivo della recollection (R ↓) o della familiarità (K ↓).\n\nQuesto framework illustra come strumenti probabilistici di base possano tradurre ipotesi psicologiche complesse in predizioni quantitative verificabili, avanzando la comprensione dei meccanismi cognitivi.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_expval_var.html#riflessioni-conclusive",
    "href": "chapters/probability/08_expval_var.html#riflessioni-conclusive",
    "title": "9  Proprietà delle variabili casuali",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn conclusione, i concetti di valore atteso e varianza sono fondamentali per comprendere il comportamento delle variabili casuali. Il valore atteso fornisce una misura centrale, rappresentando il “valore tipico” che ci si aspetta di osservare, mentre la varianza quantifica la dispersione dei valori attorno a questa media, offrendo una visione più completa della distribuzione. Questi strumenti sono essenziali per l’analisi e la modellizzazione statistica, fornendo le basi per valutare e interpretare la variabilità nei fenomeni aleatori.\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\nEsercizio 1: Calcolo del Valore Atteso per Variabili Discrete\nUtilizzando i dati raccolti dagli studenti sulla SWLS, calcola il valore atteso della soddisfazione con la vita (\\(X\\)). Organizza i dati come nell’esempio seguente e interpretalo come se fosse la distribuzione di probabilità nella popolazione:\n\n\nSWLS Score\nProbabilità \\(P(X)\\)\n\n\n\n\n5\n0.05\n\n\n10\n0.10\n\n\n15\n0.20\n\n\n20\n0.30\n\n\n25\n0.20\n\n\n30\n0.10\n\n\n35\n0.05\n\n\n\n\nCalcola il valore atteso di \\(X\\), \\(\\mathbb{E}(X)\\).\nInterpreta il risultato ottenuto.\n\nEsercizio 2: Varianza e Deviazione Standard\nData la stessa distribuzione della SWLS utilizzata nell’esercizio precedente:\n\nCalcola la varianza \\(\\mathbb{V}(X)\\).\nCalcola la deviazione standard \\(\\sigma_X\\).\nCommenta il significato della dispersione dei valori rispetto alla media.\n\nEsercizio 3: Proprietà del Valore Atteso\nUtilizzando la distribuzione della LSNS-6:\n\nDefinisci una nuova variabile casuale \\(Y = 2X + 3\\).\nCalcola il valore atteso di \\(Y\\), \\(\\mathbb{E}(Y)\\), utilizzando la linearità dell’operatore di aspettazione.\nVerifica il risultato calcolando direttamente \\(\\mathbb{E}(Y)\\) dalla distribuzione di probabilità di \\(Y\\).\n\nUtilizza una distribuzione della LSNS-6 organizzata come segue (sostituisci i valori presenti con quelli del campione):\n\n\nLSNS-6 Score\nProbabilità \\(P(Y)\\)\n\n\n\n\n5\n0.10\n\n\n10\n0.15\n\n\n15\n0.25\n\n\n20\n0.25\n\n\n25\n0.15\n\n\n30\n0.10\n\n\n\nEsercizio 4: Applicazione del Teorema di Chebyshev\nSia la soddisfazione con la vita (SWLS) distribuita con media \\(\\mu = 3.2\\) e deviazione standard \\(\\sigma = 0.8\\).\n\nUsa il teorema di Chebyshev per trovare un limite superiore alla probabilità che un valore di SWLS sia oltre due deviazioni standard dalla media.\nConfronta questo risultato con la probabilità empirica calcolata utilizzando i dati raccolti.\n\nEsercizio 5: Standardizzazione e Distribuzione Normale\n# Definizione dei dati osservati della LSNS-6 (sostituisci con i dati reali se disponibili)\nlsns6_scores &lt;- c(5, 8, 10, 12, 15, 18, 20, 22, 25, 28)\n\n# Parametri della distribuzione\nmu &lt;- 12   # Media della LSNS-6\nsigma &lt;- 4  # Deviazione standard della LSNS-6\n\n# Standardizzazione dei valori osservati\nz_scores &lt;- (lsns6_scores - mu) / sigma\n\n# Creazione dell'istogramma della distribuzione standardizzata\nhist(z_scores, \n     breaks = 10, \n     col = \"lightblue\", \n     main = \"Istogramma della distribuzione standardizzata di LSNS-6\", \n     xlab = \"Z-score\", \n     ylab = \"Frequenza\",\n     probability = TRUE)\n\n# Sovrapposizione della curva normale standard\ncurve(dnorm(x, mean = 0, sd = 1), col = \"red\", lwd = 2, add = TRUE)\n\nStandardizzazione: La trasformazione dei punteggi della LSNS-6 in Z-score permette di esprimere ogni valore in termini di deviazioni standard rispetto alla media. Un valore \\(Z = 1\\) significa che il punteggio di LSNS-6 è una deviazione standard sopra la media, mentre \\(Z = -1\\) significa che è una deviazione standard sotto la media.\nIstogramma della distribuzione standardizzata: Il grafico mostra la distribuzione dei punteggi standardizzati. Se la distribuzione originale è simile a una normale, l’istogramma dei punteggi standardizzati dovrebbe assomigliare a una distribuzione normale standard.\nConfronto con la distribuzione normale standard: La curva rossa rappresenta la densità di una normale standard (\\(\\mathcal{N}(0,1)\\)). Se i dati sono approssimativamente normali, l’istogramma dei punteggi standardizzati dovrebbe seguire la forma della curva normale standard. Differenze marcate potrebbero indicare asimmetria o curtosi anomale nella distribuzione dei punteggi LSNS-6.\n\n\n\n\n\n\n\n\n\n\nSoluzioni 1\n\n\n\n\n\nEsercizio 1: Calcolo del Valore Atteso della SWLS\nLa Satisfaction With Life Scale (SWLS) è composta da 5 item, ciascuno valutato su una scala Likert da 1 a 7. Supponiamo di avere la seguente distribuzione di probabilità per il punteggio totale della SWLS basata su un campione di studenti:\n\n\nSWLS Score\nProbabilità \\(P(X)\\)\n\n\n\n\n5\n0.05\n\n\n10\n0.10\n\n\n15\n0.20\n\n\n20\n0.30\n\n\n25\n0.20\n\n\n30\n0.10\n\n\n35\n0.05\n\n\n\nDomanda:\nCalcola il valore atteso \\(\\mathbb{E}[X]\\) del punteggio SWLS.\nSoluzione: Il valore atteso si calcola come:\n\\[\n\\mathbb{E}[X] = \\sum x_i P(x_i)\n\\]\nCalcoliamo in R:\n# Definizione dei valori SWLS e delle probabilità\nswls_scores &lt;- c(5, 10, 15, 20, 25, 30, 35)\nprob_swls &lt;- c(0.05, 0.10, 0.20, 0.30, 0.20, 0.10, 0.05)\n\n# Calcolo del valore atteso\nexpected_swls &lt;- sum(swls_scores * prob_swls)\nexpected_swls\nRisultato:\\[\n\\mathbb{E}[X] = 20\n\\]\nIl valore atteso rappresenta la media teorica della soddisfazione con la vita nella popolazione, assumendo che la distribuzione dei punteggi SWLS segua esattamente le probabilità fornite. In altre parole, se prendessimo un numero molto grande di individui con questa distribuzione di probabilità, il punteggio medio atteso sarebbe 20. Questo suggerisce che, nella popolazione considerata, il livello medio di soddisfazione con la vita si colloca al centro della scala SWLS.\nEsercizio 2: Calcolo della Varianza e Deviazione Standard della SWLS\n# Definizione dei dati\nswls_scores &lt;- c(5, 10, 15, 20, 25, 30, 35)\nprobabilities &lt;- c(0.05, 0.10, 0.20, 0.30, 0.20, 0.10, 0.05)\n\n# Calcolo del valore atteso (media attesa)\nexpected_value &lt;- sum(swls_scores * probabilities)\n\n# Calcolo della varianza\nvariance &lt;- sum((swls_scores - expected_value)^2 * probabilities)\n\n# Calcolo della deviazione standard\nstd_deviation &lt;- sqrt(variance)\n\n# Stampa dei risultati\ncat(\"Valore atteso (E[X]):\", expected_value, \"\\n\")\ncat(\"Varianza (Var[X]):\", variance, \"\\n\")\ncat(\"Deviazione standard (σ_X):\", std_deviation, \"\\n\")\n\n\nVarianza: Misura la dispersione dei punteggi SWLS rispetto alla media attesa. Se la varianza è alta, significa che i punteggi sono molto variabili; se è bassa, significa che i punteggi sono più concentrati attorno al valore atteso.\n\nDeviazione standard: È la radice quadrata della varianza e ha la stessa unità di misura dei dati originali. Fornisce un’indicazione della dispersione media dei punteggi rispetto alla media.\n\nSe la deviazione standard è elevata, significa che nella popolazione ci sono sia individui con livelli di soddisfazione molto bassi sia individui con livelli molto alti. Se è bassa, i punteggi sono più omogenei intorno alla media.\nEsercizio 3: Calcolo del Valore Atteso della Scala della Rete Sociale di Lubben (LSNS-6)\n# Definizione dei dati della LSNS-6\nlsns_scores &lt;- c(5, 10, 15, 20, 25, 30)\nprobabilities &lt;- c(0.10, 0.15, 0.25, 0.25, 0.15, 0.10)\n\n# Definizione della trasformazione della variabile casuale Y = 2X + 3\ny_values &lt;- 2 * lsns_scores + 3\n\n# Calcolo del valore atteso di X\nexpected_x &lt;- sum(lsns_scores * probabilities)\n\n# Utilizzo della linearità dell'operatore di aspettazione: E[Y] = 2E[X] + 3\nexpected_y_from_x &lt;- 2 * expected_x + 3\n\n# Calcolo diretto del valore atteso di Y\nexpected_y_direct &lt;- sum(y_values * probabilities)\n\n# Stampa dei risultati\ncat(\"Valore atteso di X (E[X]):\", expected_x, \"\\n\")\ncat(\"Valore atteso di Y calcolato con la linearità (E[Y] = 2E[X] + 3):\", expected_y_from_x, \"\\n\")\ncat(\"Valore atteso di Y calcolato direttamente dalla distribuzione di probabilità di Y:\", expected_y_direct, \"\\n\")\n\n\nLinearità dell’operatore di aspettazione: Questo principio afferma che se una variabile casuale \\(X\\) viene trasformata linearmente in \\(Y = aX + b\\), allora il valore atteso di \\(Y\\) è dato da:\n\\[\n\\mathbb{E}(Y) = a \\mathbb{E}(X) + b\n\\]\nQuesto semplifica il calcolo senza dover ridefinire una nuova distribuzione di probabilità.\n\nVerifica del risultato: Dopo aver calcolato \\(\\mathbb{E}(Y)\\) con la proprietà di linearità, lo confrontiamo con il calcolo diretto utilizzando la distribuzione trasformata. Se i due valori coincidono, confermiamo che la proprietà di linearità è rispettata.\nSignificato pratico: La trasformazione lineare di una variabile casuale può rappresentare un’operazione reale come la conversione di punteggi da una scala all’altra. Il valore atteso si comporta linearmente, il che è utile per interpretare trasformazioni senza dover ricalcolare completamente la distribuzione.\n\nEsercizio 4: Probabilità secondo il Teorema di Chebyshev\nIl Teorema di Chebyshev afferma che per qualsiasi distribuzione, la probabilità che un valore sia oltre \\(k\\) deviazioni standard dalla media è al massimo:\n\\[\nP(|X - \\mu| \\geq k\\sigma) \\leq \\frac{1}{k^2}\n\\]\nSostituendo \\(k = 2\\):\n\\[\nP(|X - 3.2| \\geq 2 \\cdot 0.8) \\leq \\frac{1}{2^2} = \\frac{1}{4} = 0.25\n\\]\nQuindi, il Teorema di Chebyshev fornisce un limite superiore del 25% alla probabilità che un valore di SWLS sia oltre due deviazioni standard dalla media.\nPer confrontare questo risultato con la probabilità empirica, è necessaro usare i dati raccolti sulla SWLS.\nEsercizio 5: Standardizzazione del Punteggio LSNS-6\nDomanda:\nStandardizza il punteggio LSNS-6 trasformandolo nella variabile standardizzata \\(Z\\).\n\\[\nZ = \\frac{Y - \\mathbb{E}(Y)}{\\sigma_Y}\n\\]\nSoluzione: Calcoliamo in R:\n# Standardizzazione dei punteggi LSNS-6\nz_lsns &lt;- (lsns_scores - expected_lsns) / sd_lsns\nz_lsns\nRisultato:\n\n\nLSNS-6 Score\nZ-Score\n\n\n\n5\n-2.23\n\n\n10\n-1.34\n\n\n15\n-0.45\n\n\n20\n0.45\n\n\n25\n1.34\n\n\n30\n2.23\n\n\n\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nEsercizio 6: Personalizzazione degli Interventi Basati sulla Probabilità Condizionata\nUno psicologo scolastico vuole identificare quali studenti potrebbero trarre maggiore beneficio da un programma di supporto psicologico. Dalla letteratura, si sa che la probabilità di avere livelli bassi di soddisfazione con la vita (SWLS ≤ 15) è più alta tra gli studenti che riportano elevati livelli di stress accademico.\nDai dati raccolti su un campione di studenti:\n\n\\(P(\\text{SWLS} \\leq 15) = 0.35\\)\n\\(P(\\text{Stress Alto}) = 0.40\\)\n\\(P(\\text{SWLS} \\leq 15 \\mid \\text{Stress Alto}) = 0.60\\)\n\nDomanda Se uno studente è scelto a caso, qual è la probabilità che abbia un alto livello di stress dato che il suo punteggio SWLS è ≤ 15?\nEsercizio 7: Prevedere il Successo di un Intervento Psicologico Uno psicologo clinico sta valutando l’efficacia di un intervento sulla riduzione dell’ansia. Ha raccolto i dati di 100 pazienti e ha osservato che il miglioramento medio nei punteggi di ansia (misurati con DASS-21) è di 5 punti con una deviazione standard di 2.5.\nSupponiamo che il miglioramento sia una variabile aleatoria normale con media 5 e deviazione standard 2.5.\nDomanda Qual è la probabilità che un paziente scelto a caso migliori di almeno 7 punti?\nEsercizio 8: Allocazione Ottimale delle Risorse in un Programma di Prevenzione Uno psicologo organizza un programma di sensibilizzazione sulla salute mentale in diverse scuole. Ha raccolto dati sulla frequenza con cui gli studenti si rivolgono allo sportello di ascolto, con la seguente distribuzione:\n\n\nNumero di Visite\nProbabilità\n\n\n\n0\n0.40\n\n\n1\n0.30\n\n\n2\n0.15\n\n\n3+\n0.15\n\n\n\nDomanda Se lo psicologo ha risorse per organizzare colloqui individuali solo per il 30% degli studenti, quale soglia può usare per selezionare gli studenti più bisognosi in base alla distribuzione delle visite?\nEsercizio 9: Misurare la Variabilità della Risposta a un Trattamento Uno psicologo somministra un trattamento per la depressione e misura la variazione nei punteggi di depressione su un campione di pazienti prima e dopo l’intervento.\nLe variazioni seguono questa distribuzione:\n\n\nΔ Punteggio DASS-21\nProbabilità\n\n\n\n-10\n0.10\n\n\n-5\n0.20\n\n\n0\n0.40\n\n\n+5\n0.20\n\n\n+10\n0.10\n\n\n\nDomanda Qual è la deviazione standard della variazione nei punteggi di depressione?\nEsercizio 10: Probabilità di un Fallimento in un Programma di Sensibilizzazione Uno psicologo organizza un programma per ridurre il pregiudizio sulla salute mentale. Dai dati precedenti, la probabilità di successo di ogni evento di sensibilizzazione è del 70%. Se organizza 5 eventi indipendenti, qual è la probabilità che almeno 1 fallisca?\n\n\n\n\n\n\n\n\n\nSoluzioni 2\n\n\n\n\n\nEsercizio 6: Personalizzazione degli Interventi Basati sulla Probabilità Condizionata\nUtilizziamo la formula della probabilità condizionata:\n\\[\nP(\\text{Stress Alto} \\mid \\text{SWLS} \\leq 15) = \\frac{P(\\text{SWLS} \\leq 15 \\mid \\text{Stress Alto}) P(\\text{Stress Alto})}{P(\\text{SWLS} \\leq 15)}\n\\]\nCalcoliamo in R:\np_swls_low &lt;- 0.35\np_stress_high &lt;- 0.40\np_swls_given_stress &lt;- 0.60\n\np_stress_given_swls &lt;- (p_swls_given_stress * p_stress_high) / p_swls_low\np_stress_given_swls\nRisultato Lo psicologo può usare questa informazione per identificare studenti con alta probabilità di avere stress elevato, anche se non hanno segnalato direttamente il problema, e offrire supporto mirato.\nEsercizio 7: Prevedere il Successo di un Intervento Psicologico\nUsiamo la normalizzazione:\n\\[\nZ = \\frac{X - \\mu}{\\sigma}\n\\]\ne calcoliamo la probabilità corrispondente:\nmean_improvement &lt;- 5\nsd_improvement &lt;- 2.5\nthreshold &lt;- 7\n\np_improve_7 &lt;- 1 - pnorm(threshold, mean = mean_improvement, sd = sd_improvement)\np_improve_7\nRisultato Questo aiuta lo psicologo a comunicare ai pazienti la probabilità di ottenere miglioramenti significativi e ad adattare le aspettative dell’intervento.\nEsercizio 8: Allocazione Ottimale delle Risorse in un Programma di Prevenzione\nSoluzione Calcoliamo la probabilità cumulativa:\nvisits &lt;- c(0, 1, 2, 3)\nprobabilities &lt;- c(0.40, 0.30, 0.15, 0.15)\ncumulative_prob &lt;- cumsum(probabilities)\n\n# Determinare la soglia per il 30% più bisognoso\nthreshold &lt;- visits[min(which(cumulative_prob &gt;= 0.70))]\nthreshold\nRisultato Lo psicologo può decidere di offrire supporto prioritario a studenti con almeno 2 visite, massimizzando l’impatto con risorse limitate.\nEsercizio 9: Misurare la Variabilità della Risposta a un Trattamento\nSoluzione Calcoliamo la varianza e la deviazione standard:\nscore_changes &lt;- c(-10, -5, 0, 5, 10)\nprobabilities &lt;- c(0.10, 0.20, 0.40, 0.20, 0.10)\n\n# Media attesa\nexpected_change &lt;- sum(score_changes * probabilities)\n\n# Varianza\nvariance_change &lt;- sum((score_changes - expected_change)^2 * probabilities)\n\n# Deviazione standard\nsd_change &lt;- sqrt(variance_change)\nsd_change\nRisultato Se la deviazione standard è grande, significa che l’effetto del trattamento è molto variabile e potrebbero essere necessarie strategie personalizzate.\nEsercizio 10: Probabilità di un Fallimento in un Programma di Sensibilizzazione\nUsiamo la distribuzione binomiale:\np_success &lt;- 0.70\nn_events &lt;- 5\n\np_failure_at_least_one &lt;- 1 - dbinom(5, n_events, p_success)\np_failure_at_least_one\nRisultato Lo psicologo può pianificare strategie di miglioramento sapendo la probabilità di un fallimento.\n\n\n\n\n\n\n\n\n\nProblemi 3\n\n\n\n\n\nEsercizio 3\nConsiglio gli esercizi di base disponibili nella seguente pagina web.\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt;  [4] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt;  [7] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [10] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [13] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [16] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [25] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.8          tidyselect_1.2.1      farver_2.1.2         \n#&gt;  [4] fastmap_1.2.0         TH.data_1.1-4         tensorA_0.36.2.1     \n#&gt;  [7] digest_0.6.37         timechange_0.3.0      estimability_1.5.1   \n#&gt; [10] lifecycle_1.0.4       survival_3.8-3        magrittr_2.0.3       \n#&gt; [13] compiler_4.5.1        rlang_1.1.6           tools_4.5.1          \n#&gt; [16] knitr_1.50            labeling_0.4.3        bridgesampling_1.1-2 \n#&gt; [19] htmlwidgets_1.6.4     curl_7.0.0            pkgbuild_1.4.8       \n#&gt; [22] RColorBrewer_1.1-3    abind_1.4-8           multcomp_1.4-28      \n#&gt; [25] withr_3.0.2           purrr_1.1.0           grid_4.5.1           \n#&gt; [28] stats4_4.5.1          colorspace_2.1-1      xtable_1.8-4         \n#&gt; [31] inline_0.3.21         emmeans_1.11.2-8      scales_1.4.0         \n#&gt; [34] MASS_7.3-65           cli_3.6.5             mvtnorm_1.3-3        \n#&gt; [37] rmarkdown_2.29        ragg_1.5.0            generics_0.1.4       \n#&gt; [40] RcppParallel_5.1.11-1 cachem_1.1.0          stringr_1.5.1        \n#&gt; [43] splines_4.5.1         parallel_4.5.1        vctrs_0.6.5          \n#&gt; [46] V8_7.0.0              Matrix_1.7-4          sandwich_3.1-1       \n#&gt; [49] jsonlite_2.0.0        arrayhelpers_1.1-0    systemfonts_1.2.3    \n#&gt; [52] glue_1.8.0            codetools_0.2-20      distributional_0.5.0 \n#&gt; [55] lubridate_1.9.4       stringi_1.8.7         gtable_0.3.6         \n#&gt; [58] QuickJSR_1.8.0        htmltools_0.5.8.1     Brobdingnag_1.2-9    \n#&gt; [61] R6_2.6.1              textshaping_1.0.3     rprojroot_2.1.1      \n#&gt; [64] evaluate_1.0.5        lattice_0.22-7        backports_1.5.0      \n#&gt; [67] memoise_2.0.1         broom_1.0.9           snakecase_0.11.1     \n#&gt; [70] rstantools_2.5.0      coda_0.19-4.1         gridExtra_2.3        \n#&gt; [73] nlme_3.1-168          checkmate_2.3.3       xfun_0.53            \n#&gt; [76] zoo_1.8-14            pkgconfig_2.0.3",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_expval_var.html#bibliografia",
    "href": "chapters/probability/08_expval_var.html#bibliografia",
    "title": "9  Proprietà delle variabili casuali",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nChan, J. C. C., & Kroese, D. P. (2025). Statistical Modeling and Computation (2ª ed.). Springer.\n\n\nHacking, I. (2006). The emergence of probability: A philosophical study of early ideas about probability, induction and statistical inference. Cambridge University Press.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:\n\n\nWixted, J. T., & Mickes, L. (2010). A continuous dual-process model of remember/know judgments. Psychological Review, 117(4), 1025–1054.\n\n\nYonelinas, A. P. (2002). The nature of recollection and familiarity: A review of 30 years of research. Journal of Memory and Language, 46(3), 441–517.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_sampling_distr.html",
    "href": "chapters/probability/09_sampling_distr.html",
    "title": "10  Stime, stimatori e parametri",
    "section": "",
    "text": "Introduzione\nIn psicologia – come in molte altre discipline – ci si trova spesso nella situazione di voler comprendere una particolare caratteristica di un’intera popolazione. Tuttavia, difficilmente è possibile raccogliere dati da tutti i membri di tale popolazione, a causa di limiti di tempo, risorse o accessibilità. Ad esempio, potremmo voler stimare la percentuale di persone che soffrono di un determinato disturbo d’ansia oppure la media di un punteggio di memoria a breve termine, ma non siamo in grado di testare ogni singolo individuo appartenente al gruppo di interesse. Per far fronte a questo limite, si sceglie di selezionare un campione di partecipanti (idealmente in modo casuale), dal quale si ricavano le informazioni utili a inferire la caratteristica dell’intera popolazione, riconoscendo un certo grado di incertezza.\nNel linguaggio statistico:\nCome esempio, immaginiamo di voler conoscere la proporzione di adulti che manifestano un certo sintomo d’ansia, indicandola con \\(p\\). Poiché non possiamo (o non vogliamo) esaminare tutta la popolazione, estraiamo un campione casuale di \\(N\\) individui, verifichiamo quanti di loro presentino il sintomo e calcoliamo:\n\\[\n\\hat{p} = \\frac{\\text{numero di individui con il sintomo}}{N}.\n\\]\nQuesto rapporto (detto stima campionaria di \\(p\\)) difficilmente coinciderà esattamente con \\(p\\), ma la teoria probabilistica mostra che, in assenza di distorsioni sistematiche, \\(\\hat{p}\\) tenderà ad avvicinarsi al valore reale al crescere della dimensione del campione.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_sampling_distr.html#introduzione",
    "href": "chapters/probability/09_sampling_distr.html#introduzione",
    "title": "10  Stime, stimatori e parametri",
    "section": "",
    "text": "Popolazione: l’insieme completo degli individui (o unità) di interesse. Esempi: tutte le persone che soddisfano certi criteri diagnostici, tutti gli studenti di una scuola, tutte le misurazioni di reazione a uno stimolo sperimentale.\n\nParametro: la quantità (sconosciuta) che descrive la caratteristica d’interesse nella popolazione (esempio: la “vera” proporzione di soggetti con un certo disturbo, oppure la “vera” media di un test cognitivo).\n\nCampione: un sottoinsieme di individui (idealmente estratto in modo casuale) dalla popolazione di interesse.\n\nStima: il valore numerico, calcolato sul campione, che approssima il parametro.\n\nStimatore: la regola o funzione matematica con cui, a partire dai dati del campione, si ottiene la stima.\n\n\n\n\nPanoramica del capitolo\n\nCome le stime dei parametri della popolazione variano da campione a campione.\nNozioni di popolazione, campione, parametro, stima e stimatore.\nConnessione tra stime campionarie e parametri reali della popolazione.\nCalcolare e interpretare il valore atteso e la varianza della media campionaria.\nUtilizzare l’errore standard per rappresentare l’incertezza nelle stime dei parametri.\nLa convergenza delle medie campionarie alla media della popolazione.\nIl teorema per approssimare distribuzioni campionarie con distribuzioni normali.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere il capitolo Sampling Distributions of Estimators (Schervish & DeGroot, 2014).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_sampling_distr.html#popolazione-e-campione",
    "href": "chapters/probability/09_sampling_distr.html#popolazione-e-campione",
    "title": "10  Stime, stimatori e parametri",
    "section": "\n10.1 Popolazione e campione",
    "text": "10.1 Popolazione e campione\nPer rendere tutto più concreto, supponiamo di voler stimare la frequenza di un sintomo ansioso in un’ampia popolazione, ad esempio l’insieme di tutti gli studenti universitari di un paese. Non potendo sottoporre un questionario a ogni studente, scegliamo un sottoinsieme di individui in modo casuale (cioè il nostro campione) e a ciascuno somministriamo uno strumento standardizzato volto a rilevare la presenza/assenza del sintomo. Il nostro obiettivo finale è utilizzare i dati campionari per trarre inferenze sulla popolazione complessiva, cioè per stimare la vera proporzione \\(p\\) di studenti che manifestano il sintomo.\nQuesta operazione di estrarre un sottogruppo rappresentativo si chiama campionamento. La proporzione di individui con il sintomo d’ansia calcolata nel campione è la nostra stima campionaria (simbolizzata con \\(\\bar{X}\\) o, più spesso in contesto di proporzioni, con \\(\\hat{p}\\)). Se il campione è selezionato in modo corretto e rappresentativo, ci aspettiamo che \\(\\bar{X}\\) rispecchi, con un certo margine di errore, il vero valore di \\(p\\) (il parametro).\n\n10.1.1 Lo stimatore: la proporzione campionaria\nPer formalizzare ulteriormente, consideriamo un modello “urna” in cui la popolazione è immaginata come un’urna piena di “biglie” di due colori (ad esempio, “blu” per sintomo presente, “rosso” per sintomo assente). Estraendo a caso \\(N\\) biglie (cioè selezionando \\(N\\) soggetti), definiamo la variabile casuale \\(X_i\\) come:\n\\[\nX_i =\n\\begin{cases}\n1 & \\text{se l’individuo } i \\text{ presenta il sintomo (biglia blu),}\\\\\n0 & \\text{se l’individuo } i \\text{ non presenta il sintomo (biglia rossa).}\n\\end{cases}\n\\]\nLa proporzione campionaria – ossia la nostra stima empirica di \\(p\\) – è data da:\n\\[\n\\bar{X} \\;=\\; \\frac{1}{N}\\sum_{i=1}^N X_i.\n\\]\nDal punto di vista interpretativo:\n\n\n\\(p\\) è la vera proporzione di studenti (biglie “blu”) nella popolazione;\n\n\\(\\bar{X}\\) è la proporzione di studenti con il sintomo riscontrata nel campione.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_sampling_distr.html#distribuzione-campionaria-valore-atteso-e-varianza",
    "href": "chapters/probability/09_sampling_distr.html#distribuzione-campionaria-valore-atteso-e-varianza",
    "title": "10  Stime, stimatori e parametri",
    "section": "\n10.2 Distribuzione campionaria: valore atteso e varianza",
    "text": "10.2 Distribuzione campionaria: valore atteso e varianza\nIl passo cruciale per il ragionamento inferenziale è capire come varia \\(\\bar{X}\\) se ripetiamo la procedura di campionamento molte volte. In altre parole, se estraessimo più volte (indipendentemente) un campione di ampiezza \\(N\\), otterremmo ogni volta un valore di \\(\\bar{X}\\) in genere diverso. La collezione di tutti questi possibili valori (con le rispettive probabilità) si chiama distribuzione campionaria di \\(\\bar{X}\\).\n\n10.2.1 Valore atteso della media (o proporzione) campionaria\nSe \\(X_1, X_2, \\dots, X_n\\) sono variabili aleatorie indipendenti e identicamente distribuite (i.i.d.), ognuna con valore atteso \\(\\mathbb{E}[X_i] = \\mu\\), allora la loro media campionaria\n\\[\n\\bar{X} \\;=\\; \\frac{1}{n}\\sum_{i=1}^n X_i\n\\]\npossiede a sua volta valore atteso\n\\[\n\\mathbb{E}[\\bar{X}] \\;=\\; \\mu.\n\\]\nQuesta semplice formula rivela che \\(\\bar{X}\\) è uno stimatore non distorto per \\(\\mu\\): in media, se ripetessimo infinite volte lo stesso tipo di campionamento, otterremmo una stima che coincide con il vero valore del parametro. Nel caso di variabili 0-1 (come presenza/assenza di sintomo), abbiamo \\(\\mu \\equiv p\\).\n\nDimostrazione. Consideriamo un campione casuale \\(X_1, X_2, \\dots, X_n\\) di variabili aleatorie indipendenti e identicamente distribuite (i.i.d.), ognuna con valore atteso \\(\\mathbb{E}[X_i] = \\mu\\). Vogliamo dimostrare che il valore atteso della media campionaria \\(\\bar{X}\\) è uguale a \\(\\mu\\):\n\\[\n\\mathbb{E}[\\bar{X}] = \\mu.\n\\]\nPasso 1: Definizione di media campionaria.\nLa media campionaria è definita come:\\[\n\\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i.\n\\]\nPasso 2: Applicazione del valore atteso.\nCalcoliamo il valore atteso di \\(\\bar{X}\\), sfruttando la linearità del valore atteso (l’aspettativa di una somma è la somma delle aspettative):\\[\n\\mathbb{E}[\\bar{X}] = \\mathbb{E}\\left[\\frac{1}{n} \\sum_{i=1}^n X_i\\right].\n\\]\nPasso 3: Portare fuori le costanti.\nIl fattore \\(\\frac{1}{n}\\) è una costante rispetto all’operatore \\(\\mathbb{E}\\):\\[\n\\mathbb{E}[\\bar{X}] = \\frac{1}{n} \\mathbb{E}\\left[\\sum_{i=1}^n X_i\\right].\n\\]\nPasso 4: Separare la somma.\nPer linearità, l’aspettativa della somma è la somma delle aspettative:\\[\n\\mathbb{E}\\left[\\sum_{i=1}^n X_i\\right] = \\sum_{i=1}^n \\mathbb{E}[X_i].\n\\]\nPasso 5: Sfruttare l’identica distribuzione.\nPoiché tutte le \\(X_i\\) sono identicamente distribuite, \\(\\mathbb{E}[X_i] = \\mu\\) per ogni \\(i\\):\\[\n\\sum_{i=1}^n \\mathbb{E}[X_i] = \\sum_{i=1}^n \\mu = n\\mu.\n\\]\nPasso 6: Combinare i risultati.\nSostituendo nel Passo 3:\\[\n\\mathbb{E}[\\bar{X}] = \\frac{1}{n} \\cdot n\\mu = \\mu.\n\\]\nInterpretazione e Significato.\n\n\nNon distorsione (Unbiasedness):\nLa dimostrazione mostra che \\(\\bar{X}\\) è uno stimatore non distorto di \\(\\mu\\). Questo significa che, in media su infinite replicazioni del campionamento, \\(\\bar{X}\\) coincide con il vero valore \\(\\mu\\).\n\n\nIndipendenza non necessaria per l’aspettativa:\nL’indipendenza tra le \\(X_i\\) non è richiesta per questa dimostrazione. Bastano l’identica distribuzione (per garantire \\(\\mathbb{E}[X_i] = \\mu\\)) e la linearità del valore atteso.\n\n\nCaso speciale: proporzione campionaria\nSe le \\(X_i\\) sono variabili di Bernoulli (0-1) con \\(\\mathbb{E}[X_i] = p\\), allora \\(\\bar{X} = \\frac{\\text{numero di successi}}{n}\\) stima la proporzione \\(p\\), e \\(\\mathbb{E}[\\bar{X}] = p\\).\n\nPerché è importante?\nQuesta proprietà è alla base dell’inferenza statistica:\n\nGiustifica l’uso della media campionaria come stima affidabile di \\(\\mu\\).\n\nÈ il fondamento della Legge dei Grandi Numeri: all’aumentare di \\(n\\), \\(\\bar{X}\\) converge a \\(\\mu\\).\n\n\n\n10.2.2 Varianza della media (o proporzione) campionaria\nOltre al valore atteso, un’altra misura fondamentale è la varianza della distribuzione campionaria, che quantifica quanto \\(\\bar{X}\\) tenda a fluttuare attorno a \\(\\mu\\). Se la varianza individuale di ciascun \\(X_i\\) è \\(\\sigma^2\\), allora per la media campionaria si ha:\n\\[\n\\mathrm{Var}(\\bar{X}) \\;=\\; \\frac{\\sigma^2}{n}.\n\\tag{10.1}\\]\nNel caso Bernoulliano (variabili 0-1) con \\(\\mathbb{E}[X_i] = p\\), sappiamo che\n\\[\n\\sigma^2 \\;=\\; p(1-p).\n\\]\nPertanto:\n\\[\n\\mathrm{Var}(\\bar{X}) \\;=\\; \\frac{p \\bigl(1-p\\bigr)}{n}.\n\\]\nLa radice quadrata di questa varianza prende il nome di errore standard (in inglese Standard Error, SE) della media (o della proporzione), e risulta:\n\\[\n\\mathrm{SE}(\\bar{X}) \\;=\\; \\sqrt{\\frac{p\\,(1-p)}{n}}.\n\\]\nCon l’aumentare di \\(n\\), la varianza di \\(\\bar{X}\\) diminuisce, e quindi la nostra stima diventa più “precisa” (in un senso statistico). Ciò spiega perché, anche nella pratica psicologica, aumentare la dimensione del campione riduce l’incertezza nella stima e migliora l’affidabilità dei risultati.\nOsservazione: nella ricerca psicologica, l’errore standard fornisce un’indicazione chiara di quanto, in media, la nostra stima potrebbe deviare dal vero parametro, se ripetessimo il campionamento molte volte. Questo concetto è centrale in molte procedure inferenziali, come la costruzione di intervalli di confidenza o il test di ipotesi, e prepara il terreno per comprendere la cosiddetta distribuzione campionaria della media (argomento che il capitolo proseguirà a trattare).\n\nDimostrazione. Forniamo qui la dimostrazione dell’Equazione 10.1. Assumiamo che \\(X_1, X_2, \\dots, X_n\\) siano variabili casuali indipendenti e identicamente distribuite (i.i.d.) con media \\(\\mu\\) e varianza \\(\\sigma^2\\). Definiamo la media campionaria\n\\[\n\\bar{X} \\;=\\; \\frac{1}{n}\\sum_{i=1}^n X_i.\n\\]\nVogliamo calcolare \\(\\mathrm{Var}(\\bar{X})\\). Per prima cosa, notiamo che:\n\\[\n\\mathrm{Var}(a\\,Y) \\;=\\; a^2 \\,\\mathrm{Var}(Y)\n\\]\nper qualunque costante \\(a\\). Nel nostro caso, poniamo \\(a = \\frac{1}{n}\\) e \\(Y = \\sum_{i=1}^n X_i\\). Otteniamo quindi:\n\\[\n\\mathrm{Var}(\\bar{X})\n\\;=\\;\n\\mathrm{Var}\\!\\Bigl(\\tfrac{1}{n}\\sum_{i=1}^n X_i\\Bigr)\n\\;=\\;\n\\frac{1}{n^2} \\, \\mathrm{Var}\\!\\Bigl(\\sum_{i=1}^n X_i\\Bigr).\n\\]\nOra sfruttiamo il fatto che \\(X_1, X_2, \\dots, X_n\\) siano indipendenti. In tal caso, la varianza della somma è la somma delle varianze:\n\\[\n\\mathrm{Var}\\Bigl(\\sum_{i=1}^n X_i\\Bigr)\n\\;=\\;\n\\sum_{i=1}^n \\mathrm{Var}(X_i)\n\\;=\\;\nn \\,\\sigma^2,\n\\]\npoiché \\(\\mathrm{Var}(X_i) = \\sigma^2\\) per tutti gli \\(i\\). Combiniamo dunque i due risultati:\n\\[\n\\mathrm{Var}(\\bar{X})\n\\;=\\;\n\\frac{1}{n^2}\\,\\bigl(n \\,\\sigma^2\\bigr)\n\\;=\\;\n\\frac{\\sigma^2}{n}.\n\\]\nIn sintesi, la chiave della dimostrazione sta nel fattore \\(\\tfrac{1}{n^2}\\) e nel fatto che, per variabili indipendenti, la varianza di una somma è la somma delle varianze. Questo ci consente di concludere che la varianza della media campionaria è \\(\\tfrac{\\sigma^2}{n}\\).\n\nQuesto risultato riflette un’importante proprietà statistica:\n\nall’aumentare di \\(n\\), la varianza della media campionaria diminuisce, rendendo la media campionaria una stima più precisa del valore atteso \\(\\mu\\). La riduzione della varianza è proporzionale a \\(1/n\\), quindi raddoppiare il campione riduce la varianza della media campionaria di un fattore 2.\n\nIn conclusione, la formula \\(\\text{Var}(\\bar{X}) = \\frac{\\sigma^2}{n}\\) mostra che la precisione della media campionaria aumenta con la dimensione del campione, poiché la varianza diminuisce. Questo principio è alla base dell’importanza di campioni più grandi nella stima statistica.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_sampling_distr.html#la-distribuzione-campionaria-della-media",
    "href": "chapters/probability/09_sampling_distr.html#la-distribuzione-campionaria-della-media",
    "title": "10  Stime, stimatori e parametri",
    "section": "\n10.3 La distribuzione campionaria della media",
    "text": "10.3 La distribuzione campionaria della media\nPer illustrare ulteriormente il concetto di distribuzione campionaria, consideriamo un caso semplice e specifico: una popolazione finita di dimensioni ridotte. Sebbene stiamo esaminando un caso particolare, è fondamentale notare che le proprietà e i principi che analizzeremo in questo contesto sono perfettamente applicabili a popolazioni di qualsiasi dimensione.\nLa distribuzione campionaria ci dà una visione della variazione che potremmo aspettarci nelle stime derivate da diversi campioni estratti dalla stessa popolazione. Ogni volta che preleviamo un campione, otteniamo una stima diversa per il parametro di interesse (come la media). La distribuzione campionaria ci mostra come queste stime sono distribuite e ci aiuta a comprendere quanto siano affidabili.\nIn termini pratici, se vogliamo calcolare la media della popolazione, non possiamo farlo direttamente (a meno di non avere accesso all’intera popolazione). Invece, possiamo estrarre un campione casuale e calcolare la media del campione come stima di \\(\\mu\\). Tuttavia, un altro campione fornirà una stima leggermente diversa. La distribuzione campionaria ci aiuta a capire quanto queste stime varino da campione a campione e ci fornisce un quadro completo dell’incertezza legata al processo di stima.\nNella simulazione seguente, ipotizziamo la seguente popolazione:\n\nx &lt;- c(2, 4.5, 5, 5.5)\nx\n#&gt; [1] 2.0 4.5 5.0 5.5\n\nL’istogramma seguente descrive la distribuzione della popolazione.\n\nggplot(data.frame(x = x), aes(x)) +\n  geom_histogram(\n    bins = 5,\n    aes(y = after_stat(density))\n  )\n\n\n\n\n\n\n\nCalcoliamo la media e la varianza della popolazione. Media:\n\nmean_x &lt;- mean(x) # Media della popolazione\nmean_x\n#&gt; [1] 4.25\n\nVarianza:\n\nvar_x &lt;- var(x) * ((length(x) - 1) / length(x)) # Varianza popolazione\nvar_x\n#&gt; [1] 1.81\n\nConsideriamo tutti i possibili campioni di dimensione \\(n = 2\\) che possono essere estratti dalla popolazione rappresentata dal vettore x. Per generare questi campioni, utilizziamo la funzione expand.grid in R, che consente di creare tutte le combinazioni possibili di valori, includendo le ripetizioni.\nIl risultato sarà un data frame con 16 righe e 2 colonne, dove ogni riga rappresenta una coppia possibile di valori estratti dal vettore x. Questo risultato è in linea con il principio del calcolo combinatorio: quando selezioniamo \\(n\\) elementi da un insieme di \\(k\\) elementi e permettiamo ripetizioni, il numero totale di combinazioni è dato da \\(k^n\\). Nel nostro caso, con \\(k = 4\\) e \\(n = 2\\), otteniamo:\n\\[\n4^2 = 16 \\text{ combinazioni}.\n\\]\nUtilizzando expand.grid, possiamo verificare questo risultato in R:\n\n# Generazione delle combinazioni con ripetizione\nsamples &lt;- expand.grid(x, x)\n\n# Visualizzazione del risultato\nprint(samples)\n#&gt;    Var1 Var2\n#&gt; 1   2.0  2.0\n#&gt; 2   4.5  2.0\n#&gt; 3   5.0  2.0\n#&gt; 4   5.5  2.0\n#&gt; 5   2.0  4.5\n#&gt; 6   4.5  4.5\n#&gt; 7   5.0  4.5\n#&gt; 8   5.5  4.5\n#&gt; 9   2.0  5.0\n#&gt; 10  4.5  5.0\n#&gt; 11  5.0  5.0\n#&gt; 12  5.5  5.0\n#&gt; 13  2.0  5.5\n#&gt; 14  4.5  5.5\n#&gt; 15  5.0  5.5\n#&gt; 16  5.5  5.5\n\nIl data frame risultante mostrerà tutte le possibili coppie \\((x_1, x_2)\\), dove \\(x_1\\) e \\(x_2\\) possono essere scelti indipendentemente dalla popolazione \\(x = \\{2, 4.5, 5, 5.5\\}\\).\nPer calcolare la media di ogni campione di ampiezza \\(n = 2\\), possiamo utilizzare la funzione rowMeans, che calcola la media per ogni riga di una matrice. In questo modo, otteniamo un vettore contenente la media di ciascuna coppia di valori. Questo insieme di valori costituisce la distribuzione campionaria delle medie dei campioni di ampiezza \\(n = 2\\) che possono essere estratti dalla popolazione x.\n\n# Calcolare la media di ciascun campione\nsample_means &lt;- rowMeans(samples)\nprint(sample_means)\n#&gt;  [1] 2.00 3.25 3.50 3.75 3.25 4.50 4.75 5.00 3.50 4.75 5.00 5.25 3.75 5.00 5.25\n#&gt; [16] 5.50\n\nUna rappresentazione grafica della distribuzione campionaria delle medie dei campioni di ampiezza \\(n = 2\\) che possono essere estratti dalla popolazione x è fornita qui sotto.\n\n# Istogramma delle medie campionarie\nggplot(data.frame(sample_means), aes(x = sample_means)) +\n  geom_histogram(\n    bins = 5,\n    aes(y = after_stat(density))\n)\n\n\n\n\n\n\n\nMostriamo qui nuovamente la lista di tutti i possibili campioni di ampiezza 2 insieme alla media di ciascun campione.\n\n# Creare un data frame con i campioni e le loro medie\ndf &lt;- data.frame(\n  Samples = apply(samples, 1, paste, collapse = \", \"),\n  x_bar = rowMeans(samples)\n)\nprint(df)\n#&gt;     Samples x_bar\n#&gt; 1      2, 2  2.00\n#&gt; 2    4.5, 2  3.25\n#&gt; 3      5, 2  3.50\n#&gt; 4    5.5, 2  3.75\n#&gt; 5    2, 4.5  3.25\n#&gt; 6  4.5, 4.5  4.50\n#&gt; 7    5, 4.5  4.75\n#&gt; 8  5.5, 4.5  5.00\n#&gt; 9      2, 5  3.50\n#&gt; 10   4.5, 5  4.75\n#&gt; 11     5, 5  5.00\n#&gt; 12   5.5, 5  5.25\n#&gt; 13   2, 5.5  3.75\n#&gt; 14 4.5, 5.5  5.00\n#&gt; 15   5, 5.5  5.25\n#&gt; 16 5.5, 5.5  5.50\n\nProcediamo ora al calcolo della media della distribuzione campionaria delle medie di campioni di ampiezza \\(n = 2\\) che possono essere estratti dalla popolazione x.\n\n# Calcolare la media delle medie campionarie\nmean(sample_means)\n#&gt; [1] 4.25\n\nSi noti che questo valore coincide con la media della popolazione.\nLa varianza delle medie campionarie, calcolata empiricamente, può essere ottenuta direttamente dai dati utilizzando la seguente formula:\n\nvar(x) * (length(x) - 1) / length(x) / length(x)\n#&gt; [1] 0.453\n\nQuesto calcolo riflette la formula teorica per la varianza della media campionaria, definita come la varianza dei dati divisa per la dimensione del campione \\(n\\). Tuttavia, poiché la funzione var() in R utilizza \\(n-1\\) al denominatore per fornire una stima non distorta della varianza della popolazione, è necessario applicare un fattore di correzione \\(\\frac{n-1}{n}\\) per ottenere la varianza campionaria corretta. Successivamente, questa varianza viene divisa per \\(n\\) per ottenere la varianza della media campionaria.\nIn alternativa, possiamo calcolare lo stesso valore prendendo la varianza delle medie di tutti i campioni (16 in questo caso):\n\nvar(sample_means) * ((length(sample_means) - 1) / length(sample_means))\n#&gt; [1] 0.906\n\nAnche in questo caso applichiamo il fattore di correzione \\(\\frac{n-1}{n}\\) per ottenere il calcolo corretto della varianza usando la funzione var() in R.\nEntrambi i calcoli forniscono risultati coerenti con la teoria, dimostrando che la varianza delle medie campionarie è inferiore a quella della popolazione.\n\n\n\n\n\n\nCollegamento con Bayes\n\n\n\nNel paradigma frequentista, la distribuzione campionaria descrive la variabilità che avremmo se ripetessimo l’esperimento un gran numero di volte. In Bayes, invece, non ragioniamo su campioni ipotetici, ma sulla distribuzione a posteriori dei parametri, che riflette la nostra incertezza dati i dati osservati. In entrambi i casi il punto chiave è lo stesso: riconoscere che c’è variabilità e incertezza, non solo un numero singolo.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_sampling_distr.html#sec-lln",
    "href": "chapters/probability/09_sampling_distr.html#sec-lln",
    "title": "10  Stime, stimatori e parametri",
    "section": "\n10.4 Legge dei Grandi Numeri",
    "text": "10.4 Legge dei Grandi Numeri\nLa Legge dei Grandi Numeri (LLN, dall’inglese Law of Large Numbers) è uno dei pilastri fondamentali della teoria della probabilità. Essa descrive come, all’aumentare del numero di osservazioni, la media campionaria si avvicini stabilmente al valore atteso teorico. In termini formali, se \\(\\bar{X}_n\\) rappresenta la media di \\(n\\) osservazioni indipendenti e identicamente distribuite (i.i.d.) con valore atteso \\(\\mu\\), allora \\(\\bar{X}_n \\to \\mu\\) quando \\(n \\to \\infty\\). Questo principio è cruciale per comprendere la relazione tra dati empirici e modelli teorici, come discusso nella sezione sull’interpretazione della probabilità (Capitolo 2).\nEsistono due versioni principali della Legge dei Grandi Numeri:\n\nLegge Forte: La media campionaria \\(\\bar{X}_n\\) converge quasi certamente a \\(\\mu\\), il che significa che, con probabilità 1, la media osservata si avvicina indefinitamente al valore teorico al crescere di \\(n\\).\n\nLegge Debole: La media campionaria \\(\\bar{X}_n\\) converge a \\(\\mu\\) in probabilità, ovvero, per ogni \\(\\varepsilon &gt; 0\\), la probabilità che la differenza tra \\(\\bar{X}_n\\) e \\(\\mu\\) superi \\(\\varepsilon\\) tende a zero al crescere di \\(n\\). Formalmente:\n\\[\n\\Pr\\bigl(| \\bar{X}_n - \\mu| &gt; \\varepsilon\\bigr) \\to 0 \\quad \\text{al crescere di }n.\n\\]\n\n\n\n10.4.1 Applicazioni in psicologia\nIn psicologia, la Legge dei Grandi Numeri ha implicazioni significative. Ad esempio, se si vuole stimare con precisione la proporzione di individui che manifestano un determinato comportamento o la media di un test cognitivo in una popolazione, è necessario raccogliere un numero sufficiente di osservazioni. Solo con un campione ampio la media campionaria si avvicinerà alla media “vera” della popolazione, riducendo l’incertezza e migliorando l’affidabilità delle stime.\n\n10.4.2 Forma debole della Legge dei Grandi Numeri\nLa forma debole della LGN, dimostrata per la prima volta da Jacob Bernoulli nel suo lavoro Ars Conjectandi, afferma che la media campionaria converge in probabilità alla media teorica (Hacking, 2006). In termini pratici, questo significa che, man mano che il numero di osservazioni aumenta, la probabilità che la differenza tra la media osservata e la media teorica superi un margine di errore \\(\\varepsilon\\) diventa sempre più piccola. Formalmente:\n\\[\n\\lim_{{n \\to \\infty}} P\\left(\\left|\\frac{1}{n} \\sum_{i=1}^n X_i - \\mu\\right| \\geq \\varepsilon\\right) = 0,\n\\] dove:\n\n\n\\(X_1, X_2, \\ldots, X_n\\) sono variabili casuali indipendenti e identicamente distribuite (i.i.d.),\n\n\\(\\mu\\) è la media teorica,\n\n\\(\\varepsilon\\) è un numero positivo arbitrariamente piccolo.\n\n10.4.3 Forma forte della Legge dei Grandi Numeri\nLa forma forte della LGN, sviluppata successivamente da matematici come Kolmogorov, è un enunciato più potente. Essa stabilisce che la media campionaria converge quasi sicuramente alla media teorica. Questo implica che, con probabilità 1, la media osservata si avvicina indefinitamente al valore teorico man mano che il numero di prove tende all’infinito. Formalmente:\n\\[\nP\\left(\\lim_{{n \\to \\infty}} \\frac{1}{n} \\sum_{i=1}^n X_i = \\mu\\right) = 1.\n\\]\n\n10.4.4 Importanza e critiche\nLa Legge dei Grandi Numeri è fondamentale per garantire la validità delle stime empiriche, ma la sua applicazione pratica richiede attenzione. Ad esempio, in psicologia, la raccolta di un numero sufficiente di osservazioni può essere costosa o difficile, specialmente quando si studiano fenomeni rari o popolazioni specifiche. Inoltre, l’assunzione di indipendenza e identica distribuzione delle osservazioni potrebbe non essere sempre realistica in contesti applicativi complessi. Nonostante queste sfide, la LGN rimane un principio essenziale per comprendere come i dati empirici possano avvicinarsi alle proprietà teoriche di una popolazione.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_sampling_distr.html#teorema-del-limite-centrale",
    "href": "chapters/probability/09_sampling_distr.html#teorema-del-limite-centrale",
    "title": "10  Stime, stimatori e parametri",
    "section": "\n10.5 Teorema del Limite Centrale",
    "text": "10.5 Teorema del Limite Centrale\nOltre alla convergenza, un ulteriore risultato importante è che la distribuzione di \\(\\bar{X}_n\\) si approssima alla normale man mano che \\(n\\) cresce, anche se i singoli \\(X_i\\) non sono distribuiti normalmente.\n\nTeorema 10.1 Se \\(X_1, X_2, \\ldots, X_n\\) sono variabili iid con media \\(\\mu\\) e deviazione standard \\(\\sigma\\), la distribuzione di\n\\[\n\\bar{X}_n = \\frac{1}{n}\\sum_{i=1}^n X_i\n\\] diventa approssimativamente normale con media \\(\\mu\\) e deviazione standard \\(\\tfrac{\\sigma}{\\sqrt{n}}\\) quando \\(n\\) è sufficientemente grande.\n\nPer il caso 0-1 (presenza/assenza di un tratto), \\(\\bar{X}\\) è quindi circa normale con media \\(p\\) e varianza \\(\\frac{p(1-p)}{n}\\). Il TLC consente, tra l’altro, di costruire intervalli di confidenza e di calcolare probabilità che la stima si discosti di una certa quantità dal vero valore.\n\nEsempio 10.1 Per visualizzare il Teorema del Limite Centrale (TLC) in azione, possiamo condurre una simulazione. Immaginiamo una popolazione distribuita in modo uniforme. Estraiamo 300 campioni di dimensione \\(n = 30\\) da questa popolazione e osserviamo come la distribuzione campionaria delle medie di questi campioni converga a una distribuzione normale. Questa simulazione fornirà un’illustrazione concreta dell’efficacia del TLC nell’approssimare distribuzioni reali.\n\n# Impostiamo il seed per la riproducibilità dei risultati\nset.seed(42)\n\n# Generiamo una popolazione con distribuzione uniforme\npopulation &lt;- runif(5000, min = 0, max = 1)\n\n# Passo 1: Visualizziamo l'istogramma della popolazione utilizzando ggplot2\nggplot(data.frame(population), aes(x = population)) +\n  geom_histogram(\n    aes(y = after_stat(density)),\n    bins = 30\n  ) +\n  labs(x = \"Valore\", y = \"Densità\")\n\n\n\n\n\n\n\n\n# Passo 2 e 3: Estraiamo campioni casuali e calcoliamo le medie campionarie\nsample_size &lt;- 30\nnum_samples &lt;- 300\n\n# Vettore vuoto per memorizzare le medie campionarie\nsample_means &lt;- c()\n\nfor (i in 1:num_samples) {\n  # Estraiamo un campione casuale\n  sample &lt;- sample(population, size = sample_size, replace = TRUE)\n  \n  # Calcoliamo la media del campione\n  sample_means[i] &lt;- mean(sample)\n}\n\n# Calcoliamo media e varianza delle medie campionarie\nx_bar &lt;- mean(sample_means)\nstd &lt;- sd(sample_means)\n\nprint('Media e Varianza delle Medie Campionarie')\n#&gt; [1] \"Media e Varianza delle Medie Campionarie\"\nprint(x_bar)\n#&gt; [1] 0.501\nprint(std^2)\n#&gt; [1] 0.00275\n\n\n# Calcoliamo media e varianza della popolazione\nmu &lt;- mean(population)\nsigma &lt;- sd(population)\n\nprint('Media e Varianza della Popolazione')\n#&gt; [1] \"Media e Varianza della Popolazione\"\nprint(mu)\n#&gt; [1] 0.503\nprint((sigma^2)/sample_size)\n#&gt; [1] 0.00282\n\n\n# Passo 4: Visualizziamo l'istogramma delle medie campionarie utilizzando ggplot2\nggplot(data.frame(sample_means), aes(x = sample_means)) +\n  geom_histogram(\n    aes(y = after_stat(density)),\n    bins = 30\n  ) +\n  stat_function(\n    fun = dnorm, args = list(mean = x_bar, sd = std), color = \"black\", size = 1\n  ) +\n  labs(\n    x = \"Media Campionaria\", y = \"Densità\"\n  ) +\n  theme(legend.position = \"top\") \n\n\n\n\n\n\n\nSpiegazione del codice e dei risultati\n\nPopolazione: Abbiamo generato una popolazione di 5000 osservazioni distribuite uniformemente tra 0 e 1. La distribuzione uniforme è stata scelta perché è chiaramente non normale, il che rende più evidente l’effetto del TLC.\nCampionamento: Abbiamo estratto 300 campioni casuali, ciascuno di dimensione \\(n = 30\\), dalla popolazione. Per ogni campione, abbiamo calcolato la media.\nDistribuzione delle Medie Campionarie: Le medie dei campioni sono state raccolte e la loro distribuzione è stata visualizzata tramite un istogramma. Nonostante la popolazione originale non fosse normale, la distribuzione delle medie campionarie si avvicina a una distribuzione normale, dimostrando il TLC.\nConfronto tra Popolazione e Campioni: Abbiamo confrontato la media e la varianza della popolazione con quelle delle medie campionarie. Come previsto dal TLC, la media delle medie campionarie è molto vicina alla media della popolazione, mentre la varianza delle medie campionarie è ridotta di un fattore pari alla dimensione del campione (\\(n = 30\\)).\n\nQuesta simulazione illustra chiaramente come il TLC permetta di approssimare la distribuzione delle medie campionarie a una distribuzione normale, anche quando la popolazione originale non è normale. Questo risultato è fondamentale per molte applicazioni pratiche della statistica inferenziale.\n\n\nEsempio 10.2 Sebbene i risultati teorici siano solidi, è comune utilizzare la simulazione Monte Carlo per verificarne la validità in contesti pratici. Supponiamo, ad esempio, che la proporzione reale di individui che soffrono di un certo sintomo in una popolazione sia \\(p = 0.45\\). Possiamo simulare campioni di dimensione \\(n\\) e calcolare la media campionaria \\(\\bar{X}\\) (ovvero la proporzione osservata in ciascun campione). Ripetendo questo processo molte volte, otteniamo una distribuzione empirica delle \\(\\bar{X}\\). Se l’approssimazione normale fornita dal Teorema del Limite Centrale (TLC) è valida, ci aspettiamo che:\n\nLa media delle \\(\\bar{X}\\) sia molto vicina al valore teorico \\(p = 0.45\\).\nLa varianza delle \\(\\bar{X}\\) sia approssimativamente uguale a \\(p(1-p)/n\\), come previsto dalla teoria.\n\nUn esempio di codice in R per questa simulazione è il seguente:\n\np &lt;- 0.45  # Proporzione reale nella popolazione\nn &lt;- 1000  # Dimensione del campione\nB &lt;- 10000 # Numero di campioni simulati\n\n# Simulazione Monte Carlo: generiamo B campioni e calcoliamo le medie campionarie\nx_hat &lt;- replicate(B, {\n  x &lt;- sample(c(0, 1), size = n, replace = TRUE, prob = c(1-p, p))\n  mean(x)\n})\n\n# Media delle medie campionarie (dovrebbe essere vicina a p)\nmean(x_hat)  # Risultato atteso: ~ 0.45\n#&gt; [1] 0.45\n\n# Deviazione standard delle medie campionarie (dovrebbe essere vicina a sqrt(p*(1-p)/n))\nsd(x_hat)    # Risultato atteso: ~ sqrt(0.45 * 0.55 / 1000)\n#&gt; [1] 0.0157\n\nRisultati attesi e interpretazione:\n\n\nMedia delle medie campionarie: Il valore medio di x_hat dovrebbe essere molto vicino a \\(0.45\\), confermando che la media campionaria è uno stimatore non distorto della proporzione reale \\(p\\).\n\nDeviazione standard delle medie campionarie: La deviazione standard di x_hat dovrebbe avvicinarsi a \\(\\sqrt{0.45 \\times 0.55 / 1000} \\approx 0.0157\\), in linea con la formula teorica \\(\\sqrt{p(1-p)/n}\\). Questo valore rappresenta l’incertezza associata alla stima della proporzione.\n\nEffetto della dimensione del campione:\n\nAumentando la dimensione del campione \\(n\\), l’ampiezza della distribuzione delle medie campionarie (e quindi l’incertezza di \\(\\bar{X}\\)) diminuisce. Questo è coerente con la teoria, poiché la varianza delle medie campionarie è inversamente proporzionale a \\(n\\). In altre parole, campioni più grandi forniscono stime più precise del parametro della popolazione.\n\nQuesta simulazione dimostra concretamente come il Teorema del Limite Centrale garantisca che, anche per popolazioni non normali (come in questo caso, dove i dati sono binari), la distribuzione delle medie campionarie si avvicini a una distribuzione normale con media \\(p\\) e varianza \\(p(1-p)/n\\), purché \\(n\\) sia sufficientemente grande.\n\n\n10.5.1 Margine di errore e intervalli di confidenza\nSe \\(\\bar{X}\\) è approssimato da \\(\\mathcal{N}(p, \\frac{p(1-p)}{n})\\), allora \\[\nZ = \\frac{\\bar{X} - p}{\\sqrt{p(1-p)/n}}\n\\] segue (approssimativamente) la distribuzione normale standard \\(\\mathcal{N}(0,1)\\). In pratica, non conoscendo \\(p\\), possiamo sostituirlo con \\(\\bar{X}\\) nello stimatore di errore standard (\\(\\mathrm{plug\\text{-}in}\\)):\n\\[\n\\hat{\\mathrm{SE}}(\\bar{X}) = \\sqrt{\\frac{\\bar{X}(1-\\bar{X})}{n}}.\n\\] Spesso si costruisce un intervallo di confidenza approssimato al 95% come:\n\\[\n\\bar{X} \\,\\pm\\, 1.96 \\times \\hat{\\mathrm{SE}}(\\bar{X}),\n\\] dove 1.96 deriva dal fatto che circa il 95% della distribuzione normale standard sta nell’intervallo \\([-1.96,+1.96]\\). Questo intervallo rappresenta la fascia di incertezza attorno alla stima, che si restringe all’aumentare di \\(n\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_sampling_distr.html#oltre-la-media-altre-distribuzioni-campionarie",
    "href": "chapters/probability/09_sampling_distr.html#oltre-la-media-altre-distribuzioni-campionarie",
    "title": "10  Stime, stimatori e parametri",
    "section": "\n10.6 Oltre la media: altre distribuzioni campionarie",
    "text": "10.6 Oltre la media: altre distribuzioni campionarie\nFinora ci siamo concentrati sulla media campionaria (o proporzione), ma in molti casi di interesse psicologico o più in generale statistico, potremmo voler studiare altre statistiche tratte da un campione. Due esempi importanti sono il massimo campionario (utile per analisi di eventi estremi, punteggi massimi nei test, tempi di reazione record, ecc.) e la varianza campionaria (fondamentale per misurare la variabilità dei punteggi in un test psicometrico, ad esempio).\n\n10.6.1 Massimo campionario\nQuando siamo interessati a misurare la performance “estrema” di un gruppo (ad esempio il punteggio più elevato in un test cognitivo, oppure la latenza di reazione più veloce se si ragiona in termini di minimi), la statistica di riferimento è il massimo (o il minimo) nel campione.\n\n10.6.1.1 Teoria e concetti chiave\n\nDefinizione: Dato un campione \\(\\{X_1, X_2, \\dots, X_n\\}\\), il massimo campionario è \\[\nM = \\max\\{X_1, X_2, \\dots, X_n\\}.\n\\] Questa variabile casuale dipende ovviamente dalla distribuzione dei singoli \\(X_i\\).\n\nProprietà:\n\nLa distribuzione di \\(M\\) spesso risulta asimmetrica e “spostata a destra” rispetto alla distribuzione di partenza. Anche se la popolazione originaria fosse normalmente distribuita, la distribuzione del massimo non sarà normale.\n\nIl valore atteso \\(E[M]\\) supera la media \\(\\mu\\) della popolazione perché, fra i \\(n\\) individui osservati, “vince” sempre il più grande.\n\n\n\nImplicazioni pratiche:\n\nAnalizzare i massimi (o i minimi) è cruciale nello studio di fenomeni estremi (per esempio, individuare il picco di stress in un compito cognitivo o la più alta temperatura registrata in una sperimentazione ambientale).\nLa cosiddetta teoria degli estremi si fonda proprio sull’analisi di come i massimi (o minimi) si distribuiscono al crescere di \\(n\\). Questa ha applicazioni in diverse discipline: dalla psicologia (prestazione massima) all’ingegneria (carichi estremi) fino alla finanza (rischi estremi).\n\n\n\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nNel seguente esempio, simuliamo 10.000 esperimenti. In ognuno:\n\nGeneriamo 5 osservazioni da una popolazione normale con media \\(\\mu = 100\\) e deviazione standard \\(\\sigma = 15\\).\n\nNe calcoliamo il massimo campionario.\n\nInfine, confrontiamo la distribuzione di questi massimi con la densità della distribuzione di partenza (cioè la normale \\(\\mathcal{N}(100, 15^2)\\)).\n\n# Impostazioni iniziali\nmu &lt;- 100\nsigma &lt;- 15\nx &lt;- seq(mu - 3 * sigma, mu + 3 * sigma, length.out = 100)\ny &lt;- dnorm(x, mean = mu, sd = sigma)\n\n# Simulazione di 10.000 esperimenti con campioni di 5 osservazioni\nset.seed(123)  # Per riproducibilità\nsample_maxes &lt;- replicate(10000, max(rnorm(5, mean = mu, sd = sigma)))\n\n# Creiamo un data frame per il grafico\ndata &lt;- data.frame(SampleMaxes = sample_maxes)\ndensity_data &lt;- data.frame(x = x, y = y)\n\n# Grafico con ggplot2\nggplot(data, aes(x = SampleMaxes)) +\n  geom_histogram(\n    aes(y = after_stat(density)),\n    bins = 30,\n    alpha = 0.7\n  ) +\n  geom_line(data = density_data, aes(x = x, y = y), size = 1, color = \"black\") +\n  labs(\n    x = \"Massimo campionario\",\n    y = \"Densità\"\n  ) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = \"bold\"),\n    plot.subtitle = element_text(hjust = 0.5)\n  )\n\n\n\n\n\n\n\nOsservazioni:\n\nL’istogramma, che rappresenta la distribuzione dei massimi campionari, è spostato a destra rispetto alla distribuzione della popolazione (tracciata in rosso).\nCiò evidenzia che \\(M\\) tende a fornire valori più alti della media \\(\\mu = 100\\). Se ripetessimo l’esperimento con campioni di dimensione maggiore di 5, questo effetto si accentuerebbe ulteriormente.\n\n\n\n\n\n10.6.2 2. Varianza campionaria\nLo studio della varianza (o in generale della variabilità) è un altro esempio cruciale in contesti psicologici. Se vogliamo descrivere quanto differiscono i punteggi di un test di personalità, o di un test cognitivo, non basta guardare solo alla media campionaria: ci interessa anche la dispersione.\n\n10.6.2.1 Teoria e concetti chiave\n\nStima della varianza:\nStimare la varianza \\(\\sigma^2\\) di una popolazione non è banale. La formula \\[\nS^2 = \\frac{1}{n} \\sum_{i=1}^n (Y_i - \\bar{Y})^2\n\\] tende a sottostimare \\(\\sigma^2\\). Per ottenere uno stimatore non distorto, si usa invece: \\[\nS^2 = \\frac{1}{n-1} \\sum_{i=1}^n (Y_i - \\bar{Y})^2.\n\\] L’uso di \\(n-1\\) serve a correggere la perdita di un grado di libertà (poiché \\(\\bar{Y}\\) è calcolata sui dati) e garantisce che \\(E[S^2] = \\sigma^2\\).\nConcetto di distorsione:\nChiamiamo uno stimatore \\(\\hat{\\theta}\\) non distorto se il suo valore atteso è uguale al parametro vero \\(\\theta\\): \\(E[\\hat{\\theta}] = \\theta\\). Con la formula a denominatore \\(n-1\\), la varianza campionaria risulta appunto non distorta.\n\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nSimuliamo 10.000 esperimenti, ognuno con \\(n=5\\) osservazioni generate da \\(\\mathcal{N}(100, 15^2)\\). Per ciascun campione, calcoliamo: 1. La varianza “distorta” \\(\\frac{1}{n}\\sum_i (X_i - \\bar{X})^2\\). 2. La varianza “corretta” con \\(n-1\\).\n\nset.seed(123)  # Per riproducibilità\n\n# Funzione per calcolare varianze con n e con n-1\ncalc_vars &lt;- function(n = 5, mu = 100, sigma = 15) {\n  sample_data &lt;- rnorm(n, mean = mu, sd = sigma)\n  var_n &lt;- sum((sample_data - mean(sample_data))^2) / n\n  var_n_minus_1 &lt;- var(sample_data)  # In R, var() usa di default n-1\n  c(var_n, var_n_minus_1)\n}\n\n# Simuliamo 10.000 campioni\nB &lt;- 10000\nvars_matrix &lt;- replicate(B, calc_vars())\nsample_vars_n &lt;- vars_matrix[1, ]\nsample_vars_n_minus_1 &lt;- vars_matrix[2, ]\n\n# Confrontiamo graficamente\ndata_n &lt;- data.frame(SampleVars = sample_vars_n, Type = \"Con n\")\ndata_n_minus_1 &lt;- data.frame(SampleVars = sample_vars_n_minus_1, Type = \"Con n-1\")\ncombined_data &lt;- rbind(data_n, data_n_minus_1)\n\nggplot(combined_data, aes(x = SampleVars, color = Type)) +\n  geom_density(size = 1.1) +\n  labs(\n    x = \"Varianza campionaria\",\n    y = \"Densità\"\n  ) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = \"bold\"),\n    plot.subtitle = element_text(hjust = 0.5)\n  ) +\n  scale_color_manual(values = c(\"Con n\" = \"gray\", \"Con n-1\" = \"black\"))\n\n\n\n\n\n\n\nOsservazioni:\n\nLa curva corrispondente a “Con \\(n\\)” tende a sottostimare la varianza, mentre quella “Con \\(n-1\\)” si centra meglio attorno a \\(\\sigma^2 = 15^2 = 225\\).\n\nSe verifichiamo le medie delle due distribuzioni:\n\nmean(sample_vars_n)\n#&gt; [1] 181\nmean(sample_vars_n_minus_1)\n#&gt; [1] 226\n\ntroveremo che la prima è sensibilmente inferiore a 225, mentre la seconda si avvicina di più al valore vero.\n\n\n\n\n\nSia il massimo campionario sia la varianza campionaria dimostrano come non tutte le distribuzioni campionarie ereditino le stesse proprietà della media. Nel caso del massimo, la variabile risulta spostata verso valori elevati e non segue una forma gaussiana; nel caso della varianza, si deve porre attenzione alla formula usata, per evitare distorsioni sistematiche.\nIn sintesi:\n\n\nMassimo campionario: utile per l’analisi di fenomeni estremi (o massimi prestazionali), con una distribuzione tipicamente asimmetrica.\n\n\nVarianza campionaria: richiede la correzione di Bessel (denominatore \\(n-1\\)) per essere uno stimatore non distorto di \\(\\sigma^2\\).\n\nCapire le proprietà di queste (e altre) distribuzioni campionarie consente allo sperimentatore di valutare correttamente le incertezze nelle stime, di evitare errori di interpretazione e di utilizzare gli stimatori più appropriati in base al tipo di fenomeno studiato.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_sampling_distr.html#errore-standard-incertezza-inferenziale-e-bias",
    "href": "chapters/probability/09_sampling_distr.html#errore-standard-incertezza-inferenziale-e-bias",
    "title": "10  Stime, stimatori e parametri",
    "section": "\n10.7 Errore standard, incertezza inferenziale e bias",
    "text": "10.7 Errore standard, incertezza inferenziale e bias\n\n10.7.1 Errore standard e incertezza\nL’errore standard (SE) è la misura di quanto una data statistica (ad esempio la media) può variare da un campione all’altro per pura casualità di campionamento. In un contesto psicologico, può essere usato per mostrare graficamente l’affidabilità di una misura. Esporre i risultati di un test psicometrico riportando solo la media, senza un’idea dell’errore standard o di un intervallo di confidenza, rischia di dare un’illusione di precisione non giustificata.\n\n10.7.2 Bias: perché non basta un campione grandissimo\nAumentare la dimensione campionaria \\(n\\) riduce l’errore standard, ma non elimina possibili bias sistematici (si veda, ad esempio, la disussione fornita dal Andrew Gelman su questo tema). Ad esempio:\n\nSe i partecipanti più ansiosi evitano di partecipare allo studio (bias di selezione), la proporzione \\(\\bar{X}\\) sarà sistematicamente sottostimata.\nSe qualcuno falsifica le risposte per desiderabilità sociale (bias di risposta), la media misurata può allontanarsi dal valore vero in maniera non corretta da un semplice aumento del campione.\nSe lo strumento di misura (ad es. un questionario) è mal tarato o concettualmente scorretto, l’intero studio può soffrirne (misurazione errata).\n\nQuando è presente un bias, nessun aumento del numero di partecipanti potrà rimuoverlo: si otterranno stime molto “precise” (varianza piccola) ma sistematicamente lontane dal valore reale.\n\n\n\n\n\n\nNota bayesiana\n\n\n\nL’errore standard è una misura frequentista di precisione della stima. Nell’approccio bayesiano, la precisione si legge direttamente dalla dispersione della distribuzione a posteriori del parametro. Quindi il concetto di “quanto è precisa la stima” resta, ma lo esprimiamo in modo diverso.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_sampling_distr.html#la-prospettiva-bayesiana",
    "href": "chapters/probability/09_sampling_distr.html#la-prospettiva-bayesiana",
    "title": "10  Stime, stimatori e parametri",
    "section": "\n10.8 La prospettiva bayesiana",
    "text": "10.8 La prospettiva bayesiana\nNelle sezioni precedenti abbiamo discusso il concetto di distribuzione campionaria da una prospettiva frequentista. Questo approccio considera il parametro della popolazione (come la proporzione \\(p\\) o la media \\(\\mu\\)) come una quantità fissa, sebbene sconosciuta. L’incertezza deriva esclusivamente dalla variabilità del processo di campionamento ripetuto.\nLa statistica bayesiana, invece, offre una prospettiva complementare e interpretativamente diversa:\n\nParametri come variabili casuali: Nel quadro bayesiano, i parametri non sono considerati quantità fisse, ma variabili aleatorie descritte da una distribuzione di probabilità. Questa distribuzione riflette il grado di convinzione (o conoscenza) del ricercatore rispetto al valore del parametro, prima di osservare i dati (distribuzione a priori), e viene aggiornata alla luce dei dati osservati per produrre una distribuzione a posteriori.\nDistribuzione a posteriori: Dopo aver osservato i dati campionari, la distribuzione a posteriori descrive completamente l’incertezza sul parametro. A differenza dell’approccio frequentista, in cui l’incertezza è quantificata considerando ripetizioni ipotetiche dell’esperimento, l’incertezza bayesiana riflette direttamente lo stato attuale della nostra conoscenza.\n\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nRiprendiamo l’esempio precedente sulla proporzione di adulti che manifestano un certo sintomo ansioso. Consideriamo che prima di raccogliere i dati dal campione, abbiamo una credenza iniziale (a priori) sulla proporzione \\(p\\). Potremmo assumere una distribuzione a priori Beta(\\(\\alpha\\), \\(\\beta\\)), scelta comunemente perché flessibile e comoda da aggiornare (si veda il Capitolo 15):\n\\[\np \\sim \\text{Beta}(\\alpha, \\beta).\n\\]\nSupponiamo ora di estrarre un campione di dimensione \\(N\\) e osservare \\(y\\) individui che manifestano il sintomo. La distribuzione a posteriori sarà allora:\n\\[\np \\mid y, N \\sim \\text{Beta}(\\alpha + y, \\beta + N - y) .\n\\]\nQuesta distribuzione incorpora sia le informazioni iniziali sia i dati osservati (si veda il ?sec-bayesian-inference-conjugate-1). Aumentando il numero di osservazioni, l’influenza della distribuzione a priori si riduce, e la distribuzione a posteriori converge verso il valore effettivo di \\(p\\), riflettendo un comportamento analogo alla Legge dei Grandi Numeri.\nInterpretazione bayesiana dei risultati.\n\nIntervallo di credibilità: Al posto dell’intervallo di confidenza frequentista (si veda il ?sec-frequentism-confidence-intervals), che descrive la probabilità di copertura considerando ripetizioni ipotetiche del campionamento, il bayesiano utilizza un intervallo di credibilità (si veda il ?sec-bayesian-inference-summary-posterior), il quale indica direttamente l’intervallo entro cui il parametro cade con una data probabilità, date le osservazioni effettivamente raccolte.\nConvergenza della distribuzione a posteriori: In analogia alla Legge dei Grandi Numeri e al Teorema del Limite Centrale, anche nel quadro bayesiano, all’aumentare della dimensione del campione, la distribuzione a posteriori diventa sempre più concentrata intorno al parametro vero, riducendo l’incertezza.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_sampling_distr.html#riflessioni-conclusive",
    "href": "chapters/probability/09_sampling_distr.html#riflessioni-conclusive",
    "title": "10  Stime, stimatori e parametri",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIl percorso qui delineato mette in luce come, nell’ambito dell’inferenza frequentista, risulti fondamentale operare una chiara distinzione tra due piani concettuali: da un lato la popolazione e i suoi parametri — entità teoriche, come la vera proporzione di un sintomo psicologico o la media di un punteggio nella popolazione generale, che per loro natura non sono direttamente osservabili — e dall’altro il campione e le sue stime, ovvero i dati empirici effettivamente raccolti e le statistiche — come la media campionaria — da essi calcolate.\nLa nozione di distribuzione campionaria, in particolare per statistiche quali la media o la proporzione, consente di comprendere alcune proprietà cruciali dell’inferenza statistica. La media campionaria, ad esempio, è uno stimatore non distorto, il cui valore atteso coincide con il parametro della popolazione che intende stimare. La sua precisione, definita come l’inverso della varianza, aumenta al crescere della numerosità campionaria. Inoltre, grazie al Teorema del Limite Centrale, è possibile approssimare la distribuzione della media campionaria a una normale per campioni sufficientemente ampi, fatto che costituisce la base per la costruzione di intervalli di confidenza e per la valutazione probabilistica delle stime. È altrettanto importante notare come l’errore standard quantifichi esclusivamente la variabilità attribuibile al campionamento, mentre eventuali bias sistematici — legati per esempio al disegno sperimentale o alla misura — permangono anche al crescere della dimensione campionaria.\nComplementare alla prospettiva frequentista è l’approccio bayesiano, il quale concepisce l’incertezza inferenziale non solo in termini di variabilità campionaria, ma come riflesso diretto del nostro stato di conoscenza. Tale stato viene rappresentato esplicitamente mediante la distribuzione a posteriori, che aggiorna le credenze iniziali alla luce dei nuovi dati. Questa caratteristica rende il framework bayesiano particolarmente adatto a contesti applicativi in psicologia, dove l’obiettivo è spesso quello di revisionare in modo incrementale la comprensione di un fenomeno man mano che nuove evidenze diventano disponibili.\nIn sintesi, una ricerca psicologica rigorosa richiede la consapevolezza di due fonti distinte di incertezza: quella casuale, riconducibile alla variabilità del campionamento e quantificabile attraverso strumenti come l’errore standard, e quella sistematica, riconducibile a distorsioni metodologiche o concettuali. Solo un’interpretazione che tenga conto di entrambe queste componenti permette di valutare con appropriatezza la solidità delle conclusioni tratte dai dati, sia in ambito teorico sia in setting applicativi e clinici.\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nEsercizi sulla distribuzione campionaria sono disponibili sulla seguente pagina web.\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt;  [4] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt;  [7] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [10] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [13] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [16] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [25] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.8          tidyselect_1.2.1      farver_2.1.2         \n#&gt;  [4] fastmap_1.2.0         TH.data_1.1-4         tensorA_0.36.2.1     \n#&gt;  [7] digest_0.6.37         timechange_0.3.0      estimability_1.5.1   \n#&gt; [10] lifecycle_1.0.4       survival_3.8-3        magrittr_2.0.3       \n#&gt; [13] compiler_4.5.1        rlang_1.1.6           tools_4.5.1          \n#&gt; [16] knitr_1.50            labeling_0.4.3        bridgesampling_1.1-2 \n#&gt; [19] htmlwidgets_1.6.4     curl_7.0.0            pkgbuild_1.4.8       \n#&gt; [22] RColorBrewer_1.1-3    abind_1.4-8           multcomp_1.4-28      \n#&gt; [25] withr_3.0.2           purrr_1.1.0           grid_4.5.1           \n#&gt; [28] stats4_4.5.1          colorspace_2.1-1      xtable_1.8-4         \n#&gt; [31] inline_0.3.21         emmeans_1.11.2-8      scales_1.4.0         \n#&gt; [34] MASS_7.3-65           cli_3.6.5             mvtnorm_1.3-3        \n#&gt; [37] rmarkdown_2.29        ragg_1.5.0            generics_0.1.4       \n#&gt; [40] RcppParallel_5.1.11-1 cachem_1.1.0          stringr_1.5.1        \n#&gt; [43] splines_4.5.1         parallel_4.5.1        vctrs_0.6.5          \n#&gt; [46] V8_7.0.0              Matrix_1.7-4          sandwich_3.1-1       \n#&gt; [49] jsonlite_2.0.0        arrayhelpers_1.1-0    systemfonts_1.2.3    \n#&gt; [52] glue_1.8.0            codetools_0.2-20      distributional_0.5.0 \n#&gt; [55] lubridate_1.9.4       stringi_1.8.7         gtable_0.3.6         \n#&gt; [58] QuickJSR_1.8.0        htmltools_0.5.8.1     Brobdingnag_1.2-9    \n#&gt; [61] R6_2.6.1              textshaping_1.0.3     rprojroot_2.1.1      \n#&gt; [64] evaluate_1.0.5        lattice_0.22-7        backports_1.5.0      \n#&gt; [67] memoise_2.0.1         broom_1.0.9           snakecase_0.11.1     \n#&gt; [70] rstantools_2.5.0      coda_0.19-4.1         gridExtra_2.3        \n#&gt; [73] nlme_3.1-168          checkmate_2.3.3       xfun_0.53            \n#&gt; [76] zoo_1.8-14            pkgconfig_2.0.3",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_sampling_distr.html#bibliografia",
    "href": "chapters/probability/09_sampling_distr.html#bibliografia",
    "title": "10  Stime, stimatori e parametri",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nHacking, I. (2006). The emergence of probability: A philosophical study of early ideas about probability, induction and statistical inference. Cambridge University Press.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_joint_prob.html",
    "href": "chapters/probability/10_joint_prob.html",
    "title": "11  Probabilità congiunta",
    "section": "",
    "text": "Introduzione\nFino a questo momento abbiamo considerato il concetto di probabilità associato a singole variabili casuali. Tuttavia, in molte situazioni pratiche e psicologiche, è fondamentale analizzare come due o più variabili casuali interagiscono tra loro. La distribuzione congiunta ci permette di descrivere la probabilità che più variabili aleatorie assumano contemporaneamente specifici valori.\nQuesto capitolo introduce e approfondisce il concetto di distribuzione congiunta attraverso definizioni, proprietà essenziali e un esempio concreto basato sulla letteratura psicologica.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_joint_prob.html#introduzione",
    "href": "chapters/probability/10_joint_prob.html#introduzione",
    "title": "11  Probabilità congiunta",
    "section": "",
    "text": "Panoramica del capitolo\n\nDefinizione di distribuzione congiunta per variabili discrete e continue.\nLe proprietà fondamentali: non-negatività e normalizzazione.\nCome ottenere e interpretare le distribuzioni marginali da una congiunta.\nIl concetto di indipendenza e come verificarla tramite la distribuzione congiunta.\nEstensione al caso continuo, con esempi grafici (mappe termiche) e densità marginali/condizionali.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere il capitolo Joint Distributions (Chan & Kroese, 2025).\nLeggere il capitolo Joint Distributions (Blitzstein & Hwang, 2019).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt;\n  source()\nlibrary(MASS)\nlibrary(viridis)\nlibrary(ggExtra)",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_joint_prob.html#cosè-la-distribuzione-congiunta",
    "href": "chapters/probability/10_joint_prob.html#cosè-la-distribuzione-congiunta",
    "title": "11  Probabilità congiunta",
    "section": "\n11.1 Cos’è la distribuzione congiunta?",
    "text": "11.1 Cos’è la distribuzione congiunta?\nQuando studiamo due variabili casuali — ad esempio ansia (\\(Y\\)) e prestazione cognitiva (\\(X\\)) — non ci interessa solo il loro comportamento individuale, ma anche come si manifestano insieme. La distribuzione congiunta descrive proprio questo: la probabilità che \\(X\\) e \\(Y\\) assumano contemporaneamente determinati valori.\n\n\nCaso discreto (variabili che possono assumere valori distinti, come categorie o conteggi)::\n\n\\[\np(x, y) = P(X = x, Y = y) .\n\\]\n\n\nCaso continuo variabili misurate su scale numeriche con molti possibili valori, come punteggi o tempi di reazione):\n\n\\[\nf(x, y)\n\\] che rappresenta la densità di probabilità congiunta.\nGrazie a queste funzioni possiamo rispondere a domande del tipo: Qual è la probabilità che uno studente con ansia elevata ottenga una prestazione insufficiente?",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_joint_prob.html#proprietà-fondamentali",
    "href": "chapters/probability/10_joint_prob.html#proprietà-fondamentali",
    "title": "11  Probabilità congiunta",
    "section": "\n11.2 Proprietà fondamentali",
    "text": "11.2 Proprietà fondamentali\nPerché una distribuzione congiunta sia una corretta distribuzione di probabilità, deve rispettare due condizioni di base.\n\n\n\n\n\n\n1. Non-negatività\n\n\n\n\\[\np(x,y) \\geq 0\n\\quad \\text{oppure} \\quad\nf(x,y) \\geq 0 .\n\\]\n\n\n\n\n\n\n\n\n2. Normalizzazione\n\n\n\n\nCaso discreto\\[\n\\sum_{x}\\sum_{y} p(x,y) = 1 .\n\\]\nCaso continuo\\[\n\\int_{-\\infty}^{+\\infty}\\int_{-\\infty}^{+\\infty} f(x,y)\\,dx\\,dy = 1 .\n\\]\n\n\n\nIn altre parole:\n\ntutte le probabilità devono essere positive,\n\ne la loro somma (o integrale) deve essere uguale a 1.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_joint_prob.html#distribuzioni-congiunte-e-inferenza-bayesiana",
    "href": "chapters/probability/10_joint_prob.html#distribuzioni-congiunte-e-inferenza-bayesiana",
    "title": "11  Probabilità congiunta",
    "section": "\n11.3 Distribuzioni congiunte e inferenza bayesiana",
    "text": "11.3 Distribuzioni congiunte e inferenza bayesiana\nIn questo libro ci concentreremo soprattutto sull’inferenza bayesiana, che si fonda proprio sul concetto di distribuzione congiunta. In termini generali, l’inferenza bayesiana mira a descrivere la distribuzione a posteriori dei parametri del modello, cioè la probabilità dei parametri dati i dati osservati.\nQuesta distribuzione a posteriori deriva dalla combinazione di:\n\nuna distribuzione a priori sui parametri, che esprime le conoscenze (o le ipotesi) disponibili prima di osservare i dati;\nla distribuzione di verosimiglianza, che è una distribuzione congiunta dei dati osservati, condizionata ai parametri.\n\nSe i dati costituiscono un campione casuale indipendente e identicamente distribuito (i.i.d.), allora la verosimiglianza — cioè la distribuzione congiunta delle osservazioni — si ottiene come prodotto delle densità di ogni singola osservazione:\n\\[\np(y_1, y_2, \\dots, y_n \\mid \\theta) = \\prod_{i=1}^n p(y_i \\mid \\theta).\n\\] Poiché il prodotto di molte densità può rapidamente generare numeri molto piccoli (problema di underflow numerico), nella pratica si lavora quasi sempre con la log-verosimiglianza (o log-densità congiunta):\n\\[\n\\log p(y_1, \\dots, y_n \\mid \\theta) = \\sum_{i=1}^n \\log p(y_i \\mid \\theta).\n\\] Questo passaggio non cambia la sostanza matematica del problema, ma rende i calcoli più stabili e più facili da gestire al computer.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_joint_prob.html#un-esempio-psicologico-ansia-e-prestazione",
    "href": "chapters/probability/10_joint_prob.html#un-esempio-psicologico-ansia-e-prestazione",
    "title": "11  Probabilità congiunta",
    "section": "\n11.4 Un esempio psicologico: ansia e prestazione",
    "text": "11.4 Un esempio psicologico: ansia e prestazione\nConsideriamo un esempio tratto dalla letteratura psicologica: la relazione tra ansia (Y) e prestazione cognitiva (X) in studenti universitari. La ricerca psicologica indica spesso una relazione negativa tra questi due fattori: livelli elevati di ansia possono associarsi a prestazioni cognitive inferiori (Eysenck et al., 2007).\nSupponiamo di aver valutato due variabili discrete in un gruppo di studenti:\n\n\nAnsia: bassa, media, alta (codificata come Y = 0, 1, 2);\n\nPrestazione cognitiva: insufficiente, sufficiente, buona (codificata come X = 0, 1, 2).\n\nLa distribuzione congiunta potrebbe essere rappresentata nella seguente tabella (i dati sono ipotetici ma coerenti con la letteratura):\n\n\n\n\n\n\n\n\n\nAnsia Bassa (0)\nAnsia Media (1)\nAnsia Alta (2)\n\n\n\nInsufficiente (0)\n0.05\n0.10\n0.15\n\n\nSufficiente (1)\n0.15\n0.20\n0.10\n\n\nBuona (2)\n0.10\n0.10\n0.05\n\n\n\nI valori nella tabella rappresentano stime empiriche delle probabilità congiunte, ovvero le proporzioni osservate di studenti che hanno manifestato una specifica combinazione di livelli delle due variabili. Ad esempio, la cella corrispondente a “Ansia Media” e “Prestazione Sufficiente” indica che il 20% degli studenti nel campione considerato ha un livello medio di ansia ed ha ottenuto prestazioni sufficienti nel compito cognitivo.\nQuesta tabella ci consente di calcolare probabilità interessanti. Ad esempio, la probabilità che uno studente raggiunga almeno la sufficienza, indipendentemente dall’ansia:\n\\[\nP(X \\geq 1) = 0.15 + 0.20 + 0.10 + 0.10 + 0.10 + 0.05 = 0.70 .\n\\]",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_joint_prob.html#distribuzioni-marginali",
    "href": "chapters/probability/10_joint_prob.html#distribuzioni-marginali",
    "title": "11  Probabilità congiunta",
    "section": "\n11.5 Distribuzioni marginali",
    "text": "11.5 Distribuzioni marginali\nDalla distribuzione congiunta possiamo ricavare le distribuzioni marginali delle singole variabili, cioè la probabilità che una variabile assuma un certo valore indipendentemente dall’altra.\nPer l’ansia:\n\nansia bassa: \\[P(Y=0)=0.05+0.15+0.10=0.30 .\\]\n\nansia media: \\[P(Y=1)=0.10+0.20+0.10=0.40 .\\]\n\nansia alta: \\[P(Y=2)=0.15+0.10+0.05=0.30 .\\]\n\n\nQueste distribuzioni ci dicono, ad esempio, che nel campione il 40% degli studenti ha ansia media.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_joint_prob.html#indipendenza-e-dipendenza",
    "href": "chapters/probability/10_joint_prob.html#indipendenza-e-dipendenza",
    "title": "11  Probabilità congiunta",
    "section": "\n11.6 Indipendenza e dipendenza",
    "text": "11.6 Indipendenza e dipendenza\nDue variabili casuali \\(X\\) e \\(Y\\) si dicono indipendenti se la loro distribuzione congiunta si fattorizza nelle rispettive distribuzioni marginali:\n\\[p(x,y)=p(x)p(y) \\quad \\text{oppure} \\quad f(x,y)=f(x)f(y) .\\]\nNel nostro esempio, se ansia e prestazione fossero indipendenti, dovremmo avere:\n\\[P(X=0,Y=2)=P(X=0)P(Y=2) .\\]\nIn realtà, come suggerisce la letteratura (Eysenck et al., 2007), ansia e prestazione tendono a essere dipendenti: più alta è l’ansia, minore è la probabilità di buone prestazioni.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_joint_prob.html#il-caso-continuo-una-mappa-termica",
    "href": "chapters/probability/10_joint_prob.html#il-caso-continuo-una-mappa-termica",
    "title": "11  Probabilità congiunta",
    "section": "\n11.7 Il caso continuo: una mappa termica",
    "text": "11.7 Il caso continuo: una mappa termica\nSe invece misuriamo ansia e prestazione come variabili continue (es. punteggi su scale numeriche), la distribuzione congiunta è una densità. Possiamo rappresentarla come una mappa termica:\n\nasse X = ansia,\nasse Y = prestazione,\ncolori più caldi = combinazioni più probabili.\n\nUn esempio simulato mostra che la maggior parte degli studenti si concentra intorno a bassa ansia (30) e buona prestazione (70), mentre i punteggi più alti di ansia si associano a prestazioni più basse.\n\n\n\n\n\n\n\n\nQuesta visualizzazione rende immediato vedere la relazione negativa tra le due variabili (Eysenck et al., 2007).\n\n11.7.1 Marginali e condizionali con variabili continue\nQuando lavoriamo con variabili continue, non possiamo semplicemente contare le combinazioni come nel caso discreto (ad esempio, lanci di un dado). Invece, misuriamo la probabilità calcolando l’area della regione interessata sulla nostra mappa termica:\n\nla probabilità che l’ansia sia tra 50 e 55, e la prestazione tra 30 e 50, è rappresentata dall’area della regione corrispondente nella mappa termica;\ngli integrali (strumenti matematici per calcolare aree) sono semplicemente un modo preciso per fare questa operazione.\n\n\n11.7.1.1 Densità marginale: proiettare la mappa su un asse\nLa densità marginale descrive come si distribuisce una singola variabile, prescindendo completamente dall’altra. Possiamo immaginare questo processo come la proiezione della mappa termica su uno degli assi, ottenendo così un’ombra o una proiezione dell’intera distribuzione:\n\nproiettando tutti i valori sull’asse dell’ansia, si ottiene la densità marginale dell’ansia;\nproiettando tutti i valori sull’asse della prestazione, si ottiene la densità marginale della prestazione.\n\nQueste proiezioni rivelano la distribuzione di ciascuna variabile considerata isolatamente. Nella figura a cui si fa riferimento, le distribuzioni marginali sono state elaborate utilizzando in modo indipendente i dati relativi a ciascuna variabile, senza considerare le loro interrelazioni.\nInfatti, i colori più caldi nella mappa termica indicano zone con maggiore densità di osservazioni. Quando proiettiamo questi valori su un asse, otteniamo una curva di densità che rappresenta la distribuzione della variabile. Le aree dove la curva raggiunge valori più alti corrispondono ai valori più frequenti della variabile nella popolazione studiata.\n\n11.7.1.2 Densità condizionale: fette della mappa termica\nLa densità condizionale risponde alla domanda: “Se osservo persone con un determinato punteggio di prestazione cognitiva (ad esempio 40 punti), qual è la distribuzione dell’ansia tra queste persone?”\n\nImmaginate di prendere una fetta verticale della mappa termica in corrispondenza della prestazione = 40 punti. Questa fetta mostra la distribuzione dell’ansia soltanto tra coloro che hanno esattamente quella prestazione cognitiva.\nPer rendere questa distribuzione coerente, normalizziamo (cioè “aggiustiamo”) la fetta rispetto alla probabilità complessiva della prestazione a quel livello.\n\nQuesta fetta verticale con i suoi vari colori (più caldi dove c’è maggiore densità) può essere convertita in una curva di densità che mostra come si distribuisce l’ansia specificamente per le persone con quel determinato livello di prestazione cognitiva. Il processo di normalizzazione assicura che l’area sotto questa curva di densità condizionale sia uguale a 1, consentendo confronti tra diverse condizioni.\n\n11.7.1.3 Perché è importante in psicologia?\nStudiare distribuzioni congiunte è cruciale perché\n\nmette in luce relazioni complesse tra variabili psicologiche (lineari, curvilinee, bimodali, cluster);\nrivela informazioni che andrebbero perse se osservassimo solo le marginali;\npermette di analizzare fenomeni realistici, in cui costrutti come ansia, motivazione o prestazione non agiscono mai isolatamente.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_joint_prob.html#riflessioni-conclusive",
    "href": "chapters/probability/10_joint_prob.html#riflessioni-conclusive",
    "title": "11  Probabilità congiunta",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nLa distribuzione congiunta rappresenta uno strumento fondamentale per l’analisi multivariata in psicologia, permettendo di studiare simultaneamente il comportamento di multiple variabili aleatorie e le loro interrelazioni. Questo approccio risulta particolarmente prezioso nella ricerca psicologica, dove i fenomeni oggetto di studio - come l’ansia, la prestazione cognitiva, la motivazione o i tratti di personalità - raramente si manifestano in isolamento, ma piuttosto attraverso complesse reti di influenze reciproche.\nI concetti di densità congiunta, marginale e condizionale costituiscono la base per un’analisi rigorosa delle relazioni tra variabili psicologiche continue. Questi strumenti consentono di esplorare come i costrutti psicologici interagiscono e si influenzano reciprocamente, offrendo un quadro analitico per comprendere la complessità dei fenomeni mentali e comportamentali.\nIl passaggio concettuale dalle variabili discrete a quelle continue, pur richiedendo l’adozione di strumenti matematici più sofisticati (integrali invece di somme), mantiene intatta la sua intuizione fondamentale. La logica appresa nel caso discreto continua a fornire una solida base interpretativa anche per i fenomeni continui, che meglio rappresentano la realtà della misurazione psicologica.\nQuesto framework analitico prepara il terreno per la successiva quantificazione delle relazioni tra variabili attraverso indicatori come la covarianza e la correlazione. Questi strumenti, che saranno approfonditi nel prossimo capitolo, permetteranno di misurare sistematicamente la forza e la direzione delle associazioni psicologiche, trasformando le osservazioni qualitative in relazioni quantitative verificabili.\nL’approccio attraverso le distribuzioni congiunte non solo fornisce un linguaggio formale per descrivere le relazioni psicologiche, ma stabilisce anche le fondamenta per modelli più avanzati di analisi dei dati, aprendo la strada a una comprensione sempre più sofisticata dei meccanismi che regolano il comportamento umano e i processi mentali.\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] ggExtra_0.11.0        viridis_0.6.5         viridisLite_0.4.2    \n#&gt;  [4] MASS_7.3-65           pillar_1.11.0         tinytable_0.13.0     \n#&gt;  [7] patchwork_1.3.2       ggdist_3.3.3          tidybayes_3.0.7      \n#&gt; [10] bayesplot_1.14.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#&gt; [13] priorsense_1.1.1      posterior_1.6.1       loo_2.8.0            \n#&gt; [16] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#&gt; [19] Rcpp_1.1.0            sessioninfo_1.2.3     conflicted_1.2.0     \n#&gt; [22] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#&gt; [25] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#&gt; [28] rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        systemfonts_1.2.3    \n#&gt; [10] vctrs_0.6.5           stringr_1.5.1         pkgconfig_2.0.3      \n#&gt; [13] arrayhelpers_1.1-0    fastmap_1.2.0         backports_1.5.0      \n#&gt; [16] labeling_0.4.3        promises_1.3.3        rmarkdown_2.29       \n#&gt; [19] ragg_1.5.0            purrr_1.1.0           xfun_0.53            \n#&gt; [22] cachem_1.1.0          jsonlite_2.0.0        later_1.4.4          \n#&gt; [25] broom_1.0.9           parallel_4.5.1        R6_2.6.1             \n#&gt; [28] stringi_1.8.7         RColorBrewer_1.1-3    lubridate_1.9.4      \n#&gt; [31] estimability_1.5.1    knitr_1.50            zoo_1.8-14           \n#&gt; [34] httpuv_1.6.16         Matrix_1.7-4          splines_4.5.1        \n#&gt; [37] timechange_0.3.0      tidyselect_1.2.1      abind_1.4-8          \n#&gt; [40] yaml_2.3.10           codetools_0.2-20      miniUI_0.1.2         \n#&gt; [43] curl_7.0.0            pkgbuild_1.4.8        lattice_0.22-7       \n#&gt; [46] shiny_1.11.1          withr_3.0.2           bridgesampling_1.1-2 \n#&gt; [49] coda_0.19-4.1         evaluate_1.0.5        survival_3.8-3       \n#&gt; [52] isoband_0.2.7         RcppParallel_5.1.11-1 tensorA_0.36.2.1     \n#&gt; [55] checkmate_2.3.3       stats4_4.5.1          distributional_0.5.0 \n#&gt; [58] generics_0.1.4        rprojroot_2.1.1       rstantools_2.5.0     \n#&gt; [61] scales_1.4.0          xtable_1.8-4          glue_1.8.0           \n#&gt; [64] emmeans_1.11.2-8      tools_4.5.1           mvtnorm_1.3-3        \n#&gt; [67] grid_4.5.1            QuickJSR_1.8.0        colorspace_2.1-1     \n#&gt; [70] nlme_3.1-168          cli_3.6.5             textshaping_1.0.3    \n#&gt; [73] svUnit_1.0.8          Brobdingnag_1.2-9     V8_7.0.0             \n#&gt; [76] gtable_0.3.6          digest_0.6.37         TH.data_1.1-4        \n#&gt; [79] htmlwidgets_1.6.4     farver_2.1.2          memoise_2.0.1        \n#&gt; [82] htmltools_0.5.8.1     lifecycle_1.0.4       mime_0.13",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_joint_prob.html#bibliografia",
    "href": "chapters/probability/10_joint_prob.html#bibliografia",
    "title": "11  Probabilità congiunta",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlitzstein, J. K., & Hwang, J. (2019). Introduction to probability. CRC Press.\n\n\nChan, J. C. C., & Kroese, D. P. (2025). Statistical Modeling and Computation (2ª ed.). Springer.\n\n\nEysenck, M. W., Derakshan, N., Santos, R., & Calvo, M. G. (2007). Anxiety and cognitive performance: attentional control theory. Emotion, 7(2), 336–353.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_cov_cor.html",
    "href": "chapters/probability/11_cov_cor.html",
    "title": "12  Covarianza e correlazione",
    "section": "",
    "text": "Introduzione\nQuando due variabili casuali non sono indipendenti, diciamo che esse sono associate o dipendenti. È importante non solo stabilire se tale relazione esista, ma anche quantificare la sua intensità e la sua direzione. A tal fine, utilizziamo due misure chiave: la covarianza e la correlazione.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Covarianza e correlazione</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_cov_cor.html#introduzione",
    "href": "chapters/probability/11_cov_cor.html#introduzione",
    "title": "12  Covarianza e correlazione",
    "section": "",
    "text": "Panoramica del capitolo\n\nDefinire e calcolare la covarianza per quantificare la relazione lineare tra due variabili casuali.\nUtilizzare la correlazione per misurare l’intensità della relazione lineare tra variabili casuali, indipendentemente dalle loro unità di misura.\nComprendere le proprietà chiave della covarianza e della correlazione, inclusa l’incorrelazione.\nEstendere i concetti di probabilità congiunta, marginale e condizionale alle variabili continue, utilizzando gli integrali.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere il capitolo Joint Distributions (Chan & Kroese, 2025).\nLeggere il capitolo Joint Distributions (Blitzstein & Hwang, 2019).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt;\n  source()",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Covarianza e correlazione</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_cov_cor.html#covarianza",
    "href": "chapters/probability/11_cov_cor.html#covarianza",
    "title": "12  Covarianza e correlazione",
    "section": "\n12.1 Covarianza",
    "text": "12.1 Covarianza\nLa covarianza misura il grado e la direzione della relazione lineare tra due variabili casuali. Una covarianza positiva indica che le due variabili tendono ad aumentare o diminuire insieme, mentre una covarianza negativa indica che una variabile tende ad aumentare quando l’altra diminuisce.\n\n12.1.1 Definizione di Covarianza\nLa covarianza tra due variabili casuali discrete \\(X\\) e \\(Y\\) è definita come:\n\\[\n\\text{Cov}(X, Y) = \\mathbb{E}\\left[(X - \\mathbb{E}[X])(Y - \\mathbb{E}[Y])\\right] .\n\\]\nEsplicitamente, questa definizione può essere riscritta come:\n\\[\n\\text{Cov}(X, Y) = \\sum_{x}\\sum_{y}(x - \\mu_X)(y - \\mu_Y)p(x, y) .\n\\]\ndove \\(\\mu_X\\) e \\(\\mu_Y\\) sono le medie delle variabili \\(X\\) e \\(Y\\) e \\(p(x,y)\\) è la funzione di massa di probabilità congiunta.\nQuesta definizione mostra una stretta analogia con la varianza, che è la covarianza di una variabile con se stessa:\n\\[\n\\mathbb{V}(X) = Cov(X, X).\n\\]\nInoltre, la covarianza può essere calcolata attraverso la relazione:\n\\[\nCov(X, Y) = \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y).\n\\]\n\n12.1.2 Dimostrazione\nLa formula alternativa per la covarianza si dimostra come segue.\nPer definizione, la covarianza tra due variabili casuali \\(X\\) e \\(Y\\) è:\n\\[\n\\mathrm{Cov}(X, Y) \\;=\\; \\mathbb{E}\\Bigl[\\bigl(X - \\mathbb{E}[X]\\bigr)\\,\\bigl(Y - \\mathbb{E}[Y]\\bigr)\\Bigr].\n\\]\nQuesta è semplicemente la definizione formale, in cui consideriamo la “deviazione” di \\(X\\) dal proprio valor medio (\\(\\mathbb{E}[X]\\)) e la “deviazione” di \\(Y\\) dal proprio valor medio (\\(\\mathbb{E}[Y]\\)), e ne calcoliamo l’aspettativa del prodotto.\nConsideriamo l’argomento dell’aspettativa: \\(\\bigl(X - \\mathbb{E}[X]\\bigr)\\,\\bigl(Y - \\mathbb{E}[Y]\\bigr)\\).\nPer prima cosa espandiamo il prodotto come faremmo con normali variabili algebriche:\n\\[\n\\bigl(X - \\mathbb{E}[X]\\bigr)\\,\\bigl(Y - \\mathbb{E}[Y]\\bigr)\n= X\\,Y \\;-\\; X\\,\\mathbb{E}[Y] \\;-\\; \\mathbb{E}[X]\\,Y \\;+\\; \\mathbb{E}[X]\\mathbb{E}[Y].\n\\]\nAdesso prendiamo l’aspettativa (o valore atteso) di ciascun termine che abbiamo ottenuto. Indichiamo con \\(\\mathbb{E}\\) l’operatore di aspettativa:\n\\[\n\\mathbb{E}\\Bigl[\\bigl(X - \\mathbb{E}[X]\\bigr)\\,\\bigl(Y - \\mathbb{E}[Y]\\bigr)\\Bigr]\n= \\mathbb{E}[\\,X\\,Y \\;-\\; X\\,\\mathbb{E}[Y] \\;-\\; \\mathbb{E}[X]\\,Y \\;+\\; \\mathbb{E}[X]\\mathbb{E}[Y]\\,].\n\\]\nGrazie alla linearità dell’aspettativa, possiamo scindere questa grande aspettativa in una somma (e differenza) di aspettative di singoli termini:\n\\[\n= \\mathbb{E}[XY]\n\\;-\\; \\mathbb{E}[X\\,\\mathbb{E}[Y]]\n\\;-\\; \\mathbb{E}[\\mathbb{E}[X]\\,Y]\n\\;+\\; \\mathbb{E}[\\mathbb{E}[X]\\mathbb{E}[Y]].\n\\]\nRicordiamo che \\(\\mathbb{E}[X]\\) e \\(\\mathbb{E}[Y]\\) sono numeri (costanti) e non variabili casuali. Dunque, quando nell’aspettativa compare un fattore costante, possiamo estrarlo fuori dall’operatore \\(\\mathbb{E}[\\cdot]\\).\n\n\\(\\mathbb{E}[X\\,\\mathbb{E}[Y]]\\) si semplifica in \\(\\mathbb{E}[Y]\\cdot \\mathbb{E}[X]\\) perché \\(\\mathbb{E}[Y]\\) è una costante. In formula: \\[\n\\mathbb{E}[X\\,\\mathbb{E}[Y]]\n= \\mathbb{E}[Y] \\,\\mathbb{E}[X].\n\\]\nAllo stesso modo, \\(\\mathbb{E}[\\mathbb{E}[X]\\,Y]\\) si semplifica in \\(\\mathbb{E}[X]\\cdot \\mathbb{E}[Y]\\).\nInfine, \\(\\mathbb{E}[\\mathbb{E}[X]\\mathbb{E}[Y]]\\) è \\(\\mathbb{E}[X]\\mathbb{E}[Y]\\) in quanto \\(\\mathbb{E}[X]\\mathbb{E}[Y]\\) è già una costante.\n\nUsando queste regole, riscriviamo i termini:\n\\[\n\\mathbb{E}[XY]\n\\;-\\; \\mathbb{E}[X]\\mathbb{E}[Y]\n\\;-\\; \\mathbb{E}[X]\\mathbb{E}[Y]\n\\;+\\; \\mathbb{E}[X]\\mathbb{E}[Y].\n\\]\nOsserviamo i termini rimanenti:\n\\[\n\\mathbb{E}[XY] \\;-\\; \\mathbb{E}[X]\\mathbb{E}[Y]\n\\;-\\; \\mathbb{E}[X]\\mathbb{E}[Y]\n\\;+\\; \\mathbb{E}[X]\\mathbb{E}[Y].\n\\]\n\nIl termine \\(\\mathbb{E}[X]\\mathbb{E}[Y]\\) compare due volte in negativo (\\(-\\,\\mathbb{E}[X]\\mathbb{E}[Y]\\)) e una volta in positivo (\\(+\\,\\mathbb{E}[X]\\mathbb{E}[Y]\\)).\n\nFacendo la somma algebrica, ne rimane solo \\(-\\,\\mathbb{E}[X]\\mathbb{E}[Y]\\) (perché \\(-\\,1 -\\,1 +\\,1 = -\\,1\\)).\n\nQuindi il risultato è:\n\\[\n\\mathbb{E}[XY]\n\\;-\\; \\mathbb{E}[X]\\mathbb{E}[Y].\n\\]\nAbbiamo quindi dimostrato in maniera esplicita che:\n\\[\n\\mathrm{Cov}(X, Y)\n= \\mathbb{E}\\bigl[(X - \\mathbb{E}[X]) (Y - \\mathbb{E}[Y])\\bigr]\n= \\mathbb{E}[XY] - \\mathbb{E}[X]\\mathbb{E}[Y].\n\\]\n\n12.1.3 Esempio Psicologico: Covarianza tra Ansia e Prestazione Cognitiva\nRiprendendo i dati del capitolo precedente sulla relazione tra ansia (Y) e prestazione cognitiva (X), calcoliamo ora la covarianza.\nMedie marginali:\n\nPrestazione cognitiva \\(X\\):\\[\\mathbb{E}(X)=0\\times0.30 + 1\\times0.45 + 2\\times0.25=0.95\\]\n\nAnsia \\(Y\\):\\[\\mathbb{E}(Y)=0\\times0.30 + 1\\times0.40 + 2\\times0.30=1.00\\]\n\n\nCalcoliamo \\(\\mathbb{E}(XY)\\):\n\\[\n\\begin{aligned}\n\\mathbb{E}(XY) &= (0\\times0\\times0.05)+(0\\times1\\times0.10)+(0\\times2\\times0.15)+\n\\notag\\\\\n& \\quad (1\\times0\\times0.15)+(1\\times1\\times0.20)+(1\\times2\\times0.10)+\n\\notag\\\\\n& \\quad(2\\times0\\times0.10)+(2\\times1\\times0.10)+(2\\times2\\times0.05)\n\\end{aligned}\n\\]\nSimplificando:\n\\[\\mathbb{E}(XY)=0.00+0.00+0.00+0.00+0.20+0.20+0.00+0.20+0.20=0.80\\]\nQuindi, la covarianza sarà:\n\\[\\text{Cov}(X,Y)=\\mathbb{E}(XY)-\\mathbb{E}(X)\\mathbb{E}(Y)=0.80-(0.95\\times1.00)=-0.15\\]\nLa covarianza negativa indica che all’aumentare del livello di ansia tende a corrispondere una diminuzione della prestazione cognitiva, coerentemente con quanto spesso riscontrato nella letteratura psicologica.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Covarianza e correlazione</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_cov_cor.html#correlazione",
    "href": "chapters/probability/11_cov_cor.html#correlazione",
    "title": "12  Covarianza e correlazione",
    "section": "\n12.2 Correlazione",
    "text": "12.2 Correlazione\nLa correlazione standardizza la covarianza, rendendola indipendente dalle unità di misura delle variabili. Essa varia tra -1 e 1 ed è definita come:\n\\[\n\\rho(X,Y)=\\frac{\\text{Cov}(X,Y)}{\\sqrt{\\text{Var}(X)\\text{Var}(Y)}} .\n\\]\ndove \\(\\mathbb{V}(X)\\) e \\(\\mathbb{V}(Y)\\) rappresentano le varianze di \\(X\\) e \\(Y\\), rispettivamente.\nIl coefficiente di correlazione \\(\\rho_{xy}\\) è un valore adimensionale, ovvero non dipende dalle unità di misura delle variabili, e varia nell’intervallo \\(-1 \\leq \\rho \\leq 1\\).\n\n12.2.1 Calcolo della Correlazione\nPer calcolare la correlazione tra ansia e prestazione cognitiva, dobbiamo prima ottenere le varianze di ciascuna variabile.\n\nVarianza di X (prestazione cognitiva):\n\n\\[\n\\begin{aligned}\n\\text{Var}(X) &=\\sum_{x}(x-\\mu_X)^2p(x)\n\\notag\\\\\n&= (0-0.95)^2\\times0.30+(1-0.95)^2\\times0.45+(2-0.95)^2\\times0.25=0.5475 \\notag\n\\end{aligned}\n\\]\n\nVarianza di Y (ansia):\n\n\\[\n\\begin{aligned}\n\\text{Var}(Y) &=\\sum_{y}(y-\\mu_Y)^2p(y) \\notag\\\\\n&= (0-1.00)^2\\times0.30+(1-1.00)^2\\times0.40+(2-1.00)^2\\times0.30=0.60 \\notag\n\\end{aligned}\n\\]\nQuindi, il coefficiente di correlazione è:\n\\[\n\\rho(X,Y)=\\frac{-0.15}{\\sqrt{0.5475\\times0.60}}=-0.261\n\\]\nIl valore negativo della correlazione conferma che ansia e prestazione cognitiva presentano una relazione inversa: all’aumentare dell’ansia, la prestazione tende a diminuire.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Covarianza e correlazione</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_cov_cor.html#interpretazione-della-correlazione",
    "href": "chapters/probability/11_cov_cor.html#interpretazione-della-correlazione",
    "title": "12  Covarianza e correlazione",
    "section": "\n12.3 Interpretazione della Correlazione",
    "text": "12.3 Interpretazione della Correlazione\nIl coefficiente di correlazione è una misura standardizzata e facile da interpretare:\n\n\n\\(\\rho = 1\\): perfetta relazione lineare positiva\n\n\\(\\rho = -1\\): perfetta relazione lineare negativa\n\n\\(\\rho = 0\\): assenza di relazione lineare\n\nNel nostro esempio, il valore \\(-0.261\\) indica una relazione lineare negativa moderata tra ansia e prestazione.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Covarianza e correlazione</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_cov_cor.html#proprietà",
    "href": "chapters/probability/11_cov_cor.html#proprietà",
    "title": "12  Covarianza e correlazione",
    "section": "\n12.4 Proprietà",
    "text": "12.4 Proprietà\nLa covarianza e la correlazione possiedono una serie di proprietà formali che ne regolano il comportamento al variare delle variabili e delle costanti coinvolte. Di seguito vengono enunciate e discusse le principali.\nLa covarianza tra una variabile aleatoria \\(X\\) e una costante \\(c\\) è sempre nulla: \\[\n\\text{Cov}(c, X) = 0.\n\\] Inoltre, la covarianza gode della proprietà di simmetria: \\[\n\\text{Cov}(X, Y) = \\text{Cov}(Y, X).\n\\]\nIl coefficiente di correlazione \\(\\rho_{X,Y}\\) è limitato nell’intervallo chiuso \\([-1, 1]\\): \\[\n-1 \\leq \\rho(X, Y) \\leq 1.\n\\] Tale coefficiente è invariante rispetto a cambiamenti di scala delle variabili: per ogni \\(a &gt; 0\\) e \\(b &gt; 0\\) si ha \\[\n\\rho(aX, bY) = \\rho(X, Y).\n\\] Nel caso di una relazione lineare perfetta della forma \\(Y = a + bX\\), il coefficiente di correlazione assume valore estremo: \\[\n\\rho(X, Y) = \\begin{cases}\n+1 & \\text{se } b &gt; 0, \\\\\n-1 & \\text{se } b &lt; 0.\n\\end{cases}\n\\]\nRiguardo alle trasformazioni lineari, la covarianza soddisfa: \\[\n\\text{Cov}(aX, bY) = ab \\cdot \\text{Cov}(X, Y),\n\\] e, più in generale, per due combinazioni lineari di variabili aleatorie: \\[\n\\text{Cov}\\left( \\sum_{i=1}^n a_i X_i, \\sum_{j=1}^m b_j Y_j \\right) = \\sum_{i=1}^n \\sum_{j=1}^m a_i b_j \\, \\text{Cov}(X_i, Y_j).\n\\]\nLa varianza della somma (o differenza) di due variabili è data da: \\[\n\\mathbb{V}(X \\pm Y) = \\mathbb{V}(X) + \\mathbb{V}(Y) \\pm 2 \\, \\text{Cov}(X, Y).\n\\] Più in generale, per una somma di \\(n\\) variabili aleatorie: \\[\n\\mathbb{V}\\left( \\sum_{i=1}^n X_i \\right) = \\sum_{i=1}^n \\mathbb{V}(X_i) + 2 \\sum_{i &lt; j} \\text{Cov}(X_i, X_j).\n\\]\nLa covarianza è additiva in ciascun argomento: per ogni variabile aleatoria \\(Z\\), \\[\n\\text{Cov}(X + Y, Z) = \\text{Cov}(X, Z) + \\text{Cov}(Y, Z).\n\\]\nNel caso particolare in cui le variabili \\(X_1, X_2, \\dots, X_n\\) siano mutualmente indipendenti, la covarianza tra due loro combinazioni lineari si semplifica in: \\[\n\\text{Cov}\\left( \\sum_{i=1}^n a_i X_i, \\sum_{j=1}^n b_j X_j \\right) = \\sum_{i=1}^n a_i b_i \\, \\mathbb{V}(X_i),\n\\] poiché i termini di covarianza incrociata sono nulli.\n\n12.4.1 Incorrelazione\nDue variabili casuali \\(X\\) e \\(Y\\) si dicono incorrelate (o linearmente indipendenti) se la loro covarianza è nulla:\n\\[\n\\text{Cov}(X, Y) = \\mathbb{E}[(X - \\mu_X)(Y - \\mu_Y)] = 0.\n\\]\nTale condizione è equivalente a ciascuna delle seguenti:\n\nil coefficiente di correlazione \\(\\rho_{XY}\\) è nullo;\nil valore atteso del prodotto è uguale al prodotto dei valori attesi: \\(\\mathbb{E}(XY) = \\mathbb{E}(X)\\mathbb{E}(Y)\\).\n\nL’incorrelazione rappresenta una forma di indipendenza statistica più debole rispetto all’indipendenza stocastica. Mentre due variabili indipendenti sono sempre incorrelate, il viceversa non è vero: è possibile che \\(X\\) e \\(Y\\) abbiano covarianza nulla pur non essendo stocasticamente indipendenti. In altri termini, l’assenza di correlazione lineare non esclude l’esistenza di altre forme di dipendenza (ad esempio, di tipo non lineare) tra le due variabili.\n\nEsempio 12.1 Consideriamo una distribuzione di probabilità congiunta di due variabili aleatorie, \\(X\\) e \\(Y\\), definita come:\n\\[\nf_{XY}(x,y) = \\left\\{\n\\begin{array}{ll}\n\\frac{1}{4} & \\text{per } (x,y) \\in \\{(0,0), (1,1), (1, -1), (2,0) \\}, \\\\\n0 & \\text{altrimenti.}\n\\end{array}\n\\right.\n\\]\nQuesto implica che le variabili aleatorie \\(X\\) e \\(Y\\) assumono valori specifici con probabilità uniforme solo per determinate coppie \\((x, y)\\) e zero in tutti gli altri casi.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Covarianza e correlazione</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_cov_cor.html#riflessioni-conclusive",
    "href": "chapters/probability/11_cov_cor.html#riflessioni-conclusive",
    "title": "12  Covarianza e correlazione",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nLa covarianza e la correlazione forniscono strumenti essenziali per quantificare le relazioni tra variabili casuali. Utilizzare queste misure permette di approfondire la comprensione delle relazioni psicologiche, come quella tra ansia e prestazione, facilitando ulteriori analisi statistiche e interpretazioni teoriche.\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\nEsercizio 1: Distribuzione congiunta di due lanci di dado\nSi lancia due volte un dado a sei facce equilibrato. Siano:\n\n\n\\(X\\) il risultato del primo lancio.\n\n\\(Y\\) il risultato del secondo lancio.\n\n\nCostruisci la tabella della distribuzione congiunta \\(P(X, Y)\\), considerando che tutti i risultati possibili hanno la stessa probabilità.\nVerifica che la somma delle probabilità sia 1.\nDetermina la distribuzione marginale di \\(X\\) e di \\(Y\\).\nLe variabili \\(X\\) e \\(Y\\) sono indipendenti? Giustifica la risposta.\n\nEsercizio 2: Somma di due dadi\nSi lancia due volte un dado a sei facce. Definiamo:\n\n\n\\(S = X + Y\\), la somma dei due risultati.\n\n\nCostruisci la tabella di probabilità congiunta \\(P(X, Y)\\).\nCalcola la distribuzione di probabilità della variabile aleatoria \\(S\\).\nDetermina \\(P(S = 7)\\) e \\(P(S \\leq 5)\\).\nQual è il valore più probabile di \\(S\\)? E il meno probabile?\n\nEsercizio 3: Lancio di tre monete\nSi lanciano tre monete equilibrate. Definiamo:\n\n\n\\(X\\) il numero di teste ottenute.\n\n\\(Y\\) il risultato del primo lancio (1 se testa, 0 se croce).\n\n\nDetermina lo spazio campionario e associa i valori delle variabili aleatorie \\(X\\) e \\(Y\\).\nCostruisci la distribuzione congiunta \\(P(X, Y)\\).\nCalcola \\(P(X = 2 \\mid Y = 1)\\) e \\(P(Y = 1 \\mid X = 2)\\).\nLe variabili \\(X\\) e \\(Y\\) sono indipendenti?\n\nEsercizio 4: Minimo e massimo tra due dadi\nSi lancia due volte un dado a sei facce. Definiamo:\n\n\n\\(X = \\min \\{X_1, X_2\\}\\), il valore minimo tra i due lanci.\n\n\\(Y = \\max \\{X_1, X_2\\}\\), il valore massimo tra i due lanci.\n\n\nCostruisci la tabella della distribuzione congiunta \\(P(X, Y)\\).\nCalcola \\(P(X = 3, Y = 5)\\) e \\(P(X \\geq 3, Y \\leq 4)\\).\nDetermina la distribuzione marginale di \\(X\\) e di \\(Y\\).\nCalcola la covarianza tra \\(X\\) e \\(Y\\).\n\nEsercizio 5: Differenza tra due dadi\nSi lanciano due dadi a sei facce. Definiamo:\n\n\n\\(X\\) il risultato del primo lancio.\n\n\\(Y\\) la differenza assoluta tra i due risultati, ovvero \\(Y = |X - X_2|\\).\n\n\nDetermina la tabella della distribuzione congiunta \\(P(X, Y)\\).\nCalcola la distribuzione marginale di \\(Y\\).\nDetermina \\(P(Y = 0)\\) e \\(P(Y = 3)\\).\nLe variabili \\(X\\) e \\(Y\\) sono indipendenti? Giustifica la risposta.\n\n\n\n\n\n\n\n\n\n\nSoluzioni 1\n\n\n\n\n\nEsercizio 1: Distribuzione congiunta di due lanci di dado\nAbbiamo due variabili aleatorie discrete: - \\(X\\), risultato del primo lancio di un dado a sei facce. - \\(Y\\), risultato del secondo lancio.\n1. Tabella della distribuzione congiunta \\(P(X, Y)\\) Poiché il dado è equo, ogni coppia di risultati \\((x, y)\\) ha la stessa probabilità. Esistono \\(6 \\times 6 = 36\\) combinazioni possibili, e ognuna ha probabilità:\n\\[\nP(X = x, Y = y) = \\frac{1}{36}, \\quad \\text{per ogni } x, y \\in \\{1, 2, 3, 4, 5, 6\\}\n\\]\nLa tabella della distribuzione congiunta è:\n\n\n\n\\(X\\)  \\(Y\\)\n\n1\n2\n3\n4\n5\n6\n\n\n\n1\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n\n\n2\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n\n\n3\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n\n\n4\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n\n\n5\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n\n\n6\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n\n\n\n2. Verifica che la somma delle probabilità sia 1 La somma di tutte le probabilità è:\n\\[\n\\sum_{x=1}^{6} \\sum_{y=1}^{6} P(X = x, Y = y) = 36 \\times \\frac{1}{36} = 1.\n\\]\n3. Distribuzione marginale di \\(X\\) e \\(Y\\) Per ottenere la distribuzione marginale di \\(X\\):\n\\[\nP(X = x) = \\sum_{y=1}^{6} P(X = x, Y = y) = 6 \\times \\frac{1}{36} = \\frac{1}{6}, \\quad \\forall x.\n\\]\nAnalogamente, per \\(Y\\):\n\\[\nP(Y = y) = \\sum_{x=1}^{6} P(X = x, Y = y) = \\frac{1}{6}, \\quad \\forall y.\n\\]\nEntrambe seguono una distribuzione uniforme su \\(\\{1, 2, 3, 4, 5, 6\\}\\).\n4. Indipendenza di \\(X\\) e \\(Y\\) Due variabili sono indipendenti se \\(P(X = x, Y = y) = P(X = x) P(Y = y)\\).\n\\[\n\\frac{1}{36} = \\frac{1}{6} \\times \\frac{1}{6} = \\frac{1}{36}, \\quad \\forall x, y.\n\\]\nPoiché questa relazione vale per tutti i valori, \\(X\\) e \\(Y\\) sono indipendenti.\nEsercizio 2: Somma di due dadi\nAbbiamo:\n\\[\nS = X + Y\n\\]\n1. Tabella di probabilità congiunta \\(P(X, Y)\\) È la stessa tabella costruita nel primo esercizio.\n2. Distribuzione di probabilità di \\(S\\) La somma \\(S\\) assume valori da \\(2\\) (1+1) a \\(12\\) (6+6). La probabilità di ogni valore di \\(S\\) si ottiene contando le coppie \\((x, y)\\) che lo producono:\n\n\n\\(S\\)\n\\(P(S)\\)\n\n\n\n2\n1/36\n\n\n3\n2/36\n\n\n4\n3/36\n\n\n5\n4/36\n\n\n6\n5/36\n\n\n7\n6/36\n\n\n8\n5/36\n\n\n9\n4/36\n\n\n10\n3/36\n\n\n11\n2/36\n\n\n12\n1/36\n\n\n\n3. Calcolo di \\(P(S = 7)\\) e \\(P(S \\leq 5)\\) - \\(P(S = 7) = 6/36 = 1/6\\). - \\(P(S \\leq 5) = P(S = 2) + P(S = 3) + P(S = 4) + P(S = 5)\\)\n\\[\n\\frac{1}{36} + \\frac{2}{36} + \\frac{3}{36} + \\frac{4}{36} = \\frac{10}{36} = \\frac{5}{18}.\n\\]\n4. Valori più probabili e meno probabili - Il valore più probabile è \\(S = 7\\) (\\(P(S=7) = 1/6\\)). - I valori meno probabili sono \\(S = 2\\) e \\(S = 12\\) (\\(P(S) = 1/36\\)).\nEsercizio 3: Lancio di tre monete\nAbbiamo:\n\nTre monete equilibrare.\nVariabili:\n\n\n\\(X\\): numero di teste ottenute.\n\n\\(Y\\): risultato del primo lancio (1 se testa, 0 se croce).\n\n\n\n1. Spazio campionario e valori di \\(X\\) e \\(Y\\)\nLo spazio campionario dei lanci è:\n\\[\n\\{ (C, C, C), (C, C, T), (C, T, C), (C, T, T), (T, C, C), (T, C, T), (T, T, C), (T, T, T) \\}\n\\]\nOra assegniamo \\(X\\) e \\(Y\\):\n\n\nLancio\n\n\\(X\\) (num. teste)\n\n\\(Y\\) (primo lancio)\n\n\n\nC, C, C\n0\n0\n\n\nC, C, T\n1\n0\n\n\nC, T, C\n1\n0\n\n\nC, T, T\n2\n0\n\n\nT, C, C\n1\n1\n\n\nT, C, T\n2\n1\n\n\nT, T, C\n2\n1\n\n\nT, T, T\n3\n1\n\n\n\n2. Distribuzione congiunta \\(P(X, Y)\\)\nPoiché ogni lancio ha probabilità \\(\\frac{1}{8}\\), la tabella di probabilità congiunta è:\n\n\n\n\\(X\\)  \\(Y\\)\n\n0\n1\n\n\n\n0\n1/8\n0\n\n\n1\n2/8\n1/8\n\n\n2\n1/8\n3/8\n\n\n3\n0\n1/8\n\n\n\n3. Probabilità condizionate \\(P(X = 2 \\mid Y = 1)\\) \\[\nP(X = 2 \\mid Y = 1) = \\frac{P(X = 2, Y = 1)}{P(Y = 1)} = \\frac{3/8}{5/8} = \\frac{3}{5}.\n\\]\n\\(P(Y = 1 \\mid X = 2)\\) \\[\nP(Y = 1 \\mid X = 2) = \\frac{P(X = 2, Y = 1)}{P(X = 2)} = \\frac{3/8}{4/8} = \\frac{3}{4}.\n\\]\n4. Indipendenza di \\(X\\) e \\(Y\\)\nVerifichiamo se \\(P(X = x, Y = y) = P(X = x) P(Y = y)\\) per ogni coppia.\nEsempio: \\(P(X = 2, Y = 1) = 3/8\\) ma \\(P(X=2) P(Y=1) = (4/8)(5/8) = 20/64 = 5/16 \\neq 3/8\\).\nQuindi \\(X\\) e \\(Y\\) non sono indipendenti.\nEsercizio 4: Minimo e massimo tra due dadi\nAbbiamo:\n\n\n\\(X = \\min(X_1, X_2)\\), il minimo tra i due lanci.\n\n\\(Y = \\max(X_1, X_2)\\), il massimo tra i due lanci.\n\n1. Tabella della distribuzione congiunta\nPoiché i due lanci sono indipendenti e simmetrici, ci sono 36 coppie \\((X_1, X_2)\\), e ogni coppia ha probabilità \\(\\frac{1}{36}\\).\nLa tabella congiunta si costruisce considerando che \\(X = \\min(X_1, X_2)\\) e \\(Y = \\max(X_1, X_2)\\):\n\n\n\n\\(X\\)  \\(Y\\)\n\n1\n2\n3\n4\n5\n6\n\n\n\n1\n1/36\n2/36\n3/36\n4/36\n5/36\n6/36\n\n\n2\n-\n1/36\n2/36\n3/36\n4/36\n5/36\n\n\n3\n-\n-\n1/36\n2/36\n3/36\n4/36\n\n\n4\n-\n-\n-\n1/36\n2/36\n3/36\n\n\n5\n-\n-\n-\n-\n1/36\n2/36\n\n\n6\n-\n-\n-\n-\n-\n1/36\n\n\n\n2. Probabilità richieste\n\n\n\\(P(X = 3, Y = 5) = 3/36\\).\n\n\\(P(X \\geq 3, Y \\leq 4) = P(X = 3, Y = 3) + P(X = 3, Y = 4) + P(X = 4, Y = 4) = 1/36 + 2/36 + 1/36 = 4/36 = 1/9\\).\n\nEsercizio 5: Differenza tra due dadi\nAbbiamo:\n\n\n\\(X\\) = primo lancio.\n\n\\(Y = |X - X_2|\\).\n\n1. Tabella della distribuzione congiunta \\(P(X, Y)\\)\n\\(Y\\) assume valori da 0 a 5, a seconda della differenza tra i due dadi:\n\n\n\n\\(X\\)  \\(Y\\)\n\n0\n1\n2\n3\n4\n5\n\n\n\n1\n1/6\n1/6\n1/6\n1/6\n1/6\n1/6\n\n\n2\n1/6\n2/6\n1/6\n1/6\n1/6\n0\n\n\n3\n1/6\n2/6\n2/6\n1/6\n0\n0\n\n\n4\n1/6\n2/6\n2/6\n1/6\n0\n0\n\n\n5\n1/6\n2/6\n1/6\n1/6\n0\n0\n\n\n6\n1/6\n1/6\n1/6\n1/6\n0\n0\n\n\n\n2. Distribuzione marginale di \\(Y\\)\nSommiamo lungo \\(X\\):\n\n\n\\(Y\\)\n\\(P(Y)\\)\n\n\n\n0\n6/36\n\n\n1\n10/36\n\n\n2\n8/36\n\n\n3\n6/36\n\n\n4\n4/36\n\n\n5\n2/36\n\n\n\n3. Probabilità richieste\n\n\n\\(P(Y = 0) = 6/36 = 1/6\\).\n\n\\(P(Y = 3) = 6/36 = 1/6\\).\n\n4. Indipendenza di \\(X\\) e \\(Y\\)\nCome nell’esercizio 3, verifichiamo che \\(P(X, Y) \\neq P(X) P(Y)\\) per alcune coppie. Essendo la tabella non simmetrica, \\(X\\) e \\(Y\\) non sono indipendenti.\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nConsidera il seguente esperimento casuale: si estrae una pallina da un’urna contenente tre palline numerate con i valori \\(1\\), \\(2\\) e \\(3\\).\nDopo l’estrazione, si definiscono due variabili casuali:\n\n\n\\(X\\), il valore della pallina estratta.\n\n\\(Y\\), il valore di un’altra variabile definita come \\(Y = X^2\\).\n\n\nCostruisci la distribuzione congiunta di \\(X\\) e \\(Y\\).\nCalcola il valore atteso di \\(X\\) e \\(Y\\), ossia \\(E[X]\\) e \\(E[Y]\\).\nCalcola la covarianza tra \\(X\\) e \\(Y\\), ossia \\(\\text{Cov}(X, Y)\\).\nCalcola la correlazione tra \\(X\\) e \\(Y\\), ossia \\(\\rho(X, Y)\\).\nInterpreta il valore della correlazione: cosa indica il segno e il valore ottenuto?\n\n\n\n\n\n\n\n\n\n\nSoluzioni 2\n\n\n\n\n\n1. Distribuzione congiunta di \\(X\\) e \\(Y\\)\nPoiché ogni pallina ha la stessa probabilità di essere estratta, la distribuzione congiunta è:\n\n\n\\(X\\)\n\\(Y = X^2\\)\n\\(P(X, Y)\\)\n\n\n\n1\n1\n\\(\\frac{1}{3}\\)\n\n\n2\n4\n\\(\\frac{1}{3}\\)\n\n\n3\n9\n\\(\\frac{1}{3}\\)\n\n\n\n2. Calcolo di \\(E[X]\\) e \\(E[Y]\\)\n\\[\nE[X] = \\sum_{i} x_i P(X = x_i) = 1 \\cdot \\frac{1}{3} + 2 \\cdot \\frac{1}{3} + 3 \\cdot \\frac{1}{3} = \\frac{1 + 2 + 3}{3} = 2\n\\]\n\\[\nE[Y] = \\sum_{i} y_i P(Y = y_i) = 1 \\cdot \\frac{1}{3} + 4 \\cdot \\frac{1}{3} + 9 \\cdot \\frac{1}{3} = \\frac{1 + 4 + 9}{3} = \\frac{14}{3}\n\\]\n3. Calcolo della covarianza \\(\\text{Cov}(X, Y)\\)\nLa covarianza è definita come:\n\\[\n\\text{Cov}(X, Y) = E[XY] - E[X]E[Y]\n\\]\nPrima calcoliamo \\(E[XY]\\):\n\\[\nE[XY] = \\sum_{i} x_i y_i P(X = x_i, Y = y_i) = 1 \\cdot 1 \\cdot \\frac{1}{3} + 2 \\cdot 4 \\cdot \\frac{1}{3} + 3 \\cdot 9 \\cdot \\frac{1}{3}\n\\]\n\\[\n= \\frac{1 + 8 + 27}{3} = \\frac{36}{3} = 12\n\\]\nOra possiamo calcolare la covarianza:\n\\[\n\\text{Cov}(X, Y) = E[XY] - E[X]E[Y] = 12 - \\left(2 \\cdot \\frac{14}{3}\\right) = 12 - \\frac{28}{3} = \\frac{36 - 28}{3} = \\frac{8}{3}\n\\]\n4. Calcolo della correlazione \\(\\rho(X, Y)\\)\nLa correlazione è definita come:\n\\[\n\\rho(X, Y) = \\frac{\\text{Cov}(X, Y)}{\\sigma_X \\cdot \\sigma_Y}\n\\]\nCalcoliamo prima le varianze:\n\\[\n\\text{Var}(X) = E[X^2] - (E[X])^2\n\\]\n\\[\nE[X^2] = 1^2 \\cdot \\frac{1}{3} + 2^2 \\cdot \\frac{1}{3} + 3^2 \\cdot \\frac{1}{3} = \\frac{1 + 4 + 9}{3} = \\frac{14}{3}\n\\]\n\\[\n\\text{Var}(X) = \\frac{14}{3} - 2^2 = \\frac{14}{3} - 4 = \\frac{14 - 12}{3} = \\frac{2}{3}\n\\]\nOra la varianza di \\(Y\\):\n\\[\n\\text{Var}(Y) = E[Y^2] - (E[Y])^2\n\\]\n\\[\nE[Y^2] = 1^2 \\cdot \\frac{1}{3} + 4^2 \\cdot \\frac{1}{3} + 9^2 \\cdot \\frac{1}{3} = \\frac{1 + 16 + 81}{3} = \\frac{98}{3}\n\\]\n\\[\n\\text{Var}(Y) = \\frac{98}{3} - \\left(\\frac{14}{3}\\right)^2 = \\frac{98}{3} - \\frac{196}{9} = \\frac{98 \\cdot 3 - 196}{9} = \\frac{294 - 196}{9} = \\frac{98}{9}\n\\]\nCalcoliamo le deviazioni standard:\n\\[\n\\sigma_X = \\sqrt{\\text{Var}(X)} = \\sqrt{\\frac{2}{3}} = \\frac{\\sqrt{6}}{3}\n\\]\n\\[\n\\sigma_Y = \\sqrt{\\text{Var}(Y)} = \\sqrt{\\frac{98}{9}} = \\frac{\\sqrt{98}}{3}\n\\]\nOra possiamo calcolare la correlazione:\n\\[\n\\rho(X, Y) = \\frac{\\text{Cov}(X, Y)}{\\sigma_X \\cdot \\sigma_Y} = \\frac{\\frac{8}{3}}{\\frac{\\sqrt{6}}{3} \\cdot \\frac{\\sqrt{98}}{3}}\n\\]\n\\[\n= \\frac{\\frac{8}{3}}{\\frac{\\sqrt{6 \\cdot 98}}{9}} = \\frac{8 \\cdot 9}{3 \\cdot \\sqrt{6 \\cdot 98}} = \\frac{24}{\\sqrt{588}}\n\\]\nPoiché \\(\\sqrt{588} = \\sqrt{4 \\cdot 147} = 2\\sqrt{147} = 2\\sqrt{49 \\cdot 3} = 2 \\cdot 7 \\cdot \\sqrt{3} = 14\\sqrt{3}\\):\n\\[\n\\rho(X, Y) = \\frac{24}{14\\sqrt{3}} = \\frac{12}{7\\sqrt{3}} = \\frac{12\\sqrt{3}}{21} \\approx 0.995\n\\]\n5. Interpretazione della correlazione\n\nIl valore \\(\\rho(X, Y) \\approx 0.995\\) è molto vicino a 1, indicando una correlazione positiva quasi perfetta tra \\(X\\) e \\(Y\\).\nIl segno positivo indica che all’aumentare di \\(X\\), anche \\(Y\\) tende ad aumentare.\nL’alto valore (prossimo a 1) indica che la relazione tra \\(X\\) e \\(Y\\) è quasi perfettamente lineare, il che è coerente con la definizione \\(Y = X^2\\) nell’intervallo considerato (piccoli valori positivi di \\(X\\)).\n\n\n\n\n\n\n\n\n\n\nProblemi 3\n\n\n\n\n\nEsercizi sulla distribuzione di probabilità congiunta sono disponibili sulla seguente pagina web.\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt;  [4] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt;  [7] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [10] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [13] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [16] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [25] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.8          tidyselect_1.2.1      farver_2.1.2         \n#&gt;  [4] fastmap_1.2.0         TH.data_1.1-4         tensorA_0.36.2.1     \n#&gt;  [7] digest_0.6.37         timechange_0.3.0      estimability_1.5.1   \n#&gt; [10] lifecycle_1.0.4       survival_3.8-3        magrittr_2.0.3       \n#&gt; [13] compiler_4.5.1        rlang_1.1.6           tools_4.5.1          \n#&gt; [16] knitr_1.50            bridgesampling_1.1-2  htmlwidgets_1.6.4    \n#&gt; [19] curl_7.0.0            pkgbuild_1.4.8        RColorBrewer_1.1-3   \n#&gt; [22] abind_1.4-8           multcomp_1.4-28       withr_3.0.2          \n#&gt; [25] purrr_1.1.0           grid_4.5.1            stats4_4.5.1         \n#&gt; [28] colorspace_2.1-1      xtable_1.8-4          inline_0.3.21        \n#&gt; [31] emmeans_1.11.2-8      scales_1.4.0          MASS_7.3-65          \n#&gt; [34] cli_3.6.5             mvtnorm_1.3-3         rmarkdown_2.29       \n#&gt; [37] ragg_1.5.0            generics_0.1.4        RcppParallel_5.1.11-1\n#&gt; [40] cachem_1.1.0          stringr_1.5.1         splines_4.5.1        \n#&gt; [43] parallel_4.5.1        vctrs_0.6.5           V8_7.0.0             \n#&gt; [46] Matrix_1.7-4          sandwich_3.1-1        jsonlite_2.0.0       \n#&gt; [49] arrayhelpers_1.1-0    systemfonts_1.2.3     glue_1.8.0           \n#&gt; [52] codetools_0.2-20      distributional_0.5.0  lubridate_1.9.4      \n#&gt; [55] stringi_1.8.7         gtable_0.3.6          QuickJSR_1.8.0       \n#&gt; [58] htmltools_0.5.8.1     Brobdingnag_1.2-9     R6_2.6.1             \n#&gt; [61] textshaping_1.0.3     rprojroot_2.1.1       evaluate_1.0.5       \n#&gt; [64] lattice_0.22-7        backports_1.5.0       memoise_2.0.1        \n#&gt; [67] broom_1.0.9           snakecase_0.11.1      rstantools_2.5.0     \n#&gt; [70] coda_0.19-4.1         gridExtra_2.3         nlme_3.1-168         \n#&gt; [73] checkmate_2.3.3       xfun_0.53             zoo_1.8-14           \n#&gt; [76] pkgconfig_2.0.3",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Covarianza e correlazione</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_cov_cor.html#bibliografia",
    "href": "chapters/probability/11_cov_cor.html#bibliografia",
    "title": "12  Covarianza e correlazione",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlitzstein, J. K., & Hwang, J. (2019). Introduction to probability. CRC Press.\n\n\nChan, J. C. C., & Kroese, D. P. (2025). Statistical Modeling and Computation (2ª ed.). Springer.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Covarianza e correlazione</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_intro_distributions.html",
    "href": "chapters/probability/12_intro_distributions.html",
    "title": "13  Introduzione alle distribuzioni di probabilità",
    "section": "",
    "text": "Introduzione\nLe distribuzioni di probabilità – discrete (a massa) e continue (a densità) – rappresentano un pilastro dell’analisi quantitativa. Strumenti come la distribuzione normale o binomiale non sono semplici modelli teorici, ma strutture matematiche che permettono di decodificare fenomeni dominati dalla variabilità. In psicologia, disciplina focalizzata sulla comprensione della mente e del comportamento, potrebbe apparire paradossale ricorrere a questi strumenti che sembrano lontani dai fenomeni oggetti del nostro interesse. Tuttavia, è proprio l’intrinseca variabilità dei processi psicologici a renderli indispensabili: senza modelli in grado di mappare e interpretare la variabilità, ogni generalizzazione rischia di ridursi a un’approssimazione inefficace.\nQuesta riflessione è ben espressa in un recente articolo di Segal et al. (2025) sui disturbi mentali. L’autore osserva come i limiti nella comprensione della loro eziologia derivino dalla sottovalutazione della variabilità. Storicamente, la ricerca in psichiatria e psicologia ha confrontato gruppi clinici con controlli sani, identificando marcatori medi (biologici o comportamentali) come tratti distintivi. Sebbene utile, questo approccio trascura un dato fondamentale: i disturbi psichiatrici, come gran parte dei fenomeni psicologici, sono caratterizzati da un’eterogeneità interindividuale estrema, incompatibile con modelli basati su medie di gruppo.\nLa variabilità, dunque, non è un “rumore di fondo” da eliminare, ma un elemento informativo cruciale. Integrare questa prospettiva richiede non solo strumenti statistici avanzati, ma una riconfigurazione metodologica che ponga la diversità individuale al centro dell’indagine.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Introduzione alle distribuzioni di probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_intro_distributions.html#introduzione",
    "href": "chapters/probability/12_intro_distributions.html#introduzione",
    "title": "13  Introduzione alle distribuzioni di probabilità",
    "section": "",
    "text": "Prerequisiti\n\n\n\n\n\n\nLeggere l’articolo Embracing variability in the search for biological mechanisms of psychiatric illness (Segal et al., 2025).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Introduzione alle distribuzioni di probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_intro_distributions.html#la-variabilità-come-fattore-costitutivo-dei-disturbi-mentali",
    "href": "chapters/probability/12_intro_distributions.html#la-variabilità-come-fattore-costitutivo-dei-disturbi-mentali",
    "title": "13  Introduzione alle distribuzioni di probabilità",
    "section": "13.1 La variabilità come fattore costitutivo dei disturbi mentali",
    "text": "13.1 La variabilità come fattore costitutivo dei disturbi mentali\nI disturbi psichiatrici sfuggono a definizioni rigide. Persone con la stessa diagnosi mostrano profili sintomatologici radicalmente diversi: ad esempio, nel disturbo da stress post-traumatico si osservano oltre 636,000 possibili combinazioni di sintomi, mentre nella depressione più di 16,000. Uno studio discusso da Segal et al. (2025) rivela che meno del 50% dei pazienti depressi presenta un’unica configurazione di sintomi. Questa variabilità si estende all’età di esordio, alla gravità, alla durata e alla dinamica temporale dei sintomi.\nUn singolo sintomo può inoltre comparire in più disturbi, spiegando i tassi elevati di comorbilità: circa il 50% dei pazienti soddisfa criteri diagnostici multipli. Questa sovrapposizione suggerisce che i disturbi non siano entità discrete, ma manifestazioni diverse di meccanismi psicopatologici condivisi. Non a caso, il 37% dei sintomi presenti nel DSM-5 non è specifico di un singolo disturbo e, complessivamente, rappresenta il 72% di tutti i sintomi inclusi nei criteri diagnostici, evidenziando una significativa mancanza di specificità sintomatologica.\nFocalizzarsi sulle medie di gruppo, tuttavia, rischia di occultare questa complessità, producendo risultati inconsistenti. Come osservato da Thomas Insel nel riepilogare il suo mandato alla guida dei National Institutes of Mental Health (NIMH) degli Stati Uniti, nonostante i consistenti investimenti in neuroscienze e genetica, i progressi nella riduzione dei suicidi, nella diminuzione dei ricoveri e nel miglioramento delle prognosi sono stati limitati.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Introduzione alle distribuzioni di probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_intro_distributions.html#verso-un-cambiamento-di-prospettiva",
    "href": "chapters/probability/12_intro_distributions.html#verso-un-cambiamento-di-prospettiva",
    "title": "13  Introduzione alle distribuzioni di probabilità",
    "section": "13.2 Verso un cambiamento di prospettiva",
    "text": "13.2 Verso un cambiamento di prospettiva\nPer superare queste criticità, secondo Segal et al. (2025), è necessario riconoscere la variabilità come proprietà costitutiva dei fenomeni psicologici. Ciò implica:\n\nAdottare approcci analitici che quantifichino la variabilità biologica e comportamentale a livello individuale, anziché di gruppo.\n\nUtilizzare modelli normativi per identificare deviazioni significative dalle traiettorie attese, anziché classificare soggetti in categorie rigide.\n\nAbbandonare l’idea di causalità univoca: una singola regione cerebrale può contribuire a sintomi multipli, così come meccanismi eterogenei possono generare lo stesso disturbo.\n\nAdottare framework dimensionali come l’HiTOP (Hierarchical Taxonomy of Psychopathology), che organizza i sintomi in dimensioni gerarchiche, massimizzando la cattura della variabilità fenotipica.\n\nIn questo contesto, le distribuzioni di probabilità diventano alleati indispensabili. Consentono di modellare la dispersione dei dati, identificare outlier e mappare traiettorie individuali, trasformando la variabilità da “problema” a “chiave interpretativa”. Analizzare la distribuzione di sintomi, tratti o risposte comportamentali permette di superare le medie di gruppo, consentendoci una migliore comprensione dei fenomeni psicologici.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Introduzione alle distribuzioni di probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_intro_distributions.html#riflessioni-conclusive",
    "href": "chapters/probability/12_intro_distributions.html#riflessioni-conclusive",
    "title": "13  Introduzione alle distribuzioni di probabilità",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nLa teoria della probabilità offre gli strumenti concettuali per navigare la complessità dei dati psicologici. Come sottolineato da Segal et al. (2025), solo integrando sistematicamente la variabilità nell’analisi empirica è possibile sviluppare modelli predittivi robusti e interventi terapeutici mirati. La sfida non è eliminare l’incertezza, ma rendere conto della variabilità attraverso modelli che riflettano la complessità dei fenomeni psicologici.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Introduzione alle distribuzioni di probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_intro_distributions.html#bibliografia",
    "href": "chapters/probability/12_intro_distributions.html#bibliografia",
    "title": "13  Introduzione alle distribuzioni di probabilità",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nSegal, A., Tiego, J., Parkes, L., Holmes, A. J., Marquand, A. F., & Fornito, A. (2025). Embracing variability in the search for biological mechanisms of psychiatric illness. Trends in Cognitive Sciences, 29(1), 85–99.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Introduzione alle distribuzioni di probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_discr_rv_distr.html",
    "href": "chapters/probability/13_discr_rv_distr.html",
    "title": "14  Distribuzioni di v.c. discrete",
    "section": "",
    "text": "14.1 Introduzione\nÈ importante distinguere tra variabili casuali discrete e continue, perché le distribuzioni di probabilità associate sono molto diverse nei due casi si veda il 7.\nIn questo capitolo ci focalizzeremo sulle distribuzioni di probabilità discrete, strumenti fondamentali per modellare fenomeni aleatori che generano un numero finito o numerabile di possibili esiti. Queste distribuzioni risultano particolarmente efficaci per descrivere eventi che si verificano in contesti discreti, come il numero di successi in un esperimento, l’occorrenza di un evento, o la selezione casuale da un insieme di opzioni finite.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_discr_rv_distr.html#introduzione",
    "href": "chapters/probability/13_discr_rv_distr.html#introduzione",
    "title": "14  Distribuzioni di v.c. discrete",
    "section": "",
    "text": "14.1.1 Panoramica delle Distribuzioni Discrete\nDi seguito, vengono presentate alcune delle principali distribuzioni discrete utilizzate in statistica e nella ricerca psicologica Ogni distribuzione è descritta in termini di caratteristiche fondamentali, applicazioni pratiche e importanza teorica.\n\n14.1.1.1 Distribuzione Uniforme Discreta\n\n\nDescrizione: La distribuzione uniforme discreta rappresenta situazioni in cui tutti gli eventi all’interno di un insieme finito hanno la stessa probabilità di verificarsi.\n\nApplicazioni: Si applica in contesti di scelta casuale equiprobabile, come:\n\nLa selezione casuale di uno stimolo da una lista di parole in un esperimento di memoria.\nL’assegnazione casuale di partecipanti a gruppi sperimentali in uno studio di psicologia sociale.\nLa scelta di un’immagine tra un insieme di stimoli visivi in una ricerca sull’attenzione.\nLa probabilità uniforme che un partecipante scelga una delle opzioni in un questionario a risposte multiple, in assenza di preferenze o conoscenze specifiche.\n\n\n\nParametri:\n\nIntervallo di supporto: l’insieme finito di valori possibili (ad esempio, \\(\\{1, 2, \\dots, k\\}\\)).\n\n\n\nImportanza: Funziona come modello di riferimento in situazioni di massima incertezza o mancanza di preferenze. È utile per definire un punto di partenza in analisi più complesse e per studiare comportamenti casuali.\n\n14.1.1.2 Distribuzione di Bernoulli\n\n\nDescrizione: La distribuzione di Bernoulli modella esperimenti con due possibili esiti, generalmente etichettati come “successo” (con probabilità \\(p\\)) e “fallimento” (con probabilità \\(1-p\\)).\n\nApplicazioni: Si applica a situazioni binarie, come il lancio di una moneta (testa/croce), la risposta a domande dicotomiche (sì/no), o l’esito di un evento che può verificarsi o meno.\n\nParametro:\n\n\n\\(p\\): probabilità di successo.\n\n\n\nImportanza: Costituisce la base per molte altre distribuzioni discrete, come la distribuzione binomiale e geometrica. È fondamentale per comprendere fenomeni con esiti dichotomici.\n\n14.1.1.3 Distribuzione Binomiale\n\n\nDescrizione: La distribuzione binomiale descrive il numero totale di successi in un numero fisso \\(n\\) di prove indipendenti, ciascuna governata da una distribuzione di Bernoulli con probabilità di successo \\(p\\).\n\nApplicazioni: Viene utilizzata per analizzare processi ripetuti con esiti binari, ad esempio:\n\nIl numero di voti favorevoli in un campione di opinione.\nIl numero di sintomi osservati in un gruppo di pazienti.\nIl conteggio di errori in un test di accuratezza.\n\n\n\nParametri:\n\n\n\\(n\\): numero di prove.\n\n\\(p\\): probabilità di successo in ogni prova.\n\n\n\nImportanza: Fornisce uno strumento essenziale per modellare fenomeni ripetuti in condizioni identiche, consentendo analisi probabilistiche avanzate e previsioni statistiche.\n\n14.1.1.4 Distribuzione di Poisson\n\n\nDescrizione: La distribuzione di Poisson modella il numero di eventi che si verificano in un intervallo fissato di tempo o spazio, quando tali eventi sono rari, indipendenti e accadono a un tasso medio costante \\(\\lambda\\).\n\nApplicazioni: Trova impiego in contesti dove gli eventi sono sporadici ma prevedibili, ad esempio:\n\nIl numero di episodi di ansia riportati in una settimana.\nIl numero di interazioni sociali spontanee di un bambino con disturbo dello spettro autistico durante una sessione di osservazione.\nLa frequenza di lapsus verbali durante una presentazione pubblica.\nIl numero di sogni vividi riportati durante una serie di notti consecutive in uno studio sul sonno.\n\n\n\nParametro:\n\n\n\\(\\lambda\\): tasso medio di eventi per unità di tempo o spazio.\n\n\n\nImportanza: È cruciale per analizzare fenomeni psicologici o comportamentali rari ma significativi. Aiuta a comprendere i meccanismi sottostanti e a modellare la variabilità osservata in contesti clinici, sperimentali o quotidiani.\n\nIn conclusione, le distribuzioni discrete sopra descritte rappresentano strumenti fondamentali per modellare una vasta gamma di fenomeni osservati in ambito scientifico, psicologico e applicativo. Ciascuna distribuzione offre una cornice teorica ben definita per interpretare e analizzare situazioni caratterizzate da variabili aleatorie discrete, fornendo così le basi per inferenze statistiche robuste e previsioni quantitative affidabili.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_discr_rv_distr.html#distribuzioni-in-r",
    "href": "chapters/probability/13_discr_rv_distr.html#distribuzioni-in-r",
    "title": "14  Distribuzioni di v.c. discrete",
    "section": "\n14.2 Distribuzioni in R",
    "text": "14.2 Distribuzioni in R\nIn R, per ogni distribuzione sono disponibili quattro funzioni principali, i cui nomi iniziano con le lettere:\n\n\nd (density): per calcolare i valori teorici relativi alla distribuzione,\n\n\np (probability): per ottenere la probabilità cumulativa,\n\n\nq (quantile): per determinare i quantili,\n\n\nr (random): per generare campioni casuali.\n\nIl pacchetto di base stats include numerose funzioni dedicate alle principali distribuzioni statistiche, permettendo di calcolare valori teorici e simulare dati in modo semplice e flessibile. Per ulteriori dettagli sulle distribuzioni disponibili e sull’uso delle relative funzioni, è possibile consultare la documentazione con il comando ?Distributions.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_discr_rv_distr.html#distribuzione-uniforme-discreta-1",
    "href": "chapters/probability/13_discr_rv_distr.html#distribuzione-uniforme-discreta-1",
    "title": "14  Distribuzioni di v.c. discrete",
    "section": "\n14.3 Distribuzione Uniforme Discreta",
    "text": "14.3 Distribuzione Uniforme Discreta\nLa distribuzione uniforme discreta è una delle più semplici e intuitive distribuzioni di probabilità. È utilizzata per modellare situazioni in cui tutti gli esiti possibili sono ugualmente probabili. Si applica, ad esempio, quando si estrae un numero a caso da un insieme finito di interi senza alcuna preferenza.\n\nDefinizione 14.1 Sia \\(X\\) una variabile casuale che può assumere i valori interi da 1 a \\(N\\), tutti con la stessa probabilità. Allora diciamo che \\(X\\) ha una distribuzione uniforme discreta sull’intervallo \\(\\{1, 2, \\dots, N\\}\\). In simboli:\n\\[\nX \\sim \\text{Uniforme Discreta}(1, N) .\n\\]\nPoiché ci sono \\(N\\) valori possibili e ciascuno ha la stessa probabilità, ogni valore ha probabilità:\n\\[\nP(X = x) = \\frac{1}{N}, \\quad \\text{per } x \\in \\{1, 2, \\dots, N\\}.\n\\]\n\n\n14.3.1 Proprietà di normalizzazione\nLa somma delle probabilità di tutti gli esiti deve essere pari a 1:\n\\[\n\\sum_{x = 1}^{N} P(X = x) = \\sum_{x = 1}^{N} \\frac{1}{N} = \\frac{1}{N} \\cdot N = 1.\n\\]\nQuesta è una proprietà fondamentale di ogni distribuzione di probabilità.\n\n14.3.2 Valore atteso\nIl valore atteso (o media) ci dice qual è il risultato medio atteso nel lungo periodo. Si calcola come:\n\\[\n\\mathbb{E}(X) = \\sum_{x = 1}^{N} x \\cdot P(X = x) = \\frac{1}{N} \\sum_{x = 1}^{N} x.\n\\]\nLa somma dei primi \\(N\\) numeri naturali è:\n\\[\n\\sum_{x = 1}^{N} x = \\frac{N(N + 1)}{2}.\n\\]\nQuindi:\n\\[\n\\mathbb{E}(X) = \\frac{1}{N} \\cdot \\frac{N(N + 1)}{2} = \\frac{N + 1}{2}.\n\\]\nIn conclusione, il valore atteso di una variabile uniforme discreta su \\(\\{1, \\dots, N\\}\\) è \\(\\frac{N + 1}{2}\\).\n\n14.3.3 Varianza\nLa varianza della distribuzione uniforme discreta è:\n\\[\n\\mathbb{V}(X) = \\frac{(N + 1)(N - 1)}{12}.\n\\]\n\n\n\n\n\n\nDimostrazione\n\n\n\n\n\nLa varianza misura quanto i valori di \\(X\\) si discostano in media dalla media \\(\\mathbb{E}(X)\\). Si calcola come:\n\\[\n\\mathbb{V}(X) = \\mathbb{E}(X^2) - \\left[\\mathbb{E}(X)\\right]^2.\n\\]\n\nCalcolo di \\(\\mathbb{E}(X^2)\\).\n\nPoiché tutti i valori hanno la stessa probabilità \\(\\frac{1}{N}\\), otteniamo:\n\\[\n\\mathbb{E}(X^2) = \\frac{1}{N} \\sum_{x = 1}^{N} x^2.\n\\]\nLa somma dei quadrati dei primi \\(N\\) interi è:\n\\[\n\\sum_{x = 1}^{N} x^2 = \\frac{N(N + 1)(2N + 1)}{6}\n\\]\n(per una dimostrazione, si veda la pagina di Wikipedia sui numeri piramidali quadrati).\nQuindi:\n\\[\n\\mathbb{E}(X^2) = \\frac{1}{N} \\cdot \\frac{N(N + 1)(2N + 1)}{6} = \\frac{(N + 1)(2N + 1)}{6}.\n\\]\n\nCalcolo della varianza.\n\nSostituendo nella formula della varianza:\n\\[\n\\begin{aligned}\n\\mathbb{V}(X) &= \\frac{(N + 1)(2N + 1)}{6} - \\left(\\frac{N + 1}{2}\\right)^2 \\\\\n&= \\frac{(N + 1)(2N + 1)}{6} - \\frac{(N + 1)^2}{4}\n\\end{aligned}\n\\]\nPer semplificare, portiamo tutto allo stesso denominatore:\n\\[\n\\begin{aligned}\n\\mathbb{V}(X) &= \\frac{2(N + 1)(2N + 1)}{12} - \\frac{3(N + 1)^2}{12} \\\\\n&= \\frac{(N + 1) \\left[2(2N + 1) - 3(N + 1)\\right]}{12} \\\\\n&= \\frac{(N + 1)(4N + 2 - 3N - 3)}{12} \\\\\n&= \\frac{(N + 1)(N - 1)}{12}.\n\\end{aligned}\n\\]\nIn conclusione, la varianza della distribuzione uniforme discreta è:\n\\[\n\\mathbb{V}(X) = \\frac{(N + 1)(N - 1)}{12}.\n\\]\n\n\n\nIn sintesi, per una variabile casuale \\(X\\) uniformemente distribuita su \\(\\{1, 2, \\dots, N\\}\\):\n\n\nProprietà\nFormula\n\n\n\nMedia\n\\(\\mathbb{E}(X) = \\dfrac{N + 1}{2}\\)\n\n\nVarianza\n\\(\\mathbb{V}(X) = \\dfrac{(N + 1)(N - 1)}{12}\\)\n\n\n\nQuesta distribuzione è utile ogni volta che non c’è alcuna ragione per preferire un valore a un altro all’interno di un insieme finito di numeri interi.\n\nEsempio 14.1 Supponiamo che \\(X\\) sia una variabile casuale con distribuzione uniforme discreta tra 1 e 10, ovvero:\n\\[\nX \\sim \\text{Uniforme Discreta}(1, 10) .\n\\]\nVogliamo:\n\ngenerare un grande campione casuale,\ncalcolare la media e la varianza osservate,\nconfrontarle con i valori teorici.\n\nCodice R.\n\nset.seed(123)  # Per rendere la simulazione riproducibile\n\n# Parametro N\nN &lt;- 10\n\n# Simulazione: 100.000 osservazioni dalla distribuzione uniforme discreta\nx &lt;- sample(1:N, size = 100000, replace = TRUE)\n\n# Media e varianza empiriche\nmedia_empirica &lt;- mean(x)\nvarianza_empirica &lt;- var(x)\n\n# Valori teorici\nmedia_teorica &lt;- (N + 1) / 2\nvarianza_teorica &lt;- ((N + 1) * (N - 1)) / 12\n\n# Risultati\ntibble(\n  `Media empirica` = media_empirica,\n  `Media teorica` = media_teorica,\n  `Varianza empirica` = varianza_empirica,\n  `Varianza teorica` = varianza_teorica\n)\n#&gt; # A tibble: 1 × 4\n#&gt;   `Media empirica` `Media teorica` `Varianza empirica` `Varianza teorica`\n#&gt;              &lt;dbl&gt;           &lt;dbl&gt;               &lt;dbl&gt;              &lt;dbl&gt;\n#&gt; 1             5.51             5.5                8.26               8.25\n\nCon un campione molto grande, le statistiche empiriche (cioè calcolate dai dati simulati) saranno molto vicine ai valori teorici:\n\n\n\nValore\n\n\n\nMedia teorica\n5.5\n\n\nMedia empirica\n≈ 5.5\n\n\nVarianza teorica\n8.25\n\n\nVarianza empirica\n≈ 8.25\n\n\n\n\nIn sintesi, a simulazione conferma che:\n\nla media empirica converge verso \\(\\mathbb{E}(X) = \\frac{N + 1}{2}\\),\nla varianza empirica converge verso \\(\\mathbb{V}(X) = \\frac{(N + 1)(N - 1)}{12}\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_discr_rv_distr.html#distribuzione-di-bernoulli-1",
    "href": "chapters/probability/13_discr_rv_distr.html#distribuzione-di-bernoulli-1",
    "title": "14  Distribuzioni di v.c. discrete",
    "section": "\n14.4 Distribuzione di Bernoulli",
    "text": "14.4 Distribuzione di Bernoulli\nIn statistica, un esperimento che ammette solo due esiti possibili è modellato attraverso quella che viene chiamata “prova Bernoulliana”. Un esempio tipico è il lancio di una moneta, che può dare come risultato testa o croce.\n\nDefinizione 14.2 Una variabile casuale \\(X\\) che assume valori in \\(\\{0, 1\\}\\) è detta variabile di Bernoulli. La sua distribuzione di probabilità è definita come:\n\\[\nP(X \\mid \\theta) =\n  \\begin{cases}\n    p     & \\text{se $X = 1$ (successo)}, \\\\\n    1 - p & \\text{se $X = 0$ (insuccesso)},\n  \\end{cases}\n\\]\ndove \\(0 \\leq p \\leq 1\\). Il parametro \\(p\\) rappresenta la probabilità del “successo” (\\(X = 1\\)), mentre \\(1 - p\\) è la probabilità dell’“insuccesso” (\\(X = 0\\)).\n\nLa distribuzione di Bernoulli descrive quindi un contesto in cui la probabilità di osservare l’esito 1 è \\(p\\) e quella di osservare l’esito 0 è \\(1 - p\\). Viene utilizzata per modellare situazioni binarie, come una risposta “sì” o “no”, oppure un “successo” o “insuccesso”.\nCalcolando il valore atteso e la varianza, otteniamo:\n\\[\n\\begin{aligned}\n\\mathbb{E}(X) &= 0 \\cdot P(X=0) + 1 \\cdot P(X=1) = p, \\\\\n\\mathbb{V}(X) &= (0 - p)^2 \\cdot P(X=0) + (1 - p)^2 \\cdot P(X=1) = p(1-p).\n\\end{aligned}\n\\tag{14.1}\\]\n\n\n\n\n\n\nDimostrazione\n\n\n\nEsaminiamo la dimostrazione algebrica del calcolo della varianza.\nEspandiamo il calcolo della somma, considerando i due possibili valori di \\(X\\) (0 e 1).\n\n\nPrimo termine (\\(X = 0\\)):\n\\[\n(0 - \\mathbb{E}(X))^2 \\cdot P(X = 0) = (0 - p)^2 \\cdot (1 - p).\n\\]\nSemplificando \\((0 - p)^2 = p^2\\), quindi:\n\\[\n(0 - \\mathbb{E}(X))^2 \\cdot P(X = 0) = p^2 \\cdot (1 - p).\n\\]\n\n\nSecondo termine (\\(X = 1\\)):\n\\[\n(1 - \\mathbb{E}(X))^2 \\cdot P(X = 1) = (1 - p)^2 \\cdot p.\n\\]\nSemplificando \\((1 - p)^2 = 1 - 2p + p^2\\), quindi:\n\\[\n(1 - \\mathbb{E}(X))^2 \\cdot P(X = 1) = (1 - 2p + p^2) \\cdot p = p - 2p^2 + p^3.\n\\]\n\n\nSomma dei termini\nOra sommiamo i due contributi:\n\\[\n\\mathbb{V}(X) = p^2 \\cdot (1 - p) + (p - 2p^2 + p^3).\n\\]\nEspandendo il primo termine:\n\\[\np^2 \\cdot (1 - p) = p^2 - p^3.\n\\]\nSomma completa:\n\\[\n\\mathbb{V}(X) = (p^2 - p^3) + (p - 2p^2 + p^3).\n\\]\n\n\nRaggruppiamo i termini\n\\[\n\\mathbb{V}(X) = p - p^2.\n\\]\nRisultato finale:\n\\[\n\\mathbb{V}(X) = p(1 - p).\n\\]\n\n\nIn sintesi, la varianza di una variabile aleatoria binaria \\(X\\), distribuita secondo Bernoulli con parametro \\(p\\), è data da \\(p(1-p)\\).\n\n\nTale risultato mostra come la varianza massima si ottenga per \\(p = 0.5\\), condizione che corrisponde alla massima incertezza intrinseca nel processo, ossia quando la probabilità di successo eguaglia quella di insuccesso.\n\n# Valori di p tra 0 e 1\np &lt;- seq(0, 1, length.out = 100)\nvariance &lt;- p * (1 - p)\ndata &lt;- data.frame(p = p, Variance = variance)\n\n# Creazione del grafico\nggplot(data, aes(x = p, y = Variance)) +\n  geom_line(linewidth = 1.2) +\n  labs(\n    x = expression(p),\n    y = \"Varianza\"\n  )\n\n\n\n\n\n\n\n\n14.4.1 Notazione\nPer indicare che la variabile casuale \\(X\\) segue una distribuzione Bernoulliana di parametro \\(p\\) Utilizziamo la notazione \\(X \\sim \\mathcal{Bern}(p)\\), o in maniera equivalente \\(\\mathcal{Bern}(X \\mid p)\\).\n\nEsempio 14.2 Nel caso del lancio di una moneta equilibrata, la variabile di Bernoulli assume i valori \\(0\\) e \\(1\\) con uguale probabilità di \\(\\frac{1}{2}\\). Pertanto, la funzione di massa di probabilità assegna una probabilità di \\(\\frac{1}{2}\\) sia per \\(X = 0\\) che per \\(X = 1\\), mentre la funzione di distribuzione cumulativa risulta essere \\(\\frac{1}{2}\\) per \\(X = 0\\) e \\(1\\) per \\(X = 1\\).\nGeneriamo dei valori casuali dalla distribuzione di Bernoulli. Iniziamo con un singolo valore:\n\n# Probabilità di successo\np &lt;- 0.5\n\n# Genera un singolo valore\nbernoulli_sample &lt;- rbinom(n = 1, size = 1, prob = p)\nprint(bernoulli_sample)\n#&gt; [1] 0\n\n# Genera un campione di 10 valori\nbernoulli_sample &lt;- rbinom(n = 10, size = 1, prob = p)\nprint(bernoulli_sample)\n#&gt;  [1] 0 1 0 1 0 0 0 1 0 0",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_discr_rv_distr.html#distribuzione-binomiale-1",
    "href": "chapters/probability/13_discr_rv_distr.html#distribuzione-binomiale-1",
    "title": "14  Distribuzioni di v.c. discrete",
    "section": "\n14.5 Distribuzione Binomiale",
    "text": "14.5 Distribuzione Binomiale\nLa distribuzione binomiale è una distribuzione di probabilità discreta che modella il numero di successi \\(y\\) in un numero fissato \\(n\\) di prove di Bernoulli indipendenti e identiche, dove ciascuna prova ha solo due esiti possibili: “successo” (rappresentato da “1”) con probabilità \\(p\\) o “insuccesso” (rappresentato da “0”) con probabilità \\(1 - p\\). La notazione utilizzata è la seguente:\n\\[\nY \\sim \\mathcal{Binom}(n, p).\n\\]\n\nDefinizione 14.3 La distribuzione binomiale descrive la probabilità di osservare esattamente \\(y\\) successi in \\(n\\) prove di Bernoulli indipendenti:\n\\[\nP(Y = y) = \\binom{n}{y} p^{y} (1 - p)^{n - y} = \\frac{n!}{y!(n - y)!} p^{y} (1 - p)^{n - y},\n\\tag{14.2}\\]\ndove \\(\\binom{n}{y}\\), noto come coefficiente binomiale, rappresenta il numero di modi possibili per ottenere \\(y\\) successi in \\(n\\) prove, e \\(p\\) è la probabilità di successo in ciascuna prova.\n\nLa distribuzione binomiale si presta bene a esempi classici come il lancio ripetuto di una moneta o l’estrazione di biglie da un’urna. Ad esempio, nel caso del lancio di una moneta, questa distribuzione descrive la probabilità di ottenere un determinato numero di “teste” in un certo numero di lanci, con ogni lancio che segue una distribuzione di Bernoulli con probabilità di successo \\(p\\).\nUna caratteristica interessante della distribuzione binomiale è la sua proprietà di riproducibilità: se due variabili casuali indipendenti, \\(y_1\\) e \\(y_2\\), seguono entrambe distribuzioni binomiali con lo stesso parametro \\(p\\), ma con un diverso numero di prove (\\(n_1\\) e \\(n_2\\)), la loro somma, \\(y = y_1 + y_2\\), sarà ancora distribuita binomialmente, con parametri \\(n_1 + n_2\\) e \\(p\\).\n\n\n\n\n\n\nDimostrazione\n\n\n\nPer chiarire il calcolo delle probabilità nella distribuzione binomiale, consideriamo una serie di prove di Bernoulli. Supponiamo di avere \\(n\\) prove indipendenti, ciascuna con probabilità \\(p\\) di successo, e di osservare esattamente \\(y\\) successi.\nUna possibile configurazione dei risultati può essere rappresentata come:\n\\[\n\\overbrace{SS\\dots S}^\\text{$y$ successi} \\, \\overbrace{II\\dots I}^\\text{$n - y$ insuccessi}\n\\]\nLa probabilità di ottenere esattamente \\(y\\) successi in una sequenza specifica (cioè in un ordine fissato) è:\n\\[\np^y \\cdot (1 - p)^{n - y},\n\\]\ndove \\(p^y\\) è la probabilità dei \\(y\\) successi e \\((1 - p)^{n - y}\\) quella dei \\(n - y\\) insuccessi.\nTuttavia, ciò che ci interessa è la probabilità complessiva di ottenere \\(y\\) successi in qualsiasi ordine. In altre parole, vogliamo calcolare la probabilità dell’unione di tutte le possibili sequenze di \\(n\\) prove che contengono esattamente \\(y\\) successi.\nIl numero di tali sequenze è dato dal coefficiente binomiale \\(\\binom{n}{y}\\), che rappresenta il numero di modi diversi in cui possiamo scegliere le \\(y\\) posizioni dei successi tra le \\(n\\) prove.\nMoltiplicando la probabilità di una singola sequenza per il numero totale di sequenze possibili, otteniamo la funzione di probabilità della distribuzione binomiale:\n\\[\nP(Y = y) = \\binom{n}{y} p^y (1 - p)^{n - y}.\n\\]\n\n\n\n14.5.1 Caso particolare \\(n = 1\\)\n\nOra consideriamo il caso particolare in cui \\(n = 1\\). Quando \\(n = 1\\), il coefficiente binomiale diventa:\n\\[\n\\binom{1}{y} = \\frac{1!}{y! (1-y)!}.\n\\]\nEspandiamo i fattoriali per i due possibili valori di \\(y\\), che può assumere solo 0 o 1 (poiché \\(y \\in \\{0, 1, \\dots, n\\}\\)).\nCaso 1: \\(y = 0\\)\n\\[\n\\binom{1}{0} = \\frac{1!}{0! (1-0)!} = \\frac{1}{1 \\cdot 1} = 1.\n\\]\nQuindi, per \\(y = 0\\): \\[\nP(Y = 0) = \\binom{1}{0} p^0 (1-p)^{1-0} = 1 \\cdot 1 \\cdot (1-p) = 1-p.\n\\]\nCaso 2: \\(y = 1\\)\n\\[\n\\binom{1}{1} = \\frac{1!}{1! (1-1)!} = \\frac{1}{1 \\cdot 1} = 1.\n\\]\nQuindi, per \\(y = 1\\): \\[\nP(Y = 1) = \\binom{1}{1} p^1 (1-p)^{1-1} = 1 \\cdot p \\cdot 1 = p.\n\\]\nIn conclusione, la PMF per la distribuzione binomiale con \\(n = 1\\) diventa:\n\\[\nP(Y = y) =\n\\begin{cases}\n1-p, & \\text{se } y = 0, \\\\\np, & \\text{se } y = 1.\n\\end{cases}\n\\]\nQuesta è esattamente la PMF della distribuzione di Bernoulli con parametro \\(p\\):\n\\[\nP(Y = y) = p^y (1-p)^{1-y}, \\quad y \\in \\{0, 1\\}.\n\\]\nPertanto, la distribuzione binomiale con \\(n = 1\\) è equivalente alla distribuzione di Bernoulli con parametro \\(p\\).\n\n14.5.2 Applicazioni Pratiche della Distribuzione Binomiale\nPer illustrare l’applicazione della distribuzione binomiale, consideriamo un esempio semplice. Supponiamo di osservare 2 successi su 4 prove di Bernoulli, dove la probabilità di successo in ogni prova è \\(p = 0.2\\). La probabilità di ottenere esattamente questo risultato si calcola con la formula:\n\\[\nP(Y = 2) = \\binom{4}{2} \\cdot 0.2^2 \\cdot (1 - 0.2)^{2} = 0.1536.\n\\]\nIn R, questo calcolo si può fare in modo diretto:\n\n# Parametri\nn &lt;- 4\np &lt;- 0.2\ny &lt;- 2\n\n# Calcolo della probabilità esatta\nprob &lt;- choose(n, y) * p^y * (1 - p)^(n - y)\nprint(prob)\n#&gt; [1] 0.154\n\nIn alternativa, possiamo usare la funzione dbinom() per ottenere la stessa probabilità:\n\nprob &lt;- dbinom(x = y, size = n, prob = p)\nprint(prob)\n#&gt; [1] 0.154\n\n\n14.5.2.1 Visualizzazione della distribuzione di probabilità\nPossiamo rappresentare graficamente la distribuzione di massa di probabilità per tutti i possibili valori di \\(y\\) da \\(0\\) a \\(n\\):\n\ny &lt;- 0:n\nprobabilities &lt;- dbinom(y, size = n, prob = p)\n\ndf &lt;- data.frame(Successi = y, Probabilità = probabilities)\n\ndf |&gt;\n  ggplot(aes(x = Successi, y = Probabilità)) +\n    geom_segment(\n      aes(xend = Successi, yend = 0), lwd = 1.2\n      ) +\n    geom_point(size = 3) +\n    labs(\n      x = \"Numero di successi y\",\n      y = \"Probabilità\"\n    )\n\n\n\n\n\n\n\n\n14.5.2.2 Generazione di un campione casuale\nLa funzione rbinom() permette di generare un campione casuale da una distribuzione binomiale:\n\nset.seed(42)\nsamples &lt;- rbinom(n = 30, size = 5, prob = 0.5)\nprint(samples)\n#&gt;  [1] 4 4 2 4 3 3 3 1 3 3 2 3 4 2 2 4 5 1 2 3 4 1 5 4 1 3 2 4 2 4\n\n\n14.5.2.3 Variazione della distribuzione al variare di \\(p\\)\n\nPer esplorare l’effetto di diversi valori di \\(p\\) sulla forma della distribuzione, possiamo visualizzare più curve binomiali per \\(n = 20\\) e \\(p\\) variabile:\n\nn &lt;- 20\np_values &lt;- seq(0.3, 0.9, by = 0.3)\ny &lt;- 0:25\n\ndf &lt;- data.frame()\n\nfor (p in p_values) {\n  binom_dist &lt;- dbinom(y, size = n, prob = p)\n  df &lt;- rbind(df, data.frame(y = y, Prob = binom_dist, p = factor(p)))\n}\n\ndf |&gt;\n  ggplot(aes(x = y, y = Prob, color = p)) +\n    geom_point() +\n    geom_line() +\n    labs(\n      x = \"Numero di successi y\",\n      y = \"Probabilità\",\n      color = expression(p)\n    )\n\n\n\n\n\n\n\n\n14.5.2.4 Funzione di ripartizione cumulativa\nPossiamo anche rappresentare la funzione di distribuzione cumulativa (CDF) per \\(n = 5\\) e \\(p = 0.5\\):\n\nn &lt;- 5\np &lt;- 0.5\ny &lt;- 0:n\n\ncdf_values &lt;- pbinom(y, size = n, prob = p)\ndf &lt;- data.frame(y = y, cdf = cdf_values)\n\ndf |&gt;\n  ggplot(aes(x = y, y = cdf)) +\n    geom_line() +\n    geom_point() +\n    geom_hline(\n      yintercept = 1, linetype = \"dashed\", color = \"black\", alpha = 0.7\n    ) +\n    labs(\n      x = \"Numero di successi y\",\n      y = \"Probabilità cumulativa\"\n    )\n\n\n\n\n\n\n\n\nEsempio 14.3 Supponiamo di lanciare una moneta equa (cioè con probabilità \\(p = 0.5\\) di ottenere testa) 5 volte. Vogliamo calcolare la probabilità di ottenere almeno 2 teste, ovvero:\n\\[\nP(Y \\geq 2) = P(Y = 2) + P(Y = 3) + P(Y = 4) + P(Y = 5).\n\\]\nPossiamo sommare direttamente queste probabilità usando dbinom():\n\nresult &lt;- sum(dbinom(2:5, size = 5, prob = 0.5))\nprint(result)\n#&gt; [1] 0.812\n\nUn modo alternativo, più efficiente, consiste nel calcolare il complemento della probabilità di ottenere meno di 2 teste (cioè 0 o 1):\n\\[\nP(Y \\geq 2) = 1 - P(Y \\leq 1)\n\\]\nIn R, possiamo usare la funzione pbinom() per calcolare questa probabilità cumulativa:\n\nresult &lt;- 1 - pbinom(q = 1, size = 5, prob = 0.5)\nprint(result)\n#&gt; [1] 0.812\n\nEntrambi i metodi restituiscono lo stesso risultato numerico, ma il secondo è spesso preferibile quando \\(n\\) è grande o quando si vuole calcolare una probabilità di coda.\n\n\n14.5.2.5 Quantili di una distribuzione binomiale\nHai perfettamente ragione — grazie per l’osservazione!\nInfatti, con i parametri size = 5, prob = 0.5 e target_probability = 0.60, la funzione qbinom() restituisce 3, non 2. Questo perché qbinom() restituisce il più piccolo valore di \\(y\\) tale che \\(P(Y \\leq y) \\geq p\\). Verifichiamolo in R:\npbinom(2, 5, 0.5)  # = 0.5\npbinom(3, 5, 0.5)  # = 0.8125\nQuindi:\n\n\n\\(P(Y \\leq 2) = 0.5\\) → troppo poco\n\n\\(P(Y \\leq 3) = 0.8125\\) → supera il 60%\n\nPertanto, qbinom(0.6, 5, 0.5) restituisce 3.\n\n14.5.2.6 Quantili di una distribuzione binomiale\nLa funzione qbinom() permette di calcolare il quantile di una distribuzione binomiale, cioè il numero minimo di successi \\(y\\) tale che la probabilità cumulativa \\(P(Y \\leq y)\\) sia maggiore o uguale a una certa soglia.\nAd esempio, supponiamo di voler sapere qual è il numero minimo di successi tale che la probabilità cumulativa sia almeno 60%. Possiamo usare:\n\n# Probabilità cumulativa desiderata\ntarget_probability &lt;- 0.60\n\n# Calcolo del quantile\nresult &lt;- qbinom(p = target_probability, size = 5, prob = 0.5)\nprint(result)\n#&gt; [1] 3\n\nIl risultato è 3, il che significa che:\n\\[\nP(Y \\leq 3) = 0.8125 \\geq 0.60,\n\\]\nmentre\n\\[\nP(Y \\leq 2) = 0.5 &lt; 0.60.\n\\]\nQuindi, servono almeno 3 successi per superare la soglia del 60% di probabilità cumulativa.\n\n🔎 qbinom(p, size, prob) restituisce il più piccolo valore di \\(y\\) tale che \\(P(Y \\leq y) \\geq p\\).\n\n\n14.5.2.7 Rappresentazione grafica del quantile\nPer visualizzare il comportamento della funzione di ripartizione cumulativa e individuare il quantile per \\(p = 0.60\\), possiamo usare il seguente codice in R:\n\n# Parametri\nn &lt;- 5\np &lt;- 0.5\ntarget_probability &lt;- 0.60\n\n# Asse y: numero di successi\ny &lt;- 0:n\n\n# Calcolo dei valori cumulativi\ncdf &lt;- pbinom(y, size = n, prob = p)\n\n# Calcolo del quantile\nq &lt;- qbinom(target_probability, size = n, prob = p)\n\n# Data frame\ndf &lt;- data.frame(Successi = y, CDF = cdf)\n\n# Grafico\ndf |&gt;\n  ggplot(aes(x = Successi, y = CDF)) +\n  geom_step(direction = \"hv\", linewidth = 1.1) +\n  geom_point(size = 2) +\n  geom_hline(\n    yintercept = target_probability, linetype = \"dashed\", color = \"red\"\n  ) +\n  geom_vline(xintercept = q, linetype = \"dotted\", color = \"blue\") +\n  annotate(\n    \"text\",\n    x = q + 0.4, y = 0.05, label = paste(\"quantile =\", q),\n    color = \"blue\"\n  ) +\n  annotate(\n    \"text\",\n    x = 0.5, y = target_probability + 0.05,\n    label = paste(\"soglia =\", target_probability), color = \"red\"\n  ) +\n  labs(\n    x = \"Numero di successi\",\n    y = \"Probabilità cumulativa\"\n  ) +\n  ylim(0, 1.05)\n\n\n\n\n\n\n\nIn questo grafico:\n\nla linea rossa tratteggiata rappresenta la soglia di probabilità desiderata (es. 0.60);\nla linea blu tratteggiata verticale indica il quantile corrispondente, cioè il più piccolo valore di \\(y\\) per cui \\(P(Y \\leq y) \\geq 0.60\\);\nil valore calcolato è 3, quindi con al massimo 3 successi, la probabilità cumulativa supera il 60%.\n\n\nEsempio 14.4 Consideriamo una distribuzione binomiale con \\(n = 10\\) prove e probabilità di successo \\(p = 0.2\\). Supponiamo di voler calcolare la probabilità di ottenere al massimo 4 successi. In termini matematici, vogliamo calcolare:\n\\[\nP(Y \\leq 4) .\n\\]\nIn R, questo si ottiene con la funzione pbinom():\n\n# Calcolo della probabilità cumulativa fino a 4 successi\np_cumulativa &lt;- pbinom(4, size = 10, prob = 0.2)\nprint(p_cumulativa)\n#&gt; [1] 0.967\n\nIl risultato indica che c’è circa l’97% di probabilità di ottenere 4 o meno successi su 10 prove, quando la probabilità di successo in ciascuna prova è 0.2.\nOra facciamo il passaggio inverso: immaginiamo di conoscere la probabilità cumulativa (per esempio, 0.97) e vogliamo sapere quanti successi bisogna considerare per raggiungere quella probabilità.\nPer questo usiamo la funzione qbinom(), che ci restituisce il più piccolo numero di successi \\(y\\) tale che \\(P(Y \\leq y) \\geq\\) quella probabilità:\n\n# Calcolo del numero di successi associato alla probabilità cumulativa\nnumero_successi &lt;- qbinom(p_cumulativa, size = 10, prob = 0.2)\nprint(numero_successi)\n#&gt; [1] 4\n\nIl valore ottenuto sarà 4, cioè il minimo numero di successi per cui la probabilità cumulativa è almeno il 97%.\nRiepilogo concetti chiave:\n\n\npbinom(y, n, p) calcola la probabilità di ottenere al massimo \\(y\\) successi;\n\nqbinom(prob, n, p) calcola il numero minimo di successi necessari per raggiungere almeno quella probabilità.\n\nIn sintesi, pbinom() e qbinom() sono strumenti complementari: pbinom ci dà la probabilità di ottenere fino a un certo numero di successi, mentre qbinom ci dice fino a quanti successi possiamo ottenere per raggiungere una certa probabilità. Nell’analisi di una distribuzione binomiale (e di molte altre distribuzioni) queste funzioni aiutano a calcolare e interpretare facilmente probabilità cumulate e quantili in R, rendendo più semplice l’analisi di eventi aleatori.\n\n\n14.5.3 Valore atteso e deviazione standard nella distribuzione binomiale\nNella distribuzione binomiale, possiamo calcolare facilmente due quantità molto importanti:\n\n\nil valore atteso (o media), che ci dice quanti successi ci aspettiamo in media su un certo numero di prove;\n\nla deviazione standard, che ci dice quanto i risultati tendono a variare attorno alla media.\n\nLe formule sono le seguenti:\n\\[\n\\text{Media (valore atteso):} \\quad \\mu = n p ,\n\\tag{14.3}\\]\n\\[\n\\text{Deviazione standard:} \\quad \\sigma = \\sqrt{n p (1 - p)} ,\n\\tag{14.4}\\]\ndove:\n\n\n\\(n\\) è il numero di prove (per esempio, il numero di lanci di una moneta),\n\n\\(p\\) è la probabilità di successo in ogni prova.\n\n\n\n\n\n\n\nDimostrazione.\nLa variabile \\(Y\\) rappresenta il numero di successi in \\(n\\) prove di Bernoulli indipendenti. Possiamo scriverla come somma di \\(n\\) variabili casuali indipendenti:\n\\[\nY = Y_1 + Y_2 + \\cdots + Y_n,\n\\]\ndove ciascuna \\(Y_i \\sim \\text{Bernoulli}(p)\\), cioè:\n\\[\nY_i =\n\\begin{cases}\n1 & \\text{con probabilità } p \\\\\n0 & \\text{con probabilità } 1 - p\n\\end{cases}\n\\]\nValore atteso di \\(Y_i\\).\nPer definizione del valore atteso:\n\\[\n\\mathbb{E}(Y_i) = 1 \\cdot p + 0 \\cdot (1 - p) = p.\n\\]\nValore atteso di \\(Y_i^2\\).\nPoiché \\(Y_i\\) assume solo i valori 0 e 1, si ha \\(Y_i^2 = Y_i\\). Quindi:\n\\[\n\\mathbb{E}(Y_i^2) = \\mathbb{E}(Y_i) = p.\n\\]\nLa varianza di una variabile casuale si definisce come:\n\\[\n\\operatorname{Var}(Y_i) = \\mathbb{E}(Y_i^2) - [\\mathbb{E}(Y_i)]^2.\n\\]\nSostituendo i valori trovati sopra:\n\\[\n\\operatorname{Var}(Y_i) = p - p^2 = p(1 - p).\n\\]\nRicordiamo che \\(Y = \\sum_{i=1}^{n} Y_i\\) e che le \\(Y_i\\) sono indipendenti. Una proprietà fondamentale della varianza è che se \\(Z_1, \\dots, Z_n\\) sono indipendenti:\n\\[\n\\operatorname{Var}(Z_1 + \\cdots + Z_n) = \\operatorname{Var}(Z_1) + \\cdots + \\operatorname{Var}(Z_n).\n\\]\nApplichiamola al nostro caso:\n\\[\n\\operatorname{Var}(Y) = \\sum_{i=1}^{n} \\operatorname{Var}(Y_i).\n\\]\nPoiché tutte le \\(Y_i\\) hanno la stessa varianza \\(p(1 - p)\\), la somma diventa:\n\\[\n\\operatorname{Var}(Y) = n \\cdot p(1 - p).\n\\]\nAbbiamo dimostrato da definizione che, se \\(Y \\sim \\text{Bin}(n, p)\\), allora:\n\\[\n\\operatorname{Var}(Y) = n \\cdot p \\cdot (1 - p).\n\\]\nQuesta formula descrive la dispersione attesa nel numero di successi su \\(n\\) prove indipendenti, ciascuna con probabilità di successo \\(p\\).\n\n\n\n\nEsempio 14.5 Supponiamo di lanciare 4 volte una moneta truccata che ha una probabilità di successo (es. ottenere testa) pari a \\(p = 0.2\\).\nVogliamo calcolare:\n\nla media attesa del numero di teste,\nla varianza,\ne la deviazione standard.\n\n\nCalcolo del valore atteso (media):\n\n\\[\n\\mu = n \\cdot p = 4 \\cdot 0.2 = 0.8 .\n\\]\nQuindi, in media, ci aspettiamo di ottenere 0.8 teste ogni 4 lanci (cioè meno di 1, ma ricordiamo che si tratta di una media).\n\nCalcolo della varianza:\n\n\\[\n\\text{Varianza} = n \\cdot p \\cdot (1 - p) = 4 \\cdot 0.2 \\cdot 0.8 = 0.64 .\n\\]\n\nCalcolo della deviazione standard:\n\n\\[\n\\sigma = \\sqrt{0.64} \\approx 0.8 .\n\\]\nLa deviazione standard ci dà un’idea della variabilità dei risultati: in questo caso, i valori osservati (numero di teste su 4 lanci) si discostano dalla media di circa 0.8 in media.\n\n\n14.5.4 Verifica con una simulazione in R\nPer vedere se i calcoli teorici dell’Esempio 14.5 funzionano anche nella pratica, possiamo simulare l’esperimento in R: lanciamo 4 monete, ma lo facciamo tantissime volte (ad esempio 1 milione) e calcoliamo la media e la varianza dei risultati ottenuti.\n\nset.seed(42)\n\n# Generiamo 1 milione di esperimenti: 4 lanci con probabilità di successo 0.2\nx &lt;- rbinom(n = 1e6, size = 4, prob = 0.2)\n\n# Calcoliamo la media empirica\nmean(x)\n#&gt; [1] 0.8\n# [1] circa 0.8\n\n# Calcoliamo la varianza empirica\nvar(x)\n#&gt; [1] 0.639\n# [1] circa 0.64\n\nCome possiamo vedere, i risultati ottenuti dalla simulazione sono molto vicini ai valori teorici: la media è circa \\(\\mu = 0.8\\) e la varianza circa \\(0.64\\), proprio come previsto dalle formule.\nQuesto non solo conferma che le formule per media e varianza nella distribuzione binomiale sono corrette, ma ci aiuta anche a capire meglio cosa significano:\n\nil valore atteso rappresenta la media dei risultati se ripetiamo l’esperimento moltissime volte;\n\nla varianza (e la sua radice quadrata, la deviazione standard) misura quanto i risultati si allontanano dalla media.\n\nLa simulazione mostra quindi in modo concreto che il valore atteso e la varianza descrivono il comportamento “medio” della variabile aleatoria, quando viene osservata in un numero molto grande di situazioni. In altre parole, questi concetti non sono solo teorici: ci dicono cosa aspettarci nella pratica, se ripetiamo molte volte lo stesso esperimento.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_discr_rv_distr.html#funzioni-r-per-le-distribuzioni-di-probabilità",
    "href": "chapters/probability/13_discr_rv_distr.html#funzioni-r-per-le-distribuzioni-di-probabilità",
    "title": "14  Distribuzioni di v.c. discrete",
    "section": "\n14.6 Funzioni R per le distribuzioni di probabilità",
    "text": "14.6 Funzioni R per le distribuzioni di probabilità\nIn R, le distribuzioni di probabilità (sia discrete che continue) sono gestite in modo sistematico. Per ogni distribuzione, esistono quattro funzioni principali, ognuna con un prefisso diverso che indica il tipo di operazione desiderata:\n\n\nd*: calcola la densità (per distribuzioni continue) o la probabilità (per distribuzioni discrete);\n\n\np*: calcola la funzione di ripartizione cumulativa (CDF), cioè \\(P(Y \\leq y)\\);\n\n\nq*: calcola la funzione quantile (inversa della CDF);\n\n\nr*: genera valori casuali secondo la distribuzione specificata.\n\nQuesta struttura è identica per tutte le distribuzioni implementate in R. La tabella seguente mostra un confronto tra le funzioni disponibili per due distribuzioni fondamentali: la binomiale (discreta) e la normale (continua).\n\n\n\n\n\n\n\nTipo di funzione\nBinomiale (\\(Y \\sim \\text{Bin}(n, p)\\))\nNormale (\\(Y \\sim \\mathcal{N}(\\mu, \\sigma)\\))\n\n\n\nDensità o probabilità esatta\ndbinom(y, size = n, prob = p)\ndnorm(y, mean = mu, sd = sigma)\n\n\n\\(P(Y = y)\\)\ndbinom(...)\n❌ Non definita: per variabili continue si usa la densità\n\n\nProbabilità cumulativa\npbinom(y, size = n, prob = p)\npnorm(y, mean = mu, sd = sigma)\n\n\n\\(P(Y \\geq y)\\)\n1 - pbinom(y - 1, ...)\n1 - pnorm(y, ...)\n\n\n\\(P(y_1 &lt; Y &lt; y_2)\\)\npbinom(y2, ...) - pbinom(y1, ...)\npnorm(y2, ...) - pnorm(y1, ...)\n\n\nQuantile (inversa della CDF)\nqbinom(q, size = n, prob = p)\nqnorm(q, mean = mu, sd = sigma)\n\n\nSimulazione di dati casuali\nrbinom(n, size = trials, prob = p)\nrnorm(n, mean = mu, sd = sigma)\n\n\n\n\n\n\n\n\n\nNota\n\n\n\n\nPer le distribuzioni discrete (come la binomiale), dbinom(y, ...) restituisce la probabilità esatta di osservare il valore \\(y\\): ad esempio, \\(P(Y = 2)\\).\nPer le distribuzioni continue (come la normale), dnorm(y, ...) restituisce la densità in \\(y\\), che non rappresenta direttamente una probabilità, ma è utile per visualizzare la forma della distribuzione.\nLe probabilità cumulative (funzioni p*) e i quantili (funzioni q*) sono sempre definiti, sia per distribuzioni discrete che continue.\nLa generazione di dati casuali con r* è molto utile per simulazioni e verifiche empiriche.\n\nPiù avanti, vedremo altre distribuzioni (Uniforme, Beta, Poisson, ecc.), tutte con lo stesso schema di funzioni: d, p, q, r.\nQuesta coerenza rende molto semplice imparare a usare le distribuzioni in R: una volta compreso lo schema, lo si può applicare a qualsiasi caso.\n\n\n\nEsempio 14.6  \n\nCalcolare la probabilità di esattamente \\(y = 3\\) successi su \\(n = 5\\) prove con \\(p = 0.5\\):\n\n\ndbinom(3, size = 5, prob = 0.5)\n#&gt; [1] 0.312\n\n\nCalcolare la probabilità cumulativa \\(P(Y \\leq 3)\\):\n\n\npbinom(3, size = 5, prob = 0.5)\n#&gt; [1] 0.812\n\n\nCalcolare il valore minimo \\(y\\) tale che \\(P(Y \\leq y) \\geq 0.9\\):\n\n\nqbinom(0.9, size = 5, prob = 0.5)\n#&gt; [1] 4\n\n\nGenerare un campione di 100 numeri casuali da una distribuzione binomiale:\n\n\nrbinom(100, size = 5, prob = 0.5)\n#&gt;   [1] 2 2 4 1 3 2 3 2 2 2 3 3 3 3 1 4 1 1 0 2 2 2 4 1 2 3 3 1 5 2 3 3 0 3 2 3 4\n#&gt;  [38] 2 3 3 3 3 1 5 3 3 2 3 1 2 1 3 3 2 2 4 1 4 2 3 1 4 2 2 3 4 1 1 4 2 3 2 3 3\n#&gt;  [75] 3 1 4 4 3 3 4 3 3 3 2 2 3 3 2 4 4 3 2 2 0 3 1 3 1 2",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_discr_rv_distr.html#distribuzione-di-poisson-1",
    "href": "chapters/probability/13_discr_rv_distr.html#distribuzione-di-poisson-1",
    "title": "14  Distribuzioni di v.c. discrete",
    "section": "\n14.7 Distribuzione di Poisson",
    "text": "14.7 Distribuzione di Poisson\nLa distribuzione di Poisson è utilizzata per modellare il numero di eventi che si verificano in un determinato intervallo di tempo o spazio, con eventi indipendenti e un tasso costante di occorrenza.\nLa funzione di massa di probabilità (PMF) è data da:\n\\[\nP(Y = y \\mid \\lambda) = \\frac{\\lambda^y \\cdot e^{-\\lambda}}{y!}, \\quad y = 0, 1, 2, \\ldots\n\\]\ndove \\(\\lambda\\) rappresenta il tasso medio di eventi e \\(y\\) è il numero di eventi.\nLa distribuzione di Poisson può essere derivata come il limite di una distribuzione binomiale quando il numero di prove, \\(n\\), tende all’infinito e la probabilità di successo in ciascuna prova, \\(p\\), tende a zero, in modo tale che \\(np = \\lambda\\).\n\n\n\n\n\n\nDimostrazione\n\n\n\nPartiamo dalla funzione di probabilità binomiale:\n\\[\np(k) = \\frac{n!}{k!(n - k)!} p^k (1 - p)^{n - k}.\n\\]\nImpostiamo \\(np = \\lambda\\), il che implica che \\(p = \\frac{\\lambda}{n}\\). Sostituendo \\(p\\) con \\(\\frac{\\lambda}{n}\\) nella formula binomiale, otteniamo:\n\\[\np(k) = \\frac{n!}{k!(n - k)!} \\left(\\frac{\\lambda}{n}\\right)^k \\left(1 - \\frac{\\lambda}{n}\\right)^{n - k}.\n\\]\nOra, separiamo i termini per rendere più chiara la semplificazione. Possiamo riscrivere \\(\\left(\\frac{\\lambda}{n}\\right)^k\\) come \\(\\frac{\\lambda^k}{n^k}\\), e \\(\\left(1 - \\frac{\\lambda}{n}\\right)^{n - k}\\) come \\(\\left(1 - \\frac{\\lambda}{n}\\right)^n \\cdot \\left(1 - \\frac{\\lambda}{n}\\right)^{-k}\\). Quindi, l’espressione diventa:\n\\[\np(k) = \\frac{n!}{k!(n - k)!} \\cdot \\frac{\\lambda^k}{n^k} \\cdot \\left(1 - \\frac{\\lambda}{n}\\right)^n \\cdot \\left(1 - \\frac{\\lambda}{n}\\right)^{-k}.\n\\]\nOra, separiamo ulteriormente i termini:\n\\[\np(k) = \\frac{\\lambda^k}{k!} \\cdot \\frac{n!}{(n - k)! n^k} \\cdot \\left(1 - \\frac{\\lambda}{n}\\right)^n \\cdot \\left(1 - \\frac{\\lambda}{n}\\right)^{-k}.\n\\]\nQuesto passaggio mostra come la funzione di probabilità binomiale, sotto le condizioni \\(np = \\lambda\\) e \\(n \\to \\infty\\), si trasformi gradualmente nella forma che conduce alla distribuzione di Poisson.\nQuando \\(n \\to \\infty\\):\n\\[\n\\frac{\\lambda}{n} \\to 0\n\\]\n\\[\n\\frac{n!}{(n - k)! n^k} \\to 1\n\\]\n\\[\n\\left(1 - \\frac{\\lambda}{n}\\right)^n \\to e^{-\\lambda}\n\\]\n\\[\n\\left(1 - \\frac{\\lambda}{n}\\right)^{-k} \\to 1\n\\]\nSi ottiene quindi:\n\\[\np(k) \\to \\frac{\\lambda^k e^{-\\lambda}}{k!}\n\\]\nche è la funzione di Poisson.\n\n\n\n\n\n\n\n\nDimostrazione\n\n\n\nAnalizziamo il limite:\n\\[\n\\left(1 - \\frac{\\lambda}{n}\\right)^n \\to e^{-\\lambda} \\quad \\text{quando} \\quad n \\to \\infty.\n\\]\nUn limite fondamentale in analisi matematica è:\n\\[\n\\lim_{n \\to \\infty} \\left(1 + \\frac{a}{n}\\right)^n = e^a,\n\\]\ndove \\(e\\) è la base del logaritmo naturale (\\(e \\approx 2.71828\\)) e \\(a\\) è una costante. Questo limite è alla base della definizione della funzione esponenziale.\nNel nostro caso, abbiamo l’espressione:\n\\[\n\\left(1 - \\frac{\\lambda}{n}\\right)^n .\n\\]\nNotiamo che questa è molto simile al limite notevole, ma con un segno negativo. Possiamo riscriverla come:\n\\[\n\\left(1 - \\frac{\\lambda}{n}\\right)^n = \\left(1 + \\frac{-\\lambda}{n}\\right)^n.\n\\]\nApplicando il limite notevole con \\(a = -\\lambda\\), otteniamo:\n\\[\n\\lim_{n \\to \\infty} \\left(1 + \\frac{-\\lambda}{n}\\right)^n = e^{-\\lambda}.\n\\]\nQuindi, quando \\(n\\) diventa molto grande, l’espressione \\(\\left(1 - \\frac{\\lambda}{n}\\right)^n\\) si avvicina sempre di più a \\(e^{-\\lambda}\\).\n\n\n\n14.7.1 Proprietà principali\n\n\nMedia: \\(\\mathbb{E}[Y] = \\lambda\\)\n\n\nVarianza: \\(\\text{Var}(Y) = \\lambda\\)\n\n\nDi seguito, presentiamo esempi di calcolo e simulazione con R.\n\n14.7.2 Grafico della distribuzione di Poisson con \\(\\lambda = 2\\)\n\n\n# Parametro lambda\nlambda &lt;- 2\n\n# Valori di y (numero di eventi)\ny &lt;- 0:10\n\n# Calcolo delle probabilità\nprobabilities &lt;- dpois(y, lambda = lambda)\n\n# Creazione di un dataframe per ggplot\ndata &lt;- data.frame(\n  Numero_eventi = y,\n  Probabilita = probabilities\n)\n\n# Grafico della funzione di massa di probabilità \nggplot(data, aes(x = Numero_eventi, y = Probabilita)) +\n  geom_col() +  \n  labs(\n    x = \"Numero di eventi (k)\",\n    y = \"Probabilità\"\n  ) \n\n\n\n\n\n\n\n\n14.7.3 Calcolo della probabilità per un numero specifico di eventi\nPer calcolare la probabilità di osservare esattamente 3 eventi con \\(\\lambda = 2\\):\n\nprob &lt;- dpois(3, lambda = 2)\nprint(prob)\n#&gt; [1] 0.18\n\n\n14.7.4 Calcolo della probabilità cumulativa \\(P(Y \\leq 3)\\)\n\nPer calcolare \\(P(Y \\leq 3)\\), la probabilità cumulativa:\n\ncum_prob &lt;- ppois(3, lambda = 2)\nprint(cum_prob)\n#&gt; [1] 0.857\n\n\n14.7.5 Trovare il quantile corrispondente a una probabilità data\nPer trovare il numero massimo di eventi per cui la probabilità cumulativa è al massimo \\(0.8125\\):\n\nquantile &lt;- qpois(0.8125, lambda = 2)\nprint(quantile)\n#&gt; [1] 3\n\n\n14.7.6 Generazione di numeri casuali\nPer generare un campione di 1.000.000 di osservazioni da una distribuzione di Poisson con \\(\\lambda = 2\\):\n\nset.seed(42)\nsample &lt;- rpois(1000000, lambda = 2)\n\n# Calcolo di media e varianza del campione\nmean_sample &lt;- mean(sample)\nvar_sample &lt;- var(sample)\n\nprint(mean_sample)\n#&gt; [1] 2\nprint(var_sample)\n#&gt; [1] 2\n\n\nEsempio 14.7 Un esempio classico dell’uso della distribuzione di Poisson viene dalla Seconda Guerra Mondiale.\nIl contesto storico. Tra il 1944 e il 1945, Londra fu colpita da centinaia di missili V1 e V2 lanciati dalla Germania nazista. Le autorità britanniche si chiesero se i bombardamenti seguissero una strategia mirata: i missili venivano forse lanciati intenzionalmente su certi quartieri? O si trattava invece di un comportamento casuale, come se fossero stati distribuiti a caso?\nPer rispondere a questa domanda, il Ministero della Guerra britannico divise Londra in 576 aree di uguale superficie (ogni area misurava 0.25 km²) e registrò quanti missili avevano colpito ciascuna area. I dati furono poi analizzati dal matematico R. D. Clarke, che li pubblicò nel 1946.\nI dati osservati. Ecco una sintesi della distribuzione osservata:\n\n\nMissili per area\nNumero di aree\nFrequenza relativa\n\n\n\n0\n229\n0.398\n\n\n1\n211\n0.367\n\n\n2\n93\n0.161\n\n\n3\n35\n0.061\n\n\n4\n7\n0.012\n\n\n≥5\n1\n0.002\n\n\n\nIl numero medio di missili per area era \\(\\lambda \\approx 0.93\\). L’idea era confrontare queste frequenze con le probabilità teoriche previste da una distribuzione di Poisson con media \\(\\lambda = 0.93\\).\nInterpretazione con la distribuzione di Poisson. Utilizzando la funzione dpois() in R, possiamo calcolare le probabilità teoriche per ciascun valore osservato, da 0 a 4 missili per area (valori superiori sono troppo rari per essere trattati separatamente).\n\n# Parametro medio osservato\nlambda &lt;- 0.93\n\n# Valori possibili di missili per area\ny &lt;- 0:4\n\n# Probabilità teoriche secondo la distribuzione di Poisson\nprob_teoriche &lt;- dpois(y, lambda = lambda)\n\n# Aggiungiamo la probabilità per y &gt;= 5\nprob_teoriche &lt;- c(prob_teoriche, 1 - sum(prob_teoriche))  # y &gt;= 5\n\n# Visualizziamo\ndata.frame(\n  Missili_per_area = c(0:4, \"&gt;=5\"),\n  Probabilita_teorica = round(prob_teoriche, 3)\n)\n#&gt;   Missili_per_area Probabilita_teorica\n#&gt; 1                0               0.395\n#&gt; 2                1               0.367\n#&gt; 3                2               0.171\n#&gt; 4                3               0.053\n#&gt; 5                4               0.012\n#&gt; 6              &gt;=5               0.003\n\nConfrontando le probabilità teoriche della Poisson con quelle osservate nei dati reali, i risultati erano sorprendentemente simili. Questo suggeriva che i missili non erano lanciati su bersagli specifici, ma seguivano un comportamento statisticamente compatibile con una distribuzione casuale.\n\n# Frequenze osservate (dati originali di Clarke, 1946)\nfrequenze_osservate &lt;- c(229, 211, 93, 35, 7, 1)\nvalori_missili &lt;- c(0, 1, 2, 3, 4, \"≥5\")\n\n# Calcolo frequenze teoriche con Poisson (lambda = 0.93)\nlambda &lt;- 0.93\nprob_teoriche &lt;- dpois(0:4, lambda)\nprob_teoriche &lt;- c(prob_teoriche, 1 - sum(prob_teoriche))  # Per y &gt;= 5\n\n# Numero totale di aree (come somma delle osservazioni)\nn_aree &lt;- sum(frequenze_osservate)\n\n# Frequenze attese = probabilità teoriche * numero totale di aree\nfrequenze_attese &lt;- round(prob_teoriche * n_aree)\n\n# Costruzione del data frame\ndf &lt;- data.frame(\n  Missili_per_area = factor(valori_missili, levels = c(\"0\", \"1\", \"2\", \"3\", \"4\", \"≥5\")),\n  Osservate = frequenze_osservate,\n  Attese = frequenze_attese\n)\n\n# Conversione in formato lungo per ggplot2\ndf_long &lt;- reshape2::melt(df, id.vars = \"Missili_per_area\", variable.name = \"Tipo\", value.name = \"Frequenza\")\n\n# Creazione del grafico\nggplot(df_long, aes(x = Missili_per_area, y = Frequenza, fill = Tipo)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(\n    x = \"Numero di missili per area\",\n    y = \"Numero di aree\",\n    fill = \"Frequenza\"\n  ) \n\n\n\n\n\n\n\n\nLe barre blu rappresentano le frequenze osservate (quante aree hanno ricevuto 0, 1, 2… missili).\nLe barre rosse mostrano le frequenze attese se i missili fossero stati lanciati in modo completamente casuale, seguendo una distribuzione di Poisson con \\(\\lambda = 0.93\\).\n\nLa sovrapposizione tra i due andamenti è molto buona, il che rafforza l’idea che i bombardamenti fossero distribuiti casualmente — senza un pattern strategico apparente.\nCosa ci insegna questo esempio?\n\nLa distribuzione di Poisson è adatta quando vogliamo modellare eventi rari e indipendenti nello spazio o nel tempo.\nI dati dei missili su Londra mostrano come un fenomeno che a prima vista potrebbe sembrare non casuale (per via della concentrazione locale degli eventi) possa invece essere ben descritto da un modello probabilistico semplice, se considerato su una scala adatta.\n\n\n\nEsempio 14.8 Supponiamo di avere osservato, nel corso degli anni, che la frequenza relativa di bocciature all’esame di Psicometria è di circa 10% (cioè \\(p = 0.1\\)). Tuttavia, il numero di studenti iscritti a ciascun appello varia in modo estremo: al primo appello dell’anno partecipano più di 200 studenti, mentre negli ultimi appelli solo 2 o 3.\nQuesto rende inadeguato l’uso della distribuzione binomiale, che richiede un numero di prove (\\(n\\)) fisso o noto per ciascun appello.\nIn questi casi, possiamo modellare il numero di bocciature per appello usando una distribuzione di Poisson.\nPer ogni appello, possiamo stimare \\(\\lambda\\) moltiplicando il numero di studenti iscritti (\\(n\\)) per la frequenza attesa di bocciature (\\(p = 0.1\\)). A quel punto, il numero di bocciature osservate può essere approssimato da:\n\\[\nY \\sim \\text{Poisson}(\\lambda = n \\cdot p) .\n\\]\nQuindi la distribuzione cambia da appello ad appello, perché \\(\\lambda\\) cambia con \\(n\\), ma il modello rimane Poissoniano.\nSupponiamo di avere osservato i seguenti dati.\n\n\n\n\n\n\n\n\nAppello\nNumero iscritti (\\(n\\))\n\\(\\lambda = n \\cdot p\\)\nDistribuzione di bocciature\n\n\n\n1\n220\n\\(220 \\cdot 0.1 = 22\\)\n\\(Y \\sim \\text{Poisson}(22)\\)\n\n\n2\n95\n\\(95 \\cdot 0.1 = 9.5\\)\n\\(Y \\sim \\text{Poisson}(9.5)\\)\n\n\n8\n3\n\\(3 \\cdot 0.1 = 0.3\\)\n\\(Y \\sim \\text{Poisson}(0.3)\\)\n\n\n\nPer ogni appello, possiamo usare la funzione dpois() in R per calcolare la probabilità di osservare un certo numero di bocciature, dato il valore di \\(\\lambda\\) specifico per quell’appello.\nAd esempio, possiamo chiederci quale sia la probabilità che, nel secondo appello (95 iscritti), si registrino esattamente 8 bocciature.\n\nlambda &lt;- 95 * 0.1  # = 9.5\ndpois(8, lambda = lambda)\n#&gt; [1] 0.123\n\nQuesta funzione calcola \\(P(Y = 8)\\) per una variabile \\(Y \\sim \\text{Poisson}(9.5)\\), cioè la probabilità di osservare esattamente 8 bocciature su 95 iscritti.\nSupponiamo di voler simulare il numero di bocciature in 8 appelli con numeri di iscritti variabili. Possiamo fare così:\n\nset.seed(42)\n\n# Numero iscritti per ciascun appello\nn_iscritti &lt;- c(220, 95, 60, 45, 20, 12, 6, 3)\n\n# Probabilità storica di bocciatura\np &lt;- 0.1\n\n# Parametri lambda per ogni appello\nlambda &lt;- n_iscritti * p\n\n# Simulazione delle bocciature per ciascun appello\nbocciature &lt;- rpois(length(lambda), lambda = lambda)\n\ndata.frame(\n  Appello = 1:8, \n  Iscritti = n_iscritti, \n  Lambda = lambda, \n  Bocciature = bocciature\n)\n#&gt;   Appello Iscritti Lambda Bocciature\n#&gt; 1       1      220   22.0         28\n#&gt; 2       2       95    9.5          8\n#&gt; 3       3       60    6.0          8\n#&gt; 4       4       45    4.5          5\n#&gt; 5       5       20    2.0          2\n#&gt; 6       6       12    1.2          2\n#&gt; 7       7        6    0.6          0\n#&gt; 8       8        3    0.3          0\n\n📈 Visualizzazione.\n\ndf &lt;- data.frame(Appello = factor(1:8), Bocciature = bocciature)\n\nggplot(df, aes(x = Appello, y = Bocciature)) +\n  geom_col() +\n  labs(\n    x = \"Appello\",\n    y = \"Numero di bocciature\"\n  )\n\n\n\n\n\n\n\nIn sintesi,\n\nquando il numero di studenti iscritti a un appello non è noto a priori o varia fortemente, non è adeguato usare la distribuzione binomiale;\nse conosciamo la frequenza relativa di bocciature (es. \\(p = 0.1\\)), possiamo usare la distribuzione di Poisson con \\(\\lambda = n \\cdot p\\), adattandola a ciascun appello;\nquesto approccio è particolarmente utile per fare stima e simulazione del numero di bocciature attese, senza dover modellare tutti i singoli esiti.\n\n\n\nEsempio 14.9 Uno degli esempi più comuni per introdurre la distribuzione di Poisson riguarda il numero di nascite giornaliere in un ospedale.\nSupponiamo che, in un grande ospedale, la media storica sia di 4.5 nascite al giorno. Possiamo allora descrivere il numero di nascite in un giorno con una variabile casuale Poisson con parametro \\(\\lambda = 4.5\\):\n\\[\nY \\sim \\text{Poisson}(\\lambda = 4.5) .\n\\]\nCi chiediamo, ad esempio: qual è la probabilità che in un giorno nascano esattamente 6 bambini?\nPossiamo calcolarla con la funzione dpois():\n\n# Parametro medio: 4.5 nascite al giorno\nlambda &lt;- 4.5\n\n# Probabilità di osservare esattamente 6 nascite\nprob &lt;- dpois(6, lambda = lambda)\nprint(prob)\n#&gt; [1] 0.128\n\nQuesto valore rappresenta la probabilità che, in un giorno qualsiasi, si verifichino esattamente 6 nascite.\nSimulazione. Simuliamo ora il numero di nascite in 365 giorni consecutivi, supponendo che la media rimanga costante a 4.5:\n\nset.seed(42)  # Per rendere i risultati riproducibili\n\nn_days &lt;- 365\nsimulated_births &lt;- rpois(n_days, lambda = lambda)\n\n# Proporzione di giorni con esattamente 6 nascite\nproportion_six_births &lt;- mean(simulated_births == 6)\nprint(proportion_six_births)\n#&gt; [1] 0.14\n\nQuesto ci dice, tra i 365 giorni simulati, quanta parte dell’anno ha avuto esattamente 6 nascite. Il valore ottenuto può essere confrontato con la probabilità teorica calcolata prima.\nVisualizzazione. Possiamo rappresentiamo graficamente i dati simulati con un istogramma:\n\n# Costruzione del data frame\ndata &lt;- data.frame(Nascite = simulated_births)\n\n# Istogramma\nggplot(data, aes(x = Nascite)) +\n  geom_histogram(\n    breaks = seq(-0.5, max(simulated_births) + 0.5, by = 1)\n  ) +\n  labs(\n    x = \"Numero di nascite per giorno\",\n    y = \"Frequenza (numero di giorni)\"\n  )\n\n\n\n\n\n\n\nL’istogramma mostra quante volte si sono verificati 0, 1, 2, …, 10 o più nascite in un giorno, evidenziando la variabilità naturale attorno alla media.\nCalcoliamo ora quanto è probabile che si verifichino più di 6 nascite in un giorno.\nProbabilità teorica:\n\nprob_more_than_six &lt;- 1 - ppois(6, lambda = lambda)\nprint(prob_more_than_six)\n#&gt; [1] 0.169\n\nProporzione osservata nella simulazione:\n\nproportion_more_than_six &lt;- mean(simulated_births &gt; 6)\nprint(proportion_more_than_six)\n#&gt; [1] 0.17\n\nIl confronto tra probabilità teorica e proporzione simulata mostra come la distribuzione di Poisson riproduca bene i fenomeni reali, quando gli eventi sono indipendenti, discreti e relativamente frequenti ma non troppo.\n\n\nEsempio 14.10 Questo esempio è tratto dal celebre lavoro di Ladislaus von Bortkiewicz del 1898, spesso citato come una delle prime applicazioni reali della distribuzione di Poisson.\nVon Bortkiewicz studiò un evento piuttosto inusuale: le morti causate da calci di cavallo all’interno della cavalleria dell’esercito prussiano. L’obiettivo era capire se questi eventi, seppur rari, potessero essere considerati casuali e indipendenti, oppure se fossero distribuiti in modo irregolare e non prevedibile.\nPer farlo, raccolse i dati su 10 squadroni osservati per 20 anni consecutivi, ottenendo così 200 unità di osservazione, che possiamo chiamare “squadroni-anno”.\nI dati raccolti. Per ogni squadrone-anno, fu registrato il numero di morti per calci di cavallo. I dati furono poi raggruppati per numero di decessi:\n\n\n\n\n\n\n\n\nNumero di decessi annui\nFrequenza osservata\nFrequenza relativa\nProbabilità teorica (Poisson)\n\n\n\n0\n109\n0.545\n0.543\n\n\n1\n65\n0.325\n0.331\n\n\n2\n22\n0.110\n0.101\n\n\n3\n3\n0.015\n0.021\n\n\n4\n1\n0.005\n0.003\n\n\n\n\n\nFrequenza osservata: Quante volte ciascun numero di decessi è stato osservato tra i 200 squadroni-anno.\n\nFrequenza relativa: Frequenza osservata divisa per 200.\n\nProbabilità teorica: Calcolata con la distribuzione di Poisson con parametro \\(\\lambda = 0.61\\), pari alla media osservata dei decessi annui.\n\nLa distribuzione di Poisson è perfetta per questo tipo di situazione perché:\n\nstiamo contando il numero di eventi rari (decessi accidentali),\nche si verificano in unità di tempo o spazio fisse (lo “squadrone-anno”),\ne presumiamo che questi eventi siano indipendenti tra loro.\n\nIn questo caso, \\(\\lambda = 0.61\\) rappresenta il numero medio di decessi per squadrone in un anno. La variabilità intorno a questo valore può essere descritta dalla distribuzione di Poisson, che assegna a ciascun possibile numero di decessi (0, 1, 2, …) una probabilità teorica.\nConfronto tra dati osservati e modello di Poisson. Come si può notare dalla tabella, le frequenze osservate sono sorprendentemente simili alle probabilità teoriche ottenute dal modello di Poisson. Ad esempio:\n\nla proporzione di squadroni-anno con zero decessi è 0.545, contro una probabilità teorica di 0.543;\nper un decesso, la frequenza relativa è 0.325, vicina alla probabilità teorica di 0.331;\nanche le classi meno frequenti (2, 3 e 4 decessi) sono coerenti con i valori attesi.\n\nQuesto esempio dimostra che la distribuzione di Poisson non solo è utile per modellare eventi rari, ma fornisce anche una buona descrizione quantitativa del comportamento osservato nel mondo reale.\nIn sintesi,\n\nil lavoro di von Bortkiewicz è uno dei primi esempi storici di modellizzazione di dati reali con la teoria delle probabilità;\nla distribuzione di Poisson si è rivelata efficace nel descrivere un fenomeno raro, ma regolare, suggerendo che i decessi fossero eventi casuali e indipendenti, non dovuti a fattori sistematici;\nancora oggi, questo esempio viene usato per insegnare che anche gli eventi accidentali e poco frequenti possono essere prevedibili in media e descritti in modo elegante da un modello probabilistico.\n\nQui di seguito viene fornito il codice R che riproduce l’analisi di von Bortkiewicz, calcola le probabilità teoriche secondo la distribuzione di Poisson con parametro \\(\\lambda = 0.61\\) e confronta visivamente le frequenze osservate con le frequenze attese.\n\n# Dati osservati da von Bortkiewicz\ndecessi &lt;- 0:4\nfrequenze_osservate &lt;- c(109, 65, 22, 3, 1)\nn_total &lt;- sum(frequenze_osservate)  # Totale = 200 squadroni-anno\n\n# Frequenze relative\nfrequenze_relative &lt;- frequenze_osservate / n_total\n\nCalcolo delle probabilità teoriche con la distribuzione di Poisson:\n\n# Parametro medio osservato\nlambda &lt;- 0.61\n\n# Calcolo delle probabilità teoriche di Poisson\nprob_poisson &lt;- dpois(decessi, lambda = lambda)\n\nConfronto: osservato vs teorico.\n\n# Frequenze attese = probabilità teoriche * numero totale di casi\nfrequenze_attese &lt;- round(prob_poisson * n_total)\n\n# Creazione del data frame per il confronto\ndf &lt;- data.frame(\n  Decessi = factor(decessi),\n  Osservato = frequenze_osservate,\n  Atteso = frequenze_attese\n)\ndf\n#&gt;   Decessi Osservato Atteso\n#&gt; 1       0       109    109\n#&gt; 2       1        65     66\n#&gt; 3       2        22     20\n#&gt; 4       3         3      4\n#&gt; 5       4         1      1\n\nVisualizzazione: confronto tra frequenze osservate e attese.\n\n# Conversione da wide a long format con pivot_longer()\ndf_long &lt;- df |&gt; \n  pivot_longer(\n    cols = c(Osservato, Atteso),\n    names_to = \"Tipo\",\n    values_to = \"Frequenza\"\n  )\n\n# Mostra le prime righe\nhead(df_long)\n#&gt; # A tibble: 6 × 3\n#&gt;   Decessi Tipo      Frequenza\n#&gt;   &lt;fct&gt;   &lt;chr&gt;         &lt;dbl&gt;\n#&gt; 1 0       Osservato       109\n#&gt; 2 0       Atteso          109\n#&gt; 3 1       Osservato        65\n#&gt; 4 1       Atteso           66\n#&gt; 5 2       Osservato        22\n#&gt; 6 2       Atteso           20\n\n\n# Grafico a barre affiancate\nggplot(df_long, aes(x = Decessi, y = Frequenza, fill = Tipo)) +\n  geom_bar(stat = \"identity\", position = \"dodge\", color = \"black\") +\n  labs(\n    x = \"Numero di decessi per squadrone-anno\",\n    y = \"Frequenza\",\n    fill = \"Tipo\"\n  ) \n\n\n\n\n\n\n\n\nLe barre blu mostrano i dati osservati da von Bortkiewicz.\nLe barre rosse indicano le frequenze attese se il numero di decessi segue una distribuzione di Poisson con media \\(\\lambda = 0.61\\).\nLa buona corrispondenza visiva tra le due serie supporta l’idea che i decessi siano eventi rari, indipendenti e distribuiti casualmente.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_discr_rv_distr.html#distribuzione-beta-binomiale",
    "href": "chapters/probability/13_discr_rv_distr.html#distribuzione-beta-binomiale",
    "title": "14  Distribuzioni di v.c. discrete",
    "section": "\n14.8 Distribuzione Beta-Binomiale",
    "text": "14.8 Distribuzione Beta-Binomiale\nLa distribuzione beta-binomiale rappresenta una estensione della distribuzione binomiale che tiene conto della variabilità nella probabilità di successo tra i vari tentativi. Viene descritta da tre parametri principali: \\(N\\), \\(\\alpha\\) e \\(\\beta\\).\nNel dettaglio, la funzione di massa di probabilità per la distribuzione beta-binomiale è data da:\n\\[\n\\text{BetaBinomiale}(y | N, \\alpha, \\beta) = \\binom{N}{y} \\cdot \\frac{B(y + \\alpha, N - y + \\beta)}{B(\\alpha, \\beta)},\n\\tag{14.5}\\]\ndove:\n\n\n\\(y\\) indica il numero di successi osservati.\n\n\\(N\\) rappresenta il numero totale di tentativi.\n\n\\(\\alpha\\) e \\(\\beta\\) sono i parametri della distribuzione beta, che modellano la variabilità nella probabilità di successo tra i tentativi.\n\nLa funzione \\(B(u, v)\\), nota come funzione beta, è definita tramite l’uso della funzione gamma \\(\\Gamma\\), secondo la formula:\n\\[\nB(u, v) = \\frac{\\Gamma(u) \\Gamma(v)}{\\Gamma(u + v)},\n\\]\ndove la funzione gamma \\(\\Gamma\\) generalizza il concetto di fattoriale a numeri reali e complessi.\nL’importanza della distribuzione beta-binomiale deriva dalla sua capacità di modellare situazioni in cui la probabilità di successo non è fissa, ma segue una distribuzione di probabilità, specificatamente una distribuzione beta. Ciò la rende particolarmente adatta per applicazioni in cui le probabilità di successo cambiano in maniera incerta da un tentativo all’altro, come può avvenire in contesti di ricerca clinica o in studi comportamentali. Rispetto alla distribuzione binomiale, che assume una probabilità di successo costante per tutti i tentativi, la beta-binomiale offre una rappresentazione più realistica e flessibile per dati empirici che presentano variabilità nelle probabilità di successo.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_discr_rv_distr.html#riflessioni-conclusive",
    "href": "chapters/probability/13_discr_rv_distr.html#riflessioni-conclusive",
    "title": "14  Distribuzioni di v.c. discrete",
    "section": "\n14.9 Riflessioni Conclusive",
    "text": "14.9 Riflessioni Conclusive\nIn questo capitolo, abbiamo approfondito alcune delle distribuzioni discrete più importanti, ognuna con caratteristiche uniche e campi di applicazione specifici. Abbiamo iniziato con la distribuzione di Bernoulli, che modella esperimenti con due soli esiti possibili, per poi passare alla distribuzione Binomiale, che generalizza la Bernoulli considerando un numero fisso di prove indipendenti. Successivamente, abbiamo esaminato la distribuzione di Poisson, utile per descrivere eventi rari in un intervallo di tempo o spazio, e la distribuzione Beta-Binomiale, un’estensione della Binomiale che incorpora la variabilità nella probabilità di successo, rendendola particolarmente adatta per modellare situazioni in cui tale probabilità non è fissa. Infine, abbiamo discusso la distribuzione Discreta Uniforme, che assegna la stessa probabilità a ciascun evento in un insieme finito e discreto.\nQueste distribuzioni rappresentano il fondamento dell’analisi statistica discreta e trovano applicazione in numerosi ambiti. In particolare, nel contesto dell’inferenza bayesiana, la comprensione della distribuzione Binomiale e della sua estensione Beta-Binomiale è essenziale. Queste distribuzioni, infatti, forniscono gli strumenti necessari per l’aggiornamento bayesiano, un processo chiave che permette di rivedere le nostre credenze iniziali alla luce di nuovi dati. Questo concetto sarà ulteriormente esplorato nei capitoli successivi, dove approfondiremo come le distribuzioni a priori e a posteriori interagiscono nel quadro bayesiano.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_discr_rv_distr.html#esercitazione-in-classe",
    "href": "chapters/probability/13_discr_rv_distr.html#esercitazione-in-classe",
    "title": "14  Distribuzioni di v.c. discrete",
    "section": "\n14.10 Esercitazione in Classe",
    "text": "14.10 Esercitazione in Classe\nValutate le emozioni che verranno presentate sullo schermo usando questo link.\nScala di risposta:\n\nRabbia: 1\nDisgusto: 2\nPaura: 3\nFelicità: 4\nTristezza: 5",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_discr_rv_distr.html#esercizi",
    "href": "chapters/probability/13_discr_rv_distr.html#esercizi",
    "title": "14  Distribuzioni di v.c. discrete",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\nPer ciascuna delle distribuzioni di massa di probabilità discusse, utilizzare R per:\n\ncreare un grafico della funzione, scegliendo opportunamente i parametri;\nestrarre un campione di 1000 valori casuali dalla distribuzione e visualizzarlo con un istogramma;\ncalcolare la media e la deviazione standard dei campioni e confrontarle con i valori teorici attesi;\nstimare l’intervallo centrale del 94% utilizzando i campioni simulati;\ndeterminare i quantili della distribuzione per gli ordini 0.05, 0.25, 0.75 e 0.95;\nscegliendo un valore della distribuzione pari alla media più una deviazione standard, calcolare la probabilità che la variabile aleatoria assuma un valore minore o uguale a questo valore.\n\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nEsercizi sulla distribuzione binomiale, risolvibili usando R, sono disponibili sulla seguente pagina web.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_discr_rv_distr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/13_discr_rv_distr.html#informazioni-sullambiente-di-sviluppo",
    "title": "14  Distribuzioni di v.c. discrete",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] reshape2_1.4.4        pillar_1.11.0         tinytable_0.13.0     \n#&gt;  [4] patchwork_1.3.2       ggdist_3.3.3          tidybayes_3.0.7      \n#&gt;  [7] bayesplot_1.14.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#&gt; [10] priorsense_1.1.1      posterior_1.6.1       loo_2.8.0            \n#&gt; [13] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#&gt; [16] Rcpp_1.1.0            sessioninfo_1.2.3     conflicted_1.2.0     \n#&gt; [19] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#&gt; [22] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#&gt; [25] rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        systemfonts_1.2.3    \n#&gt; [10] vctrs_0.6.5           stringr_1.5.1         pkgconfig_2.0.3      \n#&gt; [13] arrayhelpers_1.1-0    fastmap_1.2.0         backports_1.5.0      \n#&gt; [16] labeling_0.4.3        utf8_1.2.6            rmarkdown_2.29       \n#&gt; [19] ragg_1.5.0            purrr_1.1.0           xfun_0.53            \n#&gt; [22] cachem_1.1.0          jsonlite_2.0.0        broom_1.0.9          \n#&gt; [25] parallel_4.5.1        R6_2.6.1              stringi_1.8.7        \n#&gt; [28] RColorBrewer_1.1-3    lubridate_1.9.4       estimability_1.5.1   \n#&gt; [31] knitr_1.50            zoo_1.8-14            pacman_0.5.1         \n#&gt; [34] Matrix_1.7-4          splines_4.5.1         timechange_0.3.0     \n#&gt; [37] tidyselect_1.2.1      abind_1.4-8           yaml_2.3.10          \n#&gt; [40] codetools_0.2-20      curl_7.0.0            pkgbuild_1.4.8       \n#&gt; [43] lattice_0.22-7        plyr_1.8.9            withr_3.0.2          \n#&gt; [46] bridgesampling_1.1-2  coda_0.19-4.1         evaluate_1.0.5       \n#&gt; [49] survival_3.8-3        RcppParallel_5.1.11-1 tensorA_0.36.2.1     \n#&gt; [52] checkmate_2.3.3       stats4_4.5.1          distributional_0.5.0 \n#&gt; [55] generics_0.1.4        rprojroot_2.1.1       rstantools_2.5.0     \n#&gt; [58] scales_1.4.0          xtable_1.8-4          glue_1.8.0           \n#&gt; [61] emmeans_1.11.2-8      tools_4.5.1           mvtnorm_1.3-3        \n#&gt; [64] grid_4.5.1            QuickJSR_1.8.0        colorspace_2.1-1     \n#&gt; [67] nlme_3.1-168          cli_3.6.5             textshaping_1.0.3    \n#&gt; [70] svUnit_1.0.8          Brobdingnag_1.2-9     V8_7.0.0             \n#&gt; [73] gtable_0.3.6          digest_0.6.37         TH.data_1.1-4        \n#&gt; [76] htmlwidgets_1.6.4     farver_2.1.2          memoise_2.0.1        \n#&gt; [79] htmltools_0.5.8.1     lifecycle_1.0.4       MASS_7.3-65",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_discr_rv_distr.html#bibliografia",
    "href": "chapters/probability/13_discr_rv_distr.html#bibliografia",
    "title": "14  Distribuzioni di v.c. discrete",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlitzstein, J. K., & Hwang, J. (2019). Introduction to probability. CRC Press.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_cont_rv_distr.html",
    "href": "chapters/probability/14_cont_rv_distr.html",
    "title": "15  Distribuzioni di v.c. continue",
    "section": "",
    "text": "15.1 Introduzione\nProprio come per le variabili casuali discrete, anche per le variabili casuali continue è possibile rappresentare la variabilità di una popolazione attraverso un modello statistico. Tuttavia, mentre le distribuzioni discrete si applicano a fenomeni con un numero finito o numerabile di esiti, le variabili casuali continue richiedono l’uso di funzioni di densità di probabilità (pdf), che descrivono fenomeni in cui i valori possono assumere un continuum di possibilità. Queste funzioni ci permettono di modellare e analizzare situazioni in cui i risultati non sono discreti, ma possono variare in modo continuo.\nLa funzione di densità di probabilità \\(f(x)\\) associata a una variabile casuale continua \\(X\\) rappresenta la distribuzione della probabilità all’interno della popolazione. A differenza delle distribuzioni discrete, dove la probabilità è assegnata direttamente a singoli valori, la pdf non fornisce la probabilità di un singolo punto, ma descrive la probabilità che \\(X\\) assuma valori all’interno di un intervallo specifico. Questo approccio consente di costruire un modello matematico della popolazione, utile per fare previsioni e comprendere meglio i fenomeni aleatori continui.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_cont_rv_distr.html#la-distribuzione-uniforme-continua",
    "href": "chapters/probability/14_cont_rv_distr.html#la-distribuzione-uniforme-continua",
    "title": "15  Distribuzioni di v.c. continue",
    "section": "\n15.2 La Distribuzione Uniforme Continua",
    "text": "15.2 La Distribuzione Uniforme Continua\nLa distribuzione uniforme continua rappresenta un pilastro della teoria delle probabilità, caratterizzata da una densità di probabilità costante su un intervallo definito. Questo modello è particolarmente utile per descrivere fenomeni casuali dove ogni esito possibile ha identica probabilità di verificarsi, come nel caso di uno spinner perfettamente bilanciato o di un generatore di numeri casuali ideale.\n\n15.2.1 Un esempio intuitivo: lo spinner\nConsideriamo uno spinner circolare con valori angolari compresi tra 0° e 360°. Se il dispositivo è perfettamente equilibrato, ogni angolo ha la stessa probabilità di essere selezionato dopo una rotazione. Questo esperimento costituisce un’implementazione concreta della distribuzione uniforme sull’intervallo \\([0, 360)\\).\n\n15.2.2 Simulazione della distribuzione: dal campione piccolo alla convergenza teorica\nPer illustrare il comportamento della distribuzione, analizziamo due scenari distinti attraverso simulazioni numeriche.\nCaso 1: Campione piccolo (n = 20)\nGeneriamo 20 valori casuali e visualizziamoli con un istogramma:\n\nset.seed(123)  # Riproducibilità dei risultati\nspinner_results &lt;- runif(20, min = 0, max = 360)\nprint(spinner_results)  # Output dei dati\n#&gt;  [1] 103.5 283.8 147.2 317.9 338.6  16.4 190.1 321.3 198.5 164.4 344.5 163.2\n#&gt; [13] 243.9 206.1  37.1 323.9  88.6  15.1 118.1 343.6\n\n# Creazione dell'istogramma\nggplot(data.frame(Valori = spinner_results), aes(x = Valori)) +\n  geom_histogram(\n    binwidth = 10, \n    fill = \"skyblue\", \n    color = \"black\", \n    alpha = 0.5\n  ) +\n  labs(\n    x = \"Angolo (gradi)\", \n    y = \"Frequenza relativa\"\n  ) \n\n\n\n\n\n\n\nL’istogramma mostra un andamento irregolare, riflettendo la variabilità intrinseca dei piccoli campioni. Questa disomogeneità è attesa e diminuisce all’aumentare della dimensione campionaria.\nCaso 2: Campione grande (n = 100,000)\nRipetiamo la simulazione con un campione esteso:\n\nspinner_results_large &lt;- runif(100000, min = 0, max = 360)\n\nggplot(data.frame(Valori = spinner_results_large), aes(x = Valori)) +\n  geom_histogram(\n    binwidth = 10, \n    fill = \"skyblue\", \n    color = \"black\", \n    alpha = 0.5\n  ) +\n  labs(\n    x = \"Angolo (gradi)\", \n    y = \"Frequenza relativa\"\n  ) \n\n\n\n\n\n\n\nL’istogramma ora rivela un profilo piatto e regolare, in accordo con la forma teorica della distribuzione. Questo risultato dimostra empiricamente la Legge dei Grandi Numeri, dove all’aumentare delle osservazioni la distribuzione empirica converge a quella teorica.\n\n15.2.3 La Funzione di Densità di Probabilità (PDF)\nPer una variabile casuale \\(X \\sim \\mathcal{U}(a, b)\\), la PDF è definita come:\n\\[\nf(x) =\n\\begin{cases}\n  \\displaystyle \\frac{1}{b - a} & \\text{se } x \\in [a, b], \\\\\n  0 & \\text{altrimenti}.\n\\end{cases}\n\\]\nProprietà chiave:\n\nl’area totale sotto la curva è unitaria: \\(\\int_{a}^{b} \\frac{1}{b - a} \\, dx = 1\\);\n\nla densità è nulla al di fuori dell’intervallo \\([a, b]\\).\n\nApplicazione allo spinner:\n\\[\nf(x) = \\frac{1}{360} \\quad \\text{per } x \\in [0, 360].\n\\]\nVisualizzazione grafica in R:\n\nx &lt;- seq(-50, 410, length.out = 500)  \ndensity_uniform &lt;- dunif(x, min = 0, max = 360)\n\nggplot(data.frame(x = x, y = density_uniform), aes(x = x, y = y)) +\n  geom_line(linewidth = 1.2, color = \"blue\") +\n  geom_vline(xintercept = c(0, 360), linetype = \"dashed\", color = \"red\") +\n  labs(\n    x = \"x (gradi)\", \n    y = \"Densità f(x)\"\n  ) +\n  xlim(-50, 410) \n\n\n\n\n\n\n\nIl grafico evidenzia la densità costante nell’intervallo \\([0, 360]\\) e l’assenza di probabilità al di fuori di esso.\n\n15.2.4 Calcolo delle Probabilità: Metodo Geometrico e Funzionale\nLa probabilità che \\(X\\) assuma valori in un sottointervallo \\([c, d] \\subseteq [a, b]\\) è data da:\n\\[\nP(c \\leq X \\leq d) = \\frac{d - c}{b - a}.\n\\]\nEsempio applicativo:\nCalcoliamo la probabilità che lo spinner si fermi tra 150° e 250°:\n\\[\nP(150 \\leq X \\leq 250) = \\frac{250 - 150}{360} = \\frac{100}{360} = \\frac{5}{18} \\approx 0.2778.\n\\]\nConferma numerica in R:\n\n# Approccio manuale\nprob_manuale &lt;- (250 - 150) / 360  \n\n# Utilizzo della funzione cumulativa (CDF)\nprob_cdf &lt;- punif(250, min = 0, max = 360) - punif(150, min = 0, max = 360)  \n\nRappresentazione grafica dell’area di probabilità:\n\nggplot(data.frame(x = x, fx = density_uniform), aes(x = x, y = fx)) +\n  geom_line(linewidth = 1.2, color = \"blue\") +\n  geom_area(\n    data = subset(data.frame(x, fx = density_uniform), x &gt;= 150 & x &lt;= 250),\n    aes(x = x, y = fx), \n    fill = \"gray\", \n    alpha = 0.5\n  ) +\n  labs(\n    x = \"x (gradi)\", \n    y = \"Densità f(x)\"\n  ) \n\n\n\n\n\n\n\nL’area grigia corrisponde esattamente al valore di probabilità calcolato, illustrando visivamente il concetto di integrazione della PDF.\n\n15.2.5 Proprietà Fondamentali: Media e Varianza\nPer \\(X \\sim \\mathcal{U}(a, b)\\) valgono le seguenti relazioni:\n\n\nValore atteso (centro della distribuzione):\n\\[\nE(X) = \\frac{a + b}{2}.\n\\]\nEsempio: Per lo spinner, \\(E(X) = (0 + 360)/2 = 180\\) gradi.\n\n\nVarianza (misura di dispersione):\n\\[\n\\text{Var}(X) = \\frac{(b - a)^2}{12}.\n\\]\nEsempio: Per lo spinner, \\(\\text{Var}(X) = (360 - 0)^2 / 12 = 10,\\!800\\) gradi².\n\n\n15.2.6 Implementazione in R: Funzioni Principali\nR fornisce quattro funzioni per lavorare con la distribuzione uniforme:\n\n\n\n\n\n\n\nFunzione\nDescrizione\nEsempio d’uso\n\n\n\nrunif()\nGenera valori casuali\nrunif(5, min=0, max=1)\n\n\ndunif()\nCalcola la densità \\(f(x)\\)\n\ndunif(180, min=0, max=360)\n\n\npunif()\nCalcola la CDF \\(P(X \\leq x)\\)\n\npunif(250, min=0, max=360)\n\n\nqunif()\nDetermina il quantile per una probabilità\nqunif(0.9, min=0, max=360)\n\n\n\nEsempi operativi:\n\n# 1. Generazione di 5 numeri casuali in [0, 1]\nrunif(5, min = 0, max = 1)  \n#&gt; [1] 0.0372 0.9278 0.4480 0.9159 0.3558\n\n# 2. Valore della densità in x = 0.5 per U(0,1)\ndunif(0.5, min = 0, max = 1)  \n#&gt; [1] 1\n\n# 3. Probabilità cumulativa fino a x = 0.8 per U(0,1)\npunif(0.8, min = 0, max = 1)  \n#&gt; [1] 0.8\n\n# 4. Calcolo del quantile corrispondente al 50° percentile (mediana)\nqunif(0.5, min = 0, max = 360)  \n#&gt; [1] 180",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_cont_rv_distr.html#la-distribuzione-esponenziale",
    "href": "chapters/probability/14_cont_rv_distr.html#la-distribuzione-esponenziale",
    "title": "15  Distribuzioni di v.c. continue",
    "section": "\n15.3 La Distribuzione Esponenziale",
    "text": "15.3 La Distribuzione Esponenziale\nLa distribuzione esponenziale è una distribuzione continua fondamentale per modellare il tempo di attesa fino al verificarsi di un evento casuale. La sua caratteristica distintiva è la proprietà di assenza di memoria, che la rende unica nel panorama delle distribuzioni probabilistiche.\n\n15.3.1 La proprietà di assenza di memoria: un concetto chiave\nL’assenza di memoria implica che la probabilità che un evento si verifichi in un intervallo futuro è indipendente dal tempo già trascorso.\nEsempio intuitivo:\nimmaginiamo una persona che sperimenta attacchi di ansia improvvisi, il cui tempo tra un episodio e il successivo segue una distribuzione esponenziale. Se l’individuo non ha avuto un attacco nelle ultime 2 settimane, la probabilità che ne sperimenti uno nei prossimi 3 giorni è identica a quella di una persona appena uscita da un episodio, nel medesimo intervallo di 3 giorni.\nQuesta analogia illustra la proprietà di assenza di memoria: il “tempo trascorso dall’ultimo evento” (in questo caso, un attacco di ansia) non influenza la probabilità futura. Il sistema non “accumula stress” né riduce il rischio col passare del tempo senza episodi, riflettendo dinamiche tipiche di processi psicologici non legati a meccanismi di apprendimento o adattamento.\nParametri chiave nell’esempio:\n\n\n\\(\\lambda\\) (tasso): Frequenza media degli attacchi (es. 0.1 episodi/giorno).\n\n\\(\\mu = 1/\\lambda\\) (media): Tempo medio tra due episodi (es. 10 giorni).\n\nLa distribuzione esponenziale modellizza così situazioni in cui il comportamento è puramente stocastico e non influenzato dalla storia precedente, come certi pattern di ansia, impulsività o reazioni fisiologiche a stimoli neutri.\n\n15.3.2 Struttura matematica: PDF e parametri\nLa funzione di densità di probabilità (PDF) di una variabile \\(X \\sim \\text{Exp}(\\lambda)\\) è:\n\\[\nf(x) =\n\\begin{cases}\n\\lambda e^{-\\lambda x} & \\text{se } x \\geq 0, \\\\\n0 & \\text{altrimenti},\n\\end{cases}\n\\]\ndove:\n\n\n\\(\\lambda\\) (tasso): numero medio di eventi per unità di tempo (es. 0.25 episodi/ora).\n\n\n\\(\\mu = 1/\\lambda\\) (media): tempo medio di attesa per l’evento (es. 4 ore/episodio).\n\nForma alternativa con \\(\\mu\\):\n\\[\nf(x) = \\frac{1}{\\mu} e^{-x/\\mu} \\quad \\text{per } x \\geq 0.\n\\]\n\n15.3.3 Proprietà fondamentali\nPer \\(X \\sim \\text{Exp}(\\lambda)\\):\n\n\n\n\n\n\n\nProprietà\nFormula\nInterpretazione\n\n\n\nValore atteso (μ)\n\\(E(X) = \\frac{1}{\\lambda}\\)\nTempo medio di attesa per l’evento.\n\n\nVarianza\n\\(\\text{Var}(X) = \\frac{1}{\\lambda^2}\\)\nDispersione cresce col quadrato di 1/λ.\n\n\nDeviazione standard\n\\(\\sigma_X = \\frac{1}{\\lambda}\\)\nSpread lineare attorno alla media.\n\n\n\nEsempio applicato.\nSe il tempo medio di pubblicazione dei voti di un esame universitario è \\(\\mu = 4\\) giorni (\\(\\lambda = 0.25\\)), la PDF è:\n\\[\nf(x) = \\frac{1}{4} e^{-x/4} \\quad (x \\geq 0).\n\\]\n\n15.3.4 Visualizzazione della densità in R\n\n# Definizione dei parametri\nmu &lt;- 4\nlambda &lt;- 1 / mu  # 0.25\n\n# Generazione dei punti per il grafico\nx &lt;- seq(0, 20, by = 0.1)\npdf &lt;- dexp(x, rate = lambda)\n\n# Creazione del grafico\nggplot(data.frame(x = x, y = pdf), aes(x = x, y = y)) +\n  geom_line(linewidth = 1.2, color = \"darkblue\") +\n  labs(\n    x = \"Tempo di attesa (giorni)\", \n    y = \"Densità f(x)\",\n    title = paste(\"PDF esponenziale (μ =\", mu, \"giorni)\")\n  ) \n\n\n\n\n\n\n\nIl grafico mostra un decadimento esponenziale: la probabilità decresce rapidamente all’aumentare del tempo.\n\n15.3.5 Calcolo delle Probabilità: Tre Scenari\n1. Probabilità cumulativa: \\(P(X \\leq 1.5)\\) – qual è la probabilità che il voto venga pubblicato entro un giorno e mezzo?\nUtilizziamo la funzione di ripartizione (CDF):\n\\[\nP(X \\leq 1.5) = 1 - e^{-\\lambda \\cdot 1.5} = 1 - e^{-0.25 \\cdot 1.5} \\approx 0.312.\n\\]\nCodice R:\n\npexp(1.5, rate = lambda)  # Restituisce 0.312\n#&gt; [1] 0.313\n\nVisualizzazione:\n\n# Area sotto la curva per X &lt;= 1.5\nggplot(data.frame(x = x, y = pdf), aes(x = x, y = y)) +\n  geom_line(linewidth = 1.2, color = \"darkblue\") +\n  geom_area(\n    data = subset(data.frame(x, y = pdf), x &lt;= 1.5),\n    aes(x = x, y = y), \n    fill = \"gray\", \n    alpha = 0.5\n  ) +\n  labs(\n    x = \"Tempo (giorni)\", \n    y = \"Densità\",\n    title = \"Probabilità P(X ≤ 1.5)\"\n  )\n\n\n\n\n\n\n\n2. Probabilità intervallo: \\(P(1 \\leq X \\leq 6)\\) – qual è la probabilità che il voto venga pubblicato in un intervallo compreso tra 1 e 6 giorni dopo l’esame?\nCalcoliamo la differenza tra due CDF:\n\\[\nP(1 \\leq X \\leq 6) = F(6) - F(1) = e^{-0.25 \\cdot 1} - e^{-0.25 \\cdot 6} \\approx 0.491.\n\\]\nCodice R:\n\npexp(6, rate = lambda) - pexp(1, rate = lambda)  # 0.491\n#&gt; [1] 0.556\n\nVisualizzazione:\n\n# Area per 1 &lt;= X &lt;= 6\nggplot(data.frame(x = x, y = pdf), aes(x = x, y = y)) +\n  geom_line(linewidth = 1.2, color = \"darkblue\") +\n  geom_area(\n    data = subset(data.frame(x, y = pdf), x &gt;= 1 & x &lt;= 6),\n    aes(x = x, y = y), \n    fill = \"gray\", \n    alpha = 0.5\n  ) +\n  labs(\n    x = \"Tempo (giorni)\", \n    y = \"Densità\",\n    title = \"Probabilità P(1 ≤ X ≤ 6)\"\n  )\n\n\n\n\n\n\n\n3. Probabilità della coda: \\(P(X \\geq 5.5)\\) – qual è la probabilità di un ritardo nella pubblicazione del voto superiore a 5.5 giorni dall’esame?\nUsiamo il complemento della CDF:\n\\[\nP(X \\geq 5.5) = 1 - P(X \\leq 5.5) = e^{-0.25 \\cdot 5.5} \\approx 0.252.\n\\]\nCodice R:\n\n1 - pexp(5.5, rate = lambda)  # 0.252\n#&gt; [1] 0.253\n# Alternativa equivalente:\npexp(5.5, rate = lambda, lower.tail = FALSE)\n#&gt; [1] 0.253\n\nVisualizzazione:\n\n# Area per X &gt;= 5.5\nggplot(data.frame(x = x, y = pdf), aes(x = x, y = y)) +\n  geom_line(linewidth = 1.2, color = \"darkblue\") +\n  geom_area(\n    data = subset(data.frame(x, y = pdf), x &gt;= 5.5),\n    aes(x = x, y = y), \n    fill = \"gray\", \n    alpha = 0.5\n  ) +\n  labs(\n    x = \"Tempo (giorni)\", \n    y = \"Densità\",\n    title = \"Probabilità P(X ≥ 5.5)\"\n  )\n\n\n\n\n\n\n\n\n15.3.6 Simulazione e convergenza alla teoria\nGeneriamo 1,000,000 di osservazioni da \\(\\text{Exp}(\\lambda = 0.25)\\) e confrontiamo l’istogramma con la PDF teorica:\n\nset.seed(123)\nsimulated_data &lt;- rexp(1e6, rate = lambda)\n\nggplot(data.frame(x = simulated_data), aes(x = x)) +\n  geom_histogram(\n    aes(y = after_stat(density)), \n    bins = 100, \n    fill = \"skyblue\", \n    color = \"black\",\n    alpha = 0.6\n  ) +\n  geom_line(\n    data = data.frame(x = x, y = pdf),\n    aes(x = x, y = y), \n    color = \"red\", \n    linewidth = 1.2\n  ) +\n  coord_cartesian(xlim = c(0, 20)) +  # Escludiamo code estreme\n  labs(\n    x = \"Tempo di attesa (giorni)\", \n    y = \"Densità\",\n    title = \"Dati simulati e PDF teorica\"\n  ) \n\n\n\n\n\n\n\nL’istogramma si allinea perfettamente alla curva rossa, dimostrando la Legge dei Grandi Numeri.\n\n15.3.7 Funzioni R per la distribuzione esponenziale\nR offre quattro funzioni essenziali:\n\n\n\n\n\n\n\n\nFunzione\nDescrizione\nEsempio d’uso\nOutput Esempio\n\n\n\ndexp()\nCalcola la densità \\(f(x)\\)\n\ndexp(2, rate = 0.25)\n0.1516\n\n\npexp()\nCalcola la CDF \\(P(X \\leq x)\\)\n\npexp(4, rate = 0.25)\n0.632 (≈1 - e⁻¹)\n\n\nqexp()\nTrova il quantile \\(x\\) per una probabilità\nqexp(0.5, rate = 0.25)\n~2.773 (mediana)\n\n\nrexp()\nGenera valori casuali\nrexp(5, rate = 0.25)\n[3.1, 0.8, 5.2, …]",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_cont_rv_distr.html#distribuzione-normale",
    "href": "chapters/probability/14_cont_rv_distr.html#distribuzione-normale",
    "title": "15  Distribuzioni di v.c. continue",
    "section": "\n15.4 Distribuzione Normale",
    "text": "15.4 Distribuzione Normale\nLa distribuzione normale (o gaussiana) è fondamentale in statistica per modellare fenomeni naturali, sociali e psicologici. La sua importanza deriva dal Teorema del Limite Centrale, che garantisce la convergenza alla normalità per somme di variabili casuali indipendenti.\n\n15.4.1 La Famiglia delle Distribuzioni Normali\nOgni distribuzione normale è definita da due parametri:\n\n\n\\(\\mu\\) (media): centro della distribuzione;\n\n\n\\(\\sigma\\) (deviazione standard): dispersione dei dati attorno alla media.\n\nLa funzione di densità è:\n\\[\nf(y; \\mu, \\sigma) = \\frac{1}{\\sigma\\sqrt{2\\pi}} e^{-\\frac{(y - \\mu)^2}{2\\sigma^2}}.\n\\tag{15.1}\\]\n\n15.4.2 Distribuzione Normale Standardizzata\nLa normale standardizzata è un caso speciale con \\(\\mu = 0\\) e \\(\\sigma = 1\\). Qualsiasi variabile \\(Y \\sim \\mathcal{N}(\\mu, \\sigma)\\) può essere standardizzata tramite:\n\\[\nZ = \\frac{Y - \\mu}{\\sigma}.\n\\tag{15.2}\\]\nQuesta trasformazione preserva la forma della distribuzione ma riporta i valori in unità di deviazione standard (Z-score), permettendo confronti universali.\n\n15.4.2.1 Relazione tra Deviazione Standard e Distribuzione\nLa regola empirica 68-95-99.7 vale per tutte le distribuzioni normali, indipendentemente da \\(\\mu\\) e \\(\\sigma\\):\n\n\n68.3% dei dati cade entro \\(\\pm 1\\sigma\\) dalla media;\n\n\n95.4% entro \\(\\pm 2\\sigma\\);\n\n\n99.7% entro \\(\\pm 3\\sigma\\).\n\nPer intervalli specifici legati a test statistici:\n\n\n\\(\\pm 1.96\\sigma\\) copre il 95% dei dati (intervallo di confidenza al 95%);\n\n\\(\\pm 2.576\\sigma\\) copre il 99% (intervallo al 99%).\n\n15.4.3 Origini storiche e connessione alla binomiale\nAbraham de Moivre osservò che distribuzioni binomiali con \\(n\\) elevato approssimano una normale. Ad esempio:\n\ncon \\(n=10\\) e \\(p=0.9\\), la distribuzione è asimmetrica;\ncon \\(n=1000\\), la forma diventa simmetrica e campanulare.\n\n15.4.4 Simulazione di Passeggiate Casuali\nLa distribuzione normale emerge naturalmente come risultato della somma di un gran numero di effetti casuali indipendenti, un principio formalizzato dal Teorema del Limite Centrale. Questo la rende ideale per modellare:\n\n\nerrori di misurazione, dove piccole fluttuazioni casuali (strumentali, ambientali, umane) si combinano;\n\n\nfenomeni biologici multifattoriali come altezza, peso o QI, influenzati da decine di fattori genetici, ambientali e nutrizionali che interagiscono in modo additivo;\n\n\nprocessi sociali come i punteggi dei test, dove il risultato finale è il prodotto cumulativo di abilità innate, studio, stato emotivo e altro.\n\nSimulazione con passeggiate casuali\nPer visualizzare concretamente questo fenomeno, consideriamo una passeggiata casuale unidimensionale semplificata:\n\n\nImpostazione:\n\n1,000 partecipanti partono dalla posizione 0;\n\nogni partecipante compie 16 passi consecutivi;\n\nogni passo è determinato da un generatore casuale che assegna uno spostamento compreso tra -1 e +1 unità (simulando l’effetto di piccole perturbazioni indipendenti).\n\n\n\nDinamica:\nla posizione finale di ciascun partecipante è la somma algebrica degli spostamenti casuali. Nonostante ogni passo individuale segua una distribuzione uniforme, la posizione finale aggregata di tutti i partecipanti mostrerà una distribuzione a campana tipica della normale.\n\n\n# Parametri\nnumero_passi &lt;- 16\nripetizioni &lt;- 1000\n\n# Generazione di passeggiate casuali\nset.seed(123)\nx &lt;- matrix(0, nrow = numero_passi + 1, ncol = ripetizioni)\n\nfor (i in 1:ripetizioni) {\n  passi &lt;- runif(numero_passi, min = -1, max = 1)\n  x[-1, i] &lt;- cumsum(passi)\n}\n\n# Grafico delle passeggiate casuali\ndf &lt;- data.frame(\n  Passo = rep(0:numero_passi, times = ripetizioni), \n  Distanza = as.vector(x)\n)\n\nggplot(\n  df, \n  aes(\n    x = Passo, \n    y = Distanza, \n    group = rep(1:ripetizioni, each = numero_passi + 1))\n  ) +\n  geom_line(color = \"blue\", alpha = 0.05) +\n  labs(\n    title = \"Passeggiate Casuali\", \n    x = \"Numero di Passi\", y = \"Distanza dall'Origine\"\n  )\n\n\n\n\n\n\n\n\n# Codice di simulazione (esempio concettuale)  \nset.seed(123)  \nn_partecipanti &lt;- 1000  \nn_passi &lt;- 16  \n\n# Genera spostamenti casuali (-1 a +1)  \nspostamenti &lt;- matrix(runif(n_partecipanti * n_passi, min = -1, max = 1), ncol = n_passi)  \n\n# Calcola le posizioni finali  \nposizioni_finali &lt;- rowSums(spostamenti)  \n\n# Visualizzazione  \nggplot(data.frame(Posizione = posizioni_finali), aes(x = Posizione)) +  \n  geom_histogram(aes(y = after_stat(density)), bins = 30, fill = \"lightblue\", alpha = 0.7) +  \n  stat_function(fun = dnorm, args = list(mean = mean(posizioni_finali), sd = sd(posizioni_finali)), color = \"red\", linewidth = 1) +  \n  labs(title = \"Distribuzione delle posizioni finali\", x = \"Posizione\", y = \"Densità\")  \n\n\n\n\n\n\n\nRisultato atteso:\nl’istogramma delle posizioni finali aderirà alla curva rossa (normale teorica), dimostrando come la combinazione di piccole variazioni casuali produca una distribuzione gaussiana, anche partendo da passi non-normali. Questo esperimento illustra l’onnipresenza della normale in contesti reali governati da molteplici fattori indipendenti.\nPerché 16 passi?\nLa scelta di 16 passi non è arbitraria:\n\nun numero ridotto di passi (es. 3-5) produrrebbe una distribuzione ancora vicina all’uniforme;\ncon 16 passi, la simmetria e la curvatura tipica della gaussiana diventano chiaramente riconoscibili senza richiedere simulazioni massicce.\n\n15.4.5 Proprietà fondamentali\n\n\nMedia: \\(\\mathbb{E}(Y) = \\mu\\);\n\n\nVarianza: \\(\\mathbb{V}(Y) = \\sigma^2\\).\n\n15.4.6 Funzioni R per la Normale\n\n\n\n\n\n\n\nFunzione\nDescrizione\nEsempio\n\n\n\ndnorm()\nDensità a un punto \\(y\\)\n\ndnorm(115, mean=100, sd=15)\n\n\npnorm()\nProbabilità cumulativa \\(P(Y \\leq y)\\)\n\npnorm(115, mean=100, sd=15)\n\n\nqnorm()\nQuantile per una probabilità \\(p\\)\n\nqnorm(0.975, mean=100, sd=15)\n\n\nrnorm()\nGenera valori casuali\nrnorm(10, mean=100, sd=15)\n\n\n\n15.4.7 Visualizzazione delle aree critiche\nLe aree sotto la curva corrispondenti a \\(\\pm 1\\sigma\\), \\(\\pm 1.96\\sigma\\), e \\(\\pm 3\\sigma\\) possono essere visualizzate in R:\n\n# Esempio per ±1.96σ (95% di confidenza)  \nmu &lt;- 100  \nsigma &lt;- 15  \nx &lt;- seq(mu - 4*sigma, mu + 4*sigma, length.out=1000)  \ndf &lt;- data.frame(x=x, pdf=dnorm(x, mu, sigma))  \n\nggplot(df, aes(x=x, y=pdf)) +  \n  geom_line(color=\"blue\") +  \n  geom_area(data=subset(df, x &gt;= mu - 1.96*sigma & x &lt;= mu + 1.96*sigma),  \n            fill=\"gray\", alpha=0.5) +  \n  labs(title=\"95% dei dati entro ±1.96σ\", x=\"Valori\", y=\"Densità\")  \n\n\n\n\n\n\n\nIn sintesi, la distribuzione normale standardizzata permette di standardizzare qualsiasi fenomeno Gaussiano, rendendo confrontabili dati eterogenei. La relazione tra deviazioni standard e aree sottese è universale: indipendentemente dalla media e varianza originale, il 68-95-99.7% dei dati cadrà sempre entro 1-2-3σ.\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nUna psicologa vuole studiare i livelli di ansia tra gli studenti universitari durante la settimana degli esami. Dalle ricerche precedenti si sa che nella popolazione universitaria:\n\nil punteggio medio di ansia è di 50 punti su una scala da 0 a 100;\nla deviazione standard dei punteggi di ansia è 10 punti.\n\nLa psicologa decide di estrarre un campione casuale di 25 studenti.\nVogliamo usare la distribuzione campionaria della media per rispondere a due domande:\n\nQual è la probabilità di ottenere una media campionaria maggiore di 54 punti?\nQuale media campionaria rappresenta il 95° percentile della distribuzione campionaria?\n\n📘 Concetti chiave.\nLa distribuzione campionaria della media ha:\n\nla stessa media della popolazione (\\(\\mu\\)),\nuna deviazione standard più piccola, detta errore standard della media (SE):\n\n\\[\nSE = \\frac{\\sigma}{\\sqrt{n}} = \\frac{10}{\\sqrt{25}} = 2 .\n\\]\nUseremo due funzioni importanti in R:\n\n\ndnorm(x, mean, sd): calcola la densità della normale in un punto \\(x\\).\n\nqnorm(p, mean, sd): calcola il valore di \\(x\\) corrispondente a una certa probabilità cumulativa \\(p\\).\n\n✅ Codice base.\n\n# Parametri della popolazione e del campione\nmu &lt;- 50       # media della popolazione\nsigma &lt;- 10    # deviazione standard\nn &lt;- 25        # dimensione campione\n\n# Errore standard della media\nSE &lt;- sigma / sqrt(n)\nSE\n#&gt; [1] 2\n\n🔍 Domanda 1: Probabilità di ottenere una media &gt; 54.\n\n# Probabilità che la media campionaria sia maggiore di 54\np_oltre_54 &lt;- pnorm(54, mean = mu, sd = SE, lower.tail = FALSE)\np_oltre_54\n#&gt; [1] 0.0228\n\nLa probabilità è molto bassa. Questo vuol dire che, se la vera media della popolazione fosse 50, ottenere una media campionaria superiore a 54 sarebbe raro.\n🔍 Domanda 2: Media al 95° percentile.\n\n# Calcolo del valore soglia al 95° percentile\nq_95 &lt;- qnorm(0.95, mean = mu, sd = SE)\nq_95\n#&gt; [1] 53.3\n\nAll’interno della distribuzione campionaria, solo il 5% dei campioni ha una media superiore a questo valore.\n📊 Grafico 1: Probabilità di media &gt; 54\n\n# Dati per la distribuzione normale\nx_vals &lt;- seq(44, 56, length.out = 300)\ndens_vals &lt;- dnorm(x_vals, mean = mu, sd = SE)\ndf &lt;- data.frame(x = x_vals, y = dens_vals)\n\n# Grafico\nggplot(df, aes(x, y)) +\n  geom_line(color = \"black\") +\n  geom_area(data = subset(df, x &gt;= 54), aes(x, y), fill = \"red\", alpha = 0.4) +\n  geom_vline(xintercept = 54, color = \"red\", linetype = \"dashed\") +\n  labs(\n    title = \"Distribuzione campionaria della media (n = 25)\",\n    subtitle = \"Area rossa = P(media &gt; 54)\",\n    x = \"Media campionaria\",\n    y = \"Densità\"\n  ) \n\n\n\n\n\n\n\n📊 Grafico 2: Valore al 95° percentile\n\n# Grafico con il 95° percentile evidenziato\nggplot(df, aes(x, y)) +\n  geom_line(color = \"black\") +\n  geom_area(data = subset(df, x &lt;= q_95), aes(x, y), fill = \"blue\", alpha = 0.4) +\n  geom_vline(xintercept = q_95, color = \"blue\", linetype = \"dashed\") +\n  labs(\n    title = \"Distribuzione campionaria della media (n = 25)\",\n    subtitle = \"Area blu = 95% dei campioni (valore critico ≈ 53.29)\",\n    x = \"Media campionaria\",\n    y = \"Densità\"\n  ) \n\n\n\n\n\n\n\nDomande di approfondimento.\n\nPerché l’errore standard della media è più piccolo della deviazione standard della popolazione?\nSe la dimensione del campione aumentasse a 100, come cambierebbe l’errore standard?\nChe cosa rappresenta pnorm(54, ...) nel nostro contesto?\nIn quali casi, in psicologia, potresti voler calcolare il 95° percentile di una distribuzione campionaria?\n\nSimulazione Monte Carlo.\nSimuliamo 10.000 campioni casuali, ciascuno di 25 studenti, estratti da una popolazione normale con media = 50 e deviazione standard = 10. Per ogni campione calcoliamo la media. Alla fine, visualizziamo la distribuzione di queste medie.\n\nset.seed(123)  # per rendere la simulazione replicabile\n\n# Parametri\nmu &lt;- 50\nsigma &lt;- 10\nn &lt;- 25\nn_sim &lt;- 10000  # numero di campioni\n\n# Simulazione: 10.000 medie campionarie\ncampioni &lt;- replicate(n_sim, mean(rnorm(n, mean = mu, sd = sigma)))\n\n# Visualizza le prime 5 medie\nhead(campioni)\n#&gt; [1] 49.7 51.0 50.1 52.8 47.2 47.7\n\n📊 Istogramma delle medie campionarie.\n\n\ndf_sim &lt;- data.frame(media_campionaria = campioni)\n\nggplot(df_sim, aes(x = media_campionaria)) +\n  geom_histogram(aes(y = ..density..), bins = 40, fill = \"lightblue\", color = \"black\") +\n  stat_function(fun = dnorm, args = list(mean = mu, sd = sigma / sqrt(n)),\n                color = \"red\", size = 1) +\n  labs(\n    title = \"Distribuzione delle medie campionarie\",\n    subtitle = \"Istogramma di 10.000 medie di campioni di 25 studenti\",\n    x = \"Media campionaria\",\n    y = \"Densità\"\n  ) \n\n\n\n\n\n\n\nCosa si osserva?\n\nLe medie non sono tutte uguali, ma si distribuiscono intorno alla media vera (50).\nLa forma della distribuzione delle medie è normale, anche se i dati originali non devono necessariamente esserlo (grazie al Teorema del Limite Centrale).\nLa deviazione standard della distribuzione simulata è vicina all’errore standard teorico:\n\n\n# Confronto tra errore standard teorico e osservato\nSE_teorico &lt;- sigma / sqrt(n)\nSE_osservato &lt;- sd(campioni)\n\nc(SE_teorico = SE_teorico, SE_osservato = SE_osservato)\n#&gt;   SE_teorico SE_osservato \n#&gt;         2.00         1.97\n\nDomande di approfondimento.\n\nPerché la forma dell’istogramma è simile a una curva normale?\nCosa succederebbe alla larghezza della distribuzione se aumentassimo la dimensione del campione?\nSe la media osservata in un esperimento reale fosse fuori dalla zona centrale, come potremmo interpretarla?\n\n\n\n\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nConsideriamo un esercizio in cui si utilizza la distribuzione normale e si consultano le tavole della normale standard (z) per risolvere il problema dopo la standardizzazione.\nIn uno studio su un campione di 600 studenti universitari, i punteggi ottenuti a un test di ansia da esame seguono una distribuzione normale con media \\(\\mu = 50\\) e deviazione standard \\(\\sigma = 10\\).\n\nQual è la probabilità che uno studente scelto a caso ottenga un punteggio inferiore a 65?\nQual è la percentuale di studenti che ottengono un punteggio compreso tra 45 e 60?\nQual è il punteggio minimo che uno studente deve ottenere per rientrare nel 10% superiore della distribuzione?\n\n1. Probabilità che \\(X &lt; 65\\).\nStandardizziamo:\n\\[\nZ = \\frac{X - \\mu}{\\sigma} = \\frac{65 - 50}{10} = \\frac{15}{10} = 1.5 .\n\\]\nCerchiamo \\(P(Z &lt; 1.5)\\) nella tavola della normale standard:\n\\[\nP(Z &lt; 1.5) \\approx 0.9332 .\n\\]\nRisposta: La probabilità che uno studente ottenga meno di 65 è circa 93.32%.\n2. Probabilità che \\(45 &lt; X &lt; 60\\).\nCalcoliamo gli z-score:\n\\[\nZ_1 = \\frac{45 - 50}{10} = -0.5 \\quad ; \\quad Z_2 = \\frac{60 - 50}{10} = 1.0 .\n\\]\nCerchiamo nelle tavole:\n\n\\(P(Z &lt; 1.0) \\approx 0.8413\\)\n\\(P(Z &lt; -0.5) \\approx 0.3085\\)\n\nQuindi:\n\\[\nP(45 &lt; X &lt; 60) = P(Z &lt; 1.0) - P(Z &lt; -0.5) = 0.8413 - 0.3085 = 0.5328\n\\]\nRisposta: Circa il 53.28% degli studenti ha un punteggio tra 45 e 60.\n3. Punteggio minimo per rientrare nel 10% superiore.\nIl 10% superiore corrisponde a:\n\\[\nP(Z &gt; z) = 0.10 \\Rightarrow P(Z &lt; z) = 0.90 .\n\\]\nDalla tavola:\\(P(Z &lt; 1.28) \\approx 0.8997\\),\\(P(Z &lt; 1.29) \\approx 0.9015\\)\nPrendiamo \\(z = 1.28\\)\nOra risolviamo per \\(X\\):\n\\[\nX = z \\cdot \\sigma + \\mu = 1.28 \\cdot 10 + 50 = 62.8\n\\]\nRisposta: Il punteggio minimo per rientrare nel 10% superiore è circa 62.8.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_cont_rv_distr.html#distribuzione-chi-quadrato",
    "href": "chapters/probability/14_cont_rv_distr.html#distribuzione-chi-quadrato",
    "title": "15  Distribuzioni di v.c. continue",
    "section": "\n15.5 Distribuzione Chi-Quadrato",
    "text": "15.5 Distribuzione Chi-Quadrato\nLa distribuzione \\(\\chi^2\\) deriva dalla distribuzione normale e descrive la somma dei quadrati di \\(k\\) variabili casuali indipendenti e identicamente distribuite (i.i.d.) che seguono la distribuzione normale standard \\(\\mathcal{N}(0, 1)\\). Una variabile casuale \\(\\chi^2_{~k}\\) con \\(k\\) gradi di libertà è definita come:\n\\[\nZ_1^2 + Z_2^2 + \\dots + Z_k^2,\n\\tag{15.3}\\]\ndove \\(Z_1, Z_2, \\dots, Z_k \\sim \\mathcal{N}(0, 1)\\). Il parametro \\(k\\), detto gradi di libertà (\\(\\nu\\)), determina la forma della distribuzione.\n\n15.5.1 Funzione di densità\nLa densità di probabilità della distribuzione \\(\\chi^2_{~\\nu}\\) è data da:\n\\[\nf(x) = C_{\\nu} x^{\\nu/2 - 1} \\exp(-x/2), \\quad \\text{per } x &gt; 0,\n\\tag{15.4}\\]\ndove \\(C_{\\nu}\\) è una costante di normalizzazione.\n\n15.5.2 Simulazione della Distribuzione Chi-Quadrato\nUtilizziamo la definizione per simulare la distribuzione \\(\\chi^2\\) con 3 gradi di libertà.\n\n# Impostare il seed per la riproducibilità\nset.seed(1234)\n\n# Generare 1000 valori casuali per 3 variabili gaussiane standard\nn &lt;- 1000\nvar1 &lt;- rnorm(n, mean = 0, sd = 1)\nvar2 &lt;- rnorm(n, mean = 0, sd = 1)\nvar3 &lt;- rnorm(n, mean = 0, sd = 1)\n\n# Calcolare la somma dei quadrati\nchi_sq_values &lt;- var1^2 + var2^2 + var3^2\n\n# Creare un dataframe per il grafico\ndata &lt;- data.frame(chi_sq_values = chi_sq_values)\n\n# Istogramma e densità teorica\nggplot(data, aes(x = chi_sq_values)) +\n  geom_histogram(\n    aes(y = after_stat(density)), \n    bins = 30, fill = \"lightblue\", color = \"black\", alpha = 0.7\n    ) +\n  stat_function(fun = dchisq, args = list(df = 3), color = \"red\", size = 1) +\n  labs(\n    title = \"Distribuzione Chi-Quadrato (df = 3)\",\n    x = \"Valore\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\n\nL’istogramma rappresenta i valori empirici simulati;\nla curva rossa rappresenta la densità teorica della distribuzione \\(\\chi^2_{~3}\\).\n\n15.5.3 Media e Varianza Empiriche\nCalcoliamo la media e la varianza dei valori simulati:\n\n# Media empirica\nmean(chi_sq_values)\n#&gt; [1] 2.98\n\n# Varianza empirica\nvar(chi_sq_values)\n#&gt; [1] 5.97\n\nQuesti valori possono essere confrontati con le proprietà teoriche della distribuzione \\(\\chi^2\\):\n\n\nmedia: \\(\\nu = 3\\);\n\nvarianza: \\(2\\nu = 6\\).\n\n15.5.4 Grafico per Diversi Gradi di Libertà\nConfrontiamo le distribuzioni \\(\\chi^2\\) per diversi valori di \\(\\nu\\).\n\n# Intervallo di x\nx &lt;- seq(0, 40, by = 0.1)\n\n# Gradi di libertà\nnus &lt;- c(2, 4, 8, 16)\n\n# Creare un dataframe\ndata &lt;- do.call(rbind, lapply(nus, function(nu) {\n  data.frame(x = x, f_x = dchisq(x, df = nu), nu = as.factor(nu))\n}))\n\n# Grafico\nggplot(data, aes(x = x, y = f_x, color = nu)) +\n  geom_line(size = 1) +\n  labs(\n    x = \"x\",\n    y = \"f(x)\",\n    color = expression(nu)\n  ) \n\n\n\n\n\n\n\n\n15.5.5 Proprietà della Distribuzione Chi-Quadrato\n\n\nAsimmetria: La distribuzione \\(\\chi^2_{\\nu}\\) è asimmetrica, ma diventa più simmetrica al crescere di \\(\\nu\\).\n\nMedia: \\(\\mathbb{E}[\\chi^2_{\\nu}] = \\nu\\).\n\nVarianza: \\(\\mathbb{V}[\\chi^2_{\\nu}] = 2\\nu\\).\n\nConvergenza: Per \\(\\nu \\to \\infty\\), \\(\\chi^2_{\\nu} \\to \\mathcal{N}(\\nu, 2\\nu)\\).\n\nSomma: La somma di variabili \\(\\chi^2\\) indipendenti con gradi di libertà \\(\\nu_1, \\nu_2, \\dots, \\nu_k\\) segue una distribuzione \\(\\chi^2\\) con \\(\\nu = \\sum_{i=1}^k \\nu_i\\).\n\n15.5.6 Applicazioni\nLa distribuzione \\(\\chi^2\\) è utilizzata in molteplici ambiti statistici, tra cui:\n\n\ntest di indipendenza: per verificare se due variabili categoriche sono indipendenti;\n\ntest di adattamento: per confrontare una distribuzione empirica con una teorica.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_cont_rv_distr.html#distribuzione-t-di-student",
    "href": "chapters/probability/14_cont_rv_distr.html#distribuzione-t-di-student",
    "title": "15  Distribuzioni di v.c. continue",
    "section": "\n15.6 Distribuzione \\(t\\) di Student",
    "text": "15.6 Distribuzione \\(t\\) di Student\nLa distribuzione \\(t\\) di Student è una delle distribuzioni fondamentali della statistica inferenziale. Deriva dalle distribuzioni Normale e Chi-quadrato ed è particolarmente utile per analizzare campioni di piccole dimensioni o situazioni in cui la varianza della popolazione è sconosciuta.\n\n15.6.1 Definizione Formale\nSe:\n\n\n\\(Z \\sim \\mathcal{N}(0, 1)\\) (distribuzione Normale standard),\n\n\\(W \\sim \\chi^2_{\\nu}\\) (distribuzione Chi-quadrato con \\(\\nu\\) gradi di libertà),\n\ne \\(Z\\) e \\(W\\) sono indipendenti, allora la variabile casuale\n\\[\nT = \\frac{Z}{\\sqrt{\\frac{W}{\\nu}}}\n\\tag{15.5}\\]\nsegue una distribuzione \\(t\\) di Student con \\(\\nu\\) gradi di libertà. Si indica come \\(T \\sim t_{\\nu}\\).\n\n15.6.2 Proprietà della Distribuzione \\(t\\) di Student\n\n\nForma della distribuzione:\n\nla distribuzione \\(t\\) è simmetrica rispetto a zero, come la Normale standard (\\(\\mathcal{N}(0, 1)\\));\npresenta code più pesanti rispetto alla Normale, riflettendo una maggiore probabilità di osservare valori estremi.\n\n\n\nCode pesanti e gradi di libertà:\n\nla pesantezza delle code diminuisce con l’aumentare dei gradi di libertà (\\(\\nu\\));\nper \\(\\nu \\to \\infty\\), la distribuzione \\(t\\) converge alla distribuzione Normale standard.\n\n\n\nMedia e varianza:\n\nla media è \\(0\\) per \\(\\nu &gt; 1\\);\n\nla varianza è:\n\\[\n\\text{Var}(T) = \\frac{\\nu}{\\nu - 2}, \\quad \\text{per } \\nu &gt; 2.\n\\]\nPer \\(\\nu \\leq 2\\), la varianza non è definita.\n\n\n\n\nApplicazioni principali:\n\n\ntest t di Student: Confronto delle medie di due gruppi o test per una singola media;\n\nintervalli di confidenza: Stima dell’intervallo per la media quando la varianza è sconosciuta.\n\n\n\n15.6.3 Differenze tra la Distribuzione \\(t\\) e la Normale\n\n\n\n\n\n\n\nCaratteristica\nDistribuzione Normale\nDistribuzione \\(t\\) di Student\n\n\n\nForma\nSimmetrica, a campana\nSimmetrica, a campana\n\n\nCode\nSottili\nPesanti\n\n\nDipendenza dai gradi di libertà\nNo\nSì\n\n\nConvergenza\nNon varia\nCon \\(\\nu \\to \\infty\\), converge alla Normale\n\n\n\n15.6.4 Visualizzazione della Distribuzione \\(t\\)\n\nConfrontiamo graficamente la distribuzione \\(t\\) con diversi gradi di libertà e la distribuzione Normale standard:\n\n# Creazione dei dati\nx &lt;- seq(-4, 4, length.out = 1000)\ndf &lt;- c(1, 2, 5, 10)  # Gradi di libertà\n\n# Dataframe con curve di densità\ndata &lt;- data.frame(\n  x = rep(x, length(df) + 1),\n  density = c(\n    dnorm(x),\n    dt(x, df[1]),\n    dt(x, df[2]),\n    dt(x, df[3]),\n    dt(x, df[4])\n  ),\n  distribution = rep(c(\"Normale\", paste(\"t (df =\", df, \")\")), each = length(x))\n)\n\n# Plot\nggplot(data, aes(x = x, y = density, color = distribution)) +\n  geom_line(size = 1) +\n  labs(\n    x = \"Valore\",\n    y = \"Densità\",\n    color = \"Distribuzione\"\n  ) \n\n\n\n\n\n\n\n\n15.6.5 Simulazione della Distribuzione \\(t\\)\n\nSimuliamo una distribuzione \\(t\\) con 10 gradi di libertà e confrontiamola con la densità teorica.\n\n# Impostare il seed per la riproducibilità\nset.seed(123)\n\n# Simulare 1000 valori da una distribuzione t\nn &lt;- 1000\ndf &lt;- 10  # Gradi di libertà\nt_values &lt;- rt(n, df = df)\n\n# Creare un dataframe per il grafico\ndata &lt;- data.frame(t_values = t_values)\n\n# Istogramma con densità teorica\nggplot(data, aes(x = t_values)) +\n  geom_histogram(\n    aes(y = after_stat(density)), \n    bins = 30, fill = \"lightblue\", color = \"black\", alpha = 0.7\n  ) +\n  stat_function(fun = dt, args = list(df = df), color = \"red\", size = 1) +\n  labs(\n    x = \"Valore\",\n    y = \"Densità\"\n  ) \n\n\n\n\n\n\n\n\n15.6.6 Proprietà Teoriche della Distribuzione \\(t\\)\n\n\nMedia: \\[\n\\mathbb{E}[T] = 0, \\quad \\text{per } \\nu &gt; 1.\n\\]\nVarianza: \\[\n\\mathbb{V}[T] = \\frac{\\nu}{\\nu - 2}, \\quad \\text{per } \\nu &gt; 2.\n\\]\n\nSimmetria:\n\nla distribuzione è simmetrica rispetto a zero, come la Normale.\n\n\n\nCode:\n\nle code sono più pesanti rispetto alla Normale, riflettendo una maggiore incertezza per piccoli campioni.\n\n\n\nIn conclusione, la distribuzione \\(t\\) di Student è uno strumento versatile nell’inferenza statistica, trovando applicazione in contesti sia frequentisti che bayesiani. È particolarmente utile in situazioni in cui la conoscenza della varianza è limitata o i campioni sono di dimensioni ridotte. Grazie alla sua forma simmetrica e alle code più pesanti rispetto alla distribuzione Normale, la distribuzione \\(t\\) può modellare meglio l’incertezza, includendo una maggiore probabilità per valori estremi.\nNel contesto bayesiano, la distribuzione \\(t\\) viene utilizzata come:\n\n\nprior informativo robusto, per modellare parametri con valori plausibili lontani dalla media ma con una penalizzazione graduale per valori estremi.\n\ndistribuzione predittiva per sintetizzare l’incertezza derivante da campioni piccoli o con variabilità elevata.\n\nIn entrambi i paradigmi, la distribuzione \\(t\\) rappresenta una scelta robusta, capace di riflettere in modo flessibile la natura dei dati. Inoltre, per valori elevati dei gradi di libertà, la distribuzione \\(t\\) converge alla distribuzione Normale, un caso limite che ne estende ulteriormente l’utilità in vari contesti analitici.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_cont_rv_distr.html#funzione-beta-di-eulero",
    "href": "chapters/probability/14_cont_rv_distr.html#funzione-beta-di-eulero",
    "title": "15  Distribuzioni di v.c. continue",
    "section": "\n15.7 Funzione Beta di Eulero",
    "text": "15.7 Funzione Beta di Eulero\nLa funzione Beta di Eulero è una funzione matematica, non una densità di probabilità, ma è strettamente collegata alla distribuzione Beta, poiché appare nella sua definizione. Indicata comunemente con il simbolo \\(\\mathcal{B}(\\alpha, \\beta)\\), la funzione Beta può essere espressa in vari modi. Per i nostri scopi, utilizziamo la seguente definizione:\n\\[\n\\mathcal{B}(\\alpha, \\beta) = \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)}\\,,\n\\tag{15.6}\\]\ndove \\(\\Gamma(x)\\) rappresenta la funzione Gamma, una generalizzazione del fattoriale definita per numeri reali positivi. Quando \\(x\\) è un numero intero, la funzione Gamma si riduce al fattoriale traslato:\n\\[\n\\Gamma(x) = (x-1)!.\n\\]\n\nEsempio 15.1 Supponiamo di voler calcolare \\(\\mathcal{B}(3, 9)\\). Utilizzando la definizione, abbiamo:\n\\[\n\\mathcal{B}(3, 9) = \\frac{\\Gamma(3) \\cdot \\Gamma(9)}{\\Gamma(3 + 9)}.\n\\]\nIn R, possiamo calcolarla in tre modi diversi.\n\nUtilizzando la definizione con la funzione gamma():\n\n\nalpha &lt;- 3\nbeta &lt;- 9\n\nbeta_function &lt;- gamma(alpha) * gamma(beta) / gamma(alpha + beta)\nbeta_function\n#&gt; [1] 0.00202\n\n\nUtilizzando direttamente la funzione beta() di R:\n\n\nbeta(alpha, beta)\n#&gt; [1] 0.00202\n\n\nCalcolo manuale con fattoriali:\n\n\n(factorial(alpha - 1) * factorial(beta - 1)) / factorial(alpha + beta - 1)\n#&gt; [1] 0.00202\n\nTutti e tre i metodi restituiscono lo stesso risultato, confermando la correttezza della definizione.\n\nLa funzione Beta è utilizzata nella definizione della densità di probabilità Beta. Essa serve a normalizzare la densità, garantendo che l’area sotto la curva sia pari a \\(1\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_cont_rv_distr.html#distribuzione-beta",
    "href": "chapters/probability/14_cont_rv_distr.html#distribuzione-beta",
    "title": "15  Distribuzioni di v.c. continue",
    "section": "\n15.8 Distribuzione Beta",
    "text": "15.8 Distribuzione Beta\nLa distribuzione Beta, indicata come \\(\\mathcal{Beta}(\\alpha, \\beta)\\), è una distribuzione di probabilità continua definita sull’intervallo \\((0, 1)\\). È particolarmente utile per modellare proporzioni, probabilità, o in generale qualsiasi fenomeno che assume valori compresi tra 0 e 1.\nQuesta distribuzione è molto flessibile: a seconda dei valori dei parametri \\(\\alpha\\) e \\(\\beta\\), può assumere forme simmetriche, asimmetriche, concave, convesse, ecc. È frequentemente utilizzata come distribuzione a priori nei modelli bayesiani per parametri che rappresentano probabilità.\n\n15.8.1 Definizione\n\nDefinizione 15.1 Sia \\(\\theta\\) una variabile casuale continua. Se \\(\\theta\\) segue una distribuzione Beta con parametri \\(\\alpha &gt; 0\\) e \\(\\beta &gt; 0\\), scriviamo:\n\\[\n\\theta \\sim \\mathcal{Beta}(\\alpha, \\beta),\n\\]\ne la sua funzione di densità di probabilità (pdf) è data da:\n\\[\n\\mathcal{Beta}(\\theta \\mid \\alpha, \\beta) = \\frac{1}{\\mathcal{B}(\\alpha, \\beta)} \\, \\theta^{\\alpha - 1} (1 - \\theta)^{\\beta - 1}, \\quad \\text{per } \\theta \\in (0, 1),\n\\tag{15.7}\\]\ndove \\(\\mathcal{B}(\\alpha, \\beta)\\) è la funzione Beta (o funzione beta di Eulero).\n\n\n15.8.2 Rappresentazione alternativa\nUn’espressione equivalente della densità, che mette in evidenza il legame con la funzione Gamma, è:\n\\[\n\\mathcal{Beta}(\\theta \\mid \\alpha, \\beta) = \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha) \\, \\Gamma(\\beta)} \\, \\theta^{\\alpha - 1} (1 - \\theta)^{\\beta - 1}, \\quad \\text{per } \\theta \\in (0, 1),\n\\tag{15.8}\\]\ndove \\(\\Gamma(\\cdot)\\) è la funzione Gamma, che generalizza il fattoriale: \\(\\Gamma(n) = (n - 1)!\\) per ogni intero positivo \\(n\\).\n\n15.8.3 Ruolo dei Parametri \\(\\alpha\\) e \\(\\beta\\)\n\nI parametri \\(\\alpha\\) e \\(\\beta\\) determinano la forma della distribuzione:\n\n\n\\(\\alpha &gt; 1\\): favorisce valori di \\(\\theta\\) vicini a 1.\n\n\\(\\beta &gt; 1\\): favorisce valori di \\(\\theta\\) vicini a 0.\n\n\\(\\alpha = \\beta = 1\\): corrisponde alla distribuzione uniforme sull’intervallo \\([0, 1]\\).\n\n\\(\\alpha, \\beta &lt; 1\\): la distribuzione è bimodale, concentrandosi agli estremi (vicino a 0 e 1).\n\n15.8.4 Proprietà della Distribuzione Beta\n\nValore atteso: \\[\n\\mathbb{E}(\\theta) = \\frac{\\alpha}{\\alpha + \\beta}.\n\\]\nVarianza: \\[\n\\mathbb{V}(\\theta) = \\frac{\\alpha \\beta}{(\\alpha + \\beta)^2 (\\alpha + \\beta + 1)}.\n\\]\nModa (se \\(\\alpha, \\beta &gt; 1\\)): \\[\n\\text{Moda}(\\theta) = \\frac{\\alpha - 1}{\\alpha + \\beta - 2}.\n\\]\n\nQueste proprietà evidenziano come \\(\\alpha\\) e \\(\\beta\\) possano essere interpretati come “successi” e “fallimenti” in una serie di prove, fornendo un collegamento intuitivo con la distribuzione binomiale.\n\n15.8.5 Relazione con la Distribuzione Binomiale\nLa distribuzione Beta può essere interpretata come una generalizzazione continua della distribuzione binomiale. Mentre la distribuzione binomiale descrive la probabilità di osservare un certo numero di successi in un numero fissato di prove (\\(n\\)), la distribuzione Beta descrive l’incertezza sulla probabilità di successo \\(\\theta\\) stessa, trattandola come una variabile casuale.\n\n15.8.5.1 Contesto bayesiano\nIn un contesto di inferenza bayesiana, la distribuzione Beta viene comunemente utilizzata come distribuzione a priori coniugata per il modello binomiale. Ciò significa che, se si assume una distribuzione Beta come prior per \\(\\theta\\), anche la distribuzione a posteriori (dopo aver osservato i dati) sarà una Beta, ma con parametri aggiornati.\nSupponiamo:\n\nche \\(\\theta\\) sia la probabilità di successo in un compito con esiti binari (es. risposta corretta o errata),\ndi assumere una distribuzione a priori:\\[\n\\theta \\sim \\mathcal{Beta}(\\alpha, \\beta),\n\\]\n\ne di osservare \\(y\\) successi su \\(n\\) prove, con modello di verosimiglianza: \\[\ny \\sim \\mathcal{Binom}(n, \\theta).\n\\]\n\n\nAllora, per il teorema di Bayes, la distribuzione a posteriori di \\(\\theta\\) sarà:\n\\[\n\\theta \\mid \\text{dati} \\sim \\mathcal{Beta}(\\alpha + y, \\beta + n - y).\n\\]\n\n15.8.5.2 Vantaggi della coniugatezza\nQuesto aggiornamento è particolarmente comodo perché:\n\nsi ottiene in forma chiusa (senza dover ricorrere a metodi numerici),\ni parametri \\(\\alpha\\) e \\(\\beta\\) possono essere interpretati come conteggi fittizi di successi e insuccessi prima dell’osservazione dei dati,\nl’informazione a priori e quella empirica si combinano sommando i rispettivi “conteggi.”\n\nQuesta proprietà rende la distribuzione Beta una scelta naturale nei modelli bayesiani con dati binomiali, come in contesti psicologici in cui si vogliono modellare incertezze sulla probabilità di una risposta corretta, sull’esito di una scelta, o sul successo di un comportamento.\n\n15.8.6 Visualizzazione della Distribuzione Beta\nDi seguito mostriamo come la forma della distribuzione Beta varia al variare dei parametri \\(\\alpha\\) e \\(\\beta\\):\n\n# Parametri\nx &lt;- seq(0, 1, length.out = 200)\nalphas &lt;- c(0.5, 5.0, 1.0, 2.0, 2.0)\nbetas &lt;- c(0.5, 1.0, 3.0, 2.0, 5.0)\n\n# Creare un dataframe\ndf &lt;- do.call(rbind, lapply(1:length(alphas), function(i) {\n  data.frame(\n    x = x,\n    density = dbeta(x, alphas[i], betas[i]),\n    label = paste0(\"α = \", alphas[i], \", β = \", betas[i])\n  )\n}))\n\n# Plot\nggplot(df, aes(x = x, y = density, color = label)) +\n  geom_line(size = 1) +\n  labs(\n    x = \"x\",\n    y = \"f(x)\"\n  ) +\n  theme(legend.title = element_blank())\n\n\n\n\n\n\n\n\n15.8.7 Costante di Normalizzazione\nLa costante di normalizzazione della distribuzione Beta è il reciproco della funzione Beta di Eulero, \\(B(\\alpha, \\beta)\\). Questa garantisce che:\n\\[\n\\int_0^1 \\mathcal{Beta}(\\theta \\mid \\alpha, \\beta) \\, d\\theta = 1.\n\\]\n\nEsempio 15.2 Di seguito viene proposto un esempio in R per calcolare l’area sottesa alla distribuzione Beta non normalizzata e, con gli stessi parametri, ottenere il valore della funzione Beta di Eulero. L’obiettivo è mostrare come la costante di normalizzazione, pari al reciproco di \\(B(\\alpha, \\beta)\\), garantisca che l’integrale della densità normalizzata su \\([0,1]\\) sia pari a 1.\nSupponiamo di voler utilizzare i parametri:\n\n\\(\\alpha = 2\\)\n\\(\\beta = 5\\)\n\n\n# Parametri della distribuzione Beta\nalpha &lt;- 2\nbeta  &lt;- 5\n\n# Definiamo la funzione non normalizzata della distribuzione Beta\nunnormalized_beta &lt;- function(theta) {\n  theta^(alpha - 1) * (1 - theta)^(beta - 1)\n}\n\n# Calcoliamo l'integrale della funzione non normalizzata su [0, 1]\nintegrale &lt;- integrate(unnormalized_beta, lower = 0, upper = 1)$value\ncat(\"Integrale della funzione non normalizzata:\", integrale, \"\\n\")\n#&gt; Integrale della funzione non normalizzata: 0.0333\n\n# Calcoliamo il valore della funzione Beta usando la funzione beta() di R\nvalore_beta &lt;- beta(alpha, beta)\ncat(\"Valore della funzione Beta B(alpha, beta):\", valore_beta, \"\\n\")\n#&gt; Valore della funzione Beta B(alpha, beta): 0.0333\n\nSpiegazione del Codice\n\nDefinizione dei Parametri e della Funzione\nImpostiamo \\(\\alpha = 2\\) e \\(\\beta = 5\\) e definiamo la funzione non normalizzata: \\[\nf(\\theta) = \\theta^{\\alpha-1}(1-\\theta)^{\\beta-1}.\n\\]\nCalcolo dell’Integrale\nUtilizzando la funzione integrate(), calcoliamo l’area sottesa a \\(f(\\theta)\\) nell’intervallo \\([0,1]\\), che corrisponde a \\(\\mathcal{B}(\\alpha, \\beta)\\).\nVerifica con la Funzione Beta\nLa funzione beta(alpha, beta) di R restituisce direttamente il valore di \\(\\mathcal{B}(\\alpha, \\beta)\\). La stampa dei due valori conferma che l’integrale calcolato e il valore della funzione Beta coincidono.\nCostante di Normalizzazione\nIl reciproco di \\(\\mathcal{B}(\\alpha, \\beta)\\) è calcolato e utilizzato per definire la densità normalizzata della distribuzione Beta. L’integrazione della densità normalizzata su \\([0,1]\\) restituisce 1, confermando la corretta normalizzazione.\n\nQuesto esempio in R mostra in modo pratico come la costante di normalizzazione derivi dalla funzione Beta di Eulero e come essa venga applicata per ottenere una densità di probabilità correttamente normalizzata.\n\nIn conclusione, la distribuzione Beta si rivela particolarmente utile per modellare variabili continue comprese nell’intervallo [0, 1]. Grazie alla sua parametrizzazione tramite \\(\\alpha\\) e \\(\\beta\\), consente di adattare la forma della densità in modo specifico alle caratteristiche osservate dei dati, facilitando la stima di proporzioni. Inoltre, essendo il coniugato della distribuzione binomiale, permette un aggiornamento analitico nei modelli bayesiani, semplificando l’inferenza quando si raccolgono dati incrementali, come nella stima della probabilità di successo in esperimenti o studi psicologici.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_cont_rv_distr.html#distribuzione-di-cauchy",
    "href": "chapters/probability/14_cont_rv_distr.html#distribuzione-di-cauchy",
    "title": "15  Distribuzioni di v.c. continue",
    "section": "\n15.9 Distribuzione di Cauchy",
    "text": "15.9 Distribuzione di Cauchy\nLa distribuzione di Cauchy è un caso speciale della distribuzione \\(t\\) di Student con un solo grado di libertà (\\(t_1\\)). Questa distribuzione è caratterizzata da code molto pesanti e da una media e varianza non definite, rendendola particolarmente utile in contesti dove valori estremi possono avere un’influenza importante.\n\nDefinizione 15.2 La funzione di densità di probabilità della distribuzione di Cauchy è definita da due parametri:\n\n\n\\(\\alpha\\): posizione (location), che determina il centro della distribuzione.\n\n\\(\\beta &gt; 0\\): scala (scale), che controlla la larghezza della distribuzione.\n\nLa densità è data da:\n\\[\nf(x \\mid \\alpha, \\beta) = \\frac{1}{\\pi \\beta \\left[1 + \\left( \\frac{x - \\alpha}{\\beta} \\right)^2\\right]} ,\n\\]\ndove:\n\n\n\\(x \\in \\mathbb{R}\\),\n\n\\(\\alpha \\in \\mathbb{R}\\),\n\n\\(\\beta &gt; 0\\).\n\nQuesta funzione descrive una distribuzione simmetrica attorno a \\(\\alpha\\), con code più pesanti rispetto alla distribuzione Normale.\n\n\n15.9.1 Proprietà della Distribuzione di Cauchy\n\n\nSimmetria: La distribuzione è simmetrica rispetto a \\(\\alpha\\).\n\nCode Pesanti: Le code sono significativamente più pesanti rispetto alla distribuzione Normale, con una decrescita più lenta (\\(\\propto x^{-2}\\)).\n\nMedia e Varianza: La distribuzione non ha una media né una varianza definita.\n\nRelazione con \\(t_1\\): La distribuzione di Cauchy è equivalente a una distribuzione \\(t\\) di Student con 1 grado di libertà.\n\nCaratteristiche Estreme: I valori estremi hanno una probabilità più alta rispetto ad altre distribuzioni comuni, rendendola utile per modellare fenomeni con outlier significativi.\n\n15.9.2 Visualizzazione della Distribuzione di Cauchy\nPer comprendere l’effetto dei parametri \\(\\alpha\\) e \\(\\beta\\) sulla forma della distribuzione, consideriamo alcuni esempi con:\n\n\n\\(\\alpha = 0.0, 0.0, 0.0, -2.0\\),\n\n\\(\\beta = 0.5, 1.0, 2.0, 1.0\\).\n\n\n# Definire i parametri\nx &lt;- seq(-5, 5, length.out = 500)\nalphas &lt;- c(0.0, 0.0, 0.0, -2.0)\nbetas &lt;- c(0.5, 1.0, 2.0, 1.0)\n\n# Creare un data frame per i risultati\ndf &lt;- do.call(rbind, lapply(1:length(alphas), function(i) {\n  data.frame(\n    x = x,\n    density = dcauchy(x, location = alphas[i], scale = betas[i]),\n    label = paste0(\"α = \", alphas[i], \", β = \", betas[i])\n  )\n}))\n\n# Grafico\nggplot(df, aes(x = x, y = density, color = label)) +\n  geom_line(size = 1) +\n  labs(\n    x = \"x\",\n    y = \"f(x)\"\n  ) +\n  theme(\n    legend.title = element_blank()\n  )\n\n\n\n\n\n\n\n\n15.9.3 Applicazioni della Distribuzione di Cauchy\n\n\nInferenza Bayesiana:\n\nUtilizzata come prior robusto in modelli bayesiani, particolarmente quando si vuole attribuire una probabilità maggiore a valori estremi rispetto a una distribuzione Normale.\n\n\n\nModellazione di Fenomeni con Outlier:\n\nLa distribuzione di Cauchy è adatta per descrivere dati con valori estremi significativi che possono influenzare fortemente altre distribuzioni.\n\n\n\nIn conclusione, la distribuzione di Cauchy, con le sue proprietà uniche come code pesanti e l’assenza di media e varianza definite, è uno strumento fondamentale per modellare fenomeni in cui i valori estremi giocano un ruolo importante. La sua relazione con la distribuzione \\(t\\) di Student e la sua utilità nei modelli bayesiani ne ampliano ulteriormente le applicazioni in contesti statistici e probabilistici avanzati.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_cont_rv_distr.html#distribuzione-gamma",
    "href": "chapters/probability/14_cont_rv_distr.html#distribuzione-gamma",
    "title": "15  Distribuzioni di v.c. continue",
    "section": "\n15.10 Distribuzione Gamma",
    "text": "15.10 Distribuzione Gamma\nLa distribuzione Gamma è una distribuzione di probabilità continua utilizzata principalmente per modellare variabili strettamente positive, come tassi, varianze, o tempi di attesa. È usata nella statistica bayesiana come distribuzione a priori per parametri positivi e trova applicazione in ambiti come la modellazione di eventi rari.\n\nDefinizione 15.3 La distribuzione Gamma è caratterizzata da due parametri principali:\n\n\nParametro di forma (\\(\\alpha\\)): determina la forma generale della distribuzione.\n\nParametro di scala (\\(\\theta\\)) o, alternativamente, il parametro di tasso (\\(\\beta = 1/\\theta\\)): regola la larghezza o la dispersione della distribuzione.\n\nLa funzione di densità di probabilità (PDF) è data da:\n\\[\nf(x \\mid \\alpha, \\theta) = \\frac{x^{\\alpha-1} e^{-x/\\theta}}{\\theta^\\alpha \\Gamma(\\alpha)}, \\quad x &gt; 0,\n\\]\ndove:\n\n\n\\(x\\) è la variabile casuale continua,\n\n\\(\\Gamma(\\alpha)\\) è la funzione Gamma di Eulero, definita come:\n\n\\[\n\\Gamma(\\alpha) = \\int_0^\\infty t^{\\alpha-1} e^{-t} dt.\n\\]\nSe utilizziamo il parametro di tasso \\(\\beta = 1/\\theta\\), la PDF può essere scritta come:\n\\[\nf(x \\mid \\alpha, \\beta) = \\frac{\\beta^\\alpha x^{\\alpha-1} e^{-\\beta x}}{\\Gamma(\\alpha)}, \\quad x &gt; 0.\n\\]\n\n\n15.10.1 Proprietà della Distribuzione Gamma\n\nMedia: \\[\n\\mathbb{E}[X] = \\alpha \\cdot \\theta = \\frac{\\alpha}{\\beta}.\n\\]\nVarianza: \\[\n\\text{Var}(X) = \\alpha \\cdot \\theta^2 = \\frac{\\alpha}{\\beta^2}.\n\\]\nModa (per \\(\\alpha &gt; 1\\)): \\[\n\\text{Moda}(X) = (\\alpha - 1) \\cdot \\theta.\n\\]\n\nDi seguito, mostriamo un esempio per \\(\\alpha = 3\\) e \\(\\beta = 5/3\\), calcolando e rappresentando graficamente la distribuzione.\n\n\nCalcolo della Media e della Deviazione Standard:\n\n# Parametri\nalpha &lt;- 3\nbeta &lt;- 5 / 3\n\n# Calcolo\nmean &lt;- alpha / beta\nsigma &lt;- sqrt(alpha / beta^2)\n\ncat(\"Media:\", mean, \"\\n\")\n#&gt; Media: 1.8\ncat(\"Deviazione Standard:\", sigma, \"\\n\")\n#&gt; Deviazione Standard: 1.04\n\n\n\nGenerazione e Plot dei Dati:\n\n# Generazione di dati\nset.seed(123)\ndata &lt;- rgamma(100000, shape = alpha, rate = beta)\n\n# Data frame per ggplot\ndf &lt;- data.frame(values = data)\n\n# Plot\nggplot(df, aes(x = values)) +\n  geom_histogram(aes(y = ..density..), bins = 30, fill = \"green\", alpha = 0.6) +\n  stat_function(fun = function(x) dgamma(x, shape = alpha, rate = beta),\n                color = \"red\", size = 1) +\n  labs(\n    x = \"Valore\",\n    y = \"Densità di probabilità\"\n  ) \n\n\n\n\n\n\n\n\n\n15.10.2 Applicazioni della Distribuzione Gamma\n\nModellazione del Tempo di Attesa:\nLa distribuzione Gamma è ideale per modellare tempi di attesa, ad esempio, il tempo necessario affinché si verifichino \\(n\\) eventi in un processo di Poisson.\n\nInferenza Bayesiana:\n\nUtilizzata come prior per parametri positivi, come tassi (\\(\\lambda\\)) o varianze (\\(\\sigma^2\\)).\nAd esempio, nella modellazione bayesiana dei processi di Poisson, una distribuzione Gamma è una scelta naturale per il prior su \\(\\lambda\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_cont_rv_distr.html#riflessioni-conclusive",
    "href": "chapters/probability/14_cont_rv_distr.html#riflessioni-conclusive",
    "title": "15  Distribuzioni di v.c. continue",
    "section": "\n15.11 Riflessioni conclusive",
    "text": "15.11 Riflessioni conclusive\nLe distribuzioni di probabilità costituiscono il cuore dell’inferenza statistica, sia bayesiana che frequentista. In questo capitolo, abbiamo esplorato come R offre un insieme completo di strumenti per lavorare con diverse distribuzioni, permettendo di modellare e analizzare una vasta gamma di fenomeni.\n\n15.11.1 Principali Applicazioni\n\n\nInferenza Bayesiana:\nLe distribuzioni di probabilità, come la Beta, la Gamma e la Normale, sono essenziali per definire priors, calcolare posteriori e quantificare l’incertezza nei modelli bayesiani. Ad esempio:\n\nLa distribuzione Beta è ideale per modellare credenze a priori su proporzioni o probabilità.\nLa distribuzione Gamma è ampiamente usata per modellare parametri positivi come tassi o varianze.\n\n\nAnalisi Statistica e Modellazione:\nLe distribuzioni, come la \\(t\\) di Student, sono fondamentali per il confronto tra campioni, mentre la Normale è indispensabile per modellare fenomeni che seguono la legge del limite centrale.\nGenerazione e Simulazione di Dati:\nR permette di generare campioni casuali da distribuzioni comuni, utili per simulazioni, bootstrap e validazione di modelli.\n\n15.11.2 Funzionalità di R\nCon poche funzioni, R consente di:\n\n\nGenerare campioni casuali: con funzioni come rnorm, rgamma, rbeta, possiamo simulare dati da distribuzioni specifiche.\n\nCalcolare densità: ad esempio, con dnorm, dgamma, dbeta, possiamo visualizzare le funzioni di densità.\n\nCalcolare probabilità cumulate: con funzioni come pnorm, pbeta, possiamo determinare probabilità su intervalli specifici.\n\nDeterminare quantili: con funzioni come qnorm, qgamma, possiamo calcolare i punti corrispondenti a specifici livelli di probabilità.\n\n15.11.3 Versatilità delle Distribuzioni\nLe distribuzioni esplorate non solo descrivono fenomeni naturali, ma sono anche i “mattoncini” per costruire modelli statistici complessi. Le loro proprietà, come la media, la varianza, la simmetria o le code pesanti, consentono di adattare il modello al fenomeno studiato.\nIn conclusione, il linguaggio R, con la sua flessibilità e ricchezza di strumenti, permette di padroneggiare le distribuzioni di probabilità, non solo come oggetti matematici, ma anche come strumenti pratici per rispondere a domande complesse. La comprensione e l’uso delle distribuzioni presentate costituiscono le fondamenta per avanzare verso tecniche più sofisticate, come l’inferenza bayesiana avanzata o la modellazione gerarchica.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_cont_rv_distr.html#esercizi",
    "href": "chapters/probability/14_cont_rv_distr.html#esercizi",
    "title": "15  Distribuzioni di v.c. continue",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nEsercizi sulla distribuzione normale, risolvibili usando R, sono disponibili sulla seguente pagina web.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_cont_rv_distr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/14_cont_rv_distr.html#informazioni-sullambiente-di-sviluppo",
    "title": "15  Distribuzioni di v.c. continue",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt;  [4] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt;  [7] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [10] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [13] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [16] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [25] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.8          tidyselect_1.2.1      farver_2.1.2         \n#&gt;  [4] fastmap_1.2.0         TH.data_1.1-4         tensorA_0.36.2.1     \n#&gt;  [7] digest_0.6.37         timechange_0.3.0      estimability_1.5.1   \n#&gt; [10] lifecycle_1.0.4       survival_3.8-3        magrittr_2.0.3       \n#&gt; [13] compiler_4.5.1        rlang_1.1.6           tools_4.5.1          \n#&gt; [16] knitr_1.50            labeling_0.4.3        bridgesampling_1.1-2 \n#&gt; [19] htmlwidgets_1.6.4     curl_7.0.0            pkgbuild_1.4.8       \n#&gt; [22] RColorBrewer_1.1-3    abind_1.4-8           multcomp_1.4-28      \n#&gt; [25] withr_3.0.2           purrr_1.1.0           grid_4.5.1           \n#&gt; [28] stats4_4.5.1          colorspace_2.1-1      xtable_1.8-4         \n#&gt; [31] inline_0.3.21         emmeans_1.11.2-8      scales_1.4.0         \n#&gt; [34] MASS_7.3-65           cli_3.6.5             mvtnorm_1.3-3        \n#&gt; [37] rmarkdown_2.29        ragg_1.5.0            generics_0.1.4       \n#&gt; [40] RcppParallel_5.1.11-1 cachem_1.1.0          stringr_1.5.1        \n#&gt; [43] splines_4.5.1         parallel_4.5.1        vctrs_0.6.5          \n#&gt; [46] V8_7.0.0              Matrix_1.7-4          sandwich_3.1-1       \n#&gt; [49] jsonlite_2.0.0        arrayhelpers_1.1-0    systemfonts_1.2.3    \n#&gt; [52] glue_1.8.0            codetools_0.2-20      distributional_0.5.0 \n#&gt; [55] lubridate_1.9.4       stringi_1.8.7         gtable_0.3.6         \n#&gt; [58] QuickJSR_1.8.0        htmltools_0.5.8.1     Brobdingnag_1.2-9    \n#&gt; [61] R6_2.6.1              textshaping_1.0.3     rprojroot_2.1.1      \n#&gt; [64] evaluate_1.0.5        lattice_0.22-7        backports_1.5.0      \n#&gt; [67] memoise_2.0.1         broom_1.0.9           snakecase_0.11.1     \n#&gt; [70] rstantools_2.5.0      coda_0.19-4.1         gridExtra_2.3        \n#&gt; [73] nlme_3.1-168          checkmate_2.3.3       xfun_0.53            \n#&gt; [76] zoo_1.8-14            pkgconfig_2.0.3",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_cont_rv_distr.html#bibliografia",
    "href": "chapters/probability/14_cont_rv_distr.html#bibliografia",
    "title": "15  Distribuzioni di v.c. continue",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlitzstein, J. K., & Hwang, J. (2019). Introduction to probability. CRC Press.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_gauss.html",
    "href": "chapters/probability/15_gauss.html",
    "title": "16  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "",
    "text": "16.1 Introduzione\nNell’analisi dei dati numerici, un aspetto cruciale da affrontare è l’imprecisione delle misurazioni, una caratteristica intrinseca dei dati reali. Anche in condizioni ottimali, le misure sono soggette a incertezze: i dati rappresentano sempre una stima approssimativa della realtà, accurata solo entro un certo margine (ad esempio, pochi punti percentuali). Inoltre, in molti contesti, come quelli demografici, commerciali o sociali, i dati possono essere arrotondati intenzionalmente o risultare imprecisi a causa di stime indirette, incompletezza delle informazioni o altri fattori.\nRiconoscere e gestire questa incertezza è una componente essenziale del processo analitico. Gli strumenti statistici forniscono un framework formale per descrivere e quantificare l’incertezza, consentendo di trarre inferenze robuste dai dati. Tra le distribuzioni di probabilità, la distribuzione normale (o gaussiana) occupa un posto centrale per la sua ubiquità e versatilità. Spesso rappresentata dalla caratteristica “curva a campana,” questa distribuzione è utilizzata per descrivere molte variabili naturali. Quando i dati approssimano una distribuzione normale, gran parte dei valori si concentra intorno alla media, con una diminuzione progressiva della probabilità di valori estremi.\nUna delle proprietà più utili della distribuzione normale è la possibilità di esprimere affermazioni quantitative rigorose. Ad esempio, si può calcolare la probabilità che un valore cada entro un determinato intervallo dalla media utilizzando parametri semplici come media (\\(\\mu\\)) e deviazione standard (\\(\\sigma\\)):\npnorm(1) - pnorm(-1)\n#&gt; [1] 0.683\npnorm(3) - pnorm(-3)\n#&gt; [1] 0.997\nQuesti calcoli costituiscono la base della “regola delle tre sigma,” una strategia utilizzata per identificare valori anomali (outlier), come discusso nel ?sec-eda-outlier. Tuttavia, tale regola può risultare fuorviante se i dati non seguono effettivamente una distribuzione normale.\nLa densità della distribuzione normale è definita dalla formula:\n\\[\np(x) = \\frac{1}{\\sqrt{2\\pi}\\,\\sigma} \\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right),\n\\]\ndove \\(\\mu\\) rappresenta la media e \\(\\sigma\\) la deviazione standard. Conoscere questi due parametri permette di calcolare proprietà fondamentali della distribuzione e di stimare probabilità associate a intervalli specifici.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_gauss.html#introduzione",
    "href": "chapters/probability/15_gauss.html#introduzione",
    "title": "16  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "",
    "text": "Circa il 68.3% dei valori cade entro una deviazione standard dalla media:\n\n\n\nCirca il 99.7% cade entro tre deviazioni standard:\n\n\n\n\n\n\n\n16.1.1 Gaussianità e Inferenza Statistica\nLa distribuzione normale è particolarmente rilevante per molti metodi statistici, in particolare nell’approccio frequentista. Gran parte dei test di ipotesi e delle procedure inferenziali assume che i dati siano distribuiti normalmente, una condizione necessaria per derivare formalmente i risultati di molti test. Ad esempio, i test t di Student e l’ANOVA richiedono la normalità delle variabili o dei residui. Quando questa assunzione è soddisfatta, tali strumenti offrono inferenze precise e affidabili.\nTuttavia, se i dati non sono gaussiani, molti test perdono validità. Sebbene si siano proposti approcci che dimostrano la robustezza di alcuni test a deviazioni moderate dalla normalità (Shatz, 2024), tale robustezza non è garantita in tutte le situazioni. Inoltre, l’enfasi sui valori-p complica la questione, poiché violazioni dell’assunzione di normalità possono compromettere l’interpretazione di questi indicatori.\nUna strategia comune per affrontare la non-gaussianità è l’applicazione di trasformazioni dei dati, come la trasformazione logaritmica o quella della radice quadrata, per avvicinare i dati alla distribuzione normale (Osborne, 2002). Ad esempio, distribuzioni asimmetriche come quelle dei tempi di reazione possono essere rese più gaussiane attraverso trasformazioni adeguate, rendendo applicabili i test frequentisti standard. Tuttavia, l’uso delle trasformazioni ha un costo: la perdita di interpretabilità. Se i dati originali avevano un significato chiaro e intuitivo, la trasformazione può rendere i risultati più difficili da collegare al fenomeno studiato.\nIn questo capitolo, esploreremo come verificare se i dati seguono una distribuzione normale, discuteremo l’impatto di questa assunzione sui metodi frequentisti e valuteremo il ruolo delle trasformazioni. Il nostro obiettivo è fornire al data analyst una guida pratica per decidere come trattare i dati non gaussiani, considerando sia i vantaggi che i limiti di ciascun approccio.\n\n16.1.2 L’assunzione di Gaussianità: Quando è valida?\nSebbene la distribuzione normale sia spesso un buon modello per i dati numerici, non è sempre una rappresentazione adeguata. Questo può dipendere da caratteristiche intrinseche dei dati, come asimmetrie, code lunghe o la presenza di valori anomali. Valutare l’appropriatezza dell’assunzione di normalità è un passaggio critico in qualsiasi analisi statistica.\nPer diagnosticare la normalità, presenteremo tre strumenti grafici:\n\n\nIstogrammi, una visualizzazione semplice ma spesso limitata.\n\nGrafici di densità, che forniscono un confronto più fluido rispetto agli istogrammi.\n\nQQ-plot (Quantile-Quantile plot), uno strumento visivo particolarmente efficace per rilevare deviazioni dalla normalità.\n\nQuesti strumenti possono anche essere affiancati da test formali per consentire una diagnosi robusta e guidare le decisioni sul trattamento dei dati.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_gauss.html#istogramma",
    "href": "chapters/probability/15_gauss.html#istogramma",
    "title": "16  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "\n16.2 Istogramma",
    "text": "16.2 Istogramma\nPer illustrare il concetto, utilizziamo un set di dati simulati che hanno proprietà simili a quelle dei tempi di reazione. Creeremo un istogramma e vi sovrapporremo la curva di densità normale calcolata in base ai dati.\n\n# Dati simulati di tempi di reazione\nset.seed(123)\nrt &lt;- c(rexp(100, rate = 0.2), 50, 60) # Aggiunti valori estremi\n\n# Calcolare la media e la deviazione standard per sovrapporre la densità normale\nmean_rt &lt;- mean(rt, na.rm = TRUE)\nsd_rt &lt;- sd(rt, na.rm = TRUE)\n\n# Creare l'istogramma e sovrapporre la densità normale\nggplot(tibble(rt=rt), aes(x = rt)) +\n  geom_histogram(\n    aes(y = ..density..),\n    bins = 30, color = \"black\"\n  ) +\n  stat_function(\n    fun = dnorm,\n    args = list(mean = mean_rt, sd = sd_rt),\n    size = 1\n  ) +\n  labs(\n    x = \"Tempi di Reazione\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\nL’istogramma mostra la distribuzione empirica dei dati, mentre la curva rossa rappresenta la densità normale con la stessa media e deviazione standard. Nel nostro caso, è evidente una discrepanza tra la distribuzione empirica e la densità normale, indicando che l’assunzione di normalità non è appropriata.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_gauss.html#grafico-di-densità",
    "href": "chapters/probability/15_gauss.html#grafico-di-densità",
    "title": "16  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "\n16.3 Grafico di densità",
    "text": "16.3 Grafico di densità\nUn grafico di densità è una versione lisciata dell’istogramma che facilita il confronto con la distribuzione normale. Utilizzando il dataset precedente, possiamo creare un grafico di densità sovrapposto alla curva gaussiana.\n\nggplot(tibble(rt=rt), aes(x = rt)) +\n  geom_density(alpha = 0.5) +\n  stat_function(\n    fun = dnorm,\n    args = list(mean = mean_rt, sd = sd_rt),\n    size = 1\n  ) +\n  labs(\n    x = \"Peso\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\nAnche questa rappresentazione rende chiaro come l’assunzione di normalità non sia appropriata.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_gauss.html#diagramma-quantile-quantile",
    "href": "chapters/probability/15_gauss.html#diagramma-quantile-quantile",
    "title": "16  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "\n16.4 Diagramma quantile-quantile",
    "text": "16.4 Diagramma quantile-quantile\nIl diagramma quantile-quantile (QQ-plot) è lo strumento più utile per analizzare visivamente la conformità di un dataset a una distribuzione teorica, in particolare alla distribuzione normale. Il QQ-plot è una tecnica essenziale per chi lavora con dati che si presume seguano una distribuzione specifica, e rappresenta un passaggio cruciale in molte analisi statistiche, soprattutto per verificare l’assunto di normalità.\nUn QQ-plot permette di:\n\n\nValutare graficamente la normalità dei dati: Se i punti nel diagramma seguono approssimativamente una linea retta, i dati possono essere considerati normalmente distribuiti. In caso contrario, il QQ-plot rivela deviazioni dalla normalità, come code pesanti o asimmetrie.\n\nConfrontare distribuzioni: Il QQ-plot non si limita solo alla distribuzione normale, ma può essere utilizzato per confrontare la distribuzione del campione con qualsiasi distribuzione teorica, facilitando l’analisi di dati con forme di distribuzione complesse.\n\nIdentificare outlier: Gli outlier nei dati saranno visibili come punti che si discostano significativamente dalla linea retta del QQ-plot.\n\nIl QQ-plot è costruito tracciando i quantili del campione contro i quantili teorici di una distribuzione di riferimento. L’interpretazione è piuttosto semplice:\n\nSe il campione segue la distribuzione teorica, i punti nel QQ-plot si allineano lungo una linea retta di pendenza 1 (e intercetta 0 nel caso di distribuzione normale standardizzata).\nLa deviazione dalla linea retta indica differenze nella distribuzione del campione rispetto alla distribuzione teorica:\n\n\nIntercetta diversa da 0: indica che la media del campione differisce dalla media della distribuzione teorica.\n\nPendenza diversa da 1: indica una differenza nella varianza tra il campione e la distribuzione teorica.\n\nCurve: indicano deviazioni sistematiche, come code pesanti o distribuzioni asimmetriche.\n\n\n\nNella discussione seguente, costruiremo e analizzeremo QQ-plot per tre casi tipici:\n\n\nCampione con stessa media e varianza della distribuzione teorica.\n\nCampione con media diversa ma stessa varianza.\n\nCampione con media e varianza diverse.\n\nSimuleremo i dati, li ordineremo, calcoleremo manualmente i quantili teorici e infine utilizzeremo librerie specializzate per replicare e confrontare i risultati. Questo approccio pratico ci permetterà di comprendere a fondo l’utilità e il funzionamento del QQ-plot.\n\n16.4.1 Comprendere e Costruire un QQ-Plot (Distribuzione Normale)\nUn QQ-plot (Quantile-Quantile plot) è uno strumento grafico utilizzato per confrontare la distribuzione di un campione con una distribuzione teorica, spesso la distribuzione normale. Il QQ-plot aiuta a visualizzare se un dataset segue una distribuzione specifica, tracciando i quantili del campione contro i quantili della distribuzione teorica.\n\n16.4.2 Passi per Costruire un QQ-Plot\n\n\nOrdinare i Dati: Disporre i dati del campione in ordine crescente.\n\nDeterminare i Quantili Teorici: Per una distribuzione normale, i quantili corrispondono all’inverso della funzione di distribuzione cumulativa (CDF) della distribuzione normale.\n\nConfrontare i Quantili: Tracciare i quantili del campione rispetto ai quantili della distribuzione teorica. Se il campione proviene dalla distribuzione teorica, i punti dovrebbero trovarsi approssimativamente su una linea retta.\n\n16.4.3 Caso 1: Campione con Stessa Media e Varianza della Distribuzione Normale\nSupponiamo che il campione provenga da una distribuzione normale \\(N(\\mu = 0, \\sigma^2 = 1)\\), esattamente come la distribuzione teorica.\n\n16.4.3.1 Simulazione dei Dati\nIniziamo simulando un piccolo dataset da \\(N(0, 1)\\):\n\n# Generiamo 20 punti dati da N(0, 1)\nset.seed(42)  # Per garantire la riproducibilità\ndati_campione &lt;- rnorm(20, mean = 0, sd = 1)\n\n# Ordiniamo i dati del campione\ncampione_ordinato &lt;- sort(dati_campione)\n\n# Calcoliamo i quantili teorici da N(0, 1)\nquantili_teorici &lt;- qnorm((seq(1, 20) - 0.5) / 20)\n\n# Tracciamo il QQ-plot\nplot(quantili_teorici, campione_ordinato,\n     xlab = \"Quantili Teorici\", ylab = \"Quantili del Campione\",\n     main = \"QQ-Plot: Stessa Media e Varianza\", pch = 16)\nabline(0, 1, lwd = 2)  # Linea y = x\n\n\n\n\n\n\n\nIn questo caso, i punti del QQ-plot dovrebbero allinearsi alla linea rossa, indicando che la distribuzione del campione corrisponde a quella teorica.\n\n16.4.4 Caso 2: Campione con Media Diversa (Intercetta ≠ 0)\nSimuliamo un campione da \\(N(2, 1)\\), con una media diversa ma la stessa varianza:\n\n# Generiamo 20 punti dati da N(2, 1)\ndati_campione_media_spostata &lt;- rnorm(20, mean = 2, sd = 1)\n\n# Ordiniamo i dati del campione\ncampione_ordinato_media_spostata &lt;- sort(dati_campione_media_spostata)\n\n# Tracciamo il QQ-plot\nplot(quantili_teorici, campione_ordinato_media_spostata,\n     xlab = \"Quantili Teorici\", ylab = \"Quantili del Campione\",\n     main = \"QQ-Plot: Media Diversa (Intercetta ≠ 0)\", pch = 16)\nabline(0, 1, lwd = 2)  # Linea y = x\n\n\n\n\n\n\n\nIn questo caso, i punti dovrebbero seguire una linea retta ma essere spostati verticalmente, indicando una media diversa (intercetta ≠ 0).\n\n16.4.5 Caso 3: Campione con Media e Varianza Diverse (Pendenza ≠ 1)\nSimuliamo un campione da \\(N(2, 2^2)\\), con una media e una varianza diverse:\n\n# Generiamo 20 punti dati da N(2, 2^2)\ndati_campione_varianza_spostata &lt;- rnorm(20, mean = 2, sd = 2)\n\n# Ordiniamo i dati del campione\ncampione_ordinato_varianza_spostata &lt;- sort(dati_campione_varianza_spostata)\n\n# Tracciamo il QQ-plot\nplot(quantili_teorici, campione_ordinato_varianza_spostata,\n     xlab = \"Quantili Teorici\", ylab = \"Quantili del Campione\",\n     main = \"QQ-Plot: Media e Varianza Diverse (Pendenza ≠ 1)\", pch = 16)\nabline(0, 1, lwd = 2)  # Linea y = x\n\n\n\n\n\n\n\nIn questo caso, i punti si discosteranno sia verticalmente (per la media diversa) sia rispetto alla pendenza della linea (per la varianza diversa).\n\n16.4.6 Calcolo Manuale del QQ-Plot\nPer ciascun caso sopra, i passaggi sono i seguenti:\n\n\nOrdinamento dei dati del campione: Questo fornisce i quantili del campione.\n\nCalcolo dei quantili teorici: Utilizzando la funzione inversa della CDF per la distribuzione normale.\n\nEsempio in R:\n\n# Calcolo manuale dei quantili teorici\nquantili_teorici_manuali &lt;- function(n) {\n  sapply(1:n, function(i) qnorm((i - 0.5) / n))\n}\n\nn &lt;- length(dati_campione)\nquantili_teorici_calcolati &lt;- quantili_teorici_manuali(n)\nquantili_teorici_calcolati\n#&gt;  [1] -1.9600 -1.4395 -1.1503 -0.9346 -0.7554 -0.5978 -0.4538 -0.3186 -0.1891\n#&gt; [10] -0.0627  0.0627  0.1891  0.3186  0.4538  0.5978  0.7554  0.9346  1.1503\n#&gt; [19]  1.4395  1.9600\n\n\n16.4.7 Utilizzo di Funzioni Specializzate\nIn R, il pacchetto base offre la funzione qqnorm() per generare QQ-plot. Ad esempio:\n\n# Generazione del QQ-plot con qqnorm\nqqnorm(dati_campione, main = \"QQ-Plot: Stessa Media e Varianza\")\nqqline(dati_campione, lwd = 2)  # Linea di riferimento\n\n\n\n\n\n\n\nPossiamo ripetere lo stesso per i campioni con media e varianza spostate.\n\nQuesto approccio fornisce un’analisi completa della corrispondenza tra distribuzioni teoriche e campioni simulati utilizzando QQ-plot.\nPer concludere, esaminiamo la distribuzione dei tempi di reazione simulati con il qq-plot.\n\nqqnorm(rt, main = \"Tempi di Reazione\")\n\n\n\n\n\n\n\nIl diagramma quantile-quantile rende molto chiaro che la distribuzione del peso dei pulcini non è gaussiana.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_gauss.html#valutare-la-normalità-test-statistici",
    "href": "chapters/probability/15_gauss.html#valutare-la-normalità-test-statistici",
    "title": "16  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "\n16.5 Valutare la Normalità: Test Statistici",
    "text": "16.5 Valutare la Normalità: Test Statistici\nSebbene esistano numerosi test statistici formali per valutare la conformità dei dati alla distribuzione normale, questi sono spesso troppo conservativi o sensibili a lievi deviazioni, e nella pratica sono frequentemente sostituiti da metodi visivi più flessibili ed efficaci.\nIn R sono disponibili diversi test per verificare la normalità dei dati. Di seguito presentiamo i più comuni, insieme a un esempio pratico basato sul dataset ChickWeight.\n\n16.5.1 Test di Shapiro-Wilk\nIl test di Shapiro-Wilk è uno dei test più utilizzati per verificare la normalità. Valuta l’ipotesi nulla che i dati seguano una distribuzione normale.\n\nshapiro_test &lt;- shapiro.test(rt)\nshapiro_test\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  rt\n#&gt; W = 0.6, p-value = 5e-16\n\n\nIl p-value è inferiore a 0.05 → Rifiutiamo l’ipotesi nulla, i dati non sono normali.\nIl p-value è maggiore di 0.05 → Non rifiutiamo l’ipotesi nulla, i dati possono essere considerati normali.\n\n16.5.2 Test di Kolmogorov-Smirnov\nQuesto test confronta la distribuzione cumulativa dei dati con una distribuzione teorica, come la normale. Tuttavia, è meno sensibile rispetto al test di Shapiro-Wilk.\n\nks_test &lt;- ks.test(\n  rt, \n  \"pnorm\", \n  mean = mean(rt), \n  sd = sd(rt)\n)\nks_test\n#&gt; \n#&gt;  Asymptotic one-sample Kolmogorov-Smirnov test\n#&gt; \n#&gt; data:  rt\n#&gt; D = 0.3, p-value = 0.000005\n#&gt; alternative hypothesis: two-sided\n\nIl test di Kolmogorov-Smirnov è più adatto per grandi dataset, ma è noto per essere eccessivamente conservativo.\n\n16.5.3 Limitazioni dei test statistici\nNonostante la loro precisione formale, i test statistici per la normalità notevoli limitazioni:\n\nEccessiva sensibilità ai grandi campioni: Quando il campione è ampio, anche lievi deviazioni dalla normalità, non rilevanti per l’analisi, possono portare a un risultato di non-normalità.\nMancanza di sensibilità nei piccoli campioni: Con campioni ridotti, i test possono mancare di potere statistico, portando a falsi negativi (ovvero, non rilevare deviazioni significative dalla normalità).\n\n\nset.seed(123)\nshapiro.test(rchisq(20, 4))\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  rchisq(20, 4)\n#&gt; W = 0.9, p-value = 0.3\n\nIn questo esempio, vediamo come, con un campione di 20 osservazioni da una distribuzione \\(\\chi^2_4\\) si produca un falso negativo.\n\n\nDifficoltà interpretative: Un p-value elevato non implica che i dati siano esattamente normali; semplicemente, non c’è evidenza sufficiente per rifiutare l’ipotesi di normalità.\n\nI metodi visivi, sebbene meno formali, sono spesso più pratici ed efficaci per diagnosticare deviazioni dalla normalità.I metodi visivi sono preferibili sono preferibili perché\n\nforniscono una diagnosi immediata, che consente di identificare deviazioni rilevanti senza dipendere da un p-value.\nrivelano non solo se i dati non sono normali, ma anche come e dove differiscono dalla normalità (ad esempio, asimmetria o code pesanti).\noffrono indicazioni utili anche in presenza di grandi campioni, dove i test statistici possono risultare eccessivamente conservativi.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_gauss.html#trasformazione-dei-dati-affrontare-la-non-normalità",
    "href": "chapters/probability/15_gauss.html#trasformazione-dei-dati-affrontare-la-non-normalità",
    "title": "16  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "\n16.6 Trasformazione dei dati: affrontare la non-normalità",
    "text": "16.6 Trasformazione dei dati: affrontare la non-normalità\nQuando i dati non rispettano l’assunzione di normalità, è possibile utilizzare diverse strategie per affrontare questa violazione. Una delle più comuni è l’uso di trasformazioni dei dati, che permettono di adattare la distribuzione dei dati a una forma più vicina a quella normale, mantenendo comunque la validità dell’analisi che richiede l’assunzione di normalità. Due approcci comuni sono Winsorizing e trimming.\n\n16.6.1 Winsorizing e Trimming\nQuesti metodi si concentrano sulla gestione degli outlier, ossia valori estremi che possono distorcere la distribuzione dei dati. Entrambi gli approcci presumono che la non-normalità sia dovuta a dati contaminanti e agiscono in modo differente:\n\n\nWinsorizing: Sostituisce i valori estremi con valori meno estremi, come i percentili limite della distribuzione.\n\nTrimming: Rimuove completamente i valori estremi dalla distribuzione.\n\nConsideriamo i seguenti dati di esempio:\n\ndati &lt;- c(\n  1.0, 2.2, 3.0, 3.1, 4.0, 4.0, 4.1, 5.3, 6.5, 8.3,\n  10.9, 20.4, 21.4, 34.\n)\n\n# Winsorizing al 20%\ndati_winsorized &lt;- winsorize(\n  dati,\n  method = \"percentile\", percentile = 20\n)\nprint(dati_winsorized)\n#&gt;  [1]  3.0  3.0  3.0  3.1  4.0  4.0  4.1  5.3  6.5  8.3 10.9 20.4 20.4 20.4\n\n\n# Trimming al 20%\ndati_trimmed &lt;- dati[\n  dati &gt;= quantile(dati, 0.2) & dati &lt;= quantile(dati, 0.8)\n]\nprint(dati_trimmed)\n#&gt; [1]  3.1  4.0  4.0  4.1  5.3  6.5  8.3 10.9\n\n\n\nDati Winsorized: I valori estremi (inferiori e superiori ai percentili 20° e 80°) sono sostituiti dai valori limite.\n\nDati Trimmed: I valori fuori dai percentili 20° e 80° sono completamente rimossi.\n\nQuesti metodi riducono l’impatto degli outlier, ma possono introdurre bias se i valori estremi sono effettivamente parte della popolazione target.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_gauss.html#trasformazioni-comuni",
    "href": "chapters/probability/15_gauss.html#trasformazioni-comuni",
    "title": "16  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "\n16.7 Trasformazioni comuni",
    "text": "16.7 Trasformazioni comuni\nQuando i dati non rispettano l’assunzione di normalità, è possibile applicare trasformazioni matematiche per modificarne la forma e migliorare l’adattamento a una distribuzione normale. Di seguito, presentiamo le trasformazioni più utilizzate.\nTrasformazione logaritmica.\nLa trasformazione logaritmica è particolarmente utile per variabili con asimmetria positiva (code lunghe a destra), come i tempi di reazione.\n\n# Trasformazione logaritmica\ndati_log &lt;- log(rt)\nplot(density(dati_log), main = \"Densità dei dati log-transformati\")\n\n\n\n\n\n\n\nTrasformazione radice quadrata.\nAdatta per variabili di conteggio o proporzioni con valori vicini a zero.\n\ndati_sqrt &lt;- sqrt(rt)\nplot(density(dati_sqrt), main = \"Densità dei dati trasformati con radice quadrata\")\n\n\n\n\n\n\n\nTrasformazione inversa.\nEfficace per dati con forte asimmetria positiva, ma può complicare l’interpretazione.\n\ndati_inv &lt;- 1 / rt\nplot(density(dati_inv), main = \"Densità dei dati trasformati inversamente\")\n\n\n\n\n\n\n\nTrasformazione Box-Cox.\nLa trasformazione Box-Cox è una tecnica parametrica che generalizza le precedenti. Utilizza il massimo della verosimiglianza per determinare la trasformazione ottimale per normalizzare i dati. La funzione di trasformazione dipende da un parametro \\(\\lambda\\):\n\\[\ny(\\lambda) =\n\\begin{cases}\n\\frac{y^\\lambda - 1}{\\lambda} & \\text{se } \\lambda \\neq 0, \\\\\n\\log(y) & \\text{se } \\lambda = 0.\n\\end{cases}\n\\]\n\nb &lt;- boxcox(lm(rt ~ 1))\n\n\n\n\n\n\n\n\n# Exact lambda\nlambda &lt;- b$x[which.max(b$y)]\nlambda\n#&gt; [1] 0.182\n\nTrasformiamo i dati utilizzando lambda.\n\nrt_boxcox &lt;- (rt^lambda - 1) / lambda\nrt_boxcox |&gt; head()\n#&gt; [1]  1.645  1.168  2.261 -1.568 -1.133  0.479\n\n\nplot(\n  density(rt_boxcox), \n  main = \"Densità dei dati trasformati con Box-Cox\"\n)\n\n\n\n\n\n\n\n\n# Generazione del QQ-plot con qqnorm\nqqnorm(rt_boxcox, main = \"QQ-Plot\")\nqqline(rt_boxcox, lwd = 2) \n\n\n\n\n\n\n\n\n\n16.7.1 Pro e contro delle trasformazioni\nVantaggi:\nLe trasformazioni dei dati offrono molteplici benefici nell’analisi statistica. In primo luogo, possono migliorare l’aderenza alla normalità, un requisito fondamentale per l’applicazione di molti test statistici. Inoltre, contribuiscono a stabilizzare la varianza e a mitigare l’impatto dei valori estremi, riducendo il rischio che questi ultimi influenzino eccessivamente i risultati. Tali vantaggi migliorano la robustezza e l’accuratezza delle analisi.\nSvantaggi:\nNonostante i benefici, le trasformazioni presentano limitazioni rilevanti. La perdita di interpretabilità è uno degli aspetti più critici: i risultati su dati trasformati possono risultare meno intuitivi. Ad esempio, in un modello di regressione applicato a dati trasformati con il logaritmo, il coefficiente rappresenta un cambiamento percentuale anziché assoluto, rendendo l’interpretazione meno diretta per i non esperti.\nInoltre, l’applicazione di una trasformazione deve essere attentamente motivata in base alla natura dei dati e agli obiettivi dell’analisi. Una trasformazione inappropriata può introdurre distorsioni indesiderate, compromettendo la validità dei risultati e portando a conclusioni fuorvianti. Per questo motivo, è essenziale valutare attentamente i costi e i benefici della trasformazione nel contesto specifico della ricerca.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_gauss.html#riflessioni-conclusive",
    "href": "chapters/probability/15_gauss.html#riflessioni-conclusive",
    "title": "16  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "\n16.8 Riflessioni Conclusive",
    "text": "16.8 Riflessioni Conclusive\nLa verifica della normalità dei dati e l’eventuale utilizzo di trasformazioni matematiche costituiscono fasi fondamentali nell’analisi statistica. Sebbene i test formali (come Shapiro-Wilk o Kolmogorov-Smirnov) offrano una valutazione strutturata, essi possono risultare troppo sensibili, portando a rigettare l’assunto di normalità anche in presenza di lievi deviazioni non rilevanti dal punto di vista pratico. In questi casi, l’impiego di strumenti visivi—come istogrammi, grafici di densità o QQ-plot—si rivela spesso più informativo e flessibile, consentendo di individuare la natura e l’entità delle deviazioni.\nLe trasformazioni dei dati rappresentano una strategia utile per normalizzare la distribuzione, ma richiedono una scelta oculata. È essenziale verificare che la trasformazione adottata non comprometta il significato teorico della variabile in esame. Quando l’interpretabilità risulta compromessa, potrebbe essere preferibile ricorrere a metodi robusti o modelli alternativi (ad esempio, approcci bayesiani) che non presuppongono la normalità. In definitiva, la decisione finale dipenderà dal contesto di ricerca, dalla natura dei dati e dagli obiettivi analitici, privilegiando sempre un equilibrio tra rigore statistico e interpretabilità dei risultati.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_gauss.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/15_gauss.html#informazioni-sullambiente-di-sviluppo",
    "title": "16  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] MASS_7.3-65           datawizard_1.2.0      pillar_1.11.0        \n#&gt;  [4] tinytable_0.13.0      patchwork_1.3.2       ggdist_3.3.3         \n#&gt;  [7] tidybayes_3.0.7       bayesplot_1.14.0      ggplot2_3.5.2        \n#&gt; [10] reliabilitydiag_0.2.1 priorsense_1.1.1      posterior_1.6.1      \n#&gt; [13] loo_2.8.0             rstan_2.32.7          StanHeaders_2.32.10  \n#&gt; [16] brms_2.22.0           Rcpp_1.1.0            sessioninfo_1.2.3    \n#&gt; [19] conflicted_1.2.0      janitor_2.2.1         matrixStats_1.5.0    \n#&gt; [22] modelr_0.1.11         tibble_3.3.0          dplyr_1.1.4          \n#&gt; [25] tidyr_1.3.1           rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        systemfonts_1.2.3    \n#&gt; [10] vctrs_0.6.5           stringr_1.5.1         pkgconfig_2.0.3      \n#&gt; [13] arrayhelpers_1.1-0    fastmap_1.2.0         backports_1.5.0      \n#&gt; [16] labeling_0.4.3        rmarkdown_2.29        ragg_1.5.0           \n#&gt; [19] purrr_1.1.0           xfun_0.53             cachem_1.1.0         \n#&gt; [22] jsonlite_2.0.0        broom_1.0.9           parallel_4.5.1       \n#&gt; [25] R6_2.6.1              stringi_1.8.7         RColorBrewer_1.1-3   \n#&gt; [28] lubridate_1.9.4       estimability_1.5.1    knitr_1.50           \n#&gt; [31] zoo_1.8-14            pacman_0.5.1          Matrix_1.7-4         \n#&gt; [34] splines_4.5.1         timechange_0.3.0      tidyselect_1.2.1     \n#&gt; [37] abind_1.4-8           yaml_2.3.10           codetools_0.2-20     \n#&gt; [40] curl_7.0.0            pkgbuild_1.4.8        lattice_0.22-7       \n#&gt; [43] withr_3.0.2           bridgesampling_1.1-2  coda_0.19-4.1        \n#&gt; [46] evaluate_1.0.5        survival_3.8-3        RcppParallel_5.1.11-1\n#&gt; [49] tensorA_0.36.2.1      checkmate_2.3.3       stats4_4.5.1         \n#&gt; [52] insight_1.4.2         distributional_0.5.0  generics_0.1.4       \n#&gt; [55] rprojroot_2.1.1       rstantools_2.5.0      scales_1.4.0         \n#&gt; [58] xtable_1.8-4          glue_1.8.0            emmeans_1.11.2-8     \n#&gt; [61] tools_4.5.1           mvtnorm_1.3-3         grid_4.5.1           \n#&gt; [64] QuickJSR_1.8.0        colorspace_2.1-1      nlme_3.1-168         \n#&gt; [67] cli_3.6.5             textshaping_1.0.3     svUnit_1.0.8         \n#&gt; [70] Brobdingnag_1.2-9     V8_7.0.0              gtable_0.3.6         \n#&gt; [73] digest_0.6.37         TH.data_1.1-4         htmlwidgets_1.6.4    \n#&gt; [76] farver_2.1.2          memoise_2.0.1         htmltools_0.5.8.1    \n#&gt; [79] lifecycle_1.0.4",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_gauss.html#bibliografia",
    "href": "chapters/probability/15_gauss.html#bibliografia",
    "title": "16  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nOsborne, J. (2002). Notes on the use of data transformations. Practical Assessment, Research, and Evaluation, 8(1).\n\n\nShatz, I. (2024). Assumption-checking rather than (just) testing: The importance of visualization and effect size in statistical diagnostics. Behavior Research Methods, 56(2), 826–845.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/16_likelihood.html",
    "href": "chapters/probability/16_likelihood.html",
    "title": "17  La verosimiglianza",
    "section": "",
    "text": "Introduzione\nI ricercatori utilizzano modelli matematici per descrivere e prevedere il comportamento dei dati osservati. Questi modelli si distinguono per la loro struttura funzionale, che definisce le relazioni tra variabili osservate e parametri teorici. La selezione del modello ottimale avviene attraverso un confronto sistematico tra le previsioni teoriche generate dai diversi modelli e l’evidenza empirica. Il modello che mostra il miglior accordo con i dati sperimentali viene considerato la rappresentazione più adeguata del fenomeno studiato.\nIn questo processo di valutazione, la funzione di verosimiglianza svolge un ruolo fondamentale: per ogni possibile valore dei parametri, essa quantifica quanto siano plausibili i dati osservati sotto l’ipotesi che siano stati generati da quel specifico modello. In altre parole, la verosimiglianza costruisce una mappa di plausibilità parametrica, identificando le combinazioni di parametri che massimizzano la coerenza tra modello e realtà osservata.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/16_likelihood.html#introduzione",
    "href": "chapters/probability/16_likelihood.html#introduzione",
    "title": "17  La verosimiglianza",
    "section": "",
    "text": "Panoramica del capitolo\n\nMisura della plausibilità dei parametri alla luce dei dati osservati\nApplicazione a distribuzioni binomiali (lancio di monete) e gaussiane (misura del QI)\nMetodi per identificare i parametri più plausibili con implementazioni in R\nUtilizzo del rapporto di verosimiglianze e criteri aggiustati (AIC)\nLa verosimiglianza come componente fondamentale per l’inferenza bayesiana\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nCapitolo Estimation (Schervish & DeGroot, 2014)\n\nCapitolo Bayes’ rule (Johnson et al., 2022)\n\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n\n\n\n\n17.0.1 Il principio della verosimiglianza\nIl principio della verosimiglianza costituisce il fondamento dell’inferenza statistica moderna, fornendo un metodo per quantificare la plausibilità di un valore parametrico (come la media di una popolazione o l’effetto di una terapia) alla luce dei dati osservati.\nConcettualmente, la verosimiglianza non misura la probabilità che un’ipotesi sia vera, ma valuta quanto i dati osservati siano coerenti con una specifica ipotesi sul parametro. Rappresenta una misura di sostegno empirico: valori parametrici che rendono i dati più probabili ricevono maggiore supporto dall’evidenza.\n\nDefinizione 17.1 Sia \\(Y\\) un vettore aleatorio (come l’insieme dei punteggi dei partecipanti a un test) la cui distribuzione dipende da un parametro sconosciuto \\(\\theta\\) (ad esempio, il punteggio medio nella popolazione). La distribuzione è descritta da una funzione di densità di probabilità (per variabili continue) o di massa di probabilità (per variabili discrete), indicata con \\(f(y \\mid \\theta)\\), dove \\(\\theta \\in \\Theta\\) e \\(\\Theta\\) rappresenta lo spazio dei possibili valori parametrici.\nDopo aver osservato un campione di dati \\(y\\), la funzione di verosimiglianza è definita come:\n\\[\nL(\\theta; y) = f(y \\mid \\theta)\n\\]\nSi noti che in questa funzione:\n\n\n\\(y\\) è fissato: corrisponde ai dati effettivamente raccolti\n\n\\(\\theta\\) è variabile: rappresenta il parametro incognito oggetto di inferenza\n\nLa funzione \\(L(\\theta; y)\\) assegna quindi a ogni possibile valore di \\(\\theta\\) un grado di supporto basato sui dati, indicando quali valori rendono le osservazioni più plausibili.\n\n\n17.0.2 Relazione tra verosimiglianza e funzione di probabilità\nSebbene la funzione di probabilità (o densità) e la funzione di verosimiglianza condividano la stessa forma matematica \\(f(y \\mid \\theta)\\), il loro significato concettuale differisce sostanzialmente in base al contesto inferenziale.\n\n17.0.2.1 Due prospettive a confronto\n\n\nFunzione di probabilità (densità/massa)\n\n\nParametri (\\(\\theta\\)) fissi: assumiamo che siano noti o ipotizzati\n\nDati (\\(y\\)) aleatori: descrive la distribuzione dei possibili risultati\n\nInterpretazione: \\(f(y \\mid \\theta)\\) quantifica la probabilità (o densità) di osservare \\(y\\) sotto un modello con parametri \\(\\theta\\)\n\n\nDomanda chiave: “Se il modello fosse \\(\\theta\\), quanto sarebbero probabili questi dati?”\n\n\n\nFunzione di verosimiglianza\n\n\nDati (\\(y\\)) fissi: corrispondono alle osservazioni effettive\n\nParametri (\\(\\theta\\)) variabili: rappresentano l’incertezza da risolvere\n\nInterpretazione: \\(L(\\theta; y) = f(y \\mid \\theta)\\) misura la plausibilità relativa di \\(\\theta\\) alla luce di \\(y\\)\n\n\nDomanda chiave: “Alla luce di questi dati, quanto sono credibili i diversi \\(\\theta\\)?”\n\n\n\n17.0.2.2 Implicazioni per l’inferenza statistica\n\nApproccio frequentista: la verosimiglianza è uno strumento per stimare i parametri (es. stima di massima verosimiglianza), senza assegnare loro una distribuzione di probabilità\nApproccio bayesiano: la verosimiglianza funge da ponte tra dati e parametri, combinando l’informazione empirica con le credenze iniziali (prior) per derivare la distribuzione a posteriori:\n\n\\[\nP(\\theta \\mid y) \\propto L(\\theta; y) \\cdot P(\\theta)\n\\]\nIn questa prospettiva, i dati aggiornano la nostra conoscenza su \\(\\theta\\) attraverso la verosimiglianza.\n\n17.0.2.3 Sintesi delle differenze\n\n\n\n\n\n\n\nCaratteristica\nFunzione di probabilità\nFunzione di verosimiglianza\n\n\n\nVariabile di interesse\n\n\\(y\\) (aleatoria)\n\n\\(\\theta\\) (incognita)\n\n\nRuolo epistemologico\nGenera dati ipotetici\nValuta parametri plausibili\n\n\nContesto d’uso\nModellistica predittiva\nInferenza parametrica\n\n\n\nQuesta dualità riflette un principio fondamentale: la stessa formula matematica assume significati distinti a seconda che l’obiettivo sia la descrizione del processo generativo o l’inferenza sui suoi parametri. La verosimiglianza, in particolare, è il motore dell’apprendimento statistico, trasformando dati in conoscenza.\n\n17.0.3 La log-verosimiglianza\nIn ambito statistico e computazionale, risulta spesso vantaggioso lavorare con la log-verosimiglianza, definita come il logaritmo naturale della funzione di verosimiglianza:\n\\[\n\\ell(\\theta; y) = \\log L(\\theta; y) = \\log f(y \\mid \\theta).\n\\]\nQuesta trasformazione apporta significativi vantaggi sia dal punto di vista computazionale che analitico.\nDal punto di vista computazionale, la log-verosimiglianza offre una maggiore stabilità numerica. Il prodotto di probabilità molto piccole, tipico delle funzioni di verosimiglianza, può infatti portare a valori numericamente instabili (un fenomeno noto come underflow). La conversione logaritmica trasforma questi prodotti in somme, molto più gestibili per i calcolatori. Questo vantaggio diventa particolarmente evidente nel caso di osservazioni indipendenti e identicamente distribuite (i.i.d.), dove la log-verosimiglianza complessiva si esprime come la somma dei contributi individuali:\n\\[\n\\ell(\\theta; y_1, \\dots, y_n) = \\sum_{i=1}^n \\log f(y_i \\mid \\theta),\n\\] semplificando notevolmente i calcoli.\nSul piano analitico, la log-verosimiglianza facilita l’ottimizzazione grazie alle proprietà del logaritmo che trasformano prodotti in somme. Le derivate risultano infatti matematicamente più semplici da trattare rispetto a quelle della verosimiglianza originale. Questa semplificazione risulta particolarmente vantaggiosa nei metodi di ottimizzazione numerica come la massimizzazione della verosimiglianza (MLE), dove la stima dei parametri avviene risolvendo il sistema di equazioni ottenuto uguagliando a zero il gradiente. La forma additiva della log-verosimiglianza si dimostra inoltre particolarmente utile nei modelli gerarchici o nei casi in cui i dati provengano da più fonti indipendenti.\nÈ importante sottolineare che, poiché il logaritmo è una funzione monotona crescente, massimizzare la log-verosimiglianza \\(\\ell(\\theta; y)\\) equivale perfettamente a massimizzare la verosimiglianza \\(L(\\theta; y)\\). Pertanto, le stime di massima verosimiglianza (MLE) possono essere ottenute indifferentemente dall’una o dall’altra funzione.\nIn sintesi, la log-verosimiglianza combina efficienza computazionale e semplicità analitica, rendendola uno strumento fondamentale per l’inferenza statistica e l’analisi dati moderna. La sua adozione consente di affrontare problemi complessi con maggiore stabilità numerica e minore complessità computazionale, mantenendo inalterate le proprietà inferenziali della verosimiglianza originale.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/16_likelihood.html#modellazione-statistica-del-lancio-di-una-moneta",
    "href": "chapters/probability/16_likelihood.html#modellazione-statistica-del-lancio-di-una-moneta",
    "title": "17  La verosimiglianza",
    "section": "\n17.1 Modellazione statistica del lancio di una moneta",
    "text": "17.1 Modellazione statistica del lancio di una moneta\nUn esempio classico per introdurre il concetto di verosimiglianza è quello del lancio di una moneta. Chiamiamo \\(\\theta\\) la probabilità (incognita) di ottenere “testa”.\n\n17.1.1 Il modello probabilistico\nPer semplicità assumiamo:\n\nogni lancio è indipendente dagli altri;\nla probabilità \\(\\theta\\) resta costante in tutti i lanci.\n\nSe in \\(n\\) lanci otteniamo \\(y\\) teste, la probabilità di osservare esattamente quei dati è:\n\\[\nP(\\text{dati}\\mid \\theta) = \\theta^y (1-\\theta)^{n-y}.\n\\]\n\n17.1.2 La funzione di verosimiglianza\nLa funzione di verosimiglianza si ottiene considerando l’espressione precedente non più come funzione dei dati, ma come funzione di \\(\\theta\\):\n\\[\nL(\\theta \\mid \\text{dati}) \\propto \\theta^y (1-\\theta)^{n-y}.\n\\]\nEssa indica quali valori di \\(\\theta\\) sono più compatibili con i dati osservati. Il valore che massimizza questa funzione è lo stimatore di massima verosimiglianza (MLE).\n\n17.1.3 Esempio 1: due lanci\nSupponiamo di osservare due lanci con esito: una testa e una croce (\\(n=2, y=1\\)).\n\n\nSe \\(\\theta = 0.5\\):\n\\[\nL(0.5) = 0.5^1 \\cdot 0.5^1 = 0.25\n\\]\n\n\nSe \\(\\theta = 0.4\\):\n\\[\nL(0.4) = 0.4^1 \\cdot 0.6^1 = 0.24\n\\]\n\n\nIn questo caso \\(\\theta=0.5\\) spiega leggermente meglio i dati.\nCon R possiamo calcolare la verosimiglianza per tutta la gamma di valori di \\(\\theta\\):\n\nn &lt;- 2\ny &lt;- 1\np_H &lt;- seq(0, 1, length.out = 100)\nlikelihood &lt;- p_H^y * (1 - p_H)^(n - y)\n\nLa curva risultante ha il massimo in corrispondenza di \\(\\hat\\theta = y/n = 0.5\\).\n\n17.1.4 Esempio 2: tre lanci\nConsideriamo ora tre lanci con esito: una testa e due croci (\\(n=3, y=1\\)).\n\n\nSe \\(\\theta = 0.5\\):\n\\[\nL(0.5) = 0.5^1 \\cdot 0.5^2 = 0.125\n\\]\n\n\nSe \\(\\theta = 0.4\\):\n\\[\nL(0.4) = 0.4^1 \\cdot 0.6^2 = 0.144\n\\]\n\n\nQui il valore \\(\\theta = 0.4\\) è più plausibile di 0.5.\nCon R:\n\nn &lt;- 3\ny &lt;- 1\np_H &lt;- seq(0, 1, length.out = 100)\nlikelihood &lt;- p_H^y * (1 - p_H)^(n - y)\n\nLa curva raggiunge il massimo in \\(\\hat\\theta = y/n = 1/3 \\approx 0.33\\). Rispetto al caso precedente, la curva è più stretta, segnalando una maggiore precisione della stima grazie al numero maggiore di osservazioni.\n\n17.1.5 Interpretazione complessiva\n\nLo stimatore di massima verosimiglianza \\(\\hat\\theta\\) corrisponde sempre alla proporzione osservata di teste (\\(y/n\\)).\nAll’aumentare del numero di lanci, la curva di verosimiglianza diventa più appuntita: significa che abbiamo maggiore certezza sul valore di \\(\\theta\\).\nI valori estremi (\\(\\theta \\approx 0\\) o \\(\\theta \\approx 1\\)) risultano poco compatibili con i dati, perché non potrebbero spiegare l’osservazione sia di teste che di croci.\n\nIn sintesi: la verosimiglianza traduce l’idea intuitiva che “il valore migliore del parametro è quello che rende i dati osservati più probabili”. Questo principio, applicato in modo generale, costituisce la base della stima per massima verosimiglianza.\n\n17.1.6 Confronto tra due e tre lanci\nMettiamo ora a confronto le due situazioni:\n\n\nCaso 1: 2 lanci con 1 testa (\\(n=2, y=1\\), proporzione osservata \\(\\hat\\theta = 0.5\\)).\n\nCaso 2: 3 lanci con 1 testa (\\(n=3, y=1\\), proporzione osservata \\(\\hat\\theta \\approx 0.33\\)).\n\n\n# Dati per 2 lanci\nn1 &lt;- 2; y1 &lt;- 1\ntheta_seq &lt;- seq(0, 1, length.out = 200)\nlik1 &lt;- theta_seq^y1 * (1 - theta_seq)^(n1 - y1)\n\n# Dati per 3 lanci\nn2 &lt;- 3; y2 &lt;- 1\nlik2 &lt;- theta_seq^y2 * (1 - theta_seq)^(n2 - y2)\n\n# Creiamo un unico dataframe\ndf &lt;- data.frame(\n  theta = rep(theta_seq, 2),\n  likelihood = c(lik1, lik2),\n  caso = rep(c(\"2 lanci (1 testa)\", \"3 lanci (1 testa)\"), each = length(theta_seq))\n)\n\n# Grafico comparativo\nggplot(df, aes(x = theta, y = likelihood, color = caso)) +\n  geom_line(linewidth = 1.2) +\n  labs(\n    x = expression(theta),\n    y = \"Verosimiglianza\"\n  ) +\n  scale_color_manual(values = c(\"steelblue\", \"darkorange\"))\n\n\n\n\n\n\n\n\n17.1.7 Interpretazione del grafico\n\nNel caso dei 2 lanci, la curva ha un massimo in \\(\\hat\\theta = 0.5\\), ma è molto larga: la stima è poco precisa.\nNel caso dei 3 lanci, la curva ha un massimo in \\(\\hat\\theta = 1/3\\), ed è più stretta: significa che, con più dati, la stima diventa più affidabile.\nI valori estremi (\\(\\theta \\approx 0\\) o \\(\\theta \\approx 1\\)) hanno verosimiglianza quasi nulla in entrambi i casi, perché non spiegherebbero la presenza di almeno una testa e di almeno una croce.\n\nQuesto semplice confronto mostra visivamente come aumentare la quantità di dati restringe l’incertezza e rende la stima più precisa.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/16_likelihood.html#verosimiglianza-binomiale",
    "href": "chapters/probability/16_likelihood.html#verosimiglianza-binomiale",
    "title": "17  La verosimiglianza",
    "section": "\n17.2 Verosimiglianza binomiale",
    "text": "17.2 Verosimiglianza binomiale\nConsideriamo ora un esperimento più ampio: lanciamo una moneta \\(n = 30\\) volte e osserviamo \\(y = 23\\) teste. Per modellare il numero totale di successi utilizziamo la distribuzione binomiale, che descrive la probabilità di ottenere esattamente \\(y\\) successi in \\(n\\) prove indipendenti, con probabilità di successo \\(\\theta\\) costante:\n\\[\nP(Y = y \\mid \\theta) = \\binom{n}{y} \\theta^y (1 - \\theta)^{n - y}.\n\\]\nIn questo contesto, \\(Y\\) rappresenta la variabile casuale “numero di teste”, \\(y = 23\\) è il valore osservato, e \\(\\theta\\) (o \\(p_H\\)) è la probabilità incognita di ottenere testa in un singolo lancio.\n\n17.2.1 Dalla distribuzione di probabilità alla verosimiglianza\nDopo aver osservato i dati (\\(y = 23\\)), possiamo valutare la compatibilità dei diversi valori del parametro \\(\\theta\\) con l’evidenza sperimentale. A questo scopo, utilizziamo la formula della distribuzione binomiale trattandola come funzione di \\(\\theta\\) anziché di \\(y\\):\n\\[\nL(\\theta \\mid y = 23) = \\binom{30}{23} \\theta^{23} (1 - \\theta)^7.\n\\]\nQuesta funzione di verosimiglianza quantifica la plausibilità di ciascun valore di \\(\\theta\\) alla luce dei dati osservati. A differenza degli esempi precedenti, in questo caso manteniamo la costante moltiplicativa \\(\\binom{30}{23}\\) poiché lavoreremo con la verosimiglianza completa.\n\n17.2.2 Visualizzazione della funzione di verosimiglianza\nIl codice seguente genera il grafico della funzione di verosimiglianza, calcolando per ogni valore di \\(\\theta\\) la probabilità di osservare 23 successi su 30 prove:\n\n# Parametri osservati\nn &lt;- 30  # Numero totale di lanci\ny &lt;- 23  # Numero di teste osservate\n\n# Griglia di valori possibili per theta\ntheta &lt;- seq(0, 1, length.out = 1000)\n\n# Calcolo della verosimiglianza binomiale\nlikelihood &lt;- dbinom(y, size = n, prob = theta)\n\n# Preparazione dei dati per la visualizzazione\ndata &lt;- data.frame(theta, likelihood)\n\n# Rappresentazione grafica\nggplot(data, aes(x = theta, y = likelihood)) +\n  geom_line(linewidth = 1.2, color = \"steelblue\") +\n  labs(\n    x = expression(theta),\n    y = \"Verosimiglianza\"\n  ) \n\n\n\n\n\n\n\n\n17.2.3 Interpretazione dei risultati\nL’analisi grafica rivele che:\n\nLa funzione di verosimiglianza raggiunge il suo massimo in corrispondenza di \\(\\theta \\approx 0.77\\)\n\nQuesto valore rappresenta la stima di massima verosimiglianza (MLE) per la probabilità di successo\nLa stima corrisponde esattamente alla proporzione campionaria: \\(\\hat{\\theta} = \\frac{23}{30} \\approx 0.767\\)\n\nLa curva mostra una dispersione limitata, indicando una relativa precisione nella stima\nI valori estremi di \\(\\theta\\) (vicini a 0 o 1) presentano verosimiglianze trascurabili\n\n17.2.4 Implementazione computazionale\nIn R, il calcolo della verosimiglianza binomiale può essere efficientemente implementato utilizzando la funzione dbinom(), che calcola la funzione di massa di probabilità della distribuzione binomiale:\n# Calcolo della verosimiglianza\nlikelihood &lt;- dbinom(y, size = n, prob = theta)\ndove:\n\n\ny è il numero di successi osservati (23)\n\nn è il numero totale di prove (30)\n\ntheta è il vettore dei valori parametrici da valutare\n\nQuesto approccio dimostra come la verosimiglianza possa essere costruita direttamente a partire dalla distribuzione di probabilità sottostante, utilizzando strumenti computazionali standard. La funzione dbinom() calcola automaticamente l’intera espressione binomiale, inclusa la costante moltiplicativa, fornendo così la verosimiglianza completa per ogni valore di \\(\\theta\\).\nLa metodologia presentata mostra come concetti teorici di inferenza statistica possano essere efficacemente implementati e visualizzati attraverso strumenti computazionali, facilitando la comprensione intuitiva dei principi di verosimiglianza e stima parametrica.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/16_likelihood.html#la-stima-di-massima-verosimiglianza",
    "href": "chapters/probability/16_likelihood.html#la-stima-di-massima-verosimiglianza",
    "title": "17  La verosimiglianza",
    "section": "\n17.3 La Stima di Massima Verosimiglianza",
    "text": "17.3 La Stima di Massima Verosimiglianza\nQuando osserviamo dati sperimentali e desideriamo stimare un parametro incognito – come la probabilità \\(\\theta\\) che una moneta produca “testa” – un approccio fondamentale è rappresentato dalla stima di massima verosimiglianza (Maximum Likelihood Estimation, MLE). Sebbene l’approccio bayesiano si concentri sulla distribuzione completa dei valori plausibili del parametro piuttosto che su una singola stima puntuale, la comprensione del concetto di MLE rimane essenziale. Questo metodo identifica il valore di \\(\\theta\\) che massimizza la compatibilità tra il modello e i dati osservati. In contesti bayesiani, sotto specifiche condizioni di prior, la MLE coincide con il massimo della distribuzione a posteriori.\n\n17.3.1 Il principio fondamentale\nLa logica sottostante la MLE è intuitiva: tra tutti i possibili valori del parametro, selezioniamo quello che rende i dati osservati più probabili. Immaginiamo di testare sistematicamente diversi valori di \\(\\theta\\), chiedendoci per ciascuno: “Se questo fosse il vero valore del parametro, quanto sarebbero plausibili i dati che abbiamo effettivamente osservato?” Il valore che massimizza questa plausibilità costituisce la nostra stima ottimale.\n\n17.3.2 Esempio applicativo: il lancio della moneta\nConsideriamo una moneta lanciata 30 volte che produce 23 teste. Un risultato così marcato solleva naturalmente dubbi sull’equità della moneta. Per stimare la vera probabilità \\(\\theta\\) di ottenere testa, costruiamo la funzione di verosimiglianza, che quantifica la compatibilità di ciascun possibile valore di \\(\\theta\\) con l’evidenza sperimentale. Valori più elevati di verosimiglianza indicano una maggiore plausibilità del parametro dato i dati osservati.\n\n17.3.3 Rappresentazione grafica e interpretazione\nLa funzione di verosimiglianza \\(L(\\theta)\\) può essere visualizzata come una curva che descrive l’andamento della plausibilità al variare di \\(\\theta\\). Questa curva presenta tipicamente un massimo globale ben definito, corrispondente alla stima MLE. Geometricamente, questo punto rappresenta il vertice della “collina” di verosimiglianza.\nLa forma della curva fornisce preziose informazioni:\n\nuna curva appuntita indica alta certezza nella stima,\nuna curva più piatta suggerisce maggiore incertezza parametrica,\nla pendenza della curva riflette la sensibilità della verosimiglianza alle variazioni del parametro.\n\n17.3.4 Determinazione analitica del massimo\nMatematicamente, il massimo della funzione di verosimiglianza corrisponde al punto in cui la sua derivata si annulla. Utilizzando la trasformazione in log-verosimiglianza:\n\\[\n\\ell(\\theta) = y \\log \\theta + (n - y) \\log(1 - \\theta),\n\\]\nla soluzione analitica si ottiene ponendo la derivata uguale a zero:\n\\[\n\\hat{\\theta} = \\frac{y}{n}.\n\\]\nNel nostro esempio, questo risulta in \\(\\hat{\\theta} = \\frac{23}{30} \\approx 0.767\\), dimostrando come la MLE corrisponda alla proporzione campionaria osservata.\n\n17.3.5 Relazione con l’inferenza bayesiana\nNella statistica bayesiana, l’obiettivo principale è la caratterizzazione completa dell’incertezza parametrica attraverso la distribuzione a posteriori. Tuttavia, il punto di massimo di questa distribuzione, noto come stima MAP (Maximum A Posteriori), coincide con la MLE quando si assume una distribuzione a priori uniforme. Questa connessione evidenzia come la MLE rappresenti un caso particolare dell’approccio bayesiano, fornendo un ponte concettuale tra i due paradigmi inferenziali.\nLa comprensione della MLE non solo facilita l’interpretazione dei risultati statistici, ma costituisce anche una base essenziale per l’apprendimento dei metodi bayesiani più avanzati, mostrando come il concetto di verosimiglianza unifichi diversi approcci all’inferenza statistica.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/16_likelihood.html#calcolo-della-stima-di-massima-verosimiglianza-in-r",
    "href": "chapters/probability/16_likelihood.html#calcolo-della-stima-di-massima-verosimiglianza-in-r",
    "title": "17  La verosimiglianza",
    "section": "\n17.4 Calcolo della Stima di Massima Verosimiglianza in R",
    "text": "17.4 Calcolo della Stima di Massima Verosimiglianza in R\n\n17.4.1 Metodo 1: Valutazione su Griglia\nIl primo approccio consiste nel valutare sistematicamente la verosimiglianza per un’ampia gamma di valori del parametro θ:\n\n# Definizione dei parametri osservati\nn &lt;- 30\ny &lt;- 23\ntheta &lt;- seq(0, 1, length.out = 10000)\n\n# Calcolo della funzione di verosimiglianza\nlikelihood &lt;- dbinom(y, size = n, prob = theta)\n\n# Identificazione del massimo\nmax_index &lt;- which.max(likelihood)\noptimal_theta &lt;- theta[max_index]\n\n# Visualizzazione del risultato\noptimal_theta\n#&gt; [1] 0.767\n\nQuesto metodo offre una soluzione numerica precisa attraverso:\n\nla generazione di una griglia densa di valori possibili per \\(\\theta\\),\nil calcolo diretto della verosimiglianza per ogni punto della griglia,\nl’identificazione del valore ottimale mediante ricerca del massimo.\n\n17.4.2 Metodo 2: Ottimizzazione Numerica\nUn approccio più efficiente dal punto di vista computazionale utilizza algoritmi di ottimizzazione:\n\n# Definizione della funzione di log-verosimiglianza negativa\nneg_log_likelihood &lt;- function(theta) {\n  - (y * log(theta) + (n - y) * log(1 - theta))\n}\n\n# Ottimizzazione numerica\nresult &lt;- optim(\n  par = 0.5,              # Valore iniziale\n  fn = neg_log_likelihood, # Funzione da minimizzare\n  method = \"Brent\",       # Algoritmo per ottimizzazione unidimensionale\n  lower = 1e-6,           # Limite inferiore\n  upper = 1 - 1e-6        # Limite superiore\n)\n\noptimal_theta_numerical &lt;- result$par\noptimal_theta_numerical\n#&gt; [1] 0.767\n\nL’utilizzo della log-verosimiglianza negativa è necessario poiché la funzione optim() è progettata per la minimizzazione. Questo approccio risulta particolarmente vantaggioso per modelli complessi dove una valutazione su griglia sarebbe computazionalmente costosa.\n\n17.4.3 Confronto dei risultati\n\n# Confronto tra i diversi metodi\nc(\n  \"Griglia\" = optimal_theta, \n  \"Ottimizzazione\" = optimal_theta_numerical, \n  \"Analitica\" = y / n\n)\n#&gt;        Griglia Ottimizzazione      Analitica \n#&gt;          0.767          0.767          0.767\n\nTutti e tre i metodi convergono allo stesso risultato:\n\\[\n\\hat{\\theta} = \\frac{23}{30} \\approx 0.767 .\n\\]\nQuesta coincidenza dimostra la robustezza del metodo di massima verosimiglianza e conferma che, nel caso della distribuzione binomiale, la stima ottimale corrisponde alla proporzione campionaria osservata.\nOsservazioni metodologiche:\n\nIl metodo della griglia offre una visualizzazione completa della funzione di verosimiglianza.\nL’ottimizzazione numerica è più efficiente per problemi multidimensionali.\nLa soluzione analitica fornisce un riferimento teorico esatto.\nLa scelta del metodo dipende dalle specifiche esigenze analitiche e computazionali.\n\nL’implementazione in R dimostra come concetti statistici avanzati possano essere efficacemente applicati attraverso strumenti computazionali, facilitando sia l’analisi che l’interpretazione dei risultati.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/16_likelihood.html#verosimiglianza-congiunta",
    "href": "chapters/probability/16_likelihood.html#verosimiglianza-congiunta",
    "title": "17  La verosimiglianza",
    "section": "\n17.5 Verosimiglianza congiunta",
    "text": "17.5 Verosimiglianza congiunta\nIl concetto di verosimiglianza si estende naturalmente al caso di osservazioni multiple, dando origine alla verosimiglianza congiunta. Questo approccio consente di combinare informazioni provenienti da diverse fonti o esperimenti per ottenere stime parametriche più robuste.\n\n17.5.1 Dalla binomiale alla verosimiglianza congiunta\nNel caso di \\(n\\) lanci di moneta, la verosimiglianza basata sul numero totale di successi segue la distribuzione binomiale:\n\\[\n\\mathcal{L}(\\theta) = \\binom{n}{y} \\theta^y (1 - \\theta)^{n - y}.\n\\]\nTuttavia, possiamo concettualizzare il problema considerando ogni lancio come un’osservazione indipendente Bernoulli. Per una singola osservazione:\n\\[\n\\mathcal{L}(\\theta \\mid y_i) = \\theta^{y_i} (1 - \\theta)^{1 - y_i}.\n\\]\nPer \\(n\\) osservazioni indipendenti, la verosimiglianza congiunta diventa:\n\\[\n\\mathcal{L}(\\theta \\mid y_1, y_2, \\dots, y_n) = \\prod_{i=1}^{n} \\theta^{y_i} (1 - \\theta)^{1 - y_i} = \\theta^y (1 - \\theta)^{n - y}.\n\\]\ndove \\(y = \\sum_{i=1}^{n} y_i\\). Questo dimostra l’equivalenza tra l’approccio basato sulle osservazioni individuali e quello basato sulla statistica sufficiente binomiale.\n\n17.5.2 Importanza della verosimiglianza congiunta\nLa verosimiglianza congiunta rappresenta uno strumento fondamentale per:\n\nIntegrare informazioni da multiple osservazioni indipendenti.\nCostruire modelli statistici complessi.\nEffettuare stime parametriche basate sull’intero set di dati.\nGeneralizzare il concetto di verosimiglianza a contesti multivariati.\n\n17.5.3 Esempio applicativo: gruppi di osservazioni binomiali\nConsideriamo quattro gruppi indipendenti di osservazioni binomiali:\n\nGruppo 1: 23 successi su 30 prove.\nGruppo 2: 20 successi su 28 prove.\nGruppo 3: 29 successi su 40 prove.\nGruppo 4: 29 successi su 36 prove.\n\nAssumendo che tutti i gruppi condividano lo stesso parametro \\(\\theta\\), la log-verosimiglianza congiunta è data da:\n\\[\n\\log \\mathcal{L}(\\theta) = \\sum_{i=1}^{4} \\left[ y_i \\log(\\theta) + (n_i - y_i) \\log(1 - \\theta) \\right]\n\\]\nSviluppando l’espressione:\n\\[\n\\begin{aligned}\n\\log \\mathcal{L}(\\theta) = &23\\log(\\theta) + 7\\log(1 - \\theta) + \\\\\n&20\\log(\\theta) + 8\\log(1 - \\theta) + \\\\\n&29\\log(\\theta) + 11\\log(1 - \\theta) + \\\\\n&29\\log(\\theta) + 7\\log(1 - \\theta)\n\\end{aligned}\n\\]\nQuesta formulazione permette di valutare la plausibilità del parametro \\(\\theta\\) considerando simultaneamente tutte le informazioni disponibili dai quattro gruppi sperimentali.\n\n17.5.4 Implementazione computazionale\nIn R, la verosimiglianza congiunta può essere calcolata efficientemente:\n\n# Definizione dei parametri dei gruppi\nsuccessi &lt;- c(23, 20, 29, 29)\nprove &lt;- c(30, 28, 40, 36)\n\n# Funzione di log-verosimiglianza congiunta\nlog_verosimiglianza_congiunta &lt;- function(theta) {\n  sum(successi * log(theta) + (prove - successi) * log(1 - theta))\n}\n\n# Calcolo per un valore specifico di theta\nlog_verosimiglianza_congiunta(0.7)\n#&gt; [1] -75.8",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/16_likelihood.html#la-verosimiglianza-marginale-nellinferenza-bayesiana",
    "href": "chapters/probability/16_likelihood.html#la-verosimiglianza-marginale-nellinferenza-bayesiana",
    "title": "17  La verosimiglianza",
    "section": "\n17.6 La Verosimiglianza marginale nell’inferenza bayesiana",
    "text": "17.6 La Verosimiglianza marginale nell’inferenza bayesiana\nLa verosimiglianza marginale rappresenta un concetto fondamentale nell’inferenza bayesiana, permettendo di valutare la compatibilità complessiva di un modello con i dati osservati, considerando l’intera distribuzione dei parametri. A differenza della verosimiglianza classica che valuta la plausibilità dei dati per valori fissi dei parametri, la verosimiglianza marginal integra l’incertezza parametrica attraverso la distribuzione a priori.\n\n17.6.1 Caso di parametri discreti\nSupponiamo di osservare \\(k = 7\\) successi su \\(n = 10\\) tentativi, con il parametro \\(\\theta\\) che può assumere solo tre valori discreti:\n\\[\n\\theta \\in \\{0.1,\\; 0.5,\\; 0.9\\}.\n\\]\n\n\nAssegnazione della distribuzione a priori sui valori di \\(\\theta\\):\n\n\nPrior uniforme:\n\\[\np(\\theta = 0.1) = p(\\theta = 0.5) = p(\\theta = 0.9) = \\tfrac{1}{3}.\n\\]\n\n\nPrior non uniforme:\n\\[\np(\\theta = 0.1) = \\tfrac{1}{4}, \\quad\np(\\theta = 0.5) = \\tfrac{1}{2}, \\quad\np(\\theta = 0.9) = \\tfrac{1}{4}.\n\\]\n\n\n\n\nCalcolo della verosimiglianza per ogni valore di \\(\\theta\\):\n\\[\np(k=7 \\mid \\theta) = \\binom{10}{7}\\,\\theta^{7}(1-\\theta)^{3}.\n\\]\n\n\nMarginalizzazione tramite somma pesata:\n\\[\np(k=7 \\mid n=10) = \\sum_{i=1}^{3} p(k=7 \\mid \\theta_i)\\, p(\\theta_i).\n\\]\n\n\n17.6.2 Caso di parametri continui\nNella maggior parte delle applicazioni, il parametro \\(\\theta\\) varia in modo continuo. Per \\(\\theta \\in [0,1]\\), la verosimiglianza marginale si calcola integrando:\n\\[\np(k=7 \\mid n=10)\n= \\int_{0}^{1} \\binom{10}{7}\\,\\theta^{7}(1-\\theta)^{3}\\, p(\\theta)\\, d\\theta,\n\\]\ndove \\(p(\\theta)\\) è la distribuzione a priori.\nAd esempio, con una prior \\(\\text{Beta}(2,2)\\):\n\\[\np(\\theta) = \\frac{\\theta(1-\\theta)}{B(2,2)},\n\\]\nsi ottiene:\n\\[\np(k=7 \\mid n=10)\n= \\int_{0}^{1} \\binom{10}{7}\\, \\theta^{7}(1-\\theta)^{3} \\,\\frac{\\theta(1-\\theta)}{B(2,2)} \\, d\\theta.\n\\]\n\n17.6.3 Implementazione computazionale in R\n\n17.6.3.1 Parametri discreti\n\n# Valori discreti di θ e prior uniforme\ntheta_vals &lt;- c(0.1, 0.5, 0.9)\nprior_probs &lt;- rep(1/3, 3)\n\n# Calcolo della verosimiglianza marginale\nlikelihoods &lt;- dbinom(7, size = 10, prob = theta_vals)\nmarginal_likelihood &lt;- sum(likelihoods * prior_probs)\nprint(marginal_likelihood)\n#&gt; [1] 0.0582\n\nIn questo caso, il calcolo corrisponde alla formula\n\\[\np(k=7 \\mid n=10) = \\sum_{i=1}^3 p(k=7 \\mid \\theta_i)\\, p(\\theta_i).\n\\]\n\n17.6.3.2 Parametri continui\n\n# Integrazione numerica con prior Beta(2,2)\nintegrand &lt;- function(theta) {\n  dbinom(7, size = 10, prob = theta) * dbeta(theta, 2, 2)\n}\n\nmarginal_likelihood &lt;- integrate(integrand, 0, 1)$value\nprint(marginal_likelihood)\n#&gt; [1] 0.112\n\nQui la verosimiglianza marginale viene calcolata come\n\\[\np(k=7 \\mid n=10) = \\int_0^1 \\binom{10}{7}\\, \\theta^7 (1-\\theta)^3 \\, p(\\theta)\\, d\\theta,\n\\]\ndove, con una prior \\(\\text{Beta}(2,2)\\), vale\n\\[\np(\\theta) = \\frac{\\theta(1-\\theta)}{B(2,2)}.\n\\]\n\n17.6.4 Interpretazione\nLa verosimiglianza marginale \\(p(D)\\) quantifica la probabilità complessiva dei dati \\(D\\) tenendo conto di tutte le possibili configurazioni parametriche:\n\nvalori più alti indicano maggiore compatibilità tra modello e dati;\n\nvalori più bassi suggeriscono che i dati siano poco plausibili sotto quel modello;\n\nil confronto tra modelli si basa sul fattore di Bayes:\\[\nBF_{12} = \\frac{p(D \\mid M_1)}{p(D \\mid M_2)}.\n\\]\n\n\n17.6.5 Ruolo nell’inferenza bayesiana\nNella formula di Bayes\n\\[\np(\\theta \\mid D) = \\frac{p(D \\mid \\theta)\\,p(\\theta)}{p(D)},\n\\]\nla quantità \\(p(D)\\), ossia la verosimiglianza marginale:\n\nfunge da fattore di normalizzazione per ottenere la distribuzione a posteriori;\n\ncostituisce la base del confronto tra modelli;\n\nrappresenta una misura complessiva dell’evidenza fornita dai dati.\n\n17.6.6 Considerazioni pratiche\nIl calcolo di \\(p(D)\\) presenta spesso difficoltà:\n\nl’integrazione diventa rapidamente multidimensionale per modelli complessi;\n\ni risultati possono essere sensibili alla scelta della prior;\n\nsono necessari metodi approssimati (MCMC, bridge sampling, ecc.) per modelli realistici.\n\nNonostante queste complessità, la verosimiglianza marginale resta un concetto fondamentale:\n- permette di valutare la bontà di adattamento dei modelli,\n- guida la selezione bayesiana dei modelli,\n- e garantisce un’inferenza che integra in modo coerente l’incertezza sui parametri.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/16_likelihood.html#verosimiglianza-gaussiana",
    "href": "chapters/probability/16_likelihood.html#verosimiglianza-gaussiana",
    "title": "17  La verosimiglianza",
    "section": "\n17.7 Verosimiglianza gaussiana",
    "text": "17.7 Verosimiglianza gaussiana\nLa distribuzione gaussiana (o normale) è uno degli strumenti fondamentali della statistica. La sua importanza deriva dalla capacità di descrivere in modo efficace molte variabili continue di interesse psicologico e scientifico, come il quoziente intellettivo (QI), i tempi di reazione o diverse misurazioni psicofisiologiche.\n\n17.7.1 Caso di una singola osservazione\nConsideriamo la misurazione del QI di un individuo. Supponiamo che il QI segua una distribuzione normale con media incognita \\(\\mu\\) e deviazione standard nota \\(\\sigma = 15\\).\nLa funzione di densità di probabilità (pdf) è:\n\\[\nf(y \\mid \\mu, \\sigma) \\;=\\; \\frac{1}{\\sigma \\sqrt{2\\pi}}\n\\exp\\!\\left(-\\frac{(y-\\mu)^2}{2\\sigma^2}\\right),\n\\]\ndove \\(y\\) rappresenta il valore osservato (nel nostro caso \\(y=114\\)), \\(\\mu\\) è il parametro da stimare e \\(\\sigma\\) è noto.\nLa funzione di verosimiglianza per una singola osservazione è data dalla stessa espressione, considerata ora come funzione di \\(\\mu\\), fissato \\(y\\).\n\n# Osservazione e parametro noto\ny_obs &lt;- 114\nsigma &lt;- 15\nmu_values &lt;- seq(70, 160, length.out = 1000)\n\n# Calcolo della verosimiglianza\nlikelihood &lt;- dnorm(y_obs, mean = mu_values, sd = sigma)\n\n# Visualizzazione\nggplot(data.frame(mu = mu_values, likelihood = likelihood), \n       aes(x = mu, y = likelihood)) +\n  geom_line(linewidth = 1.2, color = \"steelblue\") +\n  labs(\n    x = \"Media μ\",\n    y = \"Verosimiglianza\"\n  )\n\n\n\n\n\n\n\nIl valore di \\(\\mu\\) che massimizza la verosimiglianza coincide con l’osservazione stessa:\n\nmu_optimal &lt;- mu_values[which.max(likelihood)]\ncat(\"Stima di massima verosimiglianza per μ:\", mu_optimal)\n#&gt; Stima di massima verosimiglianza per μ: 114\n\n\n17.7.2 Ottimizzazione tramite log-verosimiglianza\nL’uso della log-verosimiglianza è preferibile per ragioni numeriche:\n\ntrasforma prodotti di probabilità in somme,\nevita problemi di underflow con valori molto piccoli,\nsemplifica il calcolo delle derivate.\n\nPer una singola osservazione da una normale:\n\\[\n\\ell(\\mu \\mid y, \\sigma) \\;=\\; -\\tfrac{1}{2}\\log(2\\pi)\\;-\\;\\log(\\sigma)\\;-\\;\\frac{(y-\\mu)^2}{2\\sigma^2}.\n\\]\n\n17.7.2.1 Implementazione in R\n\n# Definizione della funzione di log-verosimiglianza negativa\nnegative_log_likelihood &lt;- function(mu, y, sigma) {\n  -dnorm(y, mean = mu, sd = sigma, log = TRUE)\n}\n\n# Ottimizzazione numerica\nresult &lt;- optim(\n  par = 100,                 # Valore iniziale per μ\n  fn = negative_log_likelihood,\n  y = y_obs,\n  sigma = sigma,\n  method = \"L-BFGS-B\",\n  lower = 70,\n  upper = 160\n)\n\n# Estrazione della stima\nmu_mle &lt;- result$par\ncat(\"Stima di massima verosimiglianza per μ:\", round(mu_mle, 2))\n#&gt; Stima di massima verosimiglianza per μ: 114\n\n\n17.7.3 Vantaggi della log-verosimiglianza\n\n\nStabilità numerica: riduce i rischi di underflow.\n\nEfficienza computazionale: la somma di log-probabilità è più stabile del prodotto di probabilità.\n\nProprietà additive: la log-verosimiglianza totale è la somma dei contributi dei singoli dati.\n\nDerivazioni semplificate: le derivate della log-verosimiglianza hanno forma più semplice.\n\n17.7.4 Interpretazione del risultato\nLa stima di massima verosimiglianza (MLE) per \\(\\mu\\) risulta:\n\\[\n\\hat{\\mu} = 114,\n\\]\nossia il valore osservato. Questo era atteso: per una singola osservazione da una normale con deviazione standard nota, la stima MLE della media coincide esattamente con il dato osservato.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/16_likelihood.html#campione-di-osservazioni-indipendenti",
    "href": "chapters/probability/16_likelihood.html#campione-di-osservazioni-indipendenti",
    "title": "17  La verosimiglianza",
    "section": "\n17.8 Campione di osservazioni indipendenti",
    "text": "17.8 Campione di osservazioni indipendenti\nSupponiamo di avere i punteggi BDI-II raccolti su un campione di \\(n=30\\) partecipanti. Assumiamo che ciascun punteggio sia un’osservazione indipendente da una distribuzione normale con media incognita \\(\\mu\\) e deviazione standard nota \\(\\sigma = 6.5\\).\n\n# Dati osservati (punteggi BDI-II)\ny &lt;- c(\n  26, 35, 30, 25, 44, 30, 33, 43, 22, 43, 24, 19, 39, 31, 25, \n  28, 35, 30, 26, 31, 41, 36, 26, 35, 33, 28, 27, 34, 27, 22\n)\n\nsigma &lt;- 6.5  # Deviazione standard nota\n\n\n\n17.8.1 Log-verosimiglianza\nPer un campione di \\(n\\) osservazioni indipendenti, la log-verosimiglianza del parametro \\(\\mu\\) è\n\\[\n\\ell(\\mu \\mid y, \\sigma) \\;=\\; \\sum_{i=1}^n \\log f(y_i \\mid \\mu, \\sigma),\n\\]\ndove \\(f(y_i \\mid \\mu, \\sigma)\\) è la densità normale.\nIn R:\n\nlog_likelihood &lt;- function(mu, y, sigma) {\n  sum(dnorm(y, mean = mu, sd = sigma, log = TRUE))\n}\n\nCalcoliamo \\(\\ell(\\mu)\\) per valori di \\(\\mu\\) attorno alla media campionaria:\n\nmu_range &lt;- seq(mean(y) - 2 * sigma, mean(y) + 2 * sigma, length.out = 1000)\nlog_lik_values &lt;- sapply(mu_range, function(mu_val) log_likelihood(mu_val, y, sigma))\n\n\n17.8.2 Visualizzazione\n\nlibrary(ggplot2)\n\nggplot(\n  data.frame(mu = mu_range, log_likelihood = log_lik_values),\n  aes(x = mu, y = log_likelihood)\n) +\n  geom_line(linewidth = 1.2, color = \"steelblue\") +\n  geom_vline(xintercept = mean(y), linetype = \"dashed\", color = \"red\", linewidth = 1) +\n  labs(\n    x = expression(mu),\n    y = \"Log-verosimiglianza\"\n  ) +\n  annotate(\"text\", x = mean(y) + 2, y = max(log_lik_values) - 5,\n           label = paste0(\"Media campionaria = \", round(mean(y), 2)),\n           color = \"red\", hjust = 0)\n\n\n\n\n\n\n\n\n17.8.3 Interpretazione\nLa curva mostra come varia la log-verosimiglianza al variare di \\(\\mu\\):\n\nil massimo si ottiene in corrispondenza della media campionaria, come previsto;\nla forma è concava e parabolica, tipica del modello normale;\nla larghezza della curva riflette l’incertezza della stima.\n\nIn altre parole, lo stimatore di massima verosimiglianza (MLE) di \\(\\mu\\) è la media campionaria:\n\\[\n\\hat{\\mu}_{\\text{MLE}} = \\bar{y}.\n\\]\n\n17.8.4 Ottimizzazione numerica\nPossiamo verificare la stima tramite algoritmi di ottimizzazione:\n\nnegative_log_likelihood &lt;- function(mu, y, sigma) {\n  -sum(dnorm(y, mean = mu, sd = sigma, log = TRUE))\n}\n\nresult &lt;- optim(\n  par = mean(y),\n  fn = negative_log_likelihood,\n  y = y,\n  sigma = sigma,\n  method = \"L-BFGS-B\",\n  lower = min(mu_range),\n  upper = max(mu_range)\n)\n\nmu_optimal &lt;- result$par\ncat(\"Stima numerica di massima verosimiglianza per μ:\", round(mu_optimal, 4))\n#&gt; Stima numerica di massima verosimiglianza per μ: 30.9\n\nConfronto con la media campionaria:\n\nsample_mean &lt;- mean(y)\n\ndata.frame(\n  Metodo = c(\"Ottimizzazione numerica\", \"Media campionaria\"),\n  Valore = c(mu_optimal, sample_mean),\n  Differenza = c(NA, abs(mu_optimal - sample_mean))\n)\n#&gt;                    Metodo Valore Differenza\n#&gt; 1 Ottimizzazione numerica   30.9         NA\n#&gt; 2       Media campionaria   30.9    1.1e-11\n\nIn conclusione, la stima ottenuta con l’ottimizzazione coincide perfettamente con la media campionaria. Questo conferma il risultato teorico: per un campione indipendente da una normale con varianza nota, lo stimatore MLE della media è la media campionaria.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/16_likelihood.html#il-rapporto-di-verosimiglianze",
    "href": "chapters/probability/16_likelihood.html#il-rapporto-di-verosimiglianze",
    "title": "17  La verosimiglianza",
    "section": "\n17.9 Il rapporto di verosimiglianze",
    "text": "17.9 Il rapporto di verosimiglianze\nIn statistica capita spesso di dover confrontare modelli alternativi che cercano di spiegare gli stessi dati osservati. Ad esempio, nella stima della media di una variabile psicologica (punteggi ai test, tempi di reazione, ecc.), potremmo avere due ipotesi contrastanti:\n\n\nModello nullo (\\(H_0\\)): la media assume un valore fissato \\(\\mu_1\\) (tipicamente un valore di riferimento o assenza di effetto);\n\nModello alternativo (\\(H_1\\)): la media assume un valore diverso \\(\\mu_2\\) (indicativo di un effetto o cambiamento).\n\nIl rapporto di verosimiglianze (Likelihood Ratio, LR) fornisce una misura quantitativa dell’evidenza relativa a favore di un modello rispetto all’altro, basandosi direttamente sui dati.\n\n17.9.1 Definizione formale\nIl rapporto di verosimiglianze è definito come\n\\[\n\\lambda \\;=\\; \\frac{L(\\mu_2 \\mid \\text{dati})}{L(\\mu_1 \\mid \\text{dati})},\n\\]\ndove:\n\n\n\\(L(\\mu_2 \\mid \\text{dati})\\) è la verosimiglianza sotto l’ipotesi alternativa,\n\n\\(L(\\mu_1 \\mid \\text{dati})\\) è la verosimiglianza sotto l’ipotesi nulla.\n\n17.9.2 Interpretazione\n\n\n\\(\\lambda &gt; 1\\): i dati favoriscono il modello alternativo;\n\n\\(\\lambda &lt; 1\\): i dati favoriscono il modello nullo;\n\n\\(\\lambda \\approx 1\\): i dati non discriminano tra i modelli.\n\nLa distanza dall’unità indica quanto più probabili sono i dati sotto un modello rispetto all’altro.\n\n17.9.3 Esempio: lancio di una moneta\nSupponiamo di osservare \\(x = 7\\) successi su \\(n = 10\\) lanci. Confrontiamo due modelli:\n\n\n\\(H_0\\): moneta equa (\\(\\theta = 0.5\\))\n\n\\(H_1\\): moneta sbilanciata verso il successo (\\(\\theta = 0.7\\))\n\n\n17.9.3.1 Calcolo analitico\nLa verosimiglianza binomiale è:\n\\[\nL(\\theta \\mid x, n) \\;=\\; \\binom{n}{x}\\,\\theta^x(1-\\theta)^{n-x}.\n\\]\nSostituendo i valori:\n\n\\(L(0.5) = 120 \\cdot (0.5)^{10} \\approx 0.117\\)\n\\(L(0.7) = 120 \\cdot (0.7)^7 (0.3)^3 \\approx 0.267\\)\n\nQuindi:\n\\[\n\\lambda = \\frac{0.267}{0.117} \\;\\approx\\; 2.28.\n\\]\n\n17.9.3.2 Implementazione in R\n\n# Parametri osservati\nn &lt;- 10\nx &lt;- 7\n\n# Verosimiglianze\nL_null &lt;- dbinom(x, n, 0.5)\nL_alt  &lt;- dbinom(x, n, 0.7)\nlambda &lt;- L_alt / L_null\n\ncat(\"L(H0, θ=0.5):\", round(L_null, 3), \"\\n\")\n#&gt; L(H0, θ=0.5): 0.117\ncat(\"L(H1, θ=0.7):\", round(L_alt, 3), \"\\n\")\n#&gt; L(H1, θ=0.7): 0.267\ncat(\"Rapporto di verosimiglianze λ:\", round(lambda, 2), \"\\n\")\n#&gt; Rapporto di verosimiglianze λ: 2.28\n\n\n17.9.3.3 Visualizzazione grafica\n\ntheta_seq &lt;- seq(0, 1, length.out = 1000)\nlikelihood_vals &lt;- dbinom(x, n, theta_seq)\n\ndf &lt;- data.frame(theta = theta_seq, likelihood = likelihood_vals)\n\nggplot(df, aes(x = theta, y = likelihood)) +\n  geom_line(linewidth = 1.2, color = \"steelblue\") +\n  geom_vline(xintercept = c(0.5, 0.7), linetype = \"dashed\",\n             color = c(\"red\", \"darkgreen\"), linewidth = 1) +\n  geom_point(aes(x = 0.5, y = L_null), color = \"red\", size = 3) +\n  geom_point(aes(x = 0.7, y = L_alt), color = \"darkgreen\", size = 3) +\n  labs(\n    x = expression(theta),\n    y = \"Verosimiglianza\"\n  ) +\n  annotate(\"text\", x = 0.5, y = L_null + 0.01, label = \"H₀: θ = 0.5\",\n           color = \"red\", hjust = -0.1) +\n  annotate(\"text\", x = 0.7, y = L_alt + 0.01, label = \"H₁: θ = 0.7\",\n           color = \"darkgreen\", hjust = -0.1) \n\n\n\n\n\n\n\n\n17.9.4 Interpretazione dei risultati\nIl valore \\(\\lambda \\approx 2.28\\) indica che i dati sono circa 2.3 volte più probabili sotto l’ipotesi alternativa rispetto all’ipotesi nulla. Si tratta di un’evidenza moderata ma non decisiva a favore dell’ipotesi che la moneta sia predisposta verso il successo.\n\n17.9.5 Considerazioni metodologiche\n\n\nEvidenza relativa: il rapporto di verosimiglianze non misura la bontà assoluta del modello, ma solo la preferenza relativa.\n\nScala di interpretazione: valori tra 1 e 3 suggeriscono un’evidenza debole-moderata, mentre valori più grandi indicano supporto crescente.\n\nGeneralità: la logica del LR si applica a qualsiasi modello parametrico.\n\nConnessione bayesiana: con prior poco informative, \\(\\lambda\\) si avvicina al fattore di Bayes, strumento principe della selezione di modelli in ottica bayesiana.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/16_likelihood.html#rapporti-di-verosimiglianza-aggiustati-e-criterio-di-akaike",
    "href": "chapters/probability/16_likelihood.html#rapporti-di-verosimiglianza-aggiustati-e-criterio-di-akaike",
    "title": "17  La verosimiglianza",
    "section": "\n17.10 Rapporti di verosimiglianza aggiustati e criterio di Akaike",
    "text": "17.10 Rapporti di verosimiglianza aggiustati e criterio di Akaike\nQuando si confrontano modelli statistici, occorre tenere presente che i modelli più complessi, dotati di un numero maggiore di parametri, tendono naturalmente a produrre un miglior adattamento ai dati osservati. Questo vantaggio, tuttavia, può dipendere solo dalla maggiore flessibilità del modello, senza riflettere una reale capacità esplicativa. Il fenomeno, noto come sovradattamento (overfitting), richiede quindi criteri che penalizzino opportunamente la complessità.\n\n17.10.1 Il ruolo dell’AIC\nIl Criterio di Informazione di Akaike (AIC) rappresenta una soluzione semplice ed efficace. La sua formulazione è:\n\\[\n\\text{AIC} = 2k - 2 \\log(L),\n\\] dove:\n\n\n\\(k\\) è il numero di parametri del modello,\n\n\\(L\\) è la massima verosimiglianza del modello.\n\nIn questo modo l’AIC combina due aspetti:\n\nla bontà di adattamento, catturata da \\(-2 \\log(L)\\);\nla parsimonia, garantita dal termine di penalizzazione \\(2k\\).\n\n17.10.2 Esempio: memoria visiva ed emozione\nSupponiamo di voler valutare l’effetto del contenuto emotivo delle immagini sulla memoria visiva. In un esperimento, 30 partecipanti per condizione hanno ottenuto:\n\nsuccessi_neutro &lt;- 14\nsuccessi_emozione &lt;- 22\nprove &lt;- 30\n\n\n17.10.2.1 Modello nullo (\\(H_0\\)): probabilità comune\n\n# Probabilità congiunta stimata\np_null &lt;- (successi_neutro + successi_emozione) / (2 * prove)\n\n# Log-verosimiglianza\nll_null &lt;- dbinom(successi_neutro, prove, p_null, log = TRUE) +\n           dbinom(successi_emozione, prove, p_null, log = TRUE)\n\n\n17.10.2.2 Modello alternativo (\\(H_1\\)): probabilità distinte\n\n# Probabilità stimate separatamente\np_neutro &lt;- successi_neutro / prove\np_emozione &lt;- successi_emozione / prove\n\n# Log-verosimiglianza\nll_alt &lt;- dbinom(successi_neutro, prove, p_neutro, log = TRUE) +\n          dbinom(successi_emozione, prove, p_emozione, log = TRUE)\n\n\n17.10.2.3 Confronto tramite AIC\n\nAIC_null &lt;- 2 * 1 - 2 * ll_null  # Modello con 1 parametro\nAIC_alt  &lt;- 2 * 2 - 2 * ll_alt   # Modello con 2 parametri\n\ndelta_AIC &lt;- AIC_alt - AIC_null\n\n\nUn valore di AIC più basso indica il modello preferito.\nDifferenze \\(&gt; 2\\) suggeriscono evidenza sostanziale a favore del modello migliore.\nDifferenze \\(&gt; 10\\) forniscono evidenza decisiva.\n\n17.10.2.4 Test del rapporto di verosimiglianza\n\nLR_stat &lt;- -2 * (ll_null - ll_alt)\np_value &lt;- pchisq(LR_stat, df = 1, lower.tail = FALSE)\n\n\n17.10.3 Interpretazione\nIl confronto tra modelli fornisce due prospettive complementari:\n\n\nAIC: valuta la qualità relativa dei modelli, bilanciando adattamento e complessità.\n\nRapporto di verosimiglianza: consente un test formale della differenza tra modelli.\n\nNell’esempio, il test produce \\(p \\approx 0.034\\), mentre l’AIC mostra una chiara preferenza per il modello alternativo. Entrambi i criteri concordano: il modello che assegna probabilità distinte ai due gruppi descrive meglio i dati, suggerendo che il contenuto emotivo delle immagini facilita la memoria visiva.\nIn conclusione, l’uso integrato di AIC e rapporti di verosimiglianza permette di prendere decisioni modellistiche fondate, evitando il rischio di sovradattamento. In psicologia, dove i dati sono spesso rumorosi e complessi, questo approccio consente di mantenere un equilibrio cruciale tra capacità esplicativa e parsimonia.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/16_likelihood.html#riflessioni-conclusive",
    "href": "chapters/probability/16_likelihood.html#riflessioni-conclusive",
    "title": "17  La verosimiglianza",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nLa funzione di verosimiglianza rappresenta il fondamento concettuale e operativo dell’inferenza statistica moderna, fornendo un ponte metodologico tra modelli teorici ed evidenza empirica. La sua efficacia deriva dalla capacità di quantificare sistematicamente la plausibilità dei parametri di un modello condizionatamente ai dati osservati, creando così un collegamento formale tra astrazione teorica e osservazione sperimentale.\nL’impianto teorico della verosimiglianza si basa su tre componenti essenziali: la specificazione del modello probabilistico generatore dei dati, la definizione dello spazio parametrico e l’incorporazione delle osservazioni empiriche. Questo framework si dimostra particolarmente efficace nei modelli binomiali e gaussiani, dove assume forme analiticamente trattabili che facilitano sia la stima puntuale che la verifica di ipotesi.\nNel contesto della distribuzione normale, la stima di massima verosimiglianza del parametro μ coincide elegantemente con la media campionaria, mentre la rappresentazione grafica della funzione di verosimiglianza offre una visualizzazione immediata della precisione della stima. L’adozione della log-verosimiglianza, oltre a semplificare i calcoli analitici, garantisce una maggiore stabilità numerica, particolarmente valuable in contesti con campioni di grandi dimensioni o modelli complessi.\nIl rapporto di verosimiglianza si configura come uno strumento particolarmente versatile, in grado di bilanciare sofisticatamente la bontà di adattamento con il principio di parsimonia modellistica. Questo bilanciamento trova la sua espressione formale in criteri di selezione modellistica come l’AIC, che penalizzano appropriatamente la complessità parametrica evitando il sovradattamento.\nLa verosimiglianza, nelle sue molteplici manifestazioni, non si limita a collegare modelli teorici e dati empirici, ma costituisce il motore propulsivo dell’inferenza bayesiana. Attraverso il teorema di Bayes, la verosimiglianza trasforma sistematicamente l’informazione a priori in distribuzioni posteriori, aggiornando razionalmente le nostre credenze alla luce dell’evidenza osservata. Questo duplice ruolo - sia nell’ambito frequentista che in quello bayesiano - testimonia la profondità e l’utilità di questo strumento statistico fondamentale.\nLa padronanza dei concetti di verosimiglianza e log-verosimiglianza rappresenta quindi una competenza essenziale per lo psicologo ricercatore, permettendo non solo l’analisi appropriata dei dati sperimentali, ma anche la comprensione critica dei modelli teorici che sottendono i processi psicologici investigati.\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nSpiega ciascuno dei concetti seguenti con una frase:\n\nprobabilità.\nfunzione di massa di probabilità.\nfunzione di densità di probabilità.\ndistribuzione di probabilità.\ndistribuzione di probabilità discreta.\ndistribuzione di probabilità continua.\nfunzione di distribuzione cumulativa (cdf).\nverosimiglianza\n\n\n\n\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nSupponi di aver misurato il livello di ansia (ad esempio usando una scala standardizzata) in un campione di 15 persone con i seguenti punteggi:\nansia &lt;- c(23, 27, 30, 29, 25, 28, 26, 24, 31, 29, 27, 26, 28, 30, 25)\nAssumendo che la deviazione standard sia nota e pari a 3.5, svolgi le seguenti attività in R:\n\nCalcola la funzione di verosimiglianza gaussiana per diversi valori di \\(\\mu\\) nell’intervallo da 20 a 35.\nTrova numericamente il valore di \\(\\mu\\) che rende massima la verosimiglianza (stima di massima verosimiglianza, MLE).\nDisegna un grafico della funzione di verosimiglianza per visualizzare il risultato.\n\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt;  [4] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt;  [7] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [10] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [13] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [16] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [25] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.8          tidyselect_1.2.1      farver_2.1.2         \n#&gt;  [4] fastmap_1.2.0         TH.data_1.1-4         tensorA_0.36.2.1     \n#&gt;  [7] digest_0.6.37         timechange_0.3.0      estimability_1.5.1   \n#&gt; [10] lifecycle_1.0.4       survival_3.8-3        magrittr_2.0.3       \n#&gt; [13] compiler_4.5.1        rlang_1.1.6           tools_4.5.1          \n#&gt; [16] knitr_1.50            labeling_0.4.3        bridgesampling_1.1-2 \n#&gt; [19] htmlwidgets_1.6.4     curl_7.0.0            pkgbuild_1.4.8       \n#&gt; [22] RColorBrewer_1.1-3    abind_1.4-8           multcomp_1.4-28      \n#&gt; [25] withr_3.0.2           purrr_1.1.0           grid_4.5.1           \n#&gt; [28] stats4_4.5.1          colorspace_2.1-1      xtable_1.8-4         \n#&gt; [31] inline_0.3.21         emmeans_1.11.2-8      scales_1.4.0         \n#&gt; [34] MASS_7.3-65           cli_3.6.5             mvtnorm_1.3-3        \n#&gt; [37] rmarkdown_2.29        ragg_1.5.0            generics_0.1.4       \n#&gt; [40] RcppParallel_5.1.11-1 cachem_1.1.0          stringr_1.5.1        \n#&gt; [43] splines_4.5.1         parallel_4.5.1        vctrs_0.6.5          \n#&gt; [46] V8_7.0.0              Matrix_1.7-4          sandwich_3.1-1       \n#&gt; [49] jsonlite_2.0.0        arrayhelpers_1.1-0    systemfonts_1.2.3    \n#&gt; [52] glue_1.8.0            codetools_0.2-20      distributional_0.5.0 \n#&gt; [55] lubridate_1.9.4       stringi_1.8.7         gtable_0.3.6         \n#&gt; [58] QuickJSR_1.8.0        htmltools_0.5.8.1     Brobdingnag_1.2-9    \n#&gt; [61] R6_2.6.1              textshaping_1.0.3     rprojroot_2.1.1      \n#&gt; [64] evaluate_1.0.5        lattice_0.22-7        backports_1.5.0      \n#&gt; [67] memoise_2.0.1         broom_1.0.9           snakecase_0.11.1     \n#&gt; [70] rstantools_2.5.0      coda_0.19-4.1         gridExtra_2.3        \n#&gt; [73] nlme_3.1-168          checkmate_2.3.3       xfun_0.53            \n#&gt; [76] zoo_1.8-14            pkgconfig_2.0.3",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/16_likelihood.html#bibliografia",
    "href": "chapters/probability/16_likelihood.html#bibliografia",
    "title": "17  La verosimiglianza",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a02_math_symbols.html",
    "href": "chapters/appendix/a02_math_symbols.html",
    "title": "Appendice A — Simbologia di base",
    "section": "",
    "text": "Per una scrittura più sintetica possono essere utilizzati alcuni simboli matematici.\n\n\\(\\log(x)\\): il logaritmo naturale di \\(x\\).\nL’operatore logico booleano \\(\\land\\) significa “e” (congiunzione forte) mentre il connettivo di disgiunzione \\(\\lor\\) significa “o” (oppure) (congiunzione debole).\nIl quantificatore esistenziale \\(\\exists\\) vuol dire “esiste almeno un” e indica l’esistenza di almeno una istanza del concetto/oggetto indicato. Il quantificatore esistenziale di unicità \\(\\exists!\\) (“esiste soltanto un”) indica l’esistenza di esattamente una istanza del concetto/oggetto indicato. Il quantificatore esistenziale \\(\\nexists\\) nega l’esistenza del concetto/oggetto indicato.\nIl quantificatore universale \\(\\forall\\) vuol dire “per ogni.”\n\\(\\mathcal{A, S}\\): insiemi.\n\\(x \\in A\\): \\(x\\) è un elemento dell’insieme \\(A\\).\nL’implicazione logica “\\(\\Rightarrow\\)” significa “implica” (se …allora). \\(P \\Rightarrow Q\\) vuol dire che \\(P\\) è condizione sufficiente per la verità di \\(Q\\) e che \\(Q\\) è condizione necessaria per la verità di \\(P\\).\nL’equivalenza matematica “\\(\\iff\\)” significa “se e solo se” e indica una condizione necessaria e sufficiente, o corrispondenza biunivoca.\nIl simbolo \\(\\vert\\) si legge “tale che.”\nIl simbolo \\(\\triangleq\\) (o \\(:=\\)) si legge “uguale per definizione.”\nIl simbolo \\(\\Delta\\) indica la differenza fra due valori della variabile scritta a destra del simbolo.\nIl simbolo \\(\\propto\\) si legge “proporzionale a.”\nIl simbolo \\(\\approx\\) si legge “circa.”\nIl simbolo \\(\\in\\) della teoria degli insiemi vuol dire “appartiene” e indica l’appartenenza di un elemento ad un insieme. Il simbolo \\(\\notin\\) vuol dire “non appartiene.”\nIl simbolo \\(\\subseteq\\) si legge “è un sottoinsieme di” (può coincidere con l’insieme stesso). Il simbolo \\(\\subset\\) si legge “è un sottoinsieme proprio di.”\nIl simbolo \\(\\#\\) indica la cardinalità di un insieme.\nIl simbolo \\(\\cap\\) indica l’intersezione di due insiemi. Il simbolo \\(\\cup\\) indica l’unione di due insiemi.\nIl simbolo \\(\\emptyset\\) indica l’insieme vuoto o evento impossibile.\nIn matematica, \\(\\mbox{argmax}\\) identifica l’insieme dei punti per i quali una data funzione raggiunge il suo massimo. In altre parole, \\(\\mbox{argmax}_x f(x)\\) è l’insieme dei valori di \\(x\\) per i quali \\(f(x)\\) raggiunge il valore più alto.\n\\(a, c, \\alpha, \\gamma\\): scalari.\n\\(\\boldsymbol{x}, \\boldsymbol{y}\\): vettori.\n\\(\\boldsymbol{X}, \\boldsymbol{Y}\\): matrici.\n\\(X \\sim p\\): la variabile casuale \\(X\\) si distribuisce come \\(p\\).\n\\(p(\\cdot)\\): distribuzione di massa o di densità di probabilità.\n\\(p(y \\mid \\boldsymbol{x})\\): la probabilità o densità di \\(y\\) dato \\(\\boldsymbol{x}\\), ovvero \\(p(y = \\boldsymbol{Y} \\mid x = \\boldsymbol{X})\\).\n\\(f(x)\\): una funzione arbitraria di \\(x\\).\n\\(f(\\boldsymbol{X}; \\theta, \\gamma)\\): \\(f\\) è una funzione di \\(\\boldsymbol{X}\\) con parametri \\(\\theta, \\gamma\\). Questa notazione indica che \\(\\boldsymbol{X}\\) sono i dati che vengono passati ad un modello di parametri \\(\\theta, \\gamma\\).\n\\(\\mathcal{N}(\\mu, \\sigma^2)\\): distribuzione gaussiana di media \\(\\mu\\) e varianza \\(sigma^2\\).\n\\(\\mbox{Beta}(\\alpha, \\beta)\\): distribuzione Beta di parametri \\(\\alpha\\) e \\(\\beta\\).\n\\(\\mathcal{U}(a, b)\\): distribuzione uniforme con limite inferiore \\(a\\) e limite superiore \\(b\\).\n\\(\\mbox{Cauchy}(\\alpha, \\beta)\\): distribuzione di Cauchy di parametri \\(\\alpha\\) (posizione: media) e \\(\\beta\\) (scala: radice quadrata della varianza).\n\\(\\mathcal{B}(p)\\): distribuzione di Bernoulli di parametro \\(p\\) (probabilità di successo).\n\\(\\mbox{Bin}(n, p)\\): distribuzione binomiale di parametri \\(n\\) (numero di prove) e \\(p\\) (probabilità di successo).\n\\(\\mathbb{KL} (p \\mid\\mid q)\\): la divergenza di Kullback-Leibler da \\(p\\) a \\(q\\).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Simbologia di base</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html",
    "href": "chapters/appendix/a11_numbers.html",
    "title": "Appendice B — Numeri e intervalli",
    "section": "",
    "text": "B.1 Numeri binari\nI numeri binari rappresentano il sistema numerico più elementare utilizzato in informatica, poiché sono composti unicamente da due simboli: 0 e 1. Questa caratteristica li rende particolarmente adatti alla rappresentazione di situazioni dicotomiche (vero/falso, presente/assente) e consente ai computer di operare rapidamente ed efficacemente sui dati.\nUn esempio semplice d’impiego dei valori logici binari si ottiene quando raccogliamo risposte a una domanda chiusa. Immaginiamo, ad esempio, di porre la domanda “Ti piacciono i mirtilli?” a 10 studenti. Se le risposte vengono memorizzate in R come valori logici (TRUE per “Sì” e FALSE per “No”), potremmo avere:\nopinion &lt;- c(TRUE, FALSE, TRUE, TRUE, TRUE, FALSE, TRUE, TRUE, TRUE, FALSE)\nopinion\n\n [1]  TRUE FALSE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE FALSE\nIn questo caso, TRUE e FALSE corrispondono a 1 e 0 rispettivamente quando utilizzati in operazioni numeriche. Lo stesso avviene in Python, dove True è interpretato come 1 e False come 0. Questa rappresentazione binaria permette di ottenere facilmente statistiche sintetiche. Per esempio, per calcolare la proporzione di risposte positive rispetto al totale, è sufficiente sommare i valori (contando così il numero di TRUE) e dividere per la lunghezza del vettore:\nsum(opinion) / length(opinion)\n\n[1] 0.7\nQuesto fornisce immediatamente la percentuale di studenti che hanno risposto “Sì” alla domanda.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#numeri-interi",
    "href": "chapters/appendix/a11_numbers.html#numeri-interi",
    "title": "Appendice B — Numeri e intervalli",
    "section": "\nB.2 Numeri interi",
    "text": "B.2 Numeri interi\nI numeri interi sono caratterizzati dall’assenza di componenti decimali. Essi includono sia i numeri naturali (1, 2, 3, …), tradizionalmente utilizzati per il conteggio, sia i loro opposti negativi. L’insieme dei numeri naturali è indicato con \\(\\mathbb{N}\\), mentre l’insieme dei numeri interi (che include i numeri naturali, i loro negativi e lo zero) si denota con \\(\\mathbb{Z}\\):\n\\[\n\\mathbb{Z} = \\{0, \\pm 1, \\pm 2, \\pm 3, \\dots\\}\n\\]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#numeri-razionali",
    "href": "chapters/appendix/a11_numbers.html#numeri-razionali",
    "title": "Appendice B — Numeri e intervalli",
    "section": "\nB.3 Numeri razionali",
    "text": "B.3 Numeri razionali\nI numeri razionali sono quei numeri che possono essere espressi come il rapporto tra due numeri interi, con il denominatore diverso da zero. Essi formano l’insieme:\n\\[\n\\mathbb{Q} = \\left\\{\\frac{m}{n} \\mid m,n \\in \\mathbb{Z}, n \\neq 0\\right\\}.\n\\]\nPoiché ogni numero naturale è anche un intero, e ogni intero può essere rappresentato come razionale (ad esempio \\(5 = \\frac{5}{1}\\)), si ha una catena d’inclusioni tra i diversi insiemi di numeri:\n\\[\n\\mathbb{N} \\subseteq \\mathbb{Z} \\subseteq \\mathbb{Q}.\n\\]\nSe si desidera considerare solo i numeri razionali non negativi, si utilizza la notazione:\n\\[\n\\mathbb{Q}^+ = \\{q \\in \\mathbb{Q} \\mid q \\geq 0\\}.\n\\]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#numeri-irrazionali",
    "href": "chapters/appendix/a11_numbers.html#numeri-irrazionali",
    "title": "Appendice B — Numeri e intervalli",
    "section": "\nB.4 Numeri irrazionali",
    "text": "B.4 Numeri irrazionali\nNon tutti i numeri possono essere espressi come rapporto di due interi. I numeri che non hanno questa proprietà sono detti irrazionali. Essi non possono essere scritti in forma frazionaria e la loro espansione decimale è infinita e non periodica. Esempi tipici di numeri irrazionali sono:\n\n\\(\\sqrt{2}\\)\n\\(\\sqrt{3}\\)\n\\(\\pi = 3.141592...\\)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#numeri-reali",
    "href": "chapters/appendix/a11_numbers.html#numeri-reali",
    "title": "Appendice B — Numeri e intervalli",
    "section": "\nB.5 Numeri reali",
    "text": "B.5 Numeri reali\nI numeri razionali non coprono tutti i possibili punti sulla retta reale. Per rappresentare ogni possibile misura, grandezza o punto su una linea continua, si considerano i numeri reali, denotati con \\(\\mathbb{R}\\). L’insieme dei numeri reali comprende sia i razionali sia gli irrazionali:\n\\[\n\\mathbb{N} \\subseteq \\mathbb{Z} \\subseteq \\mathbb{Q} \\subseteq \\mathbb{R}.\n\\]\nIn statistica, la precisione con cui si esprime una misura è spesso legata al numero di cifre decimali utilizzate, sfruttando così appieno la “continuità” offerta dai numeri reali.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#intervalli-numerici",
    "href": "chapters/appendix/a11_numbers.html#intervalli-numerici",
    "title": "Appendice B — Numeri e intervalli",
    "section": "\nB.6 Intervalli Numerici",
    "text": "B.6 Intervalli Numerici\nDefinizione: Un intervallo numerico è un sottoinsieme connesso della retta reale. Intuitivamente, rappresenta tutti i numeri reali compresi tra due estremi, che possono o meno essere inclusi nell’intervallo stesso.\nClassificazione degli intervalli: Gli intervalli vengono classificati in base all’inclusione o meno degli estremi:\n\n\nIntervallo chiuso: Include entrambi gli estremi. Si indica con \\([a, b]\\) e rappresenta l’insieme dei numeri reali \\(x\\) tali che \\(a \\leq x \\leq b\\).\n\nIntervallo aperto: Non include alcun estremo. Si indica con \\((a, b)\\) e rappresenta l’insieme dei numeri reali \\(x\\) tali che \\(a &lt; x &lt; b\\).\n\nIntervalli semiaperti:\n\n\nChiuso a sinistra e aperto a destra: Include l’estremo sinistro ma non quello destro. Si indica con \\([a, b)\\) e rappresenta l’insieme dei numeri reali \\(x\\) tali che \\(a \\leq x &lt; b\\).\n\nAperto a sinistra e chiuso a destra: Include l’estremo destro ma non quello sinistro. Si indica con \\((a, b]\\) e rappresenta l’insieme dei numeri reali \\(x\\) tali che \\(a &lt; x \\leq b\\).\n\n\n\nTabella riassuntiva:\n\n\nIntervallo\nNotazione\nCondizione\n\n\n\nChiuso\n\\([a, b]\\)\n\\(a \\leq x \\leq b\\)\n\n\nAperto\n\\((a, b)\\)\n\\(a &lt; x &lt; b\\)\n\n\nChiuso a sinistra, aperto a destra\n\\([a, b)\\)\n\\(a \\leq x &lt; b\\)\n\n\nAperto a sinistra, chiuso a destra\n\\((a, b]\\)\n\\(a &lt; x \\leq b\\)\n\n\n\nOsservazioni: * La scelta della notazione con parentesi quadre o tonde indica rispettivamente l’inclusione o l’esclusione degli estremi.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a12_sum_notation.html",
    "href": "chapters/appendix/a12_sum_notation.html",
    "title": "Appendice C — Sommatorie",
    "section": "",
    "text": "C.1 Manipolazione di somme\nLe somme sono uno strumento fondamentale in molti contesti matematici e statistici, e per gestirle in modo efficace è essenziale disporre di una notazione chiara e precisa. Consideriamo, ad esempio, la somma dei primi \\(n\\) numeri interi, che può essere espressa come \\(1 + 2 + \\dots + (n-1) + n\\), dove i puntini di sospensione (\\(\\dots\\)) indicano che la sequenza deve essere completata seguendo il pattern definito dai termini precedenti e successivi. Tuttavia, una notazione come \\(1 + 7 + \\dots + 73.6\\) risulterebbe ambigua senza ulteriori specifiche. In generale, ci troveremo di fronte a somme della forma\n\\[\nx_1 + x_2 + \\dots + x_n,\n\\]\ndove \\(x_n\\) rappresenta un numero definito altrove. Sebbene questa notazione con i puntini di sospensione sia utile in alcuni contesti, può risultare poco chiara in altri. Per questo motivo, si preferisce utilizzare la notazione di sommatoria:\n\\[\n\\sum_{i=1}^n x_i,\n\\]\nche si legge “sommatoria per \\(i\\) che va da \\(1\\) a \\(n\\) di \\(x_i\\)”. Il simbolo \\(\\sum\\) (la lettera sigma maiuscola dell’alfabeto greco) rappresenta l’operazione di somma, \\(x_i\\) è il generico addendo, mentre \\(1\\) e \\(n\\) sono gli estremi della sommatoria, che definiscono l’intervallo di variazione dell’indice \\(i\\). Solitamente, l’estremo inferiore è \\(1\\), ma potrebbe essere qualsiasi altro numero \\(m &lt; n\\). Pertanto, possiamo scrivere:\n\\[\n\\sum_{i=1}^n x_i = x_1 + x_2 + \\dots + x_n.\n\\]\nAd esempio, se i valori di \\(x\\) sono \\(\\{3, 11, 4, 7\\}\\), avremo:\n\\[\n\\sum_{i=1}^4 x_i = 3 + 11 + 4 + 7 = 25,\n\\]\ndove \\(x_1 = 3\\), \\(x_2 = 11\\), e così via. La quantità \\(x_i\\) è detta argomento della sommatoria, mentre la variabile \\(i\\), che assume valori interi successivi, è chiamata indice della sommatoria.\nLa notazione di sommatoria può anche essere espressa nella forma:\n\\[\n\\sum_{P(i)} x_i,\n\\]\ndove \\(P(i)\\) è una proposizione logica riguardante \\(i\\) che può essere vera o falsa. Quando è evidente che si vogliono sommare tutte le \\(n\\) osservazioni, la notazione può essere semplificata in \\(\\sum_{i} x_i\\) o addirittura \\(\\sum x_i\\). L’indice \\(i\\) può essere sostituito da altre lettere, come \\(k, j, l, \\dots\\), a seconda del contesto.\nPer semplificare i calcoli che coinvolgono le sommatorie, è utile conoscere alcune proprietà fondamentali.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Sommatorie</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a12_sum_notation.html#manipolazione-di-somme",
    "href": "chapters/appendix/a12_sum_notation.html#manipolazione-di-somme",
    "title": "Appendice C — Sommatorie",
    "section": "",
    "text": "C.1.1 Proprietà 1 (Somma di una costante)\nLa sommatoria di \\(n\\) valori tutti uguali a una costante \\(a\\) è pari a \\(n\\) volte la costante stessa:\n\\[\n\\sum_{i=1}^{n} a = \\underbrace{a + a + \\dots + a}_{n \\text{ volte}} = n a.\n\\]\n\n\nC.1.2 Proprietà 2 (Proprietà distributiva)\nSe l’argomento della sommatoria contiene una costante, è possibile fattorizzarla. Ad esempio:\n\\[\n\\sum_{i=1}^{n} a x_i = a x_1 + a x_2 + \\dots + a x_n = a (x_1 + x_2 + \\dots + x_n) = a \\sum_{i=1}^{n} x_i.\n\\]\n\n\nC.1.3 Proprietà 3 (Proprietà associativa)\nSe l’argomento della sommatoria è una somma, possiamo separare i termini:\n\\[\n\\sum_{i=1}^{n} (a + x_i) = (a + x_1) + (a + x_2) + \\dots + (a + x_n) = n a + \\sum_{i=1}^{n} x_i.\n\\]\nIn generale, possiamo scrivere:\n\\[\n\\sum_{i=1}^{n} (x_i + y_i) = \\sum_{i=1}^{n} x_i + \\sum_{i=1}^{n} y_i.\n\\]\n\n\nC.1.4 Proprietà 4 (Operazioni algebriche)\nSe è necessario eseguire un’operazione algebrica (come l’elevamento a potenza o il logaritmo) sull’argomento della sommatoria, questa operazione deve essere eseguita prima della somma. Ad esempio:\n\\[\n\\sum_{i=1}^{n} x_i^2 = x_1^2 + x_2^2 + \\dots + x_n^2 \\neq \\left( \\sum_{i=1}^{n} x_i \\right)^2.\n\\]\n\n\nC.1.5 Proprietà 5 (Prodotto di termini)\nNel caso di un prodotto tra termini, il prodotto deve essere eseguito prima della somma:\n\\[\n\\sum_{i=1}^{n} x_i y_i = x_1 y_1 + x_2 y_2 + \\dots + x_n y_n.\n\\]\nInfatti, \\(a_1 b_1 + a_2 b_2 \\neq (a_1 + a_2)(b_1 + b_2)\\).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Sommatorie</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a12_sum_notation.html#doppia-sommatoria",
    "href": "chapters/appendix/a12_sum_notation.html#doppia-sommatoria",
    "title": "Appendice C — Sommatorie",
    "section": "C.2 Doppia sommatoria",
    "text": "C.2 Doppia sommatoria\nIn alcuni contesti, si incontrano espressioni con una doppia sommatoria e un doppio indice:\n\\[\n\\sum_{i=1}^{n} \\sum_{j=1}^{m} x_{ij}.\n\\]\nQuesta notazione implica che, per ogni valore dell’indice esterno \\(i\\) (da \\(1\\) a \\(n\\)), si deve sviluppare la sommatoria interna per \\(j\\) (da \\(1\\) a \\(m\\)). Ad esempio:\n\\[\n\\sum_{i=1}^{3} \\sum_{j=4}^{6} x_{ij} = (x_{1,4} + x_{1,5} + x_{1,6}) + (x_{2,4} + x_{2,5} + x_{2,6}) + (x_{3,4} + x_{3,5} + x_{3,6}).\n\\]\nUn caso particolare interessante è la doppia sommatoria del prodotto di due variabili:\n\\[\n\\sum_{i=1}^{n} \\sum_{j=1}^{n} x_i y_j.\n\\]\nIn questo caso, poiché \\(x_i\\) non dipende dall’indice \\(j\\), possiamo estrarre \\(x_i\\) dalla sommatoria interna:\n\\[\n\\sum_{i=1}^{n} \\left( x_i \\sum_{j=1}^{n} y_j \\right).\n\\]\nAllo stesso modo, la sommatoria interna \\(\\sum_{j=1}^{n} y_j\\) non dipende da \\(i\\), quindi può essere estratta dalla sommatoria esterna:\n\\[\n\\sum_{i=1}^{n} \\sum_{j=1}^{n} x_i y_j = \\left( \\sum_{i=1}^{n} x_i \\right) \\left( \\sum_{j=1}^{n} y_j \\right).\n\\]\n\nC.2.1 Esempio pratico\nConsideriamo i vettori \\(x = \\{2, 3, 1\\}\\) e \\(y = \\{1, 4, 9\\}\\). Calcoliamo la doppia sommatoria:\n\\[\n\\begin{aligned}\n\\sum_{i=1}^3 \\sum_{j=1}^3 x_i y_j &= x_1 y_1 + x_1 y_2 + x_1 y_3 + x_2 y_1 + x_2 y_2 + x_2 y_3 + x_3 y_1 + x_3 y_2 + x_3 y_3 \\\\\n&= 2 \\times (1 + 4 + 9) + 3 \\times (1 + 4 + 9) + 1 \\times (1 + 4 + 9) \\\\\n&= 2 \\times 14 + 3 \\times 14 + 1 \\times 14 = 84.\n\\end{aligned}\n\\]\nD’altra parte, il prodotto delle due sommatorie è:\n\\[\n\\left( \\sum_{i=1}^3 x_i \\right) \\left( \\sum_{j=1}^3 y_j \\right) = (2 + 3 + 1) \\times (1 + 4 + 9) = 6 \\times 14 = 84.\n\\]\nI due risultati coincidono, confermando la validità della proprietà.\nPer ulteriori approfondimenti, si consiglia la consultazione del testo Concrete Mathematics: A Foundation for Computer Science (Graham et al., 1994).\nEsercizi pratici sono disponibili sulla seguente pagina web.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Sommatorie</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a12_sum_notation.html#bibliografia",
    "href": "chapters/appendix/a12_sum_notation.html#bibliografia",
    "title": "Appendice C — Sommatorie",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGraham, R. L., Knuth, D. E., & Patashnik, O. (1994). Concrete Mathematics: A Foundation for Computer Science (2nd ed.). Addison-Wesley.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Sommatorie</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html",
    "href": "chapters/appendix/a13_sets.html",
    "title": "Appendice D — Insiemi",
    "section": "",
    "text": "D.1 Diagrammi di Eulero-Venn\nUn insieme (o collezione, classe, gruppo, …) è stato definito da Georg Cantor nel modo seguente:\nMentre non è rilevante la natura degli oggetti che costituiscono l’insieme, ciò che importa è distinguere se un dato oggetto appartenga o meno ad un insieme. Deve essere vera una delle due possibilità: il dato oggetto è un elemento dell’insieme considerato oppure non è elemento dell’insieme considerato. Due insiemi \\(A\\) e \\(B\\) si dicono uguali se sono formati dagli stessi elementi, anche se disposti in ordine diverso: \\(A=B\\). Due insiemi \\(A\\) e \\(B\\) si dicono diversi se non contengono gli stessi elementi: \\(A \\neq B\\). Ad esempio, i seguenti insiemi sono uguali:\n\\[\n\\{1, 2, 3\\} = \\{3, 1, 2\\} = \\{1, 3, 2\\}= \\{1, 1, 1, 2, 3, 3, 3\\}.\n\\]\nGli insiemi sono denotati da una lettera maiuscola, mentre le lettere minuscole, di solito, designano gli elementi di un insieme. Per esempio, un generico insieme \\(A\\) si indica con\n\\[\nA = \\{a_1, a_2, \\dots, a_n\\}, \\quad \\text{con } n &gt; 0.\n\\]\nLa scrittura \\(a \\in A\\) dice che \\(a\\) è un elemento di \\(A\\). Per dire che \\(b\\) non è un elemento di \\(A\\) si scrive \\(b \\notin A.\\)\nPer quegli insiemi i cui elementi soddisfano una certa proprietà che li caratterizza, tale proprietà può essere usata per descrivere più sinteticamente l’insieme:\n\\[\nA = \\{x ~\\vert~ \\text{proprietà posseduta da } x\\},\n\\]\nche si legge come “\\(A\\) è l’insieme degli elementi \\(x\\) per cui è vera la proprietà indicata.” Per esempio, per indicare l’insieme \\(A\\) delle coppie di numeri reali \\((x,y)\\) che appartengono alla parabola \\(y = x^2 + 1\\) si può scrivere:\n\\[\nA = \\{(x,y) ~\\vert~ y = x^2 + 1\\}.\n\\]\nDati due insiemi \\(A\\) e \\(B\\), diremo che \\(A\\) è un sottoinsieme di \\(B\\) se e solo se tutti gli elementi di \\(A\\) sono anche elementi di \\(B\\):\n\\[\nA \\subseteq B \\iff (\\forall x \\in A \\Rightarrow x \\in B).\n\\]\nSe esiste almeno un elemento di \\(B\\) che non appartiene ad \\(A\\) allora diremo che \\(A\\) è un sottoinsieme proprio di \\(B\\):\n\\[\nA \\subset B \\iff (A \\subseteq B, \\exists~ x \\in B ~\\vert~ x \\notin A).\n\\]\nUn altro insieme, detto insieme delle parti, o insieme potenza, che si associa all’insieme \\(A\\) è l’insieme di tutti i sottoinsiemi di \\(A\\), inclusi l’insieme vuoto e \\(A\\) stesso. Per esempio, per l’insieme \\(A = \\{a, b, c\\}\\), l’insieme delle parti è:\n\\[\n\\mathcal{P}(A) = \\{\n\\emptyset, \\{a\\}, \\{b\\}, \\{c\\},\n\\{a, b\\}, \\{a, c\\}, \\{c, b\\},\n\\{a, b, c\\}\n\\}.\n\\]\nI diagrammi di Venn sono uno strumento grafico molto utile per rappresentare gli insiemi e per verificare le proprietà delle operazioni tra di essi. Questi diagrammi prendono il nome dal matematico inglese del 19° secolo John Venn, anche se rappresentazioni simili erano già state utilizzate in precedenza da Leibniz e Eulero.\nI diagrammi di Venn rappresentano gli insiemi come regioni del piano delimitate da una curva chiusa. Nel caso di insiemi finiti, è possibile evidenziare alcuni elementi di un insieme tramite punti, e in alcuni casi possono essere evidenziati tutti gli elementi degli insiemi considerati.\nIn sostanza, questi diagrammi sono un modo visuale per rappresentare le proprietà degli insiemi e delle operazioni tra di essi. Sono uno strumento molto utile per visualizzare la relazione tra gli insiemi e per capire meglio come si combinano gli elementi all’interno di essi.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html#appartenenza-ad-un-insieme",
    "href": "chapters/appendix/a13_sets.html#appartenenza-ad-un-insieme",
    "title": "Appendice D — Insiemi",
    "section": "\nD.2 Appartenenza ad un insieme",
    "text": "D.2 Appartenenza ad un insieme\nUsiamo ora R\n\nSet1 &lt;- c(1, 2)\nprint(Set1)\n\n[1] 1 2\n\nprint(class(Set1))\n\n[1] \"numeric\"\n\n\n\nmy_list &lt;- c(1, 2, 3, 4)\nmy_set_from_list &lt;- unique(my_list)\nprint(my_set_from_list)\n\n[1] 1 2 3 4\n\n\nL’appartenenza ad un insieme si verifica con %in%.\n\nmy_set &lt;- c(1, 3, 5)\nprint(\"Ecco il mio insieme:\")\n\n[1] \"Ecco il mio insieme:\"\n\nprint(my_set)\n\n[1] 1 3 5\n\nprint(\"1 appartiene all'insieme:\")\n\n[1] \"1 appartiene all'insieme:\"\n\nprint(1 %in% my_set)\n\n[1] TRUE\n\nprint(\"2 non appartiene all'insieme:\")\n\n[1] \"2 non appartiene all'insieme:\"\n\nprint(2 %in% my_set)\n\n[1] FALSE\n\nprint(\"4 NON appartiene all'insieme:\")\n\n[1] \"4 NON appartiene all'insieme:\"\n\nprint(!(4 %in% my_set))\n\n[1] TRUE",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html#relazioni-tra-insiemi",
    "href": "chapters/appendix/a13_sets.html#relazioni-tra-insiemi",
    "title": "Appendice D — Insiemi",
    "section": "\nD.3 Relazioni tra insiemi",
    "text": "D.3 Relazioni tra insiemi\nEsaminiamo le funzioni Python per descrivere le relazioni tra insiemi. In particolare, dopo avere definito l’insieme universo e l’insieme vuoto, considereremo la relazione di inclusione che conduce al concetto di sottoinsieme. Analogamente si definisce il concetto di sovrainsieme. Mostreremo anche come valutare se due insiemi sono disgiunti (si dicono disgiunti gli insiemi con intersezione vuota).\n\nUniv &lt;- 0:10\nSuper &lt;- Univ[Univ %% 2 == 0]\nDisj &lt;- Univ[Univ %% 2 == 1]\nSub &lt;- c(4, 6)\nNull &lt;- Univ[Univ &gt; 10]\n\n\nprint(\"Insieme Universo (tutti gli interi positivi fino a 10):\")\n\n[1] \"Insieme Universo (tutti gli interi positivi fino a 10):\"\n\nprint(Univ)\n\n [1]  0  1  2  3  4  5  6  7  8  9 10\n\nprint(\"Tutti gli interi positivi pari fino a 10:\")\n\n[1] \"Tutti gli interi positivi pari fino a 10:\"\n\nprint(Super)\n\n[1]  0  2  4  6  8 10\n\nprint(\"Tutti gli interi positivi dispari fino a 10:\")\n\n[1] \"Tutti gli interi positivi dispari fino a 10:\"\n\nprint(Disj)\n\n[1] 1 3 5 7 9\n\nprint(\"Insieme di due elementi, 4 e 6:\")\n\n[1] \"Insieme di due elementi, 4 e 6:\"\n\nprint(Sub)\n\n[1] 4 6\n\nprint(\"Un insieme vuoto:\")\n\n[1] \"Un insieme vuoto:\"\n\nprint(Null)\n\ninteger(0)\n\n\n\nprint('È \"Super\" un sovrainsieme di \"Sub\"?')\n\n[1] \"È \\\"Super\\\" un sovrainsieme di \\\"Sub\\\"?\"\n\nprint(all(Sub %in% Super))\n\n[1] TRUE\n\nprint('È \"Super\" un sottoinsieme di \"Univ\"?')\n\n[1] \"È \\\"Super\\\" un sottoinsieme di \\\"Univ\\\"?\"\n\nprint(all(Super %in% Univ))\n\n[1] TRUE\n\nprint('È \"Sub\" un sovrainsieme di \"Super\"?')\n\n[1] \"È \\\"Sub\\\" un sovrainsieme di \\\"Super\\\"?\"\n\nprint(all(Super %in% Sub))\n\n[1] FALSE\n\nprint('Sono \"Super\" e \"Disj\" insiemi disgiunti?')\n\n[1] \"Sono \\\"Super\\\" e \\\"Disj\\\" insiemi disgiunti?\"\n\nprint(length(intersect(Super, Disj)) == 0)\n\n[1] TRUE",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html#operazioni-tra-insiemi",
    "href": "chapters/appendix/a13_sets.html#operazioni-tra-insiemi",
    "title": "Appendice D — Insiemi",
    "section": "\nD.4 Operazioni tra insiemi",
    "text": "D.4 Operazioni tra insiemi\nSi definisce intersezione di \\(A\\) e \\(B\\) l’insieme \\(A \\cap B\\) di tutti gli elementi \\(x\\) che appartengono ad \\(A\\) e contemporaneamente a \\(B\\):\n\\[\nA \\cap B = \\{x ~\\vert~ x \\in A \\land x \\in B\\}.\n\\]\nSi definisce unione di \\(A\\) e \\(B\\) l’insieme \\(A \\cup B\\) di tutti gli elementi \\(x\\) che appartengono ad \\(A\\) o a \\(B\\), cioè\n\\[\nA \\cup B = \\{x ~\\vert~ x \\in A \\lor x \\in B\\}.\n\\]\nDifferenza. Si indica con \\(A \\setminus B\\) l’insieme degli elementi di \\(A\\) che non appartengono a \\(B\\):\n\\[\nA \\setminus B = \\{x ~\\vert~ x \\in A \\land x \\notin B\\}.\n\\]\nInsieme complementare. Nel caso che sia \\(B \\subseteq A\\), l’insieme differenza \\(A \\setminus B\\) è detto insieme complementare di \\(B\\) in \\(A\\) e si indica con \\(B^C\\).\nDato un insieme \\(S\\), una partizione di \\(S\\) è una collezione di sottoinsiemi di \\(S\\), \\(S_1, \\dots, S_k\\), tali che\n\\[\nS = S_1 \\cup S_2 \\cup \\dots S_k\n\\]\ne\n\\[\nS_i \\cap S_j, \\quad \\text{con } i \\neq j.\n\\]\nLa relazione tra unione, intersezione e insieme complementare è data dalle leggi di DeMorgan:\n\\[\n(A \\cup B)^c = A^c \\cap B^c,\n\\]\n\\[\n(A \\cap B)^c = A^c \\cup B^c.\n\\]\nIn tutte le seguenti figure, \\(S\\) è la regione delimitata dal rettangolo, \\(L\\) è la regione all’interno del cerchio di sinistra e \\(R\\) è la regione all’interno del cerchio di destra. La regione evidenziata mostra l’insieme indicato sotto ciascuna figura.\n\n\nDiagrammi di Venn\n\nI diagrammi di Eulero-Venn che illustrano le leggi di DeMorgan sono forniti nella figura seguente.\n\n\nLeggi di DeMorgan\n\nVediamo ora come si eseguono le operazioni tra insiemi con R.\nIntersezione.\n\nS1 &lt;- seq(1, 10, by = 3)\nS2 &lt;- 1:6\nS_intersection &lt;- intersect(S1, S2)\nprint(\"Intersezione di S1 e S2:\")\n\n[1] \"Intersezione di S1 e S2:\"\n\nprint(S_intersection)\n\n[1] 1 4\n\n\nUnione. Si noti che il connettivo logico | corrisponde all’unione.\n\nS_union &lt;- union(S1, S2)\nprint(\"Unione di S1 e S2:\")\n\n[1] \"Unione di S1 e S2:\"\n\nprint(S_union)\n\n[1]  1  4  7 10  2  3  5  6\n\n\nInsieme complementare.\n\nS &lt;- seq(0, 20, by = 2)\nS_complement &lt;- setdiff(0:20, S)\nprint(\"S è l'insieme dei numeri interi pari tra 0 e 20:\")\n\n[1] \"S è l'insieme dei numeri interi pari tra 0 e 20:\"\n\nprint(S)\n\n [1]  0  2  4  6  8 10 12 14 16 18 20\n\nprint(\"S_complement è l'insieme dei numeri interi dispari tra 0 e 20:\")\n\n[1] \"S_complement è l'insieme dei numeri interi dispari tra 0 e 20:\"\n\nprint(S_complement)\n\n [1]  1  3  5  7  9 11 13 15 17 19\n\n\n\nprint(\"È l'unione di S e S_complement uguale a tutti i numeri interi tra 0 e 20?\")\n\n[1] \"È l'unione di S e S_complement uguale a tutti i numeri interi tra 0 e 20?\"\n\nprint(setequal(union(S, S_complement), 0:20))\n\n[1] TRUE\n\n\nDifferenza tra insiemi.\n\nS1 &lt;- seq(0, 30, by = 3)\nS2 &lt;- seq(0, 30, by = 5)\nprint(\"Differenza tra S2 e S1:\")\n\n[1] \"Differenza tra S2 e S1:\"\n\nprint(setdiff(S2, S1))\n\n[1]  5 10 20 25\n\nprint(\"Differenza tra S1 e S2:\")\n\n[1] \"Differenza tra S1 e S2:\"\n\nprint(setdiff(S1, S2))\n\n[1]  3  6  9 12 18 21 24 27\n\n\nDifferenza simmetrica. La differenza simmetrica, indicata con il simbolo Δ, è un’operazione insiemistica definita come unione tra la differenza tra il primo e il secondo insieme e la differenza tra il secondo e il primo insieme. In modo equivalente, la differenza simmetrica equivale all’unione tra i due insiemi meno la loro intersezione.\n\nsym_diff &lt;- union(setdiff(S1, S2), setdiff(S2, S1))\nprint(\"Differenza simmetrica:\")\n\n[1] \"Differenza simmetrica:\"\n\nprint(sym_diff)\n\n [1]  3  6  9 12 18 21 24 27  5 10 20 25",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html#coppie-ordinate-e-prodotto-cartesiano",
    "href": "chapters/appendix/a13_sets.html#coppie-ordinate-e-prodotto-cartesiano",
    "title": "Appendice D — Insiemi",
    "section": "\nD.5 Coppie ordinate e prodotto cartesiano",
    "text": "D.5 Coppie ordinate e prodotto cartesiano\nUna coppia ordinata \\((x,y)\\) è l’insieme i cui elementi sono \\(x \\in A\\) e \\(y \\in B\\) e nella quale \\(x\\) è la prima componente (o prima coordinata) e \\(y\\) la seconda. L’insieme di tutte le coppie ordinate costruite a partire dagli insiemi \\(A\\) e \\(B\\) viene detto prodotto cartesiano:\n\\[\nA \\times B = \\{(x, y) ~\\vert~ x \\in A \\land y \\in B\\}.\n\\]\nAd esempio, sia \\(A = \\{1, 2, 3\\}\\) e \\(B = \\{a, b\\}\\). Allora,\n\\[\n\\{1, 2\\} \\times \\{a, b, c\\} = \\{(1, a), (1, b), (1, c), (2, a), (2, b), (2, c)\\}.\n\\]\nPiù in generale, un prodotto cartesiano di \\(n\\) insiemi può essere rappresentato da un array di \\(n\\) dimensioni, dove ogni elemento è una ennupla o tupla ordinata (ovvero, una collezione o un elenco ordinato di \\(n\\) oggetti). Una n-pla ordinata si distingue da un insieme di \\(n\\) elementi in quanto fra gli elementi di un insieme non è dato alcun ordine. Inoltre gli elementi di una ennupla possono anche essere ripetuti. Essendo la n-pla un elenco ordinato, in generale di ogni suo elemento è possibile dire se sia il primo, il secondo, il terzo, eccetera, fino all’n-esimo. Il prodotto cartesiano prende il nome da René Descartes la cui formulazione della geometria analitica ha dato origine al concetto.\n\nA &lt;- c(\"a\", \"b\", \"c\")\nS &lt;- 1:3\ncartesian_product &lt;- expand.grid(A, S)\nprint(\"Prodotto cartesiano di A e S:\")\n\n[1] \"Prodotto cartesiano di A e S:\"\n\nprint(cartesian_product)\n\n  Var1 Var2\n1    a    1\n2    b    1\n3    c    1\n4    a    2\n5    b    2\n6    c    2\n7    a    3\n8    b    3\n9    c    3\n\n\nSi definisce cardinalità (o potenza) di un insieme finito il numero degli elementi dell’insieme. Viene indicata con \\(\\vert A\\vert, \\#(A)\\) o \\(\\text{c}(A)\\).\n\nprint(\"La cardinalità dell'insieme prodotto cartesiano è:\")\n\n[1] \"La cardinalità dell'insieme prodotto cartesiano è:\"\n\nprint(nrow(cartesian_product))\n\n[1] 9\n\n\nPotenza del prodotto cartesiano\n\nA &lt;- c(\"Head\", \"Tail\")\np2 &lt;- expand.grid(A, A)\nprint(\"Il quadrato dell'insieme A è un insieme che contiene:\")\n\n[1] \"Il quadrato dell'insieme A è un insieme che contiene:\"\n\nprint(nrow(p2))\n\n[1] 4\n\nprint(p2)\n\n  Var1 Var2\n1 Head Head\n2 Tail Head\n3 Head Tail\n4 Tail Tail\n\n\n\np3 &lt;- expand.grid(A, A, A)\nprint(\"L'insieme A elevato alla terza potenza è costituito da:\")\n\n[1] \"L'insieme A elevato alla terza potenza è costituito da:\"\n\nprint(nrow(p3))\n\n[1] 8\n\nprint(p3)\n\n  Var1 Var2 Var3\n1 Head Head Head\n2 Tail Head Head\n3 Head Tail Head\n4 Tail Tail Head\n5 Head Head Tail\n6 Tail Head Tail\n7 Head Tail Tail\n8 Tail Tail Tail",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html",
    "href": "chapters/appendix/a14_combinatorics.html",
    "title": "Appendice E — Calcolo combinatorio",
    "section": "",
    "text": "E.1 Principio della somma\nIl calcolo combinatorio studia il numero di modi in cui è possibile combinare, ordinare o disporre elementi appartenenti a uno o più insiemi, seguendo regole ben definite. Molti problemi di probabilità richiedono strumenti combinatori per determinare la probabilità di eventi complessi. In questo capitolo, esploreremo i concetti fondamentali del calcolo combinatorio, illustrandoli attraverso il modello del campionamento dall’urna. Tratteremo i principi della somma e del prodotto, fondamentali per affrontare problemi più avanzati, come permutazioni, disposizioni e combinazioni.\nIl principio della somma si applica quando un insieme di elementi può essere suddiviso in sottoinsiemi disgiunti (ossia senza sovrapposizioni). In questo caso, il numero totale di elementi è dato dalla somma delle cardinalità dei sottoinsiemi:\n\\[\nn_{\\text{tot}} = n_1 + n_2 + \\dots + n_k .\n\\]\nEsempio\nUn distributore contiene tre scomparti di caramelle, ciascuno con un diverso tipo di dolci:\nQuante caramelle ci sono in totale nel distributore?\nSecondo il principio della somma, il numero totale di caramelle è:\n\\[\nn_{\\text{tot}} = n_A + n_B + n_C = 10 + 8 + 12 = 30.\n\\]\nCalcolo in R:\nA &lt;- 10\nB &lt;- 8\nC &lt;- 12\n\ntotale_caramelle &lt;- A + B + C\ntotale_caramelle\n#&gt; [1] 30\nRisultato: Nel distributore ci sono 30 caramelle in totale.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#principio-della-somma",
    "href": "chapters/appendix/a14_combinatorics.html#principio-della-somma",
    "title": "Appendice E — Calcolo combinatorio",
    "section": "",
    "text": "Scomparto A: 10 caramelle alla menta,\n\n\nScomparto B: 8 caramelle alla frutta,\n\n\nScomparto C: 12 caramelle al cioccolato.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#principio-del-prodotto",
    "href": "chapters/appendix/a14_combinatorics.html#principio-del-prodotto",
    "title": "Appendice E — Calcolo combinatorio",
    "section": "\nE.2 Principio del prodotto",
    "text": "E.2 Principio del prodotto\nIl principio del prodotto si applica quando un’operazione può essere suddivisa in più fasi indipendenti, ciascuna con un numero specifico di possibilità. In tal caso, il numero totale di combinazioni è dato dal prodotto delle possibilità offerte da ciascuna fase:\n\\[\nn_{\\text{tot}} = n_1 \\cdot n_2 \\cdot \\dots \\cdot n_k .\n\\]\nEsempio\nSupponiamo di avere quattro urne contenenti palline di diverso colore:\n\n\nUrna A: 5 palline,\n\n\nUrna B: 6 palline,\n\n\nUrna C: 3 palline,\n\n\nUrna D: 2 palline.\n\nVogliamo formare insiemi di due palline, ciascuna estratta da urne differenti.\nSecondo il principio del prodotto, per ogni coppia di urne, il numero di combinazioni è dato dal prodotto del numero di palline contenute nelle due urne. Utilizziamo poi il principio della somma per ottenere il totale complessivo:\n\\[\nn_{\\text{tot}} = AB + AC + AD + BC + BD + CD.\n\\]\nCalcolo in R:\n\nAB &lt;- 5 * 6\nAC &lt;- 5 * 3\nAD &lt;- 5 * 2\nBC &lt;- 6 * 3\nBD &lt;- 6 * 2\nCD &lt;- 3 * 2\n\ntotale_insiemi &lt;- AB + AC + AD + BC + BD + CD\ntotale_insiemi\n#&gt; [1] 91\n\nRisultato: È possibile formare 91 insiemi di due palline, ciascuna estratta da urne differenti.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#il-modello-dellurna-e-i-metodi-di-campionamento",
    "href": "chapters/appendix/a14_combinatorics.html#il-modello-dellurna-e-i-metodi-di-campionamento",
    "title": "Appendice E — Calcolo combinatorio",
    "section": "\nE.3 Il modello dell’urna e i metodi di campionamento",
    "text": "E.3 Il modello dell’urna e i metodi di campionamento\nMolti problemi di calcolo combinatorio possono essere interpretati come estrazioni di palline da un’urna. Esistono quattro modi fondamentali di effettuare un campionamento, a seconda che:\n\nle estrazioni siano con o senza ripetizione,\nl’ordine degli elementi conti o meno.\n\nQueste quattro combinazioni danno origine a quattro principali metodi di campionamento:\n\n\nCon ripetizione e con ordine: Dopo ogni estrazione, la pallina viene rimessa nell’urna. (Es. formazione di codici numerici con ripetizioni)\n\nSenza ripetizione e con ordine: Ogni estrazione rimuove definitivamente la pallina dall’urna. (Es. assegnare premi in una gara)\n\nCon ripetizione e senza ordine: Si considerano i gruppi di elementi senza preoccuparsi dell’ordine. (Es. selezionare un certo numero di ingredienti da una dispensa)\n\nSenza ripetizione e senza ordine: Si scelgono elementi distinti senza considerare l’ordine. (Es. formare squadre da un gruppo di persone)\n\n\nEsempio E.1  \n\nurna &lt;- c(\"a\", \"b\", \"c\")\n\n# Con ripetizione e ordine\ncampionamento1 &lt;- expand.grid(urna, urna) |&gt;\n    rename(Elemento1 = Var1, Elemento2 = Var2)\n\n# Senza ripetizione e con ordine\ncampionamento2 &lt;- permutations(n = length(urna), r = 2, v = urna) |&gt;\n    as.data.frame() |&gt;\n    rename(Elemento1 = V1, Elemento2 = V2)\n\n# Con ripetizione e senza ordine\ncampionamento3 &lt;- combinations(\n    n = length(urna), r = 2, v = urna, repeats.allowed = TRUE\n) |&gt;\n    as.data.frame() |&gt;\n    rename(Elemento1 = V1, Elemento2 = V2)\n\n# Senza ripetizione e senza ordine\ncampionamento4 &lt;- combinations(n = length(urna), r = 2, v = urna) |&gt;\n    as.data.frame() |&gt;\n    rename(Elemento1 = V1, Elemento2 = V2)\n\n# Risultati\nlist(\n    `Con ripetizione e ordine` = campionamento1,\n    `Senza ripetizione e con ordine` = campionamento2,\n    `Con ripetizione e senza ordine` = campionamento3,\n    `Senza ripetizione e senza ordine` = campionamento4\n)\n#&gt; $`Con ripetizione e ordine`\n#&gt;   Elemento1 Elemento2\n#&gt; 1         a         a\n#&gt; 2         b         a\n#&gt; 3         c         a\n#&gt; 4         a         b\n#&gt; 5         b         b\n#&gt; 6         c         b\n#&gt; 7         a         c\n#&gt; 8         b         c\n#&gt; 9         c         c\n#&gt; \n#&gt; $`Senza ripetizione e con ordine`\n#&gt;   Elemento1 Elemento2\n#&gt; 1         a         b\n#&gt; 2         a         c\n#&gt; 3         b         a\n#&gt; 4         b         c\n#&gt; 5         c         a\n#&gt; 6         c         b\n#&gt; \n#&gt; $`Con ripetizione e senza ordine`\n#&gt;   Elemento1 Elemento2\n#&gt; 1         a         a\n#&gt; 2         a         b\n#&gt; 3         a         c\n#&gt; 4         b         b\n#&gt; 5         b         c\n#&gt; 6         c         c\n#&gt; \n#&gt; $`Senza ripetizione e senza ordine`\n#&gt;   Elemento1 Elemento2\n#&gt; 1         a         b\n#&gt; 2         a         c\n#&gt; 3         b         c",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#permutazioni-disporre-tutti-gli-elementi-con-ordine",
    "href": "chapters/appendix/a14_combinatorics.html#permutazioni-disporre-tutti-gli-elementi-con-ordine",
    "title": "Appendice E — Calcolo combinatorio",
    "section": "\nE.4 Permutazioni: Disporre tutti gli elementi con ordine",
    "text": "E.4 Permutazioni: Disporre tutti gli elementi con ordine\nLe permutazioni rappresentano tutti i modi in cui è possibile ordinare \\(n\\) elementi distinti. Il numero di permutazioni è dato da:\n\\[\nP_n = n!\n\\]\ndove \\(n!\\) (n fattoriale) è il prodotto di tutti i numeri da 1 a \\(n\\):\n\\[\nn! = n \\cdot (n-1) \\cdot (n-2) \\cdot \\dots \\cdot 1.\n\\]\n\nE.4.1 Intuizione della formula\nImmaginiamo di avere \\(n\\) elementi distinti e di doverli disporre in una sequenza. Il primo elemento può essere scelto in \\(n\\) modi. Una volta scelto il primo, rimangono \\(n-1\\) possibilità per il secondo, poi \\(n-2\\) per il terzo e così via, fino all’ultimo elemento, che avrà 1 sola possibilità. Applicando il principio del prodotto, otteniamo:\n\\[\nP_n = n \\times (n-1) \\times (n-2) \\times \\dots \\times 1 = n!\n\\]\n\nE.4.2 Metodo di campionamento corrispondente\n\n\nCampionamento senza ripetizione e con ordine: si estrae una pallina, la si esclude dall’urna e si continua fino a esaurire gli elementi.\n\n\nEsempio pratico: Ordinare i partecipanti di una gara su un podio (primo, secondo e terzo classificato).\n\nE.4.3 Esempio in R: Permutazioni di tre elementi\nSe abbiamo tre lettere {a, b, c}, le possibili permutazioni sono:\n\\[\nP_3 = 3! = 3 \\times 2 \\times 1 = 6.\n\\]\n\nA &lt;- c(\"a\", \"b\", \"c\")\nperm &lt;- permutations(n = length(A), r = length(A), v = A)\nprint(perm)\n#&gt;      [,1] [,2] [,3]\n#&gt; [1,] \"a\"  \"b\"  \"c\" \n#&gt; [2,] \"a\"  \"c\"  \"b\" \n#&gt; [3,] \"b\"  \"a\"  \"c\" \n#&gt; [4,] \"b\"  \"c\"  \"a\" \n#&gt; [5,] \"c\"  \"a\"  \"b\" \n#&gt; [6,] \"c\"  \"b\"  \"a\"\nnrow(perm)  # Verifica del numero di permutazioni\n#&gt; [1] 6\n\nRisultato:\n\\[\n\\{a, b, c\\}, \\{a, c, b\\}, \\{b, a, c\\}, \\{b, c, a\\}, \\{c, a, b\\}, \\{c, b, a\\}.\n\\]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#disposizioni-selezionare-alcuni-elementi-con-ordine",
    "href": "chapters/appendix/a14_combinatorics.html#disposizioni-selezionare-alcuni-elementi-con-ordine",
    "title": "Appendice E — Calcolo combinatorio",
    "section": "\nE.5 Disposizioni: Selezionare alcuni elementi con ordine",
    "text": "E.5 Disposizioni: Selezionare alcuni elementi con ordine\nLe disposizioni si usano quando si scelgono \\(k\\) elementi da un insieme di \\(n\\), rispettando l’ordine. Il numero totale di disposizioni è:\n\\[\nD_{n,k} = \\frac{n!}{(n-k)!} .\n\\]\n\nE.5.1 Intuizione della formula\nSupponiamo di avere \\(n\\) elementi e di voler scegliere solo \\(k\\) elementi, mantenendo l’ordine.\n\nil primo elemento può essere scelto in \\(n\\) modi;\nil secondo elemento può essere scelto tra gli \\(n-1\\) elementi rimanenti;\n\nil terzo tra gli \\(n-2\\) rimanenti.\n\nSi prosegue fino a quando si hanno scelto \\(k\\) elementi, fermandosi prima di esaurire tutti gli elementi.\n\\[\nD_{n,k} = n \\times (n-1) \\times (n-2) \\times \\dots \\times (n-k+1) .\n\\]\nQuesta espressione corrisponde alla divisione del fattoriale di \\(n\\) per il fattoriale degli elementi che non vengono selezionati:\n\\[\nD_{n,k} = \\frac{n!}{(n-k)!} .\n\\]\n\nE.5.2 Metodo di campionamento corrispondente\n\n\nCampionamento senza ripetizione e con ordine: si estrae una pallina, la si esclude dall’urna e si continua fino a raggiungere il numero desiderato di elementi, fermandosi prima di esaurire tutti gli elementi.\n\n\nEsempio pratico: Estrarre casualmente 2 studenti da una classe di 10 e assegnare loro i ruoli di rappresentante e vice-rappresentante (l’ordine conta).\n\nE.5.3 Esempio in R: Disposizioni di 2 elementi da {a, b, c}\nSe scegliamo 2 lettere su 3, il numero di disposizioni è:\n\\[\nD_{3,2} = \\frac{3!}{(3-2)!} = \\frac{3 \\times 2 \\times 1}{1} = 6.\n\\]\n\ndisp &lt;- permutations(n = length(A), r = 2, v = A)\nprint(disp)\n#&gt;      [,1] [,2]\n#&gt; [1,] \"a\"  \"b\" \n#&gt; [2,] \"a\"  \"c\" \n#&gt; [3,] \"b\"  \"a\" \n#&gt; [4,] \"b\"  \"c\" \n#&gt; [5,] \"c\"  \"a\" \n#&gt; [6,] \"c\"  \"b\"\nnrow(disp)  # Verifica del numero di disposizioni\n#&gt; [1] 6\n\nRisultato:\n\\[\n\\{a, b\\}, \\{a, c\\}, \\{b, a\\}, \\{b, c\\}, \\{c, a\\}, \\{c, b\\}.\n\\]\nLe disposizioni considerano l’ordine, quindi \\(\\{a, b\\}\\) è diverso da \\(\\{b, a\\}\\).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#combinazioni-selezionare-alcuni-elementi-senza-ordine",
    "href": "chapters/appendix/a14_combinatorics.html#combinazioni-selezionare-alcuni-elementi-senza-ordine",
    "title": "Appendice E — Calcolo combinatorio",
    "section": "\nE.6 Combinazioni: Selezionare alcuni elementi senza ordine",
    "text": "E.6 Combinazioni: Selezionare alcuni elementi senza ordine\nLe combinazioni rappresentano il numero di modi per scegliere \\(k\\) elementi da \\(n\\) senza considerare l’ordine. Il numero di combinazioni è dato da:\n\\[\nC_{n,k} = \\binom{n}{k} = \\frac{n!}{k!(n-k)!} .\n\\]\n\nE.6.1 Intuizione della formula\nSupponiamo di avere \\(n\\) elementi e di voler selezionare \\(k\\) elementi senza considerare l’ordine.\nCome nel caso delle disposizioni, il primo elemento può essere scelto in \\(n\\) modi, il secondo in \\(n-1\\), e così via fino a selezionare \\(k\\) elementi.\n\\[\nD_{n,k} = n \\times (n-1) \\times \\dots \\times (n-k+1) .\n\\]\nTuttavia, in questo caso, l’ordine non conta, quindi ogni selezione viene duplicata per il numero di modi in cui i \\(k\\) elementi possono essere ordinati, ossia \\(k!\\) permutazioni interne. Per correggere questa duplicazione, dobbiamo dividere per \\(k!\\):\n\\[\nC_{n,k} = \\frac{D_{n,k}}{k!} = \\frac{n!}{k!(n-k)!} .\n\\]\n\nE.6.2 Metodo di campionamento corrispondente\n\n\nCampionamento senza ripetizione e senza ordine: si estrae una pallina e la si esclude dall’urna, ma non importa l’ordine in cui le palline vengono estratte.\n\n\nEsempio pratico: Formare una squadra di 2 studenti da un gruppo di 10 senza assegnare ruoli specifici (quindi \\(\\{a, b\\}\\) è uguale a \\(\\{b, a\\}\\)).\n\nE.6.3 Esempio in R: Combinazioni di 2 elementi da {a, b, c}\nSe scegliamo 2 lettere su 3 senza considerare l’ordine, otteniamo:\n\\[\nC_{3,2} = \\binom{3}{2} = \\frac{3!}{2!(3-2)!} = \\frac{3 \\times 2 \\times 1}{2 \\times 1 \\times 1} = 3.\n\\]\n\ncomb &lt;- combinations(n = length(A), r = 2, v = A)\nprint(comb)\n#&gt;      [,1] [,2]\n#&gt; [1,] \"a\"  \"b\" \n#&gt; [2,] \"a\"  \"c\" \n#&gt; [3,] \"b\"  \"c\"\nnrow(comb)  # Verifica del numero di combinazioni\n#&gt; [1] 3\n\nRisultato:\n\\[\n\\{a, b\\}, \\{a, c\\}, \\{b, c\\}.\n\\]\nLe combinazioni non considerano l’ordine, quindi \\(\\{a, b\\}\\) è uguale a \\(\\{b, a\\}\\).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#sintesi-quando-usare-ciascun-metodo",
    "href": "chapters/appendix/a14_combinatorics.html#sintesi-quando-usare-ciascun-metodo",
    "title": "Appendice E — Calcolo combinatorio",
    "section": "\nE.7 Sintesi: Quando usare ciascun metodo?",
    "text": "E.7 Sintesi: Quando usare ciascun metodo?\n\n\n\n\n\n\n\n\n\nMetodo\nRipetizione?\nOrdine?\nFormula\nMetodo di campionamento\n\n\n\nPermutazioni\n❌ No\n✅ Sì\n\\(n!\\)\nSenza ripetizione e con ordine\n\n\nDisposizioni\n❌ No\n✅ Sì\n\\(\\frac{n!}{(n-k)!}\\)\nSenza ripetizione e con ordine\n\n\nCombinazioni\n❌ No\n❌ No\n\\(\\binom{n}{k} = \\frac{n!}{k!(n-k)!}\\)\nSenza ripetizione e senza ordine\n\n\n\nIn conclusione, abbiamo visto come il modello dell’urna aiuti a comprendere i problemi combinatori. Le differenze tra permutazioni, disposizioni e combinazioni dipendono da due fattori fondamentali: ripetizione e ordine.\nQuesta classificazione è essenziale per risolvere problemi di probabilità e statistica in modo rigoroso. Gli esempi e il codice R forniscono strumenti concreti per applicare questi concetti nella pratica.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a15_calculus.html",
    "href": "chapters/appendix/a15_calculus.html",
    "title": "Appendice F — Per liberarvi dai terrori preliminari",
    "section": "",
    "text": "F.1 Integrali\nIn questo capitolo, traduciamo e adattiamo il capitolo Per liberarvi dai terrori preliminari tratto da Calculus made easy.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Per liberarvi dai terrori preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a15_calculus.html#integrali",
    "href": "chapters/appendix/a15_calculus.html#integrali",
    "title": "Appendice F — Per liberarvi dai terrori preliminari",
    "section": "",
    "text": "Il terrore preliminare, che spesso impedisce agli studenti di avvicinarsi all’analisi matematica, può essere superato comprendendo il significato intuitivo dei due simboli principali utilizzati in questo campo.\nQuesti simboli, che possono sembrare intimidatori, sono in realtà molto semplici:\n\n\\(d\\): Questo simbolo significa semplicemente “un po’ di”. Ad esempio, \\(\\operatorname{d}\\!x\\) indica un piccolo incremento di \\(x\\), mentre \\(\\operatorname{d}\\!u\\) rappresenta un piccolo incremento di \\(u\\). I matematici preferiscono dire “un elemento di” invece di “un po’ di”, ma il concetto è lo stesso. Questi piccoli incrementi possono essere considerati infinitamente piccoli.\n\\(\\int\\): Questo simbolo è una S allungata e rappresenta “la somma di”. Quindi, \\(\\int \\operatorname{d}\\!x\\) significa la somma di tutti i piccoli incrementi di \\(x\\), mentre \\(\\int \\operatorname{d}\\!t\\) indica la somma di tutti i piccoli incrementi di \\(t\\). I matematici chiamano questo simbolo “integrale”. Se consideri \\(x\\) come composto da tanti piccoli pezzi \\(\\operatorname{d}\\!x\\), sommandoli tutti otterrai l’intero valore di \\(x\\). La parola “integrale” significa semplicemente “il tutto”. Ad esempio, se pensi a un’ora come composta da 3600 secondi, la somma di tutti questi secondi ti darà un’ora. Quando vedi un’espressione che inizia con \\(\\int\\), significa che devi sommare tutti i piccoli pezzi indicati dai simboli che seguono.\n\nEcco, il terrore è svanito!\n\n\n\n\nF.1.1 Verifica con Simulazioni in R\nPer calcolare e visualizzare l’integrale di una funzione di densità, possiamo utilizzare il linguaggio di programmazione R. Consideriamo come esempio la funzione di densità gaussiana, definita dalla seguente formula:\n\\[\nf(x; \\mu, \\sigma) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} e^{-\\frac{(x - \\mu)^2}{2 \\sigma^2}}.\n\\]\nIn R, possiamo definire questa funzione come segue:\n\ngaussian &lt;- function(x, mu, sigma) {\n  1 / (sigma * sqrt(2 * pi)) * exp(-((x - mu)^2) / (2 * sigma^2))\n}\n\nDefiniamo i parametri e generiamo i valori per il calcolo della funzione di densità su un intervallo:\n\nmu &lt;- 0      # Media\nsigma &lt;- 1   # Deviazione standard\na &lt;- -10     # Limite inferiore\nb &lt;- 10      # Limite superiore\nn &lt;- 10000   # Numero di punti\n\nx_range &lt;- seq(a, b, length.out = n)  # Valori x\nfx &lt;- gaussian(x_range, mu, sigma)   # Ordinata della funzione\n\nVisualizziamo la funzione utilizzando il pacchetto ggplot2:\n\nlibrary(ggplot2)\nlibrary(scales)\n\nggplot(data.frame(x = x_range, fx = fx), aes(x, fx)) +\n  geom_line(color = \"blue\") +\n  labs(\n    title = \"Funzione di densità gaussiana\", \n    x = \"x\", \n    y = \"f(x)\"\n  )\n\n\n\n\n\n\n\nCreiamo una funzione per approssimare l’integrale sommando i prodotti \\(\\Delta x \\cdot f(x)\\):\n\nintegral_approximation &lt;- function(f, a, b, n) {\n  delta &lt;- (b - a) / n\n  sum(delta * f)\n}\n\n# Calcolo dell'integrale approssimato\napprox &lt;- integral_approximation(fx, a, b, n)\napprox\n\n[1] 0.9999\n\n\nConfrontiamo il risultato con il calcolo fornito dalla funzione integrate di R:\n\nintegrate(\n  function(x) gaussian(x, mu, sigma),\n  lower = a,\n  upper = b\n)\n\n1 with absolute error &lt; 7.4e-05\n\n\nCalcoliamo l’area sotto la curva in intervalli di interesse. Ad esempio, per \\([-1.96, 1.96]\\), che corrisponde al 95% dell’area nella distribuzione normale standard:\n\na &lt;- -1.96\nb &lt;- 1.96\nx_range &lt;- seq(a, b, length.out = n)\nfx &lt;- gaussian(x_range, mu, sigma)\n\napprox &lt;- integral_approximation(fx, a, b, n)\napprox\n\n[1] 0.9499321\n\n\nConfrontiamo con il risultato fornito da integrate():\n\nintegrate(\n  function(x) gaussian(x, mu, sigma),\n  lower = a,\n  upper = b\n)\n\n0.9500042 with absolute error &lt; 1e-11\n\n\nVerifichiamo l’area sotto la curva per \\([-1, 1]\\), che rappresenta circa il 68% dell’area totale:\n\na &lt;- -1.0\nb &lt;- 1.0\nx_range &lt;- seq(a, b, length.out = n)\nfx &lt;- gaussian(x_range, mu, sigma)\n\napprox &lt;- integral_approximation(fx, a, b, n)\napprox\n\n[1] 0.6826696\n\n\nConfronto:\n\nintegrate(\n  function(x) gaussian(x, mu, sigma),\n  lower = a,\n  upper = b\n)\n\n0.6826895 with absolute error &lt; 7.6e-15\n\n\nIn sintesi, questo approccio dimostra come calcolare l’integrale di una funzione di densità in un intervallo utilizzando sia un metodo approssimativo basato sulla somma dei rettangoli sia il metodo numerico integrato. In entrambi i casi, l’obiettivo è calcolare l’area sotto la curva, che corrisponde all’integrale della funzione di densità.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Per liberarvi dai terrori preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a15_calculus.html#potenze",
    "href": "chapters/appendix/a15_calculus.html#potenze",
    "title": "Appendice F — Per liberarvi dai terrori preliminari",
    "section": "\nF.2 Potenze",
    "text": "F.2 Potenze\nLe potenze sono un’operazione matematica che rappresenta un prodotto ripetuto. Si indicano generalmente come:\n\\[\na^n,\n\\]\ndove:\n\n\n\\(a\\) è la base,\n\n\\(n\\) è l’esponente.\n\nLa potenza rappresenta il prodotto della base \\(a\\) ripetuto \\(n\\) volte.\n\nF.2.1 Definizione di potenza\n\\[\na^n = \\underbrace{a \\cdot a \\cdot \\dots \\cdot a}_{n \\text{ fattori}} \\quad \\text{con } n \\in \\mathbb{N}.\n\\]\nAd esempio:\n\n\n\\(2^3 = 2 \\cdot 2 \\cdot 2 = 8\\),\n\n\\(3^4 = 3 \\cdot 3 \\cdot 3 \\cdot 3 = 81\\).\n\n\nF.2.2 Proprietà delle potenze\n\n\nMoltiplicazione di potenze con la stessa base:\n\\[\na^m \\cdot a^n = a^{m+n}\n\\]\nEsempio: \\(2^3 \\cdot 2^2 = 2^{3+2} = 2^5 = 32\\).\n\n\nDivisione di potenze con la stessa base:\n\\[\n\\frac{a^m}{a^n} = a^{m-n}, \\quad \\text{con } m \\geq n.\n\\]\nEsempio: \\(\\frac{5^4}{5^2} = 5^{4-2} = 5^2 = 25\\).\n\n\nPotenze di potenze:\n\\[\n(a^m)^n = a^{m \\cdot n}.\n\\]\nEsempio: \\((3^2)^3 = 3^{2 \\cdot 3} = 3^6 = 729\\).\n\n\nProdotto di potenze con basi diverse ma lo stesso esponente:\n\\[\na^n \\cdot b^n = (a \\cdot b)^n.\n\\]\nEsempio: \\(2^3 \\cdot 3^3 = (2 \\cdot 3)^3 = 6^3 = 216\\).\n\n\nDivisione di potenze con basi diverse ma lo stesso esponente:\n\\[\n\\frac{a^n}{b^n} = \\left(\\frac{a}{b}\\right)^n.\n\\]\nEsempio: \\(\\frac{4^2}{2^2} = \\left(\\frac{4}{2}\\right)^2 = 2^2 = 4\\).\n\n\nEsponente zero:\n\\[\na^0 = 1, \\quad \\text{con } a \\neq 0.\n\\]\nEsempio: \\(5^0 = 1\\).\n\n\nEsponente negativo:\n\\[\na^{-n} = \\frac{1}{a^n}.\n\\]\nEsempio: \\(2^{-3} = \\frac{1}{2^3} = \\frac{1}{8}\\).\n\n\nRadice come potenza frazionaria:\n\\[\na^{\\frac{1}{n}} = \\sqrt[n]{a}, \\quad a^{\\frac{m}{n}} = \\sqrt[n]{a^m}.\n\\]\nEsempio: \\(8^{\\frac{1}{3}} = \\sqrt[3]{8} = 2\\).\n\n\n\nF.2.3 Esempi pratici\n\n\nCalcolo semplice:\n\\[\n4^3 = 4 \\cdot 4 \\cdot 4 = 64.\n\\]\n\n\nUtilizzo delle proprietà:\n\\[\n3^5 \\cdot 3^2 = 3^{5+2} = 3^7 = 2187.\n\\]\n\n\nDivisione:\n\\[\n\\frac{6^4}{6^2} = 6^{4-2} = 6^2 = 36.\n\\]\n\n\nEsponente negativo:\n\\[\n10^{-2} = \\frac{1}{10^2} = \\frac{1}{100} = 0.01.\n\\]\n\n\nRadice come potenza:\n\\[\n16^{\\frac{1}{2}} = \\sqrt{16} = 4.\n\\]\n\n\n\nF.2.4 Nota sui numeri razionali e reali\n\nLe potenze con esponenti interi sono definite per ogni base.\nLe potenze con esponenti frazionari o reali richiedono che la base sia positiva per evitare ambiguità.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Per liberarvi dai terrori preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a15_calculus.html#logaritmi",
    "href": "chapters/appendix/a15_calculus.html#logaritmi",
    "title": "Appendice F — Per liberarvi dai terrori preliminari",
    "section": "\nF.3 Logaritmi",
    "text": "F.3 Logaritmi\nIl logaritmo è una funzione matematica che risponde alla domanda: “quante volte devo moltiplicare un certo numero (chiamato”base”) per ottenere un altro numero?” Matematicamente, questo è espresso come:\n\\[\n\\log_b(a) = x \\iff b^x = a\n\\]\nAd esempio, \\(\\log_2(8) = 3\\) perché \\(2^3 = 8\\).\nNel contesto dei logaritmi, i valori molto piccoli (compresi tra 0 e 1) diventano più grandi (in termini assoluti) e negativi quando applichiamo una funzione logaritmica. Questo è utile per stabilizzare i calcoli, specialmente quando lavoriamo con prodotti di numeri molto piccoli che potrebbero portare a problemi di underflow.\nPer esempio:\n\n\\(\\log(1) = 0\\)\n\\(\\log(0.1) = -1\\)\n\\(\\log(0.01) = -2\\)\n\\(\\log(0.001) = -3\\)\n\nCome si può vedere, i valori assoluti dei logaritmi crescono man mano che il numero originale si avvicina a zero.\nUna delle proprietà più utili dei logaritmi è che consentono di trasformare un prodotto in una somma:\n\\[\n\\log_b(a \\times c) = \\log_b(a) + \\log_b(c)\n\\]\nQuesta proprietà è estremamente utile in calcoli complessi, come nella statistica bayesiana, dove il prodotto di molte probabilità potrebbe diventare un numero molto piccolo e causare problemi numerici.\nUn’altra proprietà utile dei logaritmi è che un rapporto tra due numeri diventa la differenza dei loro logaritmi:\n\\[\n\\log_b\\left(\\frac{a}{c}\\right) = \\log_b(a) - \\log_b(c)\n\\]\nAnche questa proprietà è molto utilizzata in matematica, specialmente in situazioni in cui è necessario normalizzare i dati.\nIn sintesi, i logaritmi sono strumenti potenti per semplificare e stabilizzare i calcoli matematici. Essi consentono di lavorare più agevolmente con numeri molto grandi o molto piccoli e di trasformare operazioni complesse come prodotti e divisioni in somme e differenze, rendendo i calcoli più gestibili e meno inclini a errori numerici.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Per liberarvi dai terrori preliminari</span>"
    ]
  }
]