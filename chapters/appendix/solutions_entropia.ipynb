{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Entropia {#sec-solutions-entropia}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project directory: /Users/corradocaudek/_repositories/psicometria\n"
          ]
        }
      ],
      "source": [
        "# Standard library imports\n",
        "import os\n",
        "\n",
        "# Third-party imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import arviz as az\n",
        "import scipy.stats as stats\n",
        "from scipy.special import expit  # Funzione logistica\n",
        "from cmdstanpy import cmdstan_path, CmdStanModel\n",
        "\n",
        "# Configuration\n",
        "seed = sum(map(ord, \"stan_poisson_regression\"))\n",
        "rng = np.random.default_rng(seed=seed)\n",
        "az.style.use(\"arviz-darkgrid\")\n",
        "%config InlineBackend.figure_format = \"retina\"\n",
        "\n",
        "# Define directories\n",
        "home_directory = os.path.expanduser(\"~\")\n",
        "project_directory = f\"{home_directory}/_repositories/psicometria\"\n",
        "\n",
        "# Print project directory to verify\n",
        "print(f\"Project directory: {project_directory}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# @sec-entropy {.unnumbered} \n",
        "\n",
        "@exr-entropy-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "p = np.array([0.2, 0.5, 0.3])\n",
        "q = np.array([0.1, 0.2, 0.7])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Entropia di p:  1.0296530140645737\n"
          ]
        }
      ],
      "source": [
        "# Calcoliamo l'entropia di $p$.\n",
        "h_p = -np.sum(p * np.log(p))\n",
        "print(\"Entropia di p: \", h_p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Entropia incrociata tra p e q:  1.372238457997479\n"
          ]
        }
      ],
      "source": [
        "# Calcoliamo l'entropia incrociata tra $p$ e $q$.\n",
        "h_pq = -np.sum(p * np.log(q))\n",
        "print(\"Entropia incrociata tra p e q: \", h_pq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Divergenza KL da p a q:  0.34258544393290524\n"
          ]
        }
      ],
      "source": [
        "# Calcoliamo la divergenza di Kullback-Leibler da $p$ a $q$.\n",
        "kl_pq = h_pq - h_p\n",
        "print(\"Divergenza KL da p a q: \", kl_pq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.3425854439329054"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Lo stesso risultato si ottiene applicando la formula della Divergenza $\\mathbb{KL}$.\n",
        "np.sum(p * (np.log(p) - np.log(q)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.007041377136023895"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Se invece $q$ è molto simile a $p$, la differenza $\\mathbb{KL}$ è molto minore.\n",
        "p = np.array([0.2, 0.5, 0.3])\n",
        "q = np.array([0.2, 0.55, 0.25])\n",
        "np.sum(p * (np.log(p) - np.log(q)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "@exr-entropy-2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.4096 0.4096 0.1536 0.0256 0.0016]\n"
          ]
        }
      ],
      "source": [
        "# Define the parameters\n",
        "n = 4\n",
        "p = 0.2\n",
        "\n",
        "# Compute the probability mass function\n",
        "true_py = stats.binom.pmf(range(n + 1), n, p)\n",
        "print(true_py)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.46 0.42 0.1  0.01 0.01]\n"
          ]
        }
      ],
      "source": [
        "q1 = np.array([0.46, 0.42, 0.10, 0.01, 0.01])\n",
        "print(q1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.2, 0.2, 0.2, 0.2, 0.2]\n"
          ]
        }
      ],
      "source": [
        "q2 = [0.2] * 5\n",
        "print(q2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Divergenza KL di q1 da p:  0.02925199033345882\n"
          ]
        }
      ],
      "source": [
        "# La divergenza $\\mathbb{KL}$ di $q_1$ da $p$ è\n",
        "kl_pq1 = np.sum(true_py * (np.log(true_py) - np.log(q1)))\n",
        "print(\"Divergenza KL di q1 da p: \", kl_pq1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Divergenza KL di q2 da p:  0.48635777871415425\n"
          ]
        }
      ],
      "source": [
        "# La divergenza $\\mathbb{KL}$ di $q_2$ da $p$ è:\n",
        "kl_pq2 = np.sum(true_py * (np.log(true_py) - np.log(q2)))\n",
        "print(\"Divergenza KL di q2 da p: \", kl_pq2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "È chiaro che perdiamo una quantità maggiore di informazioni se, per descrivere la distribuzione binomiale $p$, usiamo la distribuzione uniforme $q_2$ anziché $q_1$.\n",
        "\n",
        "@exr-entropy-3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Entropia di p: 0.056001534354847345\n",
            "Entropia incrociata da p a q: 1.1954998257220641\n",
            "Divergenza KL da p a q: 1.1394982913672167\n",
            "\n",
            "Entropia di q: 0.6108643020548935\n",
            "Entropia incrociata da q a p: 3.226634230947714\n",
            "Divergenza KL da q a p: 2.6157699288928207\n"
          ]
        }
      ],
      "source": [
        "# Definire le distribuzioni p e q\n",
        "p = np.array([0.01, 0.99])\n",
        "q = np.array([0.7, 0.3])\n",
        "\n",
        "# Calcolo dell'entropia di p\n",
        "h_p = -np.sum(p * np.log(p))\n",
        "\n",
        "# Calcolo dell'entropia incrociata da p a q\n",
        "h_pq = -np.sum(p * np.log(q))\n",
        "\n",
        "# Calcolo della divergenza KL da p a q\n",
        "kl_pq = h_pq - h_p\n",
        "\n",
        "# Calcolo dell'entropia di q\n",
        "h_q = -np.sum(q * np.log(q))\n",
        "\n",
        "# Calcolo dell'entropia incrociata da q a p\n",
        "h_qp = -np.sum(q * np.log(p))\n",
        "\n",
        "# Calcolo della divergenza KL da q a p\n",
        "kl_qp = h_qp - h_q\n",
        "\n",
        "print(f\"Entropia di p: {h_p}\")\n",
        "print(f\"Entropia incrociata da p a q: {h_pq}\")\n",
        "print(f\"Divergenza KL da p a q: {kl_pq}\")\n",
        "\n",
        "print(f\"\\nEntropia di q: {h_q}\")\n",
        "print(f\"Entropia incrociata da q a p: {h_qp}\")\n",
        "print(f\"Divergenza KL da q a p: {kl_qp}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
