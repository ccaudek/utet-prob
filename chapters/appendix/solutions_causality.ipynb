{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Causalità {#sec-solutions-causality}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project directory: /Users/corradocaudek/_repositories/psicometria\n"
          ]
        }
      ],
      "source": [
        "# Standard library imports\n",
        "import os\n",
        "\n",
        "# Third-party imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import arviz as az\n",
        "import scipy.stats as stats\n",
        "from scipy.special import expit  # Funzione logistica\n",
        "from cmdstanpy import cmdstan_path, CmdStanModel\n",
        "\n",
        "# Configuration\n",
        "seed = sum(map(ord, \"stan_poisson_regression\"))\n",
        "rng = np.random.default_rng(seed=seed)\n",
        "az.style.use(\"arviz-darkgrid\")\n",
        "%config InlineBackend.figure_format = \"retina\"\n",
        "\n",
        "# Define directories\n",
        "home_directory = os.path.expanduser(\"~\")\n",
        "project_directory = f\"{home_directory}/_repositories/psicometria\"\n",
        "\n",
        "# Print project directory to verify\n",
        "print(f\"Project directory: {project_directory}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# @sec-causality {.unnumbered} \n",
        "\n",
        "@exr-causality-1\n",
        "\n",
        "Risposta corretta: \n",
        "\n",
        "a) Controllare per B è sufficiente e necessario per ottenere una stima non distorta dell'effetto di A su C.\n",
        "\n",
        "Spiegazione: In questo DAG, B agisce come un mediatore nella catena causale da A a C (A → B → C). Controllare per B è sufficiente per bloccare il flusso di informazioni lungo questo percorso. Inoltre, B è anche un collider nel percorso A → B ← D, ma questo percorso non crea un back-door path tra A e C, quindi non è necessario controllare per D. Controllare per B è necessario perché altrimenti l'effetto di A su C attraverso B non verrebbe rimosso. Le altre opzioni sono errate perché:\n",
        "\n",
        "b) Non c'è un back-door path da A a C attraverso D.\n",
        "c) B è un mediatore che deve essere controllato.\n",
        "d) Controllare per D non è necessario e potrebbe introdurre bias.\n",
        "e) B non è un collider nel percorso rilevante per l'effetto di A su C.\n",
        "\n",
        "@exr-causality-2\n",
        "\n",
        "Risposta corretta: \n",
        "\n",
        "b) È necessario controllare solo per Z per bloccare tutti i back-door paths tra X e Y.\n",
        "\n",
        "Spiegazione: In questo DAG, esiste un back-door path tra X e Y attraverso Z (X ← Z → W → Y). Secondo il criterio del back-door, per ottenere una stima non distorta dell'effetto causale di X su Y, dobbiamo bloccare tutti i back-door paths tra queste variabili.\n",
        "\n",
        "Controllare per Z è sufficiente per bloccare questo back-door path, poiché Z è una \"forchetta\" (fork) nel percorso. Una volta che controlliamo per Z, il flusso di informazioni non causali da X a Y attraverso questo percorso viene bloccato.\n",
        "\n",
        "Le altre opzioni sono errate perché:\n",
        "\n",
        "a) C'è un back-door path che deve essere bloccato.\n",
        "c) Controllare solo per W non è sufficiente, poiché non blocca il flusso di informazioni attraverso Z.\n",
        "d) Non è necessario controllare per W una volta che si è controllato per Z. Controllare per variabili non necessarie può ridurre la precisione della stima.\n",
        "e) È possibile stimare l'effetto causale in questo DAG utilizzando il criterio del back-door, controllando per Z.\n",
        "\n",
        "Questo esercizio illustra l'importanza di identificare correttamente i back-door paths e di selezionare il set minimo di variabili necessarie per bloccarli quando si applica il criterio del back-door nell'inferenza causale.\n",
        "\n",
        "@exr-causality-3\n",
        "\n",
        "Risposta corretta: \n",
        "\n",
        "a) A e B sono indipendenti, ma diventano dipendenti se controlliamo per C.\n",
        "\n",
        "Spiegazione: In questo DAG, C è un collider rispetto ad A e B. Un collider è una variabile che riceve frecce da due o più altre variabili nel grafo. Il comportamento dei collider è particolare e contro-intuitivo nell'analisi causale.\n",
        "\n",
        "Quando non controlliamo per un collider o per i suoi discendenti:\n",
        "\n",
        "- Le variabili che influenzano il collider (in questo caso, A e B) sono indipendenti tra loro.\n",
        "\n",
        "Quando controlliamo per un collider o per i suoi discendenti:\n",
        "\n",
        "- Introduciamo una dipendenza tra le variabili che influenzano il collider.\n",
        "\n",
        "Quindi, in questo caso:\n",
        "\n",
        "- A e B sono originariamente indipendenti.\n",
        "- Se controlliamo per C (il collider), creiamo una dipendenza tra A e B.\n",
        "- Anche controllare per D (discendente del collider) creerebbe una dipendenza tra A e B.\n",
        "\n",
        "Le altre opzioni sono errate perché:\n",
        "\n",
        "b) La direzione della dipendenza è opposta a quella corretta.\n",
        "c) A e B non sono sempre dipendenti; lo diventano solo se controlliamo per C o D.\n",
        "d) A e B diventano dipendenti se controlliamo per C o D.\n",
        "e) Controllare per D non rende A e B indipendenti, ma al contrario crea una dipendenza.\n",
        "\n",
        "Questo esercizio illustra l'importanza di identificare correttamente i collider in un DAG e di comprendere come il controllo di queste variabili possa influenzare le relazioni tra altre variabili nel sistema.\n",
        "\n",
        "@exr-causality-4\n",
        "\n",
        "Risposta corretta: \n",
        "\n",
        "e) Controllare per Z potrebbe introdurre un bias nella stima dell'effetto causale di X su Y.\n",
        "\n",
        "Spiegazione: In questo DAG, abbiamo la seguente situazione:\n",
        "\n",
        "1. C'è un back-door path da X a Y attraverso U (X ← U → Y). Questo percorso crea confondimento.\n",
        "2. Z è un collider nel percorso X → Z ← Y.\n",
        "3. U non è osservata, quindi non possiamo controllare direttamente per essa.\n",
        "\n",
        "Applicando il criterio del back-door:\n",
        "\n",
        "- Non possiamo bloccare il back-door path X ← U → Y perché U non è osservata.\n",
        "- Controllare per Z non aiuterebbe a bloccare questo back-door path.\n",
        "- Anzi, controllare per Z (un collider) aprirebbe un nuovo percorso non causale tra X e Y, introducendo un bias nella stima dell'effetto causale.\n",
        "\n",
        "Le altre opzioni sono errate perché:\n",
        "\n",
        "a) Anche se U non è osservata, possiamo ancora applicare il criterio del back-door per analizzare la situazione.\n",
        "b) Controllare per Z non è sufficiente e anzi introdurrebbe un bias.\n",
        "c) C'è un back-door path attraverso U.\n",
        "d) Non possiamo controllare per U poiché non è osservata.\n",
        "\n",
        "Questo esercizio illustra l'importanza di identificare correttamente i back-door paths e i collider in un DAG, e di comprendere come la presenza di variabili non osservate possa complicare l'applicazione del criterio del back-door nell'inferenza causale.\n",
        "\n",
        "@exr-causality-5\n",
        "\n",
        "La struttura causale è quella della mediazione.\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Numero di punti dati\n",
        "n = 10000\n",
        "\n",
        "# A è una variabile casuale distribuita secondo una normale standard\n",
        "A = np.random.normal(0, 1, n)\n",
        "\n",
        "# M è una funzione lineare di A con un termine di errore\n",
        "M = A + np.random.normal(0, 1, n)\n",
        "\n",
        "# B è una funzione lineare di M con un termine di errore\n",
        "B = M + np.random.normal(0, 1, n)\n",
        "\n",
        "# Plot di A contro B\n",
        "plt.scatter(A, B, alpha=0.5)\n",
        "plt.xlabel('A')\n",
        "plt.ylabel('B')\n",
        "plt.title('Relazione tra A e B')\n",
        "plt.show()\n",
        "\n",
        "# Calcolo della correlazione tra A e B\n",
        "correlation_matrix = np.corrcoef(A, B)\n",
        "correlation = correlation_matrix[0, 1]\n",
        "\n",
        "# Stampa il valore della correlazione\n",
        "print(f\"Correlazione tra A e B: {correlation:.4f}\")\n",
        "```\n",
        "\n",
        "@exr-causality-6\n",
        "\n",
        "Se \\( A \\) e \\( B \\) condividono un antenato comune \\( C \\) (biforcazione causale), \\( A \\) e \\( B \\) saranno correlati nei dati. Questo fenomeno è chiamato confondimento. La regola si applica anche se l'effetto di C su A e/o su B è mediato da altre variabili.\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Numero di punti dati\n",
        "n = 10000\n",
        "\n",
        "# C è una variabile casuale distribuita secondo una normale standard\n",
        "C = np.random.normal(0, 1, n)\n",
        "\n",
        "# A è una funzione lineare di C con un termine di errore\n",
        "A = C + np.random.normal(0, 1, n)\n",
        "\n",
        "# B è una funzione lineare di C con un termine di errore\n",
        "B = C + np.random.normal(0, 1, n)\n",
        "\n",
        "# Plot di A contro B\n",
        "plt.scatter(A, B, alpha=0.5)\n",
        "plt.xlabel('A')\n",
        "plt.ylabel('B')\n",
        "plt.title('Relazione tra A e B')\n",
        "plt.show()\n",
        "\n",
        "# Calcolo della correlazione tra A e B\n",
        "correlation_matrix = np.corrcoef(A, B)\n",
        "correlation = correlation_matrix[0, 1]\n",
        "\n",
        "# Stampa il valore della correlazione\n",
        "print(f\"Correlazione tra A e B: {correlation:.4f}\")\n",
        "```\n",
        "\n",
        "@exr-causality-7\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Numero di punti dati\n",
        "n = 10000\n",
        "\n",
        "# Generazione delle variabili secondo le specifiche\n",
        "C = np.random.normal(0, 1, n)\n",
        "A = C + np.random.normal(0, 1, n)\n",
        "B = C + np.random.normal(0, 1, n)\n",
        "\n",
        "# Regressione A ~ C per ottenere i residui\n",
        "model_A_C = sm.OLS(A, sm.add_constant(C)).fit()\n",
        "residuals_A = model_A_C.resid\n",
        "\n",
        "# Regressione B ~ C per ottenere i residui\n",
        "model_B_C = sm.OLS(B, sm.add_constant(C)).fit()\n",
        "residuals_B = model_B_C.resid\n",
        "\n",
        "# Calcolo della correlazione tra i residui di A e B\n",
        "correlation_residuals = np.corrcoef(residuals_A, residuals_B)[0, 1]\n",
        "\n",
        "# Stampa del risultato\n",
        "print(f\"Correlazione tra A e B dopo aver controllato per C: {correlation_residuals:.4f}\")\n",
        "\n",
        "# Plot dei residui di A contro i residui di B\n",
        "plt.scatter(residuals_A, residuals_B, alpha=0.5)\n",
        "plt.xlabel('Residui di A')\n",
        "plt.ylabel('Residui di B')\n",
        "plt.title('Correlazione tra i residui di A e B')\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "@exr-causality-8\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Numero di punti dati\n",
        "n = 10000\n",
        "\n",
        "# Generazione delle variabili secondo le specifiche\n",
        "A = np.random.normal(0, 1, n)\n",
        "M = A + np.random.normal(0, 1, n)\n",
        "B = M + np.random.normal(0, 1, n)\n",
        "\n",
        "# Regressione M ~ A per ottenere i residui\n",
        "model_M_A = sm.OLS(M, sm.add_constant(A)).fit()\n",
        "residuals_M = model_M_A.resid\n",
        "\n",
        "# Regressione B ~ M per ottenere i residui\n",
        "model_B_M = sm.OLS(B, sm.add_constant(M)).fit()\n",
        "residuals_B = model_B_M.resid\n",
        "\n",
        "# Calcolo della correlazione tra A e i residui di B\n",
        "correlation_residuals = np.corrcoef(A, residuals_B)[0, 1]\n",
        "\n",
        "# Stampa del risultato\n",
        "print(f\"Correlazione tra A e i residui di B (dopo aver controllato per M): {correlation_residuals:.4f}\")\n",
        "\n",
        "# Plot di A contro i residui di B\n",
        "plt.scatter(A, residuals_B, alpha=0.5)\n",
        "plt.xlabel('A')\n",
        "plt.ylabel('Residui di B')\n",
        "plt.title('Correlazione tra A e i residui di B')\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "Se \\( M \\) media completamente l'effetto di \\( A \\) su \\( B \\), ci aspettiamo che, una volta controllato \\( M \\), non ci sia alcuna correlazione residua significativa tra \\( A \\) e \\( B \\). La correlazione calcolata dovrebbe essere prossima a zero se la mediazione è completa. Se la correlazione è significativamente diversa da zero, potrebbe indicare che esistono effetti diretti di \\( A \\) su \\( B \\) non mediati da \\( M \\) o che esistono altri percorsi attraverso i quali \\( A \\) influenza \\( B \\).\n",
        "\n",
        "@exr-causality-9\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Numero di punti dati\n",
        "n = 10000\n",
        "\n",
        "# Generazione delle variabili secondo le specifiche\n",
        "A = np.random.normal(0, 1, n)\n",
        "B = np.random.normal(0, 1, n)\n",
        "D = A + B + np.random.normal(0, 1, n)\n",
        "\n",
        "# Regressione A ~ D per ottenere i residui\n",
        "model_A_D = sm.OLS(A, sm.add_constant(D)).fit()\n",
        "residuals_A = model_A_D.resid\n",
        "\n",
        "# Regressione B ~ D per ottenere i residui\n",
        "model_B_D = sm.OLS(B, sm.add_constant(D)).fit()\n",
        "residuals_B = model_B_D.resid\n",
        "\n",
        "# Plot dei residui di A contro i residui di B\n",
        "plt.scatter(residuals_A, residuals_B, alpha=0.5)\n",
        "plt.xlabel(\"Residui di A\")\n",
        "plt.ylabel(\"Residui di B\")\n",
        "plt.title(\"Correlazione tra i residui di A e B dopo aver controllato per D\")\n",
        "plt.show()\n",
        "\n",
        "# Calcolo della correlazione tra A e i residui di B\n",
        "correlation_residuals = np.corrcoef(residuals_A, residuals_B)[0, 1]\n",
        "\n",
        "# Stampa del risultato\n",
        "print(\n",
        "    f\"Correlazione tra A e i residui di B (dopo aver controllato per D): {correlation_residuals:.4f}\"\n",
        ")\n",
        "```\n",
        "\n",
        "In una struttura causale di tipo collider, A e B sono indipendenti, ma quando si controlla per \n",
        "D si può generare una correlazione spuria tra A e B. Questo effetto è dovuto alla struttura del collider: controllare per D introduce una dipendenza tra A e B, anche se non esiste un legame diretto tra loro.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
