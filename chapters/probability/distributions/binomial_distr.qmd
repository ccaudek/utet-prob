```{r}
#| echo: false
#| 
here::here("code", "_common.R") |> 
  source()
```

In statistica, un esperimento che ammette solo due esiti possibili è modellato attraverso quella che viene chiamata "prova Bernoulliana". Un esempio tipico è il lancio di una moneta, che può dare come risultato testa o croce.

::: {#def-}
Una variabile casuale $X$ che assume valori in $\{0, 1\}$ è detta variabile di Bernoulli. La sua distribuzione di probabilità è definita come:

$$
P(X \mid \theta) =
  \begin{cases}
    p     & \text{se $X = 1$ (successo)}, \\
    1 - p & \text{se $X = 0$ (insuccesso)},
  \end{cases}
$$

dove $0 \leq p \leq 1$. Il parametro $p$ rappresenta la probabilità del "successo" ($X = 1$), mentre $1 - p$ è la probabilità dell'"insuccesso" ($X = 0$).
:::

La distribuzione di Bernoulli descrive quindi un contesto in cui la probabilità di osservare l'esito 1 è $p$ e quella di osservare l'esito 0 è $1 - p$. Viene utilizzata per modellare situazioni binarie, come una risposta "sì" o "no", oppure un "successo" o "insuccesso".

Calcolando il valore atteso e la varianza, otteniamo:

$$
\begin{aligned}
\mathbb{E}(X) &= 0 \cdot P(X=0) + 1 \cdot P(X=1) = p, \\
\mathbb{V}(X) &= (0 - p)^2 \cdot P(X=0) + (1 - p)^2 \cdot P(X=1) = p(1-p).
\end{aligned}
$$ {#eq-ev-var-bern}

::: {.callout-note}
## Dimostrazione

Esaminiamo la dimostrazione algebrica del calcolo della varianza.

Espandiamo il calcolo della somma, considerando i due possibili valori di $X$ (0 e 1).

1. **Primo termine ($X = 0$):**

   $$
   (0 - \mathbb{E}(X))^2 \cdot P(X = 0) = (0 - p)^2 \cdot (1 - p).
   $$

   Semplificando $(0 - p)^2 = p^2$, quindi:

   $$
   (0 - \mathbb{E}(X))^2 \cdot P(X = 0) = p^2 \cdot (1 - p).
   $$

2. **Secondo termine ($X = 1$):**

   $$
   (1 - \mathbb{E}(X))^2 \cdot P(X = 1) = (1 - p)^2 \cdot p.
   $$

   Semplificando $(1 - p)^2 = 1 - 2p + p^2$, quindi:

   $$
   (1 - \mathbb{E}(X))^2 \cdot P(X = 1) = (1 - 2p + p^2) \cdot p = p - 2p^2 + p^3.
   $$

3. **Somma dei termini**

   Ora sommiamo i due contributi:

   $$
   \mathbb{V}(X) = p^2 \cdot (1 - p) + (p - 2p^2 + p^3).
   $$

   Espandendo il primo termine:

   $$
   p^2 \cdot (1 - p) = p^2 - p^3.
   $$

   Somma completa:

   $$
   \mathbb{V}(X) = (p^2 - p^3) + (p - 2p^2 + p^3).
   $$

4. **Raggruppiamo i termini**

   $$
   \mathbb{V}(X) = p - p^2.
   $$

   **Risultato finale:**

   $$
   \mathbb{V}(X) = p(1 - p).
   $$

In sintesi, la varianza di una variabile aleatoria binaria $X$, distribuita secondo Bernoulli con parametro $p$, è data da $p(1-p)$. 
:::

Tale risultato mostra come la varianza massima si ottenga per $p = 0.5$, condizione che corrisponde alla massima incertezza intrinseca nel processo, ossia quando la probabilità di successo eguaglia quella di insuccesso.

```{r}
# Valori di p tra 0 e 1
p <- seq(0, 1, length.out = 100)
variance <- p * (1 - p)
data <- data.frame(p = p, Variance = variance)

# Creazione del grafico
ggplot(data, aes(x = p, y = Variance)) +
  geom_line(linewidth = 1.2) +
  labs(
    x = expression(p),
    y = "Varianza"
  )
```

### Notazione

Per indicare che la variabile casuale $X$ segue una distribuzione Bernoulliana di parametro $p$ Utilizziamo la notazione $X \sim \mathcal{Bern}(p)$, o in maniera equivalente $\mathcal{Bern}(X \mid p)$.

::: {#exm-}
Nel caso del lancio di una moneta equilibrata, la variabile di Bernoulli assume i valori $0$ e $1$ con uguale probabilità di $\frac{1}{2}$. Pertanto, la funzione di massa di probabilità assegna una probabilità di $\frac{1}{2}$ sia per $X = 0$ che per $X = 1$, mentre la funzione di distribuzione cumulativa risulta essere $\frac{1}{2}$ per $X = 0$ e $1$ per $X = 1$.

Generiamo dei valori casuali dalla distribuzione di Bernoulli. Iniziamo con un singolo valore:

```{r}
# Probabilità di successo
p <- 0.5

# Genera un singolo valore
bernoulli_sample <- rbinom(n = 1, size = 1, prob = p)
print(bernoulli_sample)

# Genera un campione di 10 valori
bernoulli_sample <- rbinom(n = 10, size = 1, prob = p)
print(bernoulli_sample)
```
:::

