<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="it" xml:lang="it"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.34">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>17&nbsp; La verosimiglianza – Probabilità per la psicologia — Modulo di richiamo</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>

<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../chapters/appendix/a02_math_symbols.html" rel="next">
<link href="../../chapters/probability/15_gauss.html" rel="prev">
<link href="../../style/gauss.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-0a72236910a44089af39cd28873f322e.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-9908c7b05874059c2106d454ac00f1d0.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Nessun risultato",
    "search-matching-documents-text": "documenti trovati",
    "search-copy-link-title": "Copiare il link nella ricerca",
    "search-hide-matches-text": "Nascondere i risultati aggiuntivi",
    "search-more-match-text": "ci sono altri risultati in questo documento",
    "search-more-matches-text": "ulteriori risultati in questo documento",
    "search-clear-button-title": "Pulire",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancellare",
    "search-submit-button-title": "Inviare",
    "search-label": "Ricerca"
  }
}</script><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-QT5S3P9D31"></script><script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-QT5S3P9D31', { 'anonymize_ip': true});
</script><style>html{ scroll-behavior: smooth; }</style>
<script>
window.MathJax = {
  tex: { inlineMath: [['$', '$'], ['\\(', '\\)']] },
  svg: { scale: 1, mtextInheritFont: true, fontCache: 'none', minScale: 1 },
  options: { renderActions: { addMenu: [0, '', ''] } },
  loader: { load: ['input/tex','output/svg'] }
};
</script><script>
window.MathJax = {
  tex: { inlineMath: [['$', '$'], ['\\(', '\\)']] },
  svg: { scale: 1, mtextInheritFont: true, fontCache: 'none', minScale: 1 },
  options: { renderActions: { addMenu: [0, '', ''] } },
  loader: { load: ['input/tex','output/svg'] }
};
// Suggerimento CSS: vedi sezione 3 per gli spazi attorno a display math
</script><script>
window.MathJax = {
  tex: {
    packages: {'[+]': ['boldsymbol']},
    inlineMath: [['$', '$'], ['\\(', '\\)']]
  },
  svg: { fontCache: 'global' }
};
</script><script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script><script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script><link rel="stylesheet" href="../../style/_typography-extras.css">
<link rel="stylesheet" href="../../style/_code-extras.css">
<link rel="stylesheet" href="../../style/_math-extras.css">
<link rel="stylesheet" href="../../style/styles.css">
</head>
<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Attiva/disattiva la barra laterale" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../chapters/probability/introduction_probability.html">Probabilità</a></li><li class="breadcrumb-item"><a href="../../chapters/probability/16_likelihood.html"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">La verosimiglianza</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Attiva/disattiva la barra laterale" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Ricerca" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../../">Probabilità per la psicologia — Modulo di richiamo</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/ccaudek/utet-prob/" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Attiva/disattiva la modalità lettore">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Ricerca"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Percorso e obiettivi</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../prefazione.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Prefazione</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../chapters/probability/introduction_probability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Probabilità</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/01_intro_prob.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Interpretazione della probabilità</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/02_probability_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Modelli probabilistici</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/03_sigma-algebra.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Dal Discreto al Continuo: la <span class="math inline">\(\sigma\)</span>-algebra</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/04_conditional_prob.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Probabilità condizionata</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/05_bayes_theorem.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Il teorema di Bayes</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/06_random_var.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Variabili casuali</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/07_prob_distributions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Distribuzioni di massa e di densità</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/08_expval_var.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Proprietà delle variabili casuali</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/09_sampling_distr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Stime, stimatori e parametri</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/10_joint_prob.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Probabilità congiunta</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/11_cov_cor.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Covarianza e correlazione</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/12_intro_distributions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Introduzione alle distribuzioni di probabilità</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/13_discr_rv_distr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Distribuzioni di v.c. discrete</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/14_cont_rv_distr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Distribuzioni di v.c. continue</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/15_gauss.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Assunzione di gaussianità e trasformazioni dei dati</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/16_likelihood.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">La verosimiglianza</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a02_math_symbols.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Simbologia di base</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a11_numbers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Numeri e intervalli</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a12_sum_notation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">Sommatorie</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a13_sets.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Insiemi</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a14_combinatorics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">E</span>&nbsp; <span class="chapter-title">Calcolo combinatorio</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a15_calculus.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">F</span>&nbsp; <span class="chapter-title">Per liberarvi dai terrori preliminari</span></span></a>
  </div>
</li>
      </ul>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Sommario</h2>
   
  <ul class="collapse">
<li><a href="#modellazione-statistica-del-lancio-di-una-moneta" id="toc-modellazione-statistica-del-lancio-di-una-moneta" class="nav-link active" data-scroll-target="#modellazione-statistica-del-lancio-di-una-moneta"><span class="header-section-number">17.1</span> Modellazione statistica del lancio di una moneta</a></li>
  <li><a href="#verosimiglianza-binomiale" id="toc-verosimiglianza-binomiale" class="nav-link" data-scroll-target="#verosimiglianza-binomiale"><span class="header-section-number">17.2</span> Verosimiglianza binomiale</a></li>
  <li><a href="#la-stima-di-massima-verosimiglianza" id="toc-la-stima-di-massima-verosimiglianza" class="nav-link" data-scroll-target="#la-stima-di-massima-verosimiglianza"><span class="header-section-number">17.3</span> La Stima di Massima Verosimiglianza</a></li>
  <li><a href="#calcolo-della-stima-di-massima-verosimiglianza-in-r" id="toc-calcolo-della-stima-di-massima-verosimiglianza-in-r" class="nav-link" data-scroll-target="#calcolo-della-stima-di-massima-verosimiglianza-in-r"><span class="header-section-number">17.4</span> Calcolo della Stima di Massima Verosimiglianza in R</a></li>
  <li><a href="#verosimiglianza-congiunta" id="toc-verosimiglianza-congiunta" class="nav-link" data-scroll-target="#verosimiglianza-congiunta"><span class="header-section-number">17.5</span> Verosimiglianza congiunta</a></li>
  <li><a href="#la-verosimiglianza-marginale-nellinferenza-bayesiana" id="toc-la-verosimiglianza-marginale-nellinferenza-bayesiana" class="nav-link" data-scroll-target="#la-verosimiglianza-marginale-nellinferenza-bayesiana"><span class="header-section-number">17.6</span> La Verosimiglianza marginale nell’inferenza bayesiana</a></li>
  <li><a href="#verosimiglianza-gaussiana" id="toc-verosimiglianza-gaussiana" class="nav-link" data-scroll-target="#verosimiglianza-gaussiana"><span class="header-section-number">17.7</span> Verosimiglianza gaussiana</a></li>
  <li><a href="#campione-di-osservazioni-indipendenti" id="toc-campione-di-osservazioni-indipendenti" class="nav-link" data-scroll-target="#campione-di-osservazioni-indipendenti"><span class="header-section-number">17.8</span> Campione di osservazioni indipendenti</a></li>
  <li><a href="#il-rapporto-di-verosimiglianze" id="toc-il-rapporto-di-verosimiglianze" class="nav-link" data-scroll-target="#il-rapporto-di-verosimiglianze"><span class="header-section-number">17.9</span> Il rapporto di verosimiglianze</a></li>
  <li><a href="#rapporti-di-verosimiglianza-aggiustati-e-criterio-di-akaike" id="toc-rapporti-di-verosimiglianza-aggiustati-e-criterio-di-akaike" class="nav-link" data-scroll-target="#rapporti-di-verosimiglianza-aggiustati-e-criterio-di-akaike"><span class="header-section-number">17.10</span> Rapporti di verosimiglianza aggiustati e criterio di Akaike</a></li>
  </ul><div class="toc-actions"><ul class="collapse"><li><a href="https://github.com/ccaudek/utet-prob/blob/main/chapters/probability/16_likelihood.qmd" class="toc-action"><i class="bi bi-github"></i>Mostra il codice</a></li><li><a href="https://github.com/ccaudek/utet-prob/issues/new" class="toc-action"><i class="bi empty"></i>Segnala un problema</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../chapters/probability/introduction_probability.html">Probabilità</a></li><li class="breadcrumb-item"><a href="../../chapters/probability/16_likelihood.html"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">La verosimiglianza</span></a></li></ol></nav><div class="quarto-title">
<h1 class="title"><span id="sec-prob-likelihood" class="quarto-section-identifier"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">La verosimiglianza</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header><div class="epigraph">
<blockquote class="blockquote">
<p>“In Bayesian inference the likelihood plays the central role: it tells us how to update our prior beliefs in the light of observed data.”</p>
<p>– <strong>Dennis V. Lindley</strong>, Making Decisions (1971)</p>
</blockquote>
</div>
<section id="introduzione" class="level2 unnumbered unlisted"><h2 class="unnumbered unlisted anchored" data-anchor-id="introduzione">Introduzione</h2>
<p>I ricercatori utilizzano modelli matematici per descrivere e prevedere il comportamento dei dati osservati. Questi modelli si distinguono per la loro struttura funzionale, che definisce le relazioni tra variabili osservate e parametri teorici. La selezione del modello ottimale avviene attraverso un confronto sistematico tra le previsioni teoriche generate dai diversi modelli e l’evidenza empirica. Il modello che mostra il miglior accordo con i dati sperimentali viene considerato la rappresentazione più adeguata del fenomeno studiato.</p>
<p>In questo processo di valutazione, la funzione di verosimiglianza svolge un ruolo fondamentale: per ogni possibile valore dei parametri, essa quantifica quanto siano plausibili i dati osservati sotto l’ipotesi che siano stati generati da quel specifico modello. In altre parole, la verosimiglianza costruisce una mappa di plausibilità parametrica, identificando le combinazioni di parametri che massimizzano la coerenza tra modello e realtà osservata.</p>
<section id="panoramica-del-capitolo" class="level3 unnumbered unlisted"><h3 class="unnumbered unlisted anchored" data-anchor-id="panoramica-del-capitolo">Panoramica del capitolo</h3>
<ul>
<li>Misura della plausibilità dei parametri alla luce dei dati osservati</li>
<li>Applicazione a distribuzioni binomiali (lancio di monete) e gaussiane (misura del QI)</li>
<li>Metodi per identificare i parametri più plausibili con implementazioni in R</li>
<li>Utilizzo del rapporto di verosimiglianze e criteri aggiustati (AIC)</li>
<li>La verosimiglianza come componente fondamentale per l’inferenza bayesiana</li>
</ul>
<div class="callout callout-style-simple callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Prerequisiti
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul>
<li>Capitolo <em>Estimation</em> <span class="citation" data-cites="schervish2014probability">(<a href="#ref-schervish2014probability" role="doc-biblioref">Schervish &amp; DeGroot, 2014</a>)</span>
</li>
<li>Capitolo <em>Bayes’ rule</em> <span class="citation" data-cites="Johnson2022bayesrules">(<a href="#ref-Johnson2022bayesrules" role="doc-biblioref">Johnson et al., 2022</a>)</span>
</li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-caution no-icon callout-titled" title="Preparazione del Notebook">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Preparazione del Notebook
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<div class="cell">
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">here</span><span class="fu">::</span><span class="fu"><a href="https://here.r-lib.org/reference/here.html">here</a></span><span class="op">(</span><span class="st">"code"</span>, <span class="st">"_common.R"</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/source.html">source</a></span><span class="op">(</span><span class="op">)</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</div>
</section><section id="il-principio-della-verosimiglianza" class="level3" data-number="17.0.1"><h3 data-number="17.0.1" class="anchored" data-anchor-id="il-principio-della-verosimiglianza">
<span class="header-section-number">17.0.1</span> Il principio della verosimiglianza</h3>
<p>Il principio della verosimiglianza costituisce il fondamento dell’inferenza statistica moderna, fornendo un metodo per quantificare la plausibilità di un valore parametrico (come la media di una popolazione o l’effetto di una terapia) alla luce dei dati osservati.</p>
<p>Concettualmente, la verosimiglianza non misura la probabilità che un’ipotesi sia vera, ma valuta quanto i dati osservati siano coerenti con una specifica ipotesi sul parametro. Rappresenta una misura di sostegno empirico: valori parametrici che rendono i dati più probabili ricevono maggiore supporto dall’evidenza.</p>
<div id="def-" class="theorem definition">
<p><span class="theorem-title"><strong>Definizione 17.1</strong></span> Sia <span class="math inline">\(Y\)</span> un vettore aleatorio (come l’insieme dei punteggi dei partecipanti a un test) la cui distribuzione dipende da un parametro sconosciuto <span class="math inline">\(\theta\)</span> (ad esempio, il punteggio medio nella popolazione). La distribuzione è descritta da una funzione di densità di probabilità (per variabili continue) o di massa di probabilità (per variabili discrete), indicata con <span class="math inline">\(f(y \mid \theta)\)</span>, dove <span class="math inline">\(\theta \in \Theta\)</span> e <span class="math inline">\(\Theta\)</span> rappresenta lo spazio dei possibili valori parametrici.</p>
<p>Dopo aver osservato un campione di dati <span class="math inline">\(y\)</span>, la <em>funzione di verosimiglianza</em> è definita come:</p>
<p><span class="math display">\[
L(\theta; y) = f(y \mid \theta)
\]</span></p>
<p>Si noti che in questa funzione:</p>
<ul>
<li>
<em><span class="math inline">\(y\)</span> è fissato</em>: corrisponde ai dati effettivamente raccolti</li>
<li>
<em><span class="math inline">\(\theta\)</span> è variabile</em>: rappresenta il parametro incognito oggetto di inferenza</li>
</ul>
<p>La funzione <span class="math inline">\(L(\theta; y)\)</span> assegna quindi a ogni possibile valore di <span class="math inline">\(\theta\)</span> un grado di supporto basato sui dati, indicando quali valori rendono le osservazioni più plausibili.</p>
</div>
</section><section id="relazione-tra-verosimiglianza-e-funzione-di-probabilità" class="level3" data-number="17.0.2"><h3 data-number="17.0.2" class="anchored" data-anchor-id="relazione-tra-verosimiglianza-e-funzione-di-probabilità">
<span class="header-section-number">17.0.2</span> Relazione tra verosimiglianza e funzione di probabilità</h3>
<p>Sebbene la funzione di probabilità (o densità) e la funzione di verosimiglianza condividano la stessa forma matematica <span class="math inline">\(f(y \mid \theta)\)</span>, il loro significato concettuale differisce sostanzialmente in base al contesto inferenziale.</p>
<section id="due-prospettive-a-confronto" class="level4" data-number="17.0.2.1"><h4 data-number="17.0.2.1" class="anchored" data-anchor-id="due-prospettive-a-confronto">
<span class="header-section-number">17.0.2.1</span> Due prospettive a confronto</h4>
<ol type="1">
<li>
<strong>Funzione di probabilità (densità/massa)</strong>
<ul>
<li>
<em>Parametri (<span class="math inline">\(\theta\)</span>) fissi</em>: assumiamo che siano noti o ipotizzati</li>
<li>
<em>Dati (<span class="math inline">\(y\)</span>) aleatori</em>: descrive la distribuzione dei possibili risultati</li>
<li>
<em>Interpretazione</em>: <span class="math inline">\(f(y \mid \theta)\)</span> quantifica la probabilità (o densità) di osservare <span class="math inline">\(y\)</span> sotto un modello con parametri <span class="math inline">\(\theta\)</span>
</li>
<li>
<em>Domanda chiave</em>: “Se il modello fosse <span class="math inline">\(\theta\)</span>, quanto sarebbero probabili questi dati?”</li>
</ul>
</li>
<li>
<strong>Funzione di verosimiglianza</strong>
<ul>
<li>
<em>Dati (<span class="math inline">\(y\)</span>) fissi</em>: corrispondono alle osservazioni effettive</li>
<li>
<em>Parametri (<span class="math inline">\(\theta\)</span>) variabili</em>: rappresentano l’incertezza da risolvere</li>
<li>
<em>Interpretazione</em>: <span class="math inline">\(L(\theta; y) = f(y \mid \theta)\)</span> misura la plausibilità relativa di <span class="math inline">\(\theta\)</span> alla luce di <span class="math inline">\(y\)</span>
</li>
<li>
<em>Domanda chiave</em>: “Alla luce di questi dati, quanto sono credibili i diversi <span class="math inline">\(\theta\)</span>?”</li>
</ul>
</li>
</ol></section><section id="implicazioni-per-linferenza-statistica" class="level4" data-number="17.0.2.2"><h4 data-number="17.0.2.2" class="anchored" data-anchor-id="implicazioni-per-linferenza-statistica">
<span class="header-section-number">17.0.2.2</span> Implicazioni per l’inferenza statistica</h4>
<ul>
<li><p><strong>Approccio frequentista</strong>: la verosimiglianza è uno strumento per stimare i parametri (es. stima di massima verosimiglianza), senza assegnare loro una distribuzione di probabilità</p></li>
<li><p><strong>Approccio bayesiano</strong>: la verosimiglianza funge da ponte tra dati e parametri, combinando l’informazione empirica con le credenze iniziali (<em>prior</em>) per derivare la distribuzione a posteriori:</p></li>
</ul>
<p><span class="math display">\[
P(\theta \mid y) \propto L(\theta; y) \cdot P(\theta)
\]</span></p>
<p>In questa prospettiva, i dati aggiornano la nostra conoscenza su <span class="math inline">\(\theta\)</span> attraverso la verosimiglianza.</p>
</section><section id="sintesi-delle-differenze" class="level4" data-number="17.0.2.3"><h4 data-number="17.0.2.3" class="anchored" data-anchor-id="sintesi-delle-differenze">
<span class="header-section-number">17.0.2.3</span> Sintesi delle differenze</h4>
<table class="caption-top table">
<colgroup>
<col style="width: 31%">
<col style="width: 31%">
<col style="width: 36%">
</colgroup>
<thead><tr class="header">
<th>Caratteristica</th>
<th>Funzione di probabilità</th>
<th>Funzione di verosimiglianza</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><em>Variabile di interesse</em></td>
<td>
<span class="math inline">\(y\)</span> (aleatoria)</td>
<td>
<span class="math inline">\(\theta\)</span> (incognita)</td>
</tr>
<tr class="even">
<td><em>Ruolo epistemologico</em></td>
<td>Genera dati ipotetici</td>
<td>Valuta parametri plausibili</td>
</tr>
<tr class="odd">
<td><em>Contesto d’uso</em></td>
<td>Modellistica predittiva</td>
<td>Inferenza parametrica</td>
</tr>
</tbody>
</table>
<p>Questa dualità riflette un principio fondamentale: la stessa formula matematica assume significati distinti a seconda che l’obiettivo sia la descrizione del processo generativo o l’inferenza sui suoi parametri. La verosimiglianza, in particolare, è il motore dell’apprendimento statistico, trasformando dati in conoscenza.</p>
</section></section><section id="la-log-verosimiglianza" class="level3" data-number="17.0.3"><h3 data-number="17.0.3" class="anchored" data-anchor-id="la-log-verosimiglianza">
<span class="header-section-number">17.0.3</span> La log-verosimiglianza</h3>
<p>In ambito statistico e computazionale, risulta spesso vantaggioso lavorare con la <em>log-verosimiglianza</em>, definita come il logaritmo naturale della funzione di verosimiglianza:</p>
<p><span class="math display">\[
\ell(\theta; y) = \log L(\theta; y) = \log f(y \mid \theta).
\]</span></p>
<p>Questa trasformazione apporta significativi vantaggi sia dal punto di vista computazionale che analitico.</p>
<p>Dal punto di vista computazionale, la log-verosimiglianza offre una maggiore stabilità numerica. Il prodotto di probabilità molto piccole, tipico delle funzioni di verosimiglianza, può infatti portare a valori numericamente instabili (un fenomeno noto come <em>underflow</em>). La conversione logaritmica trasforma questi prodotti in somme, molto più gestibili per i calcolatori. Questo vantaggio diventa particolarmente evidente nel caso di osservazioni indipendenti e identicamente distribuite (i.i.d.), dove la log-verosimiglianza complessiva si esprime come la somma dei contributi individuali:</p>
<p><span class="math display">\[
\ell(\theta; y_1, \dots, y_n) = \sum_{i=1}^n \log f(y_i \mid \theta),
\]</span> semplificando notevolmente i calcoli.</p>
<p>Sul piano analitico, la log-verosimiglianza facilita l’ottimizzazione grazie alle proprietà del logaritmo che trasformano prodotti in somme. Le derivate risultano infatti matematicamente più semplici da trattare rispetto a quelle della verosimiglianza originale. Questa semplificazione risulta particolarmente vantaggiosa nei metodi di ottimizzazione numerica come la massimizzazione della verosimiglianza (MLE), dove la stima dei parametri avviene risolvendo il sistema di equazioni ottenuto uguagliando a zero il gradiente. La forma additiva della log-verosimiglianza si dimostra inoltre particolarmente utile nei modelli gerarchici o nei casi in cui i dati provengano da più fonti indipendenti.</p>
<p>È importante sottolineare che, poiché il logaritmo è una funzione monotona crescente, massimizzare la log-verosimiglianza <span class="math inline">\(\ell(\theta; y)\)</span> equivale perfettamente a massimizzare la verosimiglianza <span class="math inline">\(L(\theta; y)\)</span>. Pertanto, le stime di massima verosimiglianza (MLE) possono essere ottenute indifferentemente dall’una o dall’altra funzione.</p>
<p>In sintesi, la log-verosimiglianza combina efficienza computazionale e semplicità analitica, rendendola uno strumento fondamentale per l’inferenza statistica e l’analisi dati moderna. La sua adozione consente di affrontare problemi complessi con maggiore stabilità numerica e minore complessità computazionale, mantenendo inalterate le proprietà inferenziali della verosimiglianza originale.</p>
</section></section><section id="modellazione-statistica-del-lancio-di-una-moneta" class="level2" data-number="17.1"><h2 data-number="17.1" class="anchored" data-anchor-id="modellazione-statistica-del-lancio-di-una-moneta">
<span class="header-section-number">17.1</span> Modellazione statistica del lancio di una moneta</h2>
<p>Un esempio classico per introdurre il concetto di <em>verosimiglianza</em> è quello del lancio di una moneta. Chiamiamo <span class="math inline">\(\theta\)</span> la probabilità (incognita) di ottenere “testa”.</p>
<section id="il-modello-probabilistico" class="level3" data-number="17.1.1"><h3 data-number="17.1.1" class="anchored" data-anchor-id="il-modello-probabilistico">
<span class="header-section-number">17.1.1</span> Il modello probabilistico</h3>
<p>Per semplicità assumiamo:</p>
<ol type="1">
<li>ogni lancio è <em>indipendente</em> dagli altri;</li>
<li>la probabilità <span class="math inline">\(\theta\)</span> resta <em>costante</em> in tutti i lanci.</li>
</ol>
<p>Se in <span class="math inline">\(n\)</span> lanci otteniamo <span class="math inline">\(y\)</span> teste, la probabilità di osservare esattamente quei dati è:</p>
<p><span class="math display">\[
P(\text{dati}\mid \theta) = \theta^y (1-\theta)^{n-y}.
\]</span></p>
</section><section id="la-funzione-di-verosimiglianza" class="level3" data-number="17.1.2"><h3 data-number="17.1.2" class="anchored" data-anchor-id="la-funzione-di-verosimiglianza">
<span class="header-section-number">17.1.2</span> La funzione di verosimiglianza</h3>
<p>La <em>funzione di verosimiglianza</em> si ottiene considerando l’espressione precedente non più come funzione dei dati, ma come funzione di <span class="math inline">\(\theta\)</span>:</p>
<p><span class="math display">\[
L(\theta \mid \text{dati}) \propto \theta^y (1-\theta)^{n-y}.
\]</span></p>
<p>Essa indica quali valori di <span class="math inline">\(\theta\)</span> sono più compatibili con i dati osservati. Il valore che massimizza questa funzione è lo <em>stimatore di massima verosimiglianza (MLE)</em>.</p>
</section><section id="esempio-1-due-lanci" class="level3" data-number="17.1.3"><h3 data-number="17.1.3" class="anchored" data-anchor-id="esempio-1-due-lanci">
<span class="header-section-number">17.1.3</span> Esempio 1: due lanci</h3>
<p>Supponiamo di osservare due lanci con esito: una testa e una croce (<span class="math inline">\(n=2, y=1\)</span>).</p>
<ul>
<li>
<p>Se <span class="math inline">\(\theta = 0.5\)</span>:</p>
<p><span class="math display">\[
L(0.5) = 0.5^1 \cdot 0.5^1 = 0.25
\]</span></p>
</li>
<li>
<p>Se <span class="math inline">\(\theta = 0.4\)</span>:</p>
<p><span class="math display">\[
L(0.4) = 0.4^1 \cdot 0.6^1 = 0.24
\]</span></p>
</li>
</ul>
<p>In questo caso <span class="math inline">\(\theta=0.5\)</span> spiega leggermente meglio i dati.</p>
<p>Con R possiamo calcolare la verosimiglianza per tutta la gamma di valori di <span class="math inline">\(\theta\)</span>:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">2</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fl">1</span></span>
<span><span class="va">p_H</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, length.out <span class="op">=</span> <span class="fl">100</span><span class="op">)</span></span>
<span><span class="va">likelihood</span> <span class="op">&lt;-</span> <span class="va">p_H</span><span class="op">^</span><span class="va">y</span> <span class="op">*</span> <span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">p_H</span><span class="op">)</span><span class="op">^</span><span class="op">(</span><span class="va">n</span> <span class="op">-</span> <span class="va">y</span><span class="op">)</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>La curva risultante ha il massimo in corrispondenza di <span class="math inline">\(\hat\theta = y/n = 0.5\)</span>.</p>
</section><section id="esempio-2-tre-lanci" class="level3" data-number="17.1.4"><h3 data-number="17.1.4" class="anchored" data-anchor-id="esempio-2-tre-lanci">
<span class="header-section-number">17.1.4</span> Esempio 2: tre lanci</h3>
<p>Consideriamo ora tre lanci con esito: una testa e due croci (<span class="math inline">\(n=3, y=1\)</span>).</p>
<ul>
<li>
<p>Se <span class="math inline">\(\theta = 0.5\)</span>:</p>
<p><span class="math display">\[
L(0.5) = 0.5^1 \cdot 0.5^2 = 0.125
\]</span></p>
</li>
<li>
<p>Se <span class="math inline">\(\theta = 0.4\)</span>:</p>
<p><span class="math display">\[
L(0.4) = 0.4^1 \cdot 0.6^2 = 0.144
\]</span></p>
</li>
</ul>
<p>Qui il valore <span class="math inline">\(\theta = 0.4\)</span> è più plausibile di 0.5.</p>
<p>Con R:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">3</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fl">1</span></span>
<span><span class="va">p_H</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, length.out <span class="op">=</span> <span class="fl">100</span><span class="op">)</span></span>
<span><span class="va">likelihood</span> <span class="op">&lt;-</span> <span class="va">p_H</span><span class="op">^</span><span class="va">y</span> <span class="op">*</span> <span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">p_H</span><span class="op">)</span><span class="op">^</span><span class="op">(</span><span class="va">n</span> <span class="op">-</span> <span class="va">y</span><span class="op">)</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>La curva raggiunge il massimo in <span class="math inline">\(\hat\theta = y/n = 1/3 \approx 0.33\)</span>. Rispetto al caso precedente, la curva è più <em>stretta</em>, segnalando una maggiore precisione della stima grazie al numero maggiore di osservazioni.</p>
</section><section id="interpretazione-complessiva" class="level3" data-number="17.1.5"><h3 data-number="17.1.5" class="anchored" data-anchor-id="interpretazione-complessiva">
<span class="header-section-number">17.1.5</span> Interpretazione complessiva</h3>
<ul>
<li>Lo <em>stimatore di massima verosimiglianza</em> <span class="math inline">\(\hat\theta\)</span> corrisponde sempre alla <em>proporzione osservata di teste</em> (<span class="math inline">\(y/n\)</span>).</li>
<li>All’aumentare del numero di lanci, la curva di verosimiglianza diventa più appuntita: significa che abbiamo <em>maggiore certezza</em> sul valore di <span class="math inline">\(\theta\)</span>.</li>
<li>I valori estremi (<span class="math inline">\(\theta \approx 0\)</span> o <span class="math inline">\(\theta \approx 1\)</span>) risultano poco compatibili con i dati, perché non potrebbero spiegare l’osservazione sia di teste che di croci.</li>
</ul>
<p>In sintesi: la verosimiglianza traduce l’idea intuitiva che “il valore migliore del parametro è quello che rende i dati osservati più probabili”. Questo principio, applicato in modo generale, costituisce la base della <em>stima per massima verosimiglianza</em>.</p>
</section><section id="confronto-tra-due-e-tre-lanci" class="level3" data-number="17.1.6"><h3 data-number="17.1.6" class="anchored" data-anchor-id="confronto-tra-due-e-tre-lanci">
<span class="header-section-number">17.1.6</span> Confronto tra due e tre lanci</h3>
<p>Mettiamo ora a confronto le due situazioni:</p>
<ul>
<li>
<strong>Caso 1</strong>: 2 lanci con 1 testa (<span class="math inline">\(n=2, y=1\)</span>, proporzione osservata <span class="math inline">\(\hat\theta = 0.5\)</span>).</li>
<li>
<strong>Caso 2</strong>: 3 lanci con 1 testa (<span class="math inline">\(n=3, y=1\)</span>, proporzione osservata <span class="math inline">\(\hat\theta \approx 0.33\)</span>).</li>
</ul>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Dati per 2 lanci</span></span>
<span><span class="va">n1</span> <span class="op">&lt;-</span> <span class="fl">2</span>; <span class="va">y1</span> <span class="op">&lt;-</span> <span class="fl">1</span></span>
<span><span class="va">theta_seq</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, length.out <span class="op">=</span> <span class="fl">200</span><span class="op">)</span></span>
<span><span class="va">lik1</span> <span class="op">&lt;-</span> <span class="va">theta_seq</span><span class="op">^</span><span class="va">y1</span> <span class="op">*</span> <span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">theta_seq</span><span class="op">)</span><span class="op">^</span><span class="op">(</span><span class="va">n1</span> <span class="op">-</span> <span class="va">y1</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Dati per 3 lanci</span></span>
<span><span class="va">n2</span> <span class="op">&lt;-</span> <span class="fl">3</span>; <span class="va">y2</span> <span class="op">&lt;-</span> <span class="fl">1</span></span>
<span><span class="va">lik2</span> <span class="op">&lt;-</span> <span class="va">theta_seq</span><span class="op">^</span><span class="va">y2</span> <span class="op">*</span> <span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">theta_seq</span><span class="op">)</span><span class="op">^</span><span class="op">(</span><span class="va">n2</span> <span class="op">-</span> <span class="va">y2</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Creiamo un unico dataframe</span></span>
<span><span class="va">df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span></span>
<span>  theta <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="va">theta_seq</span>, <span class="fl">2</span><span class="op">)</span>,</span>
<span>  likelihood <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">lik1</span>, <span class="va">lik2</span><span class="op">)</span>,</span>
<span>  caso <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"2 lanci (1 testa)"</span>, <span class="st">"3 lanci (1 testa)"</span><span class="op">)</span>, each <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">theta_seq</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Grafico comparativo</span></span>
<span><span class="fu">ggplot</span><span class="op">(</span><span class="va">df</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">theta</span>, y <span class="op">=</span> <span class="va">likelihood</span>, color <span class="op">=</span> <span class="va">caso</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_line</span><span class="op">(</span>linewidth <span class="op">=</span> <span class="fl">1.2</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span></span>
<span>    x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="va">theta</span><span class="op">)</span>,</span>
<span>    y <span class="op">=</span> <span class="st">"Verosimiglianza"</span></span>
<span>  <span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">scale_color_manual</span><span class="op">(</span>values <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"steelblue"</span>, <span class="st">"darkorange"</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="16_likelihood_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:85.0%"></p>
</figure>
</div>
</div>
</div>
</section><section id="interpretazione-del-grafico" class="level3" data-number="17.1.7"><h3 data-number="17.1.7" class="anchored" data-anchor-id="interpretazione-del-grafico">
<span class="header-section-number">17.1.7</span> Interpretazione del grafico</h3>
<ul>
<li>Nel <em>caso dei 2 lanci</em>, la curva ha un massimo in <span class="math inline">\(\hat\theta = 0.5\)</span>, ma è <em>molto larga</em>: la stima è poco precisa.</li>
<li>Nel <em>caso dei 3 lanci</em>, la curva ha un massimo in <span class="math inline">\(\hat\theta = 1/3\)</span>, ed è <em>più stretta</em>: significa che, con più dati, la stima diventa più affidabile.</li>
<li>I valori estremi (<span class="math inline">\(\theta \approx 0\)</span> o <span class="math inline">\(\theta \approx 1\)</span>) hanno verosimiglianza quasi nulla in entrambi i casi, perché non spiegherebbero la presenza di almeno una testa e di almeno una croce.</li>
</ul>
<p>Questo semplice confronto mostra visivamente come <em>aumentare la quantità di dati restringe l’incertezza</em> e rende la stima più precisa.</p>
</section></section><section id="verosimiglianza-binomiale" class="level2" data-number="17.2"><h2 data-number="17.2" class="anchored" data-anchor-id="verosimiglianza-binomiale">
<span class="header-section-number">17.2</span> Verosimiglianza binomiale</h2>
<p>Consideriamo ora un esperimento più ampio: lanciamo una moneta <span class="math inline">\(n = 30\)</span> volte e osserviamo <span class="math inline">\(y = 23\)</span> teste. Per modellare il numero totale di successi utilizziamo la distribuzione binomiale, che descrive la probabilità di ottenere esattamente <span class="math inline">\(y\)</span> successi in <span class="math inline">\(n\)</span> prove indipendenti, con probabilità di successo <span class="math inline">\(\theta\)</span> costante:</p>
<p><span class="math display">\[
P(Y = y \mid \theta) = \binom{n}{y} \theta^y (1 - \theta)^{n - y}.
\]</span></p>
<p>In questo contesto, <span class="math inline">\(Y\)</span> rappresenta la variabile casuale “numero di teste”, <span class="math inline">\(y = 23\)</span> è il valore osservato, e <span class="math inline">\(\theta\)</span> (o <span class="math inline">\(p_H\)</span>) è la probabilità incognita di ottenere testa in un singolo lancio.</p>
<section id="dalla-distribuzione-di-probabilità-alla-verosimiglianza" class="level3" data-number="17.2.1"><h3 data-number="17.2.1" class="anchored" data-anchor-id="dalla-distribuzione-di-probabilità-alla-verosimiglianza">
<span class="header-section-number">17.2.1</span> Dalla distribuzione di probabilità alla verosimiglianza</h3>
<p>Dopo aver osservato i dati (<span class="math inline">\(y = 23\)</span>), possiamo valutare la compatibilità dei diversi valori del parametro <span class="math inline">\(\theta\)</span> con l’evidenza sperimentale. A questo scopo, utilizziamo la formula della distribuzione binomiale trattandola come funzione di <span class="math inline">\(\theta\)</span> anziché di <span class="math inline">\(y\)</span>:</p>
<p><span class="math display">\[
L(\theta \mid y = 23) = \binom{30}{23} \theta^{23} (1 - \theta)^7.
\]</span></p>
<p>Questa funzione di verosimiglianza quantifica la plausibilità di ciascun valore di <span class="math inline">\(\theta\)</span> alla luce dei dati osservati. A differenza degli esempi precedenti, in questo caso manteniamo la costante moltiplicativa <span class="math inline">\(\binom{30}{23}\)</span> poiché lavoreremo con la verosimiglianza completa.</p>
</section><section id="visualizzazione-della-funzione-di-verosimiglianza" class="level3" data-number="17.2.2"><h3 data-number="17.2.2" class="anchored" data-anchor-id="visualizzazione-della-funzione-di-verosimiglianza">
<span class="header-section-number">17.2.2</span> Visualizzazione della funzione di verosimiglianza</h3>
<p>Il codice seguente genera il grafico della funzione di verosimiglianza, calcolando per ogni valore di <span class="math inline">\(\theta\)</span> la probabilità di osservare 23 successi su 30 prove:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Parametri osservati</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">30</span>  <span class="co"># Numero totale di lanci</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fl">23</span>  <span class="co"># Numero di teste osservate</span></span>
<span></span>
<span><span class="co"># Griglia di valori possibili per theta</span></span>
<span><span class="va">theta</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, length.out <span class="op">=</span> <span class="fl">1000</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Calcolo della verosimiglianza binomiale</span></span>
<span><span class="va">likelihood</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="va">y</span>, size <span class="op">=</span> <span class="va">n</span>, prob <span class="op">=</span> <span class="va">theta</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Preparazione dei dati per la visualizzazione</span></span>
<span><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">theta</span>, <span class="va">likelihood</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Rappresentazione grafica</span></span>
<span><span class="fu">ggplot</span><span class="op">(</span><span class="va">data</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">theta</span>, y <span class="op">=</span> <span class="va">likelihood</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_line</span><span class="op">(</span>linewidth <span class="op">=</span> <span class="fl">1.2</span>, color <span class="op">=</span> <span class="st">"steelblue"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span></span>
<span>    x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="va">theta</span><span class="op">)</span>,</span>
<span>    y <span class="op">=</span> <span class="st">"Verosimiglianza"</span></span>
<span>  <span class="op">)</span> </span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="16_likelihood_files/figure-html/unnamed-chunk-5-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:85.0%"></p>
</figure>
</div>
</div>
</div>
</section><section id="interpretazione-dei-risultati" class="level3" data-number="17.2.3"><h3 data-number="17.2.3" class="anchored" data-anchor-id="interpretazione-dei-risultati">
<span class="header-section-number">17.2.3</span> Interpretazione dei risultati</h3>
<p>L’analisi grafica rivele che:</p>
<ul>
<li>La funzione di verosimiglianza raggiunge il suo massimo in corrispondenza di <span class="math inline">\(\theta \approx 0.77\)</span>
</li>
<li>Questo valore rappresenta la stima di massima verosimiglianza (MLE) per la probabilità di successo</li>
<li>La stima corrisponde esattamente alla proporzione campionaria: <span class="math inline">\(\hat{\theta} = \frac{23}{30} \approx 0.767\)</span>
</li>
<li>La curva mostra una dispersione limitata, indicando una relativa precisione nella stima</li>
<li>I valori estremi di <span class="math inline">\(\theta\)</span> (vicini a 0 o 1) presentano verosimiglianze trascurabili</li>
</ul></section><section id="implementazione-computazionale" class="level3" data-number="17.2.4"><h3 data-number="17.2.4" class="anchored" data-anchor-id="implementazione-computazionale">
<span class="header-section-number">17.2.4</span> Implementazione computazionale</h3>
<p>In R, il calcolo della verosimiglianza binomiale può essere efficientemente implementato utilizzando la funzione <code><a href="https://rdrr.io/r/stats/Binomial.html">dbinom()</a></code>, che calcola la funzione di massa di probabilità della distribuzione binomiale:</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Calcolo della verosimiglianza</span></span>
<span><span class="va">likelihood</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="va">y</span>, size <span class="op">=</span> <span class="va">n</span>, prob <span class="op">=</span> <span class="va">theta</span><span class="op">)</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>dove:</p>
<ul>
<li>
<code>y</code> è il numero di successi osservati (23)</li>
<li>
<code>n</code> è il numero totale di prove (30)</li>
<li>
<code>theta</code> è il vettore dei valori parametrici da valutare</li>
</ul>
<p>Questo approccio dimostra come la verosimiglianza possa essere costruita direttamente a partire dalla distribuzione di probabilità sottostante, utilizzando strumenti computazionali standard. La funzione <code><a href="https://rdrr.io/r/stats/Binomial.html">dbinom()</a></code> calcola automaticamente l’intera espressione binomiale, inclusa la costante moltiplicativa, fornendo così la verosimiglianza completa per ogni valore di <span class="math inline">\(\theta\)</span>.</p>
<p>La metodologia presentata mostra come concetti teorici di inferenza statistica possano essere efficacemente implementati e visualizzati attraverso strumenti computazionali, facilitando la comprensione intuitiva dei principi di verosimiglianza e stima parametrica.</p>
</section></section><section id="la-stima-di-massima-verosimiglianza" class="level2" data-number="17.3"><h2 data-number="17.3" class="anchored" data-anchor-id="la-stima-di-massima-verosimiglianza">
<span class="header-section-number">17.3</span> La Stima di Massima Verosimiglianza</h2>
<p>Quando osserviamo dati sperimentali e desideriamo stimare un parametro incognito – come la probabilità <span class="math inline">\(\theta\)</span> che una moneta produca “testa” – un approccio fondamentale è rappresentato dalla <em>stima di massima verosimiglianza</em> (Maximum Likelihood Estimation, MLE). Sebbene l’approccio bayesiano si concentri sulla distribuzione completa dei valori plausibili del parametro piuttosto che su una singola stima puntuale, la comprensione del concetto di MLE rimane essenziale. Questo metodo identifica il valore di <span class="math inline">\(\theta\)</span> che massimizza la compatibilità tra il modello e i dati osservati. In contesti bayesiani, sotto specifiche condizioni di prior, la MLE coincide con il massimo della distribuzione a posteriori.</p>
<section id="il-principio-fondamentale" class="level3" data-number="17.3.1"><h3 data-number="17.3.1" class="anchored" data-anchor-id="il-principio-fondamentale">
<span class="header-section-number">17.3.1</span> Il principio fondamentale</h3>
<p>La logica sottostante la MLE è intuitiva: tra tutti i possibili valori del parametro, selezioniamo quello che rende i dati osservati più probabili. Immaginiamo di testare sistematicamente diversi valori di <span class="math inline">\(\theta\)</span>, chiedendoci per ciascuno: “Se questo fosse il vero valore del parametro, quanto sarebbero plausibili i dati che abbiamo effettivamente osservato?” Il valore che massimizza questa plausibilità costituisce la nostra stima ottimale.</p>
</section><section id="esempio-applicativo-il-lancio-della-moneta" class="level3" data-number="17.3.2"><h3 data-number="17.3.2" class="anchored" data-anchor-id="esempio-applicativo-il-lancio-della-moneta">
<span class="header-section-number">17.3.2</span> Esempio applicativo: il lancio della moneta</h3>
<p>Consideriamo una moneta lanciata 30 volte che produce 23 teste. Un risultato così marcato solleva naturalmente dubbi sull’equità della moneta. Per stimare la vera probabilità <span class="math inline">\(\theta\)</span> di ottenere testa, costruiamo la funzione di verosimiglianza, che quantifica la compatibilità di ciascun possibile valore di <span class="math inline">\(\theta\)</span> con l’evidenza sperimentale. Valori più elevati di verosimiglianza indicano una maggiore plausibilità del parametro dato i dati osservati.</p>
</section><section id="rappresentazione-grafica-e-interpretazione" class="level3" data-number="17.3.3"><h3 data-number="17.3.3" class="anchored" data-anchor-id="rappresentazione-grafica-e-interpretazione">
<span class="header-section-number">17.3.3</span> Rappresentazione grafica e interpretazione</h3>
<p>La funzione di verosimiglianza <span class="math inline">\(L(\theta)\)</span> può essere visualizzata come una curva che descrive l’andamento della plausibilità al variare di <span class="math inline">\(\theta\)</span>. Questa curva presenta tipicamente un massimo globale ben definito, corrispondente alla stima MLE. Geometricamente, questo punto rappresenta il vertice della “collina” di verosimiglianza.</p>
<p>La forma della curva fornisce preziose informazioni:</p>
<ul>
<li>una curva appuntita indica alta certezza nella stima,</li>
<li>una curva più piatta suggerisce maggiore incertezza parametrica,</li>
<li>la pendenza della curva riflette la sensibilità della verosimiglianza alle variazioni del parametro.</li>
</ul></section><section id="determinazione-analitica-del-massimo" class="level3" data-number="17.3.4"><h3 data-number="17.3.4" class="anchored" data-anchor-id="determinazione-analitica-del-massimo">
<span class="header-section-number">17.3.4</span> Determinazione analitica del massimo</h3>
<p>Matematicamente, il massimo della funzione di verosimiglianza corrisponde al punto in cui la sua derivata si annulla. Utilizzando la trasformazione in log-verosimiglianza:</p>
<p><span class="math display">\[
\ell(\theta) = y \log \theta + (n - y) \log(1 - \theta),
\]</span></p>
<p>la soluzione analitica si ottiene ponendo la derivata uguale a zero:</p>
<p><span class="math display">\[
\hat{\theta} = \frac{y}{n}.
\]</span></p>
<p>Nel nostro esempio, questo risulta in <span class="math inline">\(\hat{\theta} = \frac{23}{30} \approx 0.767\)</span>, dimostrando come la MLE corrisponda alla proporzione campionaria osservata.</p>
</section><section id="relazione-con-linferenza-bayesiana" class="level3" data-number="17.3.5"><h3 data-number="17.3.5" class="anchored" data-anchor-id="relazione-con-linferenza-bayesiana">
<span class="header-section-number">17.3.5</span> Relazione con l’inferenza bayesiana</h3>
<p>Nella statistica bayesiana, l’obiettivo principale è la caratterizzazione completa dell’incertezza parametrica attraverso la distribuzione a posteriori. Tuttavia, il punto di massimo di questa distribuzione, noto come stima MAP (Maximum A Posteriori), coincide con la MLE quando si assume una distribuzione a priori uniforme. Questa connessione evidenzia come la MLE rappresenti un caso particolare dell’approccio bayesiano, fornendo un ponte concettuale tra i due paradigmi inferenziali.</p>
<p>La comprensione della MLE non solo facilita l’interpretazione dei risultati statistici, ma costituisce anche una base essenziale per l’apprendimento dei metodi bayesiani più avanzati, mostrando come il concetto di verosimiglianza unifichi diversi approcci all’inferenza statistica.</p>
</section></section><section id="calcolo-della-stima-di-massima-verosimiglianza-in-r" class="level2" data-number="17.4"><h2 data-number="17.4" class="anchored" data-anchor-id="calcolo-della-stima-di-massima-verosimiglianza-in-r">
<span class="header-section-number">17.4</span> Calcolo della Stima di Massima Verosimiglianza in R</h2>
<section id="metodo-1-valutazione-su-griglia" class="level3" data-number="17.4.1"><h3 data-number="17.4.1" class="anchored" data-anchor-id="metodo-1-valutazione-su-griglia">
<span class="header-section-number">17.4.1</span> Metodo 1: Valutazione su Griglia</h3>
<p>Il primo approccio consiste nel valutare sistematicamente la verosimiglianza per un’ampia gamma di valori del parametro θ:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Definizione dei parametri osservati</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">30</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fl">23</span></span>
<span><span class="va">theta</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, length.out <span class="op">=</span> <span class="fl">10000</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Calcolo della funzione di verosimiglianza</span></span>
<span><span class="va">likelihood</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="va">y</span>, size <span class="op">=</span> <span class="va">n</span>, prob <span class="op">=</span> <span class="va">theta</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Identificazione del massimo</span></span>
<span><span class="va">max_index</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/which.min.html">which.max</a></span><span class="op">(</span><span class="va">likelihood</span><span class="op">)</span></span>
<span><span class="va">optimal_theta</span> <span class="op">&lt;-</span> <span class="va">theta</span><span class="op">[</span><span class="va">max_index</span><span class="op">]</span></span>
<span></span>
<span><span class="co"># Visualizzazione del risultato</span></span>
<span><span class="va">optimal_theta</span></span>
<span><span class="co">#&gt; [1] 0.767</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Questo metodo offre una soluzione numerica precisa attraverso:</p>
<ul>
<li>la generazione di una griglia densa di valori possibili per <span class="math inline">\(\theta\)</span>,</li>
<li>il calcolo diretto della verosimiglianza per ogni punto della griglia,</li>
<li>l’identificazione del valore ottimale mediante ricerca del massimo.</li>
</ul></section><section id="metodo-2-ottimizzazione-numerica" class="level3" data-number="17.4.2"><h3 data-number="17.4.2" class="anchored" data-anchor-id="metodo-2-ottimizzazione-numerica">
<span class="header-section-number">17.4.2</span> Metodo 2: Ottimizzazione Numerica</h3>
<p>Un approccio più efficiente dal punto di vista computazionale utilizza algoritmi di ottimizzazione:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Definizione della funzione di log-verosimiglianza negativa</span></span>
<span><span class="va">neg_log_likelihood</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">theta</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="op">-</span> <span class="op">(</span><span class="va">y</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">theta</span><span class="op">)</span> <span class="op">+</span> <span class="op">(</span><span class="va">n</span> <span class="op">-</span> <span class="va">y</span><span class="op">)</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">theta</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Ottimizzazione numerica</span></span>
<span><span class="va">result</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/optim.html">optim</a></span><span class="op">(</span></span>
<span>  par <span class="op">=</span> <span class="fl">0.5</span>,              <span class="co"># Valore iniziale</span></span>
<span>  fn <span class="op">=</span> <span class="va">neg_log_likelihood</span>, <span class="co"># Funzione da minimizzare</span></span>
<span>  method <span class="op">=</span> <span class="st">"Brent"</span>,       <span class="co"># Algoritmo per ottimizzazione unidimensionale</span></span>
<span>  lower <span class="op">=</span> <span class="fl">1e-6</span>,           <span class="co"># Limite inferiore</span></span>
<span>  upper <span class="op">=</span> <span class="fl">1</span> <span class="op">-</span> <span class="fl">1e-6</span>        <span class="co"># Limite superiore</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">optimal_theta_numerical</span> <span class="op">&lt;-</span> <span class="va">result</span><span class="op">$</span><span class="va">par</span></span>
<span><span class="va">optimal_theta_numerical</span></span>
<span><span class="co">#&gt; [1] 0.767</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>L’utilizzo della log-verosimiglianza negativa è necessario poiché la funzione <code><a href="https://rdrr.io/r/stats/optim.html">optim()</a></code> è progettata per la minimizzazione. Questo approccio risulta particolarmente vantaggioso per modelli complessi dove una valutazione su griglia sarebbe computazionalmente costosa.</p>
</section><section id="confronto-dei-risultati" class="level3" data-number="17.4.3"><h3 data-number="17.4.3" class="anchored" data-anchor-id="confronto-dei-risultati">
<span class="header-section-number">17.4.3</span> Confronto dei risultati</h3>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Confronto tra i diversi metodi</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span></span>
<span>  <span class="st">"Griglia"</span> <span class="op">=</span> <span class="va">optimal_theta</span>, </span>
<span>  <span class="st">"Ottimizzazione"</span> <span class="op">=</span> <span class="va">optimal_theta_numerical</span>, </span>
<span>  <span class="st">"Analitica"</span> <span class="op">=</span> <span class="va">y</span> <span class="op">/</span> <span class="va">n</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt;        Griglia Ottimizzazione      Analitica </span></span>
<span><span class="co">#&gt;          0.767          0.767          0.767</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Tutti e tre i metodi convergono allo stesso risultato:</p>
<p><span class="math display">\[
\hat{\theta} = \frac{23}{30} \approx 0.767 .
\]</span></p>
<p>Questa coincidenza dimostra la robustezza del metodo di massima verosimiglianza e conferma che, nel caso della distribuzione binomiale, la stima ottimale corrisponde alla proporzione campionaria osservata.</p>
<p><strong>Osservazioni metodologiche:</strong></p>
<ul>
<li>Il metodo della griglia offre una visualizzazione completa della funzione di verosimiglianza.</li>
<li>L’ottimizzazione numerica è più efficiente per problemi multidimensionali.</li>
<li>La soluzione analitica fornisce un riferimento teorico esatto.</li>
<li>La scelta del metodo dipende dalle specifiche esigenze analitiche e computazionali.</li>
</ul>
<p>L’implementazione in R dimostra come concetti statistici avanzati possano essere efficacemente applicati attraverso strumenti computazionali, facilitando sia l’analisi che l’interpretazione dei risultati.</p>
</section></section><section id="verosimiglianza-congiunta" class="level2" data-number="17.5"><h2 data-number="17.5" class="anchored" data-anchor-id="verosimiglianza-congiunta">
<span class="header-section-number">17.5</span> Verosimiglianza congiunta</h2>
<p>Il concetto di verosimiglianza si estende naturalmente al caso di osservazioni multiple, dando origine alla verosimiglianza congiunta. Questo approccio consente di combinare informazioni provenienti da diverse fonti o esperimenti per ottenere stime parametriche più robuste.</p>
<section id="dalla-binomiale-alla-verosimiglianza-congiunta" class="level3" data-number="17.5.1"><h3 data-number="17.5.1" class="anchored" data-anchor-id="dalla-binomiale-alla-verosimiglianza-congiunta">
<span class="header-section-number">17.5.1</span> Dalla binomiale alla verosimiglianza congiunta</h3>
<p>Nel caso di <span class="math inline">\(n\)</span> lanci di moneta, la verosimiglianza basata sul numero totale di successi segue la distribuzione binomiale:</p>
<p><span class="math display">\[
\mathcal{L}(\theta) = \binom{n}{y} \theta^y (1 - \theta)^{n - y}.
\]</span></p>
<p>Tuttavia, possiamo concettualizzare il problema considerando ogni lancio come un’osservazione indipendente Bernoulli. Per una singola osservazione:</p>
<p><span class="math display">\[
\mathcal{L}(\theta \mid y_i) = \theta^{y_i} (1 - \theta)^{1 - y_i}.
\]</span></p>
<p>Per <span class="math inline">\(n\)</span> osservazioni indipendenti, la verosimiglianza congiunta diventa:</p>
<p><span class="math display">\[
\mathcal{L}(\theta \mid y_1, y_2, \dots, y_n) = \prod_{i=1}^{n} \theta^{y_i} (1 - \theta)^{1 - y_i} = \theta^y (1 - \theta)^{n - y}.
\]</span></p>
<p>dove <span class="math inline">\(y = \sum_{i=1}^{n} y_i\)</span>. Questo dimostra l’equivalenza tra l’approccio basato sulle osservazioni individuali e quello basato sulla statistica sufficiente binomiale.</p>
</section><section id="importanza-della-verosimiglianza-congiunta" class="level3" data-number="17.5.2"><h3 data-number="17.5.2" class="anchored" data-anchor-id="importanza-della-verosimiglianza-congiunta">
<span class="header-section-number">17.5.2</span> Importanza della verosimiglianza congiunta</h3>
<p>La verosimiglianza congiunta rappresenta uno strumento fondamentale per:</p>
<ul>
<li>Integrare informazioni da multiple osservazioni indipendenti.</li>
<li>Costruire modelli statistici complessi.</li>
<li>Effettuare stime parametriche basate sull’intero set di dati.</li>
<li>Generalizzare il concetto di verosimiglianza a contesti multivariati.</li>
</ul></section><section id="esempio-applicativo-gruppi-di-osservazioni-binomiali" class="level3" data-number="17.5.3"><h3 data-number="17.5.3" class="anchored" data-anchor-id="esempio-applicativo-gruppi-di-osservazioni-binomiali">
<span class="header-section-number">17.5.3</span> Esempio applicativo: gruppi di osservazioni binomiali</h3>
<p>Consideriamo quattro gruppi indipendenti di osservazioni binomiali:</p>
<ul>
<li>Gruppo 1: 23 successi su 30 prove.</li>
<li>Gruppo 2: 20 successi su 28 prove.</li>
<li>Gruppo 3: 29 successi su 40 prove.</li>
<li>Gruppo 4: 29 successi su 36 prove.</li>
</ul>
<p>Assumendo che tutti i gruppi condividano lo stesso parametro <span class="math inline">\(\theta\)</span>, la log-verosimiglianza congiunta è data da:</p>
<p><span class="math display">\[
\log \mathcal{L}(\theta) = \sum_{i=1}^{4} \left[ y_i \log(\theta) + (n_i - y_i) \log(1 - \theta) \right]
\]</span></p>
<p>Sviluppando l’espressione:</p>
<p><span class="math display">\[
\begin{aligned}
\log \mathcal{L}(\theta) = &amp;23\log(\theta) + 7\log(1 - \theta) + \\
&amp;20\log(\theta) + 8\log(1 - \theta) + \\
&amp;29\log(\theta) + 11\log(1 - \theta) + \\
&amp;29\log(\theta) + 7\log(1 - \theta)
\end{aligned}
\]</span></p>
<p>Questa formulazione permette di valutare la plausibilità del parametro <span class="math inline">\(\theta\)</span> considerando simultaneamente tutte le informazioni disponibili dai quattro gruppi sperimentali.</p>
</section><section id="implementazione-computazionale-1" class="level3" data-number="17.5.4"><h3 data-number="17.5.4" class="anchored" data-anchor-id="implementazione-computazionale-1">
<span class="header-section-number">17.5.4</span> Implementazione computazionale</h3>
<p>In R, la verosimiglianza congiunta può essere calcolata efficientemente:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Definizione dei parametri dei gruppi</span></span>
<span><span class="va">successi</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">23</span>, <span class="fl">20</span>, <span class="fl">29</span>, <span class="fl">29</span><span class="op">)</span></span>
<span><span class="va">prove</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">30</span>, <span class="fl">28</span>, <span class="fl">40</span>, <span class="fl">36</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Funzione di log-verosimiglianza congiunta</span></span>
<span><span class="va">log_verosimiglianza_congiunta</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">theta</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">successi</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">theta</span><span class="op">)</span> <span class="op">+</span> <span class="op">(</span><span class="va">prove</span> <span class="op">-</span> <span class="va">successi</span><span class="op">)</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">theta</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Calcolo per un valore specifico di theta</span></span>
<span><span class="fu">log_verosimiglianza_congiunta</span><span class="op">(</span><span class="fl">0.7</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] -75.8</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section></section><section id="la-verosimiglianza-marginale-nellinferenza-bayesiana" class="level2" data-number="17.6"><h2 data-number="17.6" class="anchored" data-anchor-id="la-verosimiglianza-marginale-nellinferenza-bayesiana">
<span class="header-section-number">17.6</span> La Verosimiglianza marginale nell’inferenza bayesiana</h2>
<p>La verosimiglianza marginale rappresenta un concetto fondamentale nell’inferenza bayesiana, permettendo di valutare la compatibilità complessiva di un modello con i dati osservati, considerando l’intera distribuzione dei parametri. A differenza della verosimiglianza classica che valuta la plausibilità dei dati per valori fissi dei parametri, la verosimiglianza marginal integra l’incertezza parametrica attraverso la distribuzione a priori.</p>
<section id="caso-di-parametri-discreti" class="level3" data-number="17.6.1"><h3 data-number="17.6.1" class="anchored" data-anchor-id="caso-di-parametri-discreti">
<span class="header-section-number">17.6.1</span> Caso di parametri discreti</h3>
<p>Supponiamo di osservare <span class="math inline">\(k = 7\)</span> successi su <span class="math inline">\(n = 10\)</span> tentativi, con il parametro <span class="math inline">\(\theta\)</span> che può assumere solo tre valori discreti:</p>
<p><span class="math display">\[
\theta \in \{0.1,\; 0.5,\; 0.9\}.
\]</span></p>
<ol type="1">
<li>
<p><strong>Assegnazione della distribuzione a priori</strong> sui valori di <span class="math inline">\(\theta\)</span>:</p>
<ul>
<li>
<p>Prior uniforme:</p>
<p><span class="math display">\[
p(\theta = 0.1) = p(\theta = 0.5) = p(\theta = 0.9) = \tfrac{1}{3}.
\]</span></p>
</li>
<li>
<p>Prior non uniforme:</p>
<p><span class="math display">\[
p(\theta = 0.1) = \tfrac{1}{4}, \quad
p(\theta = 0.5) = \tfrac{1}{2}, \quad
p(\theta = 0.9) = \tfrac{1}{4}.
\]</span></p>
</li>
</ul>
</li>
<li>
<p><strong>Calcolo della verosimiglianza</strong> per ogni valore di <span class="math inline">\(\theta\)</span>:</p>
<p><span class="math display">\[
p(k=7 \mid \theta) = \binom{10}{7}\,\theta^{7}(1-\theta)^{3}.
\]</span></p>
</li>
<li>
<p><strong>Marginalizzazione tramite somma pesata</strong>:</p>
<p><span class="math display">\[
p(k=7 \mid n=10) = \sum_{i=1}^{3} p(k=7 \mid \theta_i)\, p(\theta_i).
\]</span></p>
</li>
</ol></section><section id="caso-di-parametri-continui" class="level3" data-number="17.6.2"><h3 data-number="17.6.2" class="anchored" data-anchor-id="caso-di-parametri-continui">
<span class="header-section-number">17.6.2</span> Caso di parametri continui</h3>
<p>Nella maggior parte delle applicazioni, il parametro <span class="math inline">\(\theta\)</span> varia in modo continuo. Per <span class="math inline">\(\theta \in [0,1]\)</span>, la verosimiglianza marginale si calcola integrando:</p>
<p><span class="math display">\[
p(k=7 \mid n=10)
= \int_{0}^{1} \binom{10}{7}\,\theta^{7}(1-\theta)^{3}\, p(\theta)\, d\theta,
\]</span></p>
<p>dove <span class="math inline">\(p(\theta)\)</span> è la distribuzione a priori.</p>
<p>Ad esempio, con una prior <span class="math inline">\(\text{Beta}(2,2)\)</span>:</p>
<p><span class="math display">\[
p(\theta) = \frac{\theta(1-\theta)}{B(2,2)},
\]</span></p>
<p>si ottiene:</p>
<p><span class="math display">\[
p(k=7 \mid n=10)
= \int_{0}^{1} \binom{10}{7}\, \theta^{7}(1-\theta)^{3} \,\frac{\theta(1-\theta)}{B(2,2)} \, d\theta.
\]</span></p>
</section><section id="implementazione-computazionale-in-r" class="level3" data-number="17.6.3"><h3 data-number="17.6.3" class="anchored" data-anchor-id="implementazione-computazionale-in-r">
<span class="header-section-number">17.6.3</span> Implementazione computazionale in R</h3>
<section id="parametri-discreti" class="level4" data-number="17.6.3.1"><h4 data-number="17.6.3.1" class="anchored" data-anchor-id="parametri-discreti">
<span class="header-section-number">17.6.3.1</span> Parametri discreti</h4>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Valori discreti di θ e prior uniforme</span></span>
<span><span class="va">theta_vals</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.1</span>, <span class="fl">0.5</span>, <span class="fl">0.9</span><span class="op">)</span></span>
<span><span class="va">prior_probs</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">/</span><span class="fl">3</span>, <span class="fl">3</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Calcolo della verosimiglianza marginale</span></span>
<span><span class="va">likelihoods</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="fl">7</span>, size <span class="op">=</span> <span class="fl">10</span>, prob <span class="op">=</span> <span class="va">theta_vals</span><span class="op">)</span></span>
<span><span class="va">marginal_likelihood</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">likelihoods</span> <span class="op">*</span> <span class="va">prior_probs</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">marginal_likelihood</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 0.0582</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>In questo caso, il calcolo corrisponde alla formula</p>
<p><span class="math display">\[
p(k=7 \mid n=10) = \sum_{i=1}^3 p(k=7 \mid \theta_i)\, p(\theta_i).
\]</span></p>
</section><section id="parametri-continui" class="level4" data-number="17.6.3.2"><h4 data-number="17.6.3.2" class="anchored" data-anchor-id="parametri-continui">
<span class="header-section-number">17.6.3.2</span> Parametri continui</h4>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Integrazione numerica con prior Beta(2,2)</span></span>
<span><span class="va">integrand</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">theta</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="fl">7</span>, size <span class="op">=</span> <span class="fl">10</span>, prob <span class="op">=</span> <span class="va">theta</span><span class="op">)</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/Beta.html">dbeta</a></span><span class="op">(</span><span class="va">theta</span>, <span class="fl">2</span>, <span class="fl">2</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="va">marginal_likelihood</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/integrate.html">integrate</a></span><span class="op">(</span><span class="va">integrand</span>, <span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span><span class="op">$</span><span class="va">value</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">marginal_likelihood</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 0.112</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Qui la verosimiglianza marginale viene calcolata come</p>
<p><span class="math display">\[
p(k=7 \mid n=10) = \int_0^1 \binom{10}{7}\, \theta^7 (1-\theta)^3 \, p(\theta)\, d\theta,
\]</span></p>
<p>dove, con una prior <span class="math inline">\(\text{Beta}(2,2)\)</span>, vale</p>
<p><span class="math display">\[
p(\theta) = \frac{\theta(1-\theta)}{B(2,2)}.
\]</span></p>
</section></section><section id="interpretazione" class="level3" data-number="17.6.4"><h3 data-number="17.6.4" class="anchored" data-anchor-id="interpretazione">
<span class="header-section-number">17.6.4</span> Interpretazione</h3>
<p>La <em>verosimiglianza marginale</em> <span class="math inline">\(p(D)\)</span> quantifica la probabilità complessiva dei dati <span class="math inline">\(D\)</span> tenendo conto di tutte le possibili configurazioni parametriche:</p>
<ul>
<li>valori <em>più alti</em> indicano maggiore compatibilità tra modello e dati;<br>
</li>
<li>valori <em>più bassi</em> suggeriscono che i dati siano poco plausibili sotto quel modello;<br>
</li>
<li>il <em>confronto tra modelli</em> si basa sul <em>fattore di Bayes</em>:<br><span class="math display">\[
BF_{12} = \frac{p(D \mid M_1)}{p(D \mid M_2)}.
\]</span>
</li>
</ul></section><section id="ruolo-nellinferenza-bayesiana" class="level3" data-number="17.6.5"><h3 data-number="17.6.5" class="anchored" data-anchor-id="ruolo-nellinferenza-bayesiana">
<span class="header-section-number">17.6.5</span> Ruolo nell’inferenza bayesiana</h3>
<p>Nella formula di Bayes</p>
<p><span class="math display">\[
p(\theta \mid D) = \frac{p(D \mid \theta)\,p(\theta)}{p(D)},
\]</span></p>
<p>la quantità <span class="math inline">\(p(D)\)</span>, ossia la verosimiglianza marginale:</p>
<ul>
<li>funge da <em>fattore di normalizzazione</em> per ottenere la distribuzione a posteriori;<br>
</li>
<li>costituisce la <em>base del confronto tra modelli</em>;<br>
</li>
<li>rappresenta una <em>misura complessiva dell’evidenza</em> fornita dai dati.</li>
</ul></section><section id="considerazioni-pratiche" class="level3" data-number="17.6.6"><h3 data-number="17.6.6" class="anchored" data-anchor-id="considerazioni-pratiche">
<span class="header-section-number">17.6.6</span> Considerazioni pratiche</h3>
<p>Il calcolo di <span class="math inline">\(p(D)\)</span> presenta spesso difficoltà:</p>
<ul>
<li>l’integrazione diventa rapidamente <em>multidimensionale</em> per modelli complessi;<br>
</li>
<li>i risultati possono essere <em>sensibili alla scelta della prior</em>;<br>
</li>
<li>sono necessari <em>metodi approssimati</em> (MCMC, bridge sampling, ecc.) per modelli realistici.</li>
</ul>
<p>Nonostante queste complessità, la verosimiglianza marginale resta un concetto fondamentale:<br>
- permette di valutare la bontà di adattamento dei modelli,<br>
- guida la <em>selezione bayesiana dei modelli</em>,<br>
- e garantisce un’inferenza che integra in modo coerente l’incertezza sui parametri.</p>
</section></section><section id="verosimiglianza-gaussiana" class="level2" data-number="17.7"><h2 data-number="17.7" class="anchored" data-anchor-id="verosimiglianza-gaussiana">
<span class="header-section-number">17.7</span> Verosimiglianza gaussiana</h2>
<p>La distribuzione gaussiana (o normale) è uno degli strumenti fondamentali della statistica. La sua importanza deriva dalla capacità di descrivere in modo efficace molte variabili continue di interesse psicologico e scientifico, come il <em>quoziente intellettivo (QI)</em>, i <em>tempi di reazione</em> o diverse <em>misurazioni psicofisiologiche</em>.</p>
<section id="caso-di-una-singola-osservazione" class="level3" data-number="17.7.1"><h3 data-number="17.7.1" class="anchored" data-anchor-id="caso-di-una-singola-osservazione">
<span class="header-section-number">17.7.1</span> Caso di una singola osservazione</h3>
<p>Consideriamo la misurazione del QI di un individuo. Supponiamo che il QI segua una distribuzione normale con media incognita <span class="math inline">\(\mu\)</span> e deviazione standard nota <span class="math inline">\(\sigma = 15\)</span>.</p>
<p>La funzione di densità di probabilità (pdf) è:</p>
<p><span class="math display">\[
f(y \mid \mu, \sigma) \;=\; \frac{1}{\sigma \sqrt{2\pi}}
\exp\!\left(-\frac{(y-\mu)^2}{2\sigma^2}\right),
\]</span></p>
<p>dove <span class="math inline">\(y\)</span> rappresenta il valore osservato (nel nostro caso <span class="math inline">\(y=114\)</span>), <span class="math inline">\(\mu\)</span> è il parametro da stimare e <span class="math inline">\(\sigma\)</span> è noto.</p>
<p>La <em>funzione di verosimiglianza</em> per una singola osservazione è data dalla stessa espressione, considerata ora come funzione di <span class="math inline">\(\mu\)</span>, fissato <span class="math inline">\(y\)</span>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Osservazione e parametro noto</span></span>
<span><span class="va">y_obs</span> <span class="op">&lt;-</span> <span class="fl">114</span></span>
<span><span class="va">sigma</span> <span class="op">&lt;-</span> <span class="fl">15</span></span>
<span><span class="va">mu_values</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">70</span>, <span class="fl">160</span>, length.out <span class="op">=</span> <span class="fl">1000</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Calcolo della verosimiglianza</span></span>
<span><span class="va">likelihood</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">y_obs</span>, mean <span class="op">=</span> <span class="va">mu_values</span>, sd <span class="op">=</span> <span class="va">sigma</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Visualizzazione</span></span>
<span><span class="fu">ggplot</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>mu <span class="op">=</span> <span class="va">mu_values</span>, likelihood <span class="op">=</span> <span class="va">likelihood</span><span class="op">)</span>, </span>
<span>       <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">mu</span>, y <span class="op">=</span> <span class="va">likelihood</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_line</span><span class="op">(</span>linewidth <span class="op">=</span> <span class="fl">1.2</span>, color <span class="op">=</span> <span class="st">"steelblue"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span></span>
<span>    x <span class="op">=</span> <span class="st">"Media μ"</span>,</span>
<span>    y <span class="op">=</span> <span class="st">"Verosimiglianza"</span></span>
<span>  <span class="op">)</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="16_likelihood_files/figure-html/unnamed-chunk-12-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:85.0%"></p>
</figure>
</div>
</div>
</div>
<p>Il valore di <span class="math inline">\(\mu\)</span> che massimizza la verosimiglianza coincide con l’osservazione stessa:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">mu_optimal</span> <span class="op">&lt;-</span> <span class="va">mu_values</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/which.min.html">which.max</a></span><span class="op">(</span><span class="va">likelihood</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Stima di massima verosimiglianza per μ:"</span>, <span class="va">mu_optimal</span><span class="op">)</span></span>
<span><span class="co">#&gt; Stima di massima verosimiglianza per μ: 114</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section><section id="ottimizzazione-tramite-log-verosimiglianza" class="level3" data-number="17.7.2"><h3 data-number="17.7.2" class="anchored" data-anchor-id="ottimizzazione-tramite-log-verosimiglianza">
<span class="header-section-number">17.7.2</span> Ottimizzazione tramite log-verosimiglianza</h3>
<p>L’uso della <em>log-verosimiglianza</em> è preferibile per ragioni numeriche:</p>
<ul>
<li>trasforma prodotti di probabilità in somme,</li>
<li>evita problemi di <em>underflow</em> con valori molto piccoli,</li>
<li>semplifica il calcolo delle derivate.</li>
</ul>
<p>Per una singola osservazione da una normale:</p>
<p><span class="math display">\[
\ell(\mu \mid y, \sigma) \;=\; -\tfrac{1}{2}\log(2\pi)\;-\;\log(\sigma)\;-\;\frac{(y-\mu)^2}{2\sigma^2}.
\]</span></p>
<section id="implementazione-in-r" class="level4" data-number="17.7.2.1"><h4 data-number="17.7.2.1" class="anchored" data-anchor-id="implementazione-in-r">
<span class="header-section-number">17.7.2.1</span> Implementazione in R</h4>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Definizione della funzione di log-verosimiglianza negativa</span></span>
<span><span class="va">negative_log_likelihood</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">mu</span>, <span class="va">y</span>, <span class="va">sigma</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">y</span>, mean <span class="op">=</span> <span class="va">mu</span>, sd <span class="op">=</span> <span class="va">sigma</span>, log <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Ottimizzazione numerica</span></span>
<span><span class="va">result</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/optim.html">optim</a></span><span class="op">(</span></span>
<span>  par <span class="op">=</span> <span class="fl">100</span>,                 <span class="co"># Valore iniziale per μ</span></span>
<span>  fn <span class="op">=</span> <span class="va">negative_log_likelihood</span>,</span>
<span>  y <span class="op">=</span> <span class="va">y_obs</span>,</span>
<span>  sigma <span class="op">=</span> <span class="va">sigma</span>,</span>
<span>  method <span class="op">=</span> <span class="st">"L-BFGS-B"</span>,</span>
<span>  lower <span class="op">=</span> <span class="fl">70</span>,</span>
<span>  upper <span class="op">=</span> <span class="fl">160</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Estrazione della stima</span></span>
<span><span class="va">mu_mle</span> <span class="op">&lt;-</span> <span class="va">result</span><span class="op">$</span><span class="va">par</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Stima di massima verosimiglianza per μ:"</span>, <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="va">mu_mle</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; Stima di massima verosimiglianza per μ: 114</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section></section><section id="vantaggi-della-log-verosimiglianza" class="level3" data-number="17.7.3"><h3 data-number="17.7.3" class="anchored" data-anchor-id="vantaggi-della-log-verosimiglianza">
<span class="header-section-number">17.7.3</span> Vantaggi della log-verosimiglianza</h3>
<ol type="1">
<li>
<em>Stabilità numerica</em>: riduce i rischi di underflow.</li>
<li>
<em>Efficienza computazionale</em>: la somma di log-probabilità è più stabile del prodotto di probabilità.</li>
<li>
<em>Proprietà additive</em>: la log-verosimiglianza totale è la somma dei contributi dei singoli dati.</li>
<li>
<em>Derivazioni semplificate</em>: le derivate della log-verosimiglianza hanno forma più semplice.</li>
</ol></section><section id="interpretazione-del-risultato" class="level3" data-number="17.7.4"><h3 data-number="17.7.4" class="anchored" data-anchor-id="interpretazione-del-risultato">
<span class="header-section-number">17.7.4</span> Interpretazione del risultato</h3>
<p>La stima di massima verosimiglianza (MLE) per <span class="math inline">\(\mu\)</span> risulta:</p>
<p><span class="math display">\[
\hat{\mu} = 114,
\]</span></p>
<p>ossia il valore osservato. Questo era atteso: per una singola osservazione da una normale con deviazione standard nota, la stima MLE della media coincide esattamente con il dato osservato.</p>
</section></section><section id="campione-di-osservazioni-indipendenti" class="level2" data-number="17.8"><h2 data-number="17.8" class="anchored" data-anchor-id="campione-di-osservazioni-indipendenti">
<span class="header-section-number">17.8</span> Campione di osservazioni indipendenti</h2>
<p>Supponiamo di avere i punteggi <em>BDI-II</em> raccolti su un campione di <span class="math inline">\(n=30\)</span> partecipanti. Assumiamo che ciascun punteggio sia un’osservazione indipendente da una distribuzione normale con media incognita <span class="math inline">\(\mu\)</span> e deviazione standard nota <span class="math inline">\(\sigma = 6.5\)</span>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Dati osservati (punteggi BDI-II)</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span></span>
<span>  <span class="fl">26</span>, <span class="fl">35</span>, <span class="fl">30</span>, <span class="fl">25</span>, <span class="fl">44</span>, <span class="fl">30</span>, <span class="fl">33</span>, <span class="fl">43</span>, <span class="fl">22</span>, <span class="fl">43</span>, <span class="fl">24</span>, <span class="fl">19</span>, <span class="fl">39</span>, <span class="fl">31</span>, <span class="fl">25</span>, </span>
<span>  <span class="fl">28</span>, <span class="fl">35</span>, <span class="fl">30</span>, <span class="fl">26</span>, <span class="fl">31</span>, <span class="fl">41</span>, <span class="fl">36</span>, <span class="fl">26</span>, <span class="fl">35</span>, <span class="fl">33</span>, <span class="fl">28</span>, <span class="fl">27</span>, <span class="fl">34</span>, <span class="fl">27</span>, <span class="fl">22</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">sigma</span> <span class="op">&lt;-</span> <span class="fl">6.5</span>  <span class="co"># Deviazione standard nota</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<hr>
<section id="log-verosimiglianza" class="level3" data-number="17.8.1"><h3 data-number="17.8.1" class="anchored" data-anchor-id="log-verosimiglianza">
<span class="header-section-number">17.8.1</span> Log-verosimiglianza</h3>
<p>Per un campione di <span class="math inline">\(n\)</span> osservazioni indipendenti, la log-verosimiglianza del parametro <span class="math inline">\(\mu\)</span> è</p>
<p><span class="math display">\[
\ell(\mu \mid y, \sigma) \;=\; \sum_{i=1}^n \log f(y_i \mid \mu, \sigma),
\]</span></p>
<p>dove <span class="math inline">\(f(y_i \mid \mu, \sigma)\)</span> è la densità normale.</p>
<p>In R:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">log_likelihood</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">mu</span>, <span class="va">y</span>, <span class="va">sigma</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">y</span>, mean <span class="op">=</span> <span class="va">mu</span>, sd <span class="op">=</span> <span class="va">sigma</span>, log <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Calcoliamo <span class="math inline">\(\ell(\mu)\)</span> per valori di <span class="math inline">\(\mu\)</span> attorno alla media campionaria:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">mu_range</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span> <span class="op">-</span> <span class="fl">2</span> <span class="op">*</span> <span class="va">sigma</span>, <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span> <span class="op">+</span> <span class="fl">2</span> <span class="op">*</span> <span class="va">sigma</span>, length.out <span class="op">=</span> <span class="fl">1000</span><span class="op">)</span></span>
<span><span class="va">log_lik_values</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">sapply</a></span><span class="op">(</span><span class="va">mu_range</span>, <span class="kw">function</span><span class="op">(</span><span class="va">mu_val</span><span class="op">)</span> <span class="fu">log_likelihood</span><span class="op">(</span><span class="va">mu_val</span>, <span class="va">y</span>, <span class="va">sigma</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<hr></section><section id="visualizzazione" class="level3" data-number="17.8.2"><h3 data-number="17.8.2" class="anchored" data-anchor-id="visualizzazione">
<span class="header-section-number">17.8.2</span> Visualizzazione</h3>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org">ggplot2</a></span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>mu <span class="op">=</span> <span class="va">mu_range</span>, log_likelihood <span class="op">=</span> <span class="va">log_lik_values</span><span class="op">)</span>,</span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">mu</span>, y <span class="op">=</span> <span class="va">log_likelihood</span><span class="op">)</span></span>
<span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span>linewidth <span class="op">=</span> <span class="fl">1.2</span>, color <span class="op">=</span> <span class="st">"steelblue"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html">geom_vline</a></span><span class="op">(</span>xintercept <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span>, linetype <span class="op">=</span> <span class="st">"dashed"</span>, color <span class="op">=</span> <span class="st">"red"</span>, linewidth <span class="op">=</span> <span class="fl">1</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span></span>
<span>    x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="va">mu</span><span class="op">)</span>,</span>
<span>    y <span class="op">=</span> <span class="st">"Log-verosimiglianza"</span></span>
<span>  <span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/annotate.html">annotate</a></span><span class="op">(</span><span class="st">"text"</span>, x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span> <span class="op">+</span> <span class="fl">2</span>, y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">log_lik_values</span><span class="op">)</span> <span class="op">-</span> <span class="fl">5</span>,</span>
<span>           label <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span><span class="op">(</span><span class="st">"Media campionaria = "</span>, <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span>,</span>
<span>           color <span class="op">=</span> <span class="st">"red"</span>, hjust <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="16_likelihood_files/figure-html/unnamed-chunk-18-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:85.0%"></p>
</figure>
</div>
</div>
</div>
</section><section id="interpretazione-1" class="level3" data-number="17.8.3"><h3 data-number="17.8.3" class="anchored" data-anchor-id="interpretazione-1">
<span class="header-section-number">17.8.3</span> Interpretazione</h3>
<p>La curva mostra come varia la log-verosimiglianza al variare di <span class="math inline">\(\mu\)</span>:</p>
<ul>
<li>il massimo si ottiene <em>in corrispondenza della media campionaria</em>, come previsto;</li>
<li>la forma è <em>concava e parabolica</em>, tipica del modello normale;</li>
<li>la <em>larghezza della curva</em> riflette l’incertezza della stima.</li>
</ul>
<p>In altre parole, lo stimatore di massima verosimiglianza (MLE) di <span class="math inline">\(\mu\)</span> è la media campionaria:</p>
<p><span class="math display">\[
\hat{\mu}_{\text{MLE}} = \bar{y}.
\]</span></p>
<hr></section><section id="ottimizzazione-numerica" class="level3" data-number="17.8.4"><h3 data-number="17.8.4" class="anchored" data-anchor-id="ottimizzazione-numerica">
<span class="header-section-number">17.8.4</span> Ottimizzazione numerica</h3>
<p>Possiamo verificare la stima tramite algoritmi di ottimizzazione:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">negative_log_likelihood</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">mu</span>, <span class="va">y</span>, <span class="va">sigma</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">y</span>, mean <span class="op">=</span> <span class="va">mu</span>, sd <span class="op">=</span> <span class="va">sigma</span>, log <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="va">result</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/optim.html">optim</a></span><span class="op">(</span></span>
<span>  par <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span>,</span>
<span>  fn <span class="op">=</span> <span class="va">negative_log_likelihood</span>,</span>
<span>  y <span class="op">=</span> <span class="va">y</span>,</span>
<span>  sigma <span class="op">=</span> <span class="va">sigma</span>,</span>
<span>  method <span class="op">=</span> <span class="st">"L-BFGS-B"</span>,</span>
<span>  lower <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">min</a></span><span class="op">(</span><span class="va">mu_range</span><span class="op">)</span>,</span>
<span>  upper <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">mu_range</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">mu_optimal</span> <span class="op">&lt;-</span> <span class="va">result</span><span class="op">$</span><span class="va">par</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Stima numerica di massima verosimiglianza per μ:"</span>, <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="va">mu_optimal</span>, <span class="fl">4</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; Stima numerica di massima verosimiglianza per μ: 30.9</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Confronto con la media campionaria:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">sample_mean</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span></span>
<span>  Metodo <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Ottimizzazione numerica"</span>, <span class="st">"Media campionaria"</span><span class="op">)</span>,</span>
<span>  Valore <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">mu_optimal</span>, <span class="va">sample_mean</span><span class="op">)</span>,</span>
<span>  Differenza <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="cn">NA</span>, <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">abs</a></span><span class="op">(</span><span class="va">mu_optimal</span> <span class="op">-</span> <span class="va">sample_mean</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt;                    Metodo Valore Differenza</span></span>
<span><span class="co">#&gt; 1 Ottimizzazione numerica   30.9         NA</span></span>
<span><span class="co">#&gt; 2       Media campionaria   30.9    1.1e-11</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>In conclusione, la stima ottenuta con l’ottimizzazione coincide perfettamente con la media campionaria. Questo conferma il risultato teorico: <em>per un campione indipendente da una normale con varianza nota, lo stimatore MLE della media è la media campionaria</em>.</p>
</section></section><section id="il-rapporto-di-verosimiglianze" class="level2" data-number="17.9"><h2 data-number="17.9" class="anchored" data-anchor-id="il-rapporto-di-verosimiglianze">
<span class="header-section-number">17.9</span> Il rapporto di verosimiglianze</h2>
<p>In statistica capita spesso di dover <em>confrontare modelli alternativi</em> che cercano di spiegare gli stessi dati osservati. Ad esempio, nella stima della media di una variabile psicologica (punteggi ai test, tempi di reazione, ecc.), potremmo avere due ipotesi contrastanti:</p>
<ul>
<li>
<strong>Modello nullo (<span class="math inline">\(H_0\)</span>)</strong>: la media assume un valore fissato <span class="math inline">\(\mu_1\)</span> (tipicamente un valore di riferimento o assenza di effetto);</li>
<li>
<strong>Modello alternativo (<span class="math inline">\(H_1\)</span>)</strong>: la media assume un valore diverso <span class="math inline">\(\mu_2\)</span> (indicativo di un effetto o cambiamento).</li>
</ul>
<p>Il <em>rapporto di verosimiglianze (Likelihood Ratio, LR)</em> fornisce una misura quantitativa dell’evidenza relativa a favore di un modello rispetto all’altro, basandosi direttamente sui dati.</p>
<section id="definizione-formale" class="level3" data-number="17.9.1"><h3 data-number="17.9.1" class="anchored" data-anchor-id="definizione-formale">
<span class="header-section-number">17.9.1</span> Definizione formale</h3>
<p>Il rapporto di verosimiglianze è definito come</p>
<p><span class="math display">\[
\lambda \;=\; \frac{L(\mu_2 \mid \text{dati})}{L(\mu_1 \mid \text{dati})},
\]</span></p>
<p>dove:</p>
<ul>
<li>
<span class="math inline">\(L(\mu_2 \mid \text{dati})\)</span> è la verosimiglianza sotto l’ipotesi alternativa,</li>
<li>
<span class="math inline">\(L(\mu_1 \mid \text{dati})\)</span> è la verosimiglianza sotto l’ipotesi nulla.</li>
</ul></section><section id="interpretazione-2" class="level3" data-number="17.9.2"><h3 data-number="17.9.2" class="anchored" data-anchor-id="interpretazione-2">
<span class="header-section-number">17.9.2</span> Interpretazione</h3>
<ul>
<li>
<span class="math inline">\(\lambda &gt; 1\)</span>: i dati favoriscono il modello alternativo;</li>
<li>
<span class="math inline">\(\lambda &lt; 1\)</span>: i dati favoriscono il modello nullo;</li>
<li>
<span class="math inline">\(\lambda \approx 1\)</span>: i dati non discriminano tra i modelli.</li>
</ul>
<p>La distanza dall’unità indica <em>quanto più probabili</em> sono i dati sotto un modello rispetto all’altro.</p>
</section><section id="esempio-lancio-di-una-moneta" class="level3" data-number="17.9.3"><h3 data-number="17.9.3" class="anchored" data-anchor-id="esempio-lancio-di-una-moneta">
<span class="header-section-number">17.9.3</span> Esempio: lancio di una moneta</h3>
<p>Supponiamo di osservare <span class="math inline">\(x = 7\)</span> successi su <span class="math inline">\(n = 10\)</span> lanci. Confrontiamo due modelli:</p>
<ul>
<li>
<span class="math inline">\(H_0\)</span>: moneta equa (<span class="math inline">\(\theta = 0.5\)</span>)</li>
<li>
<span class="math inline">\(H_1\)</span>: moneta sbilanciata verso il successo (<span class="math inline">\(\theta = 0.7\)</span>)</li>
</ul>
<section id="calcolo-analitico" class="level4" data-number="17.9.3.1"><h4 data-number="17.9.3.1" class="anchored" data-anchor-id="calcolo-analitico">
<span class="header-section-number">17.9.3.1</span> Calcolo analitico</h4>
<p>La verosimiglianza binomiale è:</p>
<p><span class="math display">\[
L(\theta \mid x, n) \;=\; \binom{n}{x}\,\theta^x(1-\theta)^{n-x}.
\]</span></p>
<p>Sostituendo i valori:</p>
<ul>
<li><span class="math inline">\(L(0.5) = 120 \cdot (0.5)^{10} \approx 0.117\)</span></li>
<li><span class="math inline">\(L(0.7) = 120 \cdot (0.7)^7 (0.3)^3 \approx 0.267\)</span></li>
</ul>
<p>Quindi:</p>
<p><span class="math display">\[
\lambda = \frac{0.267}{0.117} \;\approx\; 2.28.
\]</span></p>
</section><section id="implementazione-in-r-1" class="level4" data-number="17.9.3.2"><h4 data-number="17.9.3.2" class="anchored" data-anchor-id="implementazione-in-r-1">
<span class="header-section-number">17.9.3.2</span> Implementazione in R</h4>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Parametri osservati</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">10</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fl">7</span></span>
<span></span>
<span><span class="co"># Verosimiglianze</span></span>
<span><span class="va">L_null</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">n</span>, <span class="fl">0.5</span><span class="op">)</span></span>
<span><span class="va">L_alt</span>  <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">n</span>, <span class="fl">0.7</span><span class="op">)</span></span>
<span><span class="va">lambda</span> <span class="op">&lt;-</span> <span class="va">L_alt</span> <span class="op">/</span> <span class="va">L_null</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"L(H0, θ=0.5):"</span>, <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="va">L_null</span>, <span class="fl">3</span><span class="op">)</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; L(H0, θ=0.5): 0.117</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"L(H1, θ=0.7):"</span>, <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="va">L_alt</span>, <span class="fl">3</span><span class="op">)</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; L(H1, θ=0.7): 0.267</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Rapporto di verosimiglianze λ:"</span>, <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="va">lambda</span>, <span class="fl">2</span><span class="op">)</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Rapporto di verosimiglianze λ: 2.28</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section><section id="visualizzazione-grafica" class="level4" data-number="17.9.3.3"><h4 data-number="17.9.3.3" class="anchored" data-anchor-id="visualizzazione-grafica">
<span class="header-section-number">17.9.3.3</span> Visualizzazione grafica</h4>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">theta_seq</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, length.out <span class="op">=</span> <span class="fl">1000</span><span class="op">)</span></span>
<span><span class="va">likelihood_vals</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">n</span>, <span class="va">theta_seq</span><span class="op">)</span></span>
<span></span>
<span><span class="va">df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>theta <span class="op">=</span> <span class="va">theta_seq</span>, likelihood <span class="op">=</span> <span class="va">likelihood_vals</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">df</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">theta</span>, y <span class="op">=</span> <span class="va">likelihood</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span>linewidth <span class="op">=</span> <span class="fl">1.2</span>, color <span class="op">=</span> <span class="st">"steelblue"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html">geom_vline</a></span><span class="op">(</span>xintercept <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.5</span>, <span class="fl">0.7</span><span class="op">)</span>, linetype <span class="op">=</span> <span class="st">"dashed"</span>,</span>
<span>             color <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"red"</span>, <span class="st">"darkgreen"</span><span class="op">)</span>, linewidth <span class="op">=</span> <span class="fl">1</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fl">0.5</span>, y <span class="op">=</span> <span class="va">L_null</span><span class="op">)</span>, color <span class="op">=</span> <span class="st">"red"</span>, size <span class="op">=</span> <span class="fl">3</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fl">0.7</span>, y <span class="op">=</span> <span class="va">L_alt</span><span class="op">)</span>, color <span class="op">=</span> <span class="st">"darkgreen"</span>, size <span class="op">=</span> <span class="fl">3</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span></span>
<span>    x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="va">theta</span><span class="op">)</span>,</span>
<span>    y <span class="op">=</span> <span class="st">"Verosimiglianza"</span></span>
<span>  <span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/annotate.html">annotate</a></span><span class="op">(</span><span class="st">"text"</span>, x <span class="op">=</span> <span class="fl">0.5</span>, y <span class="op">=</span> <span class="va">L_null</span> <span class="op">+</span> <span class="fl">0.01</span>, label <span class="op">=</span> <span class="st">"H₀: θ = 0.5"</span>,</span>
<span>           color <span class="op">=</span> <span class="st">"red"</span>, hjust <span class="op">=</span> <span class="op">-</span><span class="fl">0.1</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/annotate.html">annotate</a></span><span class="op">(</span><span class="st">"text"</span>, x <span class="op">=</span> <span class="fl">0.7</span>, y <span class="op">=</span> <span class="va">L_alt</span> <span class="op">+</span> <span class="fl">0.01</span>, label <span class="op">=</span> <span class="st">"H₁: θ = 0.7"</span>,</span>
<span>           color <span class="op">=</span> <span class="st">"darkgreen"</span>, hjust <span class="op">=</span> <span class="op">-</span><span class="fl">0.1</span><span class="op">)</span> </span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="16_likelihood_files/figure-html/unnamed-chunk-22-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:85.0%"></p>
</figure>
</div>
</div>
</div>
</section></section><section id="interpretazione-dei-risultati-1" class="level3" data-number="17.9.4"><h3 data-number="17.9.4" class="anchored" data-anchor-id="interpretazione-dei-risultati-1">
<span class="header-section-number">17.9.4</span> Interpretazione dei risultati</h3>
<p>Il valore <span class="math inline">\(\lambda \approx 2.28\)</span> indica che i dati sono circa <em>2.3 volte più probabili sotto l’ipotesi alternativa</em> rispetto all’ipotesi nulla. Si tratta di un’evidenza <em>moderata ma non decisiva</em> a favore dell’ipotesi che la moneta sia predisposta verso il successo.</p>
</section><section id="considerazioni-metodologiche" class="level3" data-number="17.9.5"><h3 data-number="17.9.5" class="anchored" data-anchor-id="considerazioni-metodologiche">
<span class="header-section-number">17.9.5</span> Considerazioni metodologiche</h3>
<ol type="1">
<li>
<strong>Evidenza relativa</strong>: il rapporto di verosimiglianze non misura la bontà assoluta del modello, ma solo la preferenza relativa.</li>
<li>
<strong>Scala di interpretazione</strong>: valori tra 1 e 3 suggeriscono un’evidenza debole-moderata, mentre valori più grandi indicano supporto crescente.</li>
<li>
<strong>Generalità</strong>: la logica del LR si applica a qualsiasi modello parametrico.</li>
<li>
<strong>Connessione bayesiana</strong>: con prior poco informative, <span class="math inline">\(\lambda\)</span> si avvicina al <em>fattore di Bayes</em>, strumento principe della selezione di modelli in ottica bayesiana.</li>
</ol></section></section><section id="rapporti-di-verosimiglianza-aggiustati-e-criterio-di-akaike" class="level2" data-number="17.10"><h2 data-number="17.10" class="anchored" data-anchor-id="rapporti-di-verosimiglianza-aggiustati-e-criterio-di-akaike">
<span class="header-section-number">17.10</span> Rapporti di verosimiglianza aggiustati e criterio di Akaike</h2>
<p>Quando si confrontano modelli statistici, occorre tenere presente che i modelli più complessi, dotati di un numero maggiore di parametri, tendono <em>naturalmente</em> a produrre un miglior adattamento ai dati osservati. Questo vantaggio, tuttavia, può dipendere solo dalla maggiore flessibilità del modello, senza riflettere una reale capacità esplicativa. Il fenomeno, noto come <em>sovradattamento</em> (<em>overfitting</em>), richiede quindi criteri che penalizzino opportunamente la complessità.</p>
<section id="il-ruolo-dellaic" class="level3" data-number="17.10.1"><h3 data-number="17.10.1" class="anchored" data-anchor-id="il-ruolo-dellaic">
<span class="header-section-number">17.10.1</span> Il ruolo dell’AIC</h3>
<p>Il <em>Criterio di Informazione di Akaike (AIC)</em> rappresenta una soluzione semplice ed efficace. La sua formulazione è:</p>
<p><span class="math display">\[
\text{AIC} = 2k - 2 \log(L),
\]</span> dove:</p>
<ul>
<li>
<span class="math inline">\(k\)</span> è il numero di parametri del modello,</li>
<li>
<span class="math inline">\(L\)</span> è la massima verosimiglianza del modello.</li>
</ul>
<p>In questo modo l’AIC combina due aspetti:</p>
<ul>
<li>la bontà di adattamento, catturata da <span class="math inline">\(-2 \log(L)\)</span>;</li>
<li>la parsimonia, garantita dal termine di penalizzazione <span class="math inline">\(2k\)</span>.</li>
</ul></section><section id="esempio-memoria-visiva-ed-emozione" class="level3" data-number="17.10.2"><h3 data-number="17.10.2" class="anchored" data-anchor-id="esempio-memoria-visiva-ed-emozione">
<span class="header-section-number">17.10.2</span> Esempio: memoria visiva ed emozione</h3>
<p>Supponiamo di voler valutare l’effetto del contenuto emotivo delle immagini sulla memoria visiva. In un esperimento, 30 partecipanti per condizione hanno ottenuto:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">successi_neutro</span> <span class="op">&lt;-</span> <span class="fl">14</span></span>
<span><span class="va">successi_emozione</span> <span class="op">&lt;-</span> <span class="fl">22</span></span>
<span><span class="va">prove</span> <span class="op">&lt;-</span> <span class="fl">30</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="modello-nullo-h_0-probabilità-comune" class="level4" data-number="17.10.2.1"><h4 data-number="17.10.2.1" class="anchored" data-anchor-id="modello-nullo-h_0-probabilità-comune">
<span class="header-section-number">17.10.2.1</span> Modello nullo (<span class="math inline">\(H_0\)</span>): probabilità comune</h4>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Probabilità congiunta stimata</span></span>
<span><span class="va">p_null</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="va">successi_neutro</span> <span class="op">+</span> <span class="va">successi_emozione</span><span class="op">)</span> <span class="op">/</span> <span class="op">(</span><span class="fl">2</span> <span class="op">*</span> <span class="va">prove</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Log-verosimiglianza</span></span>
<span><span class="va">ll_null</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="va">successi_neutro</span>, <span class="va">prove</span>, <span class="va">p_null</span>, log <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">+</span></span>
<span>           <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="va">successi_emozione</span>, <span class="va">prove</span>, <span class="va">p_null</span>, log <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section><section id="modello-alternativo-h_1-probabilità-distinte" class="level4" data-number="17.10.2.2"><h4 data-number="17.10.2.2" class="anchored" data-anchor-id="modello-alternativo-h_1-probabilità-distinte">
<span class="header-section-number">17.10.2.2</span> Modello alternativo (<span class="math inline">\(H_1\)</span>): probabilità distinte</h4>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Probabilità stimate separatamente</span></span>
<span><span class="va">p_neutro</span> <span class="op">&lt;-</span> <span class="va">successi_neutro</span> <span class="op">/</span> <span class="va">prove</span></span>
<span><span class="va">p_emozione</span> <span class="op">&lt;-</span> <span class="va">successi_emozione</span> <span class="op">/</span> <span class="va">prove</span></span>
<span></span>
<span><span class="co"># Log-verosimiglianza</span></span>
<span><span class="va">ll_alt</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="va">successi_neutro</span>, <span class="va">prove</span>, <span class="va">p_neutro</span>, log <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">+</span></span>
<span>          <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="va">successi_emozione</span>, <span class="va">prove</span>, <span class="va">p_emozione</span>, log <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section><section id="confronto-tramite-aic" class="level4" data-number="17.10.2.3"><h4 data-number="17.10.2.3" class="anchored" data-anchor-id="confronto-tramite-aic">
<span class="header-section-number">17.10.2.3</span> Confronto tramite AIC</h4>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">AIC_null</span> <span class="op">&lt;-</span> <span class="fl">2</span> <span class="op">*</span> <span class="fl">1</span> <span class="op">-</span> <span class="fl">2</span> <span class="op">*</span> <span class="va">ll_null</span>  <span class="co"># Modello con 1 parametro</span></span>
<span><span class="va">AIC_alt</span>  <span class="op">&lt;-</span> <span class="fl">2</span> <span class="op">*</span> <span class="fl">2</span> <span class="op">-</span> <span class="fl">2</span> <span class="op">*</span> <span class="va">ll_alt</span>   <span class="co"># Modello con 2 parametri</span></span>
<span></span>
<span><span class="va">delta_AIC</span> <span class="op">&lt;-</span> <span class="va">AIC_alt</span> <span class="op">-</span> <span class="va">AIC_null</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ul>
<li>Un valore di AIC più basso indica il modello preferito.</li>
<li>Differenze <span class="math inline">\(&gt; 2\)</span> suggeriscono evidenza sostanziale a favore del modello migliore.</li>
<li>Differenze <span class="math inline">\(&gt; 10\)</span> forniscono evidenza decisiva.</li>
</ul></section><section id="test-del-rapporto-di-verosimiglianza" class="level4" data-number="17.10.2.4"><h4 data-number="17.10.2.4" class="anchored" data-anchor-id="test-del-rapporto-di-verosimiglianza">
<span class="header-section-number">17.10.2.4</span> Test del rapporto di verosimiglianza</h4>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb28"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">LR_stat</span> <span class="op">&lt;-</span> <span class="op">-</span><span class="fl">2</span> <span class="op">*</span> <span class="op">(</span><span class="va">ll_null</span> <span class="op">-</span> <span class="va">ll_alt</span><span class="op">)</span></span>
<span><span class="va">p_value</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Chisquare.html">pchisq</a></span><span class="op">(</span><span class="va">LR_stat</span>, df <span class="op">=</span> <span class="fl">1</span>, lower.tail <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section></section><section id="interpretazione-3" class="level3" data-number="17.10.3"><h3 data-number="17.10.3" class="anchored" data-anchor-id="interpretazione-3">
<span class="header-section-number">17.10.3</span> Interpretazione</h3>
<p>Il confronto tra modelli fornisce due prospettive complementari:</p>
<ol type="1">
<li>
<em>AIC</em>: valuta la qualità relativa dei modelli, bilanciando adattamento e complessità.</li>
<li>
<em>Rapporto di verosimiglianza</em>: consente un test formale della differenza tra modelli.</li>
</ol>
<p>Nell’esempio, il test produce <span class="math inline">\(p \approx 0.034\)</span>, mentre l’AIC mostra una chiara preferenza per il modello alternativo. Entrambi i criteri concordano: il modello che assegna probabilità distinte ai due gruppi descrive meglio i dati, suggerendo che il <em>contenuto emotivo delle immagini facilita la memoria visiva</em>.</p>
<p>In conclusione, l’uso integrato di <em>AIC</em> e <em>rapporti di verosimiglianza</em> permette di prendere decisioni modellistiche fondate, evitando il rischio di sovradattamento. In psicologia, dove i dati sono spesso rumorosi e complessi, questo approccio consente di mantenere un equilibrio cruciale tra <em>capacità esplicativa</em> e <em>parsimonia</em>.</p>
</section></section><section id="riflessioni-conclusive" class="level2 unnumbered unlisted"><h2 class="unnumbered unlisted anchored" data-anchor-id="riflessioni-conclusive">Riflessioni conclusive</h2>
<p>La funzione di verosimiglianza rappresenta il fondamento concettuale e operativo dell’inferenza statistica moderna, fornendo un ponte metodologico tra modelli teorici ed evidenza empirica. La sua efficacia deriva dalla capacità di quantificare sistematicamente la plausibilità dei parametri di un modello condizionatamente ai dati osservati, creando così un collegamento formale tra astrazione teorica e osservazione sperimentale.</p>
<p>L’impianto teorico della verosimiglianza si basa su tre componenti essenziali: la specificazione del modello probabilistico generatore dei dati, la definizione dello spazio parametrico e l’incorporazione delle osservazioni empiriche. Questo framework si dimostra particolarmente efficace nei modelli binomiali e gaussiani, dove assume forme analiticamente trattabili che facilitano sia la stima puntuale che la verifica di ipotesi.</p>
<p>Nel contesto della distribuzione normale, la stima di massima verosimiglianza del parametro μ coincide elegantemente con la media campionaria, mentre la rappresentazione grafica della funzione di verosimiglianza offre una visualizzazione immediata della precisione della stima. L’adozione della log-verosimiglianza, oltre a semplificare i calcoli analitici, garantisce una maggiore stabilità numerica, particolarmente valuable in contesti con campioni di grandi dimensioni o modelli complessi.</p>
<p>Il rapporto di verosimiglianza si configura come uno strumento particolarmente versatile, in grado di bilanciare sofisticatamente la bontà di adattamento con il principio di parsimonia modellistica. Questo bilanciamento trova la sua espressione formale in criteri di selezione modellistica come l’AIC, che penalizzano appropriatamente la complessità parametrica evitando il sovradattamento.</p>
<p>La verosimiglianza, nelle sue molteplici manifestazioni, non si limita a collegare modelli teorici e dati empirici, ma costituisce il motore propulsivo dell’inferenza bayesiana. Attraverso il teorema di Bayes, la verosimiglianza trasforma sistematicamente l’informazione a priori in distribuzioni posteriori, aggiornando razionalmente le nostre credenze alla luce dell’evidenza osservata. Questo duplice ruolo - sia nell’ambito frequentista che in quello bayesiano - testimonia la profondità e l’utilità di questo strumento statistico fondamentale.</p>
<p>La padronanza dei concetti di verosimiglianza e log-verosimiglianza rappresenta quindi una competenza essenziale per lo psicologo ricercatore, permettendo non solo l’analisi appropriata dei dati sperimentali, ma anche la comprensione critica dei modelli teorici che sottendono i processi psicologici investigati.</p>
<div class="callout callout-style-simple callout-important no-icon callout-titled" title="Problemi">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Problemi
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Spiega ciascuno dei concetti seguenti con una frase:</p>
<ul>
<li>probabilità.</li>
<li>funzione di massa di probabilità.</li>
<li>funzione di densità di probabilità.</li>
<li>distribuzione di probabilità.</li>
<li>distribuzione di probabilità discreta.</li>
<li>distribuzione di probabilità continua.</li>
<li>funzione di distribuzione cumulativa (cdf).</li>
<li>verosimiglianza</li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-important no-icon callout-titled" title="Problemi">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Problemi
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Supponi di aver misurato il livello di ansia (ad esempio usando una scala standardizzata) in un campione di 15 persone con i seguenti punteggi:</p>
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">ansia</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">23</span>, <span class="fl">27</span>, <span class="fl">30</span>, <span class="fl">29</span>, <span class="fl">25</span>, <span class="fl">28</span>, <span class="fl">26</span>, <span class="fl">24</span>, <span class="fl">31</span>, <span class="fl">29</span>, <span class="fl">27</span>, <span class="fl">26</span>, <span class="fl">28</span>, <span class="fl">30</span>, <span class="fl">25</span><span class="op">)</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Assumendo che la deviazione standard sia nota e pari a 3.5, svolgi le seguenti attività in R:</p>
<ol type="1">
<li>Calcola la funzione di verosimiglianza gaussiana per diversi valori di <span class="math inline">\(\mu\)</span> nell’intervallo da 20 a 35.</li>
<li>Trova numericamente il valore di <span class="math inline">\(\mu\)</span> che rende massima la verosimiglianza (stima di massima verosimiglianza, MLE).</li>
<li>Disegna un grafico della funzione di verosimiglianza per visualizzare il risultato.</li>
</ol>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-note no-icon callout-titled" title="Informazioni sull'ambiente di sviluppo">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Informazioni sull’ambiente di sviluppo
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb30"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/sessionInfo.html">sessionInfo</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">#&gt; R version 4.5.1 (2025-06-13)</span></span>
<span><span class="co">#&gt; Platform: aarch64-apple-darwin20</span></span>
<span><span class="co">#&gt; Running under: macOS Sequoia 15.6.1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Matrix products: default</span></span>
<span><span class="co">#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib </span></span>
<span><span class="co">#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; locale:</span></span>
<span><span class="co">#&gt; [1] C/UTF-8/C/C/C/C</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; time zone: Europe/Rome</span></span>
<span><span class="co">#&gt; tzcode source: internal</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; attached base packages:</span></span>
<span><span class="co">#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; other attached packages:</span></span>
<span><span class="co">#&gt;  [1] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      </span></span>
<span><span class="co">#&gt;  [4] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     </span></span>
<span><span class="co">#&gt;  [7] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     </span></span>
<span><span class="co">#&gt; [10] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         </span></span>
<span><span class="co">#&gt; [13] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           </span></span>
<span><span class="co">#&gt; [16] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        </span></span>
<span><span class="co">#&gt; [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         </span></span>
<span><span class="co">#&gt; [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            </span></span>
<span><span class="co">#&gt; [25] here_1.0.1           </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; loaded via a namespace (and not attached):</span></span>
<span><span class="co">#&gt;  [1] svUnit_1.0.8          tidyselect_1.2.1      farver_2.1.2         </span></span>
<span><span class="co">#&gt;  [4] fastmap_1.2.0         TH.data_1.1-4         tensorA_0.36.2.1     </span></span>
<span><span class="co">#&gt;  [7] digest_0.6.37         timechange_0.3.0      estimability_1.5.1   </span></span>
<span><span class="co">#&gt; [10] lifecycle_1.0.4       survival_3.8-3        magrittr_2.0.3       </span></span>
<span><span class="co">#&gt; [13] compiler_4.5.1        rlang_1.1.6           tools_4.5.1          </span></span>
<span><span class="co">#&gt; [16] knitr_1.50            labeling_0.4.3        bridgesampling_1.1-2 </span></span>
<span><span class="co">#&gt; [19] htmlwidgets_1.6.4     curl_7.0.0            pkgbuild_1.4.8       </span></span>
<span><span class="co">#&gt; [22] RColorBrewer_1.1-3    abind_1.4-8           multcomp_1.4-28      </span></span>
<span><span class="co">#&gt; [25] withr_3.0.2           purrr_1.1.0           grid_4.5.1           </span></span>
<span><span class="co">#&gt; [28] stats4_4.5.1          colorspace_2.1-1      xtable_1.8-4         </span></span>
<span><span class="co">#&gt; [31] inline_0.3.21         emmeans_1.11.2-8      scales_1.4.0         </span></span>
<span><span class="co">#&gt; [34] MASS_7.3-65           cli_3.6.5             mvtnorm_1.3-3        </span></span>
<span><span class="co">#&gt; [37] rmarkdown_2.29        ragg_1.5.0            generics_0.1.4       </span></span>
<span><span class="co">#&gt; [40] RcppParallel_5.1.11-1 cachem_1.1.0          stringr_1.5.1        </span></span>
<span><span class="co">#&gt; [43] splines_4.5.1         parallel_4.5.1        vctrs_0.6.5          </span></span>
<span><span class="co">#&gt; [46] V8_7.0.0              Matrix_1.7-4          sandwich_3.1-1       </span></span>
<span><span class="co">#&gt; [49] jsonlite_2.0.0        arrayhelpers_1.1-0    systemfonts_1.2.3    </span></span>
<span><span class="co">#&gt; [52] glue_1.8.0            codetools_0.2-20      distributional_0.5.0 </span></span>
<span><span class="co">#&gt; [55] lubridate_1.9.4       stringi_1.8.7         gtable_0.3.6         </span></span>
<span><span class="co">#&gt; [58] QuickJSR_1.8.0        htmltools_0.5.8.1     Brobdingnag_1.2-9    </span></span>
<span><span class="co">#&gt; [61] R6_2.6.1              textshaping_1.0.3     rprojroot_2.1.1      </span></span>
<span><span class="co">#&gt; [64] evaluate_1.0.5        lattice_0.22-7        backports_1.5.0      </span></span>
<span><span class="co">#&gt; [67] memoise_2.0.1         broom_1.0.9           snakecase_0.11.1     </span></span>
<span><span class="co">#&gt; [70] rstantools_2.5.0      coda_0.19-4.1         gridExtra_2.3        </span></span>
<span><span class="co">#&gt; [73] nlme_3.1-168          checkmate_2.3.3       xfun_0.53            </span></span>
<span><span class="co">#&gt; [76] zoo_1.8-14            pkgconfig_2.0.3</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</div>
</section><section id="bibliografia" class="level2 unnumbered unlisted"><h2 class="unnumbered unlisted anchored" data-anchor-id="bibliografia">Bibliografia</h2>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" data-line-spacing="2" role="list">
<div id="ref-Johnson2022bayesrules" class="csl-entry" role="listitem">
Johnson, A. A., Ott, M., &amp; Dogucu, M. (2022). <em><span>Bayes Rules! An Introduction to Bayesian Modeling with R</span></em>. CRC Press.
</div>
<div id="ref-schervish2014probability" class="csl-entry" role="listitem">
Schervish, M. J., &amp; DeGroot, M. H. (2014). <em>Probability and statistics</em> (Vol. 563). Pearson Education London, UK:
</div>
</div>
</section></main><!-- /main --><script>
document.body.classList.add('classic-book');
document.addEventListener('DOMContentLoaded', function() {
  const paragraphs = document.querySelectorAll('p');
  paragraphs.forEach(p => {
    if (p.textContent.length > 200) {
      p.style.hyphens = 'auto';
      p.style.hyphenateCharacter = '-';
    }
  });
  const headings = document.querySelectorAll('h1, h2, h3, h4, h5, h6');
  headings.forEach(h => {
    h.style.fontFeatureSettings = '"liga" 1, "dlig" 1, "smcp" 1';
  });
});
</script><script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copiato!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copiato!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/ccaudek\.github\.io\/utet-prob\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
            // default icon
            link.classList.add("external");
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="../../chapters/probability/15_gauss.html" class="pagination-link" aria-label="Assunzione di gaussianità e trasformazioni dei dati">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Assunzione di gaussianità e trasformazioni dei dati</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../chapters/appendix/a02_math_symbols.html" class="pagination-link" aria-label="Simbologia di base">
        <span class="nav-page-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Simbologia di base</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer"><div class="nav-footer">
    <div class="nav-footer-left">
<p><strong>Probabilità per la psicologia</strong> — Modulo di richiamo del progetto UTET a supporto del manuale <em>Metodi bayesiani in psicologia</em>.</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/ccaudek/utet-prob/blob/main/chapters/probability/16_likelihood.qmd" class="toc-action"><i class="bi bi-github"></i>Mostra il codice</a></li><li><a href="https://github.com/ccaudek/utet-prob/issues/new" class="toc-action"><i class="bi empty"></i>Segnala un problema</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>Realizzato con <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>


<script src="../../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>