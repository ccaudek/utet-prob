<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="it" xml:lang="it"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.34">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>10&nbsp; Stime, stimatori e parametri – Probabilità per la psicologia — Modulo di richiamo</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>

<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../chapters/probability/10_joint_prob.html" rel="next">
<link href="../../chapters/probability/08_expval_var.html" rel="prev">
<link href="../../style/gauss.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-0a72236910a44089af39cd28873f322e.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-9908c7b05874059c2106d454ac00f1d0.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Nessun risultato",
    "search-matching-documents-text": "documenti trovati",
    "search-copy-link-title": "Copiare il link nella ricerca",
    "search-hide-matches-text": "Nascondere i risultati aggiuntivi",
    "search-more-match-text": "ci sono altri risultati in questo documento",
    "search-more-matches-text": "ulteriori risultati in questo documento",
    "search-clear-button-title": "Pulire",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancellare",
    "search-submit-button-title": "Inviare",
    "search-label": "Ricerca"
  }
}</script><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-QT5S3P9D31"></script><script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-QT5S3P9D31', { 'anonymize_ip': true});
</script><style>html{ scroll-behavior: smooth; }</style>
<script>
window.MathJax = {
  tex: { inlineMath: [['$', '$'], ['\\(', '\\)']] },
  svg: { scale: 1, mtextInheritFont: true, fontCache: 'none', minScale: 1 },
  options: { renderActions: { addMenu: [0, '', ''] } },
  loader: { load: ['input/tex','output/svg'] }
};
</script><script>
window.MathJax = {
  tex: { inlineMath: [['$', '$'], ['\\(', '\\)']] },
  svg: { scale: 1, mtextInheritFont: true, fontCache: 'none', minScale: 1 },
  options: { renderActions: { addMenu: [0, '', ''] } },
  loader: { load: ['input/tex','output/svg'] }
};
// Suggerimento CSS: vedi sezione 3 per gli spazi attorno a display math
</script><script>
window.MathJax = {
  tex: {
    packages: {'[+]': ['boldsymbol']},
    inlineMath: [['$', '$'], ['\\(', '\\)']]
  },
  svg: { fontCache: 'global' }
};
</script><script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script><script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script><link rel="stylesheet" href="../../style/_typography-extras.css">
<link rel="stylesheet" href="../../style/_code-extras.css">
<link rel="stylesheet" href="../../style/_math-extras.css">
<link rel="stylesheet" href="../../style/styles.css">
</head>
<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Attiva/disattiva la barra laterale" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../chapters/probability/introduction_probability.html">Probabilità</a></li><li class="breadcrumb-item"><a href="../../chapters/probability/09_sampling_distr.html"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Stime, stimatori e parametri</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Attiva/disattiva la barra laterale" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Ricerca" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../../">Probabilità per la psicologia — Modulo di richiamo</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/ccaudek/utet-prob/" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Attiva/disattiva la modalità lettore">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Ricerca"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Percorso e obiettivi</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../prefazione.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Prefazione</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../chapters/probability/introduction_probability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Probabilità</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/01_intro_prob.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Interpretazione della probabilità</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/02_probability_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Modelli probabilistici</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/03_sigma-algebra.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Dal Discreto al Continuo: la <span class="math inline">\(\sigma\)</span>-algebra</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/04_conditional_prob.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Probabilità condizionata</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/05_bayes_theorem.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Il teorema di Bayes</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/06_random_var.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Variabili casuali</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/07_prob_distributions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Distribuzioni di massa e di densità</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/08_expval_var.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Proprietà delle variabili casuali</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/09_sampling_distr.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Stime, stimatori e parametri</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/10_joint_prob.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Probabilità congiunta</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/11_cov_cor.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Covarianza e correlazione</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/12_intro_distributions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Introduzione alle distribuzioni di probabilità</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/13_discr_rv_distr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Distribuzioni di v.c. discrete</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/14_cont_rv_distr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Distribuzioni di v.c. continue</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/15_gauss.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Assunzione di gaussianità e trasformazioni dei dati</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/16_likelihood.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">La verosimiglianza</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a02_math_symbols.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Simbologia di base</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a11_numbers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Numeri e intervalli</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a12_sum_notation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">Sommatorie</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a13_sets.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Insiemi</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a14_combinatorics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">E</span>&nbsp; <span class="chapter-title">Calcolo combinatorio</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a15_calculus.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">F</span>&nbsp; <span class="chapter-title">Per liberarvi dai terrori preliminari</span></span></a>
  </div>
</li>
      </ul>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Sommario</h2>
   
  <ul class="collapse">
<li><a href="#popolazione-e-campione" id="toc-popolazione-e-campione" class="nav-link active" data-scroll-target="#popolazione-e-campione"><span class="header-section-number">10.1</span> Popolazione e campione</a></li>
  <li><a href="#distribuzione-campionaria-valore-atteso-e-varianza" id="toc-distribuzione-campionaria-valore-atteso-e-varianza" class="nav-link" data-scroll-target="#distribuzione-campionaria-valore-atteso-e-varianza"><span class="header-section-number">10.2</span> Distribuzione campionaria: valore atteso e varianza</a></li>
  <li><a href="#la-distribuzione-campionaria-della-media" id="toc-la-distribuzione-campionaria-della-media" class="nav-link" data-scroll-target="#la-distribuzione-campionaria-della-media"><span class="header-section-number">10.3</span> La distribuzione campionaria della media</a></li>
  <li><a href="#sec-lln" id="toc-sec-lln" class="nav-link" data-scroll-target="#sec-lln"><span class="header-section-number">10.4</span> Legge dei Grandi Numeri</a></li>
  <li><a href="#teorema-del-limite-centrale" id="toc-teorema-del-limite-centrale" class="nav-link" data-scroll-target="#teorema-del-limite-centrale"><span class="header-section-number">10.5</span> Teorema del Limite Centrale</a></li>
  <li><a href="#oltre-la-media-altre-distribuzioni-campionarie" id="toc-oltre-la-media-altre-distribuzioni-campionarie" class="nav-link" data-scroll-target="#oltre-la-media-altre-distribuzioni-campionarie"><span class="header-section-number">10.6</span> Oltre la media: altre distribuzioni campionarie</a></li>
  <li><a href="#errore-standard-incertezza-inferenziale-e-bias" id="toc-errore-standard-incertezza-inferenziale-e-bias" class="nav-link" data-scroll-target="#errore-standard-incertezza-inferenziale-e-bias"><span class="header-section-number">10.7</span> Errore standard, incertezza inferenziale e bias</a></li>
  <li><a href="#la-prospettiva-bayesiana" id="toc-la-prospettiva-bayesiana" class="nav-link" data-scroll-target="#la-prospettiva-bayesiana"><span class="header-section-number">10.8</span> La prospettiva bayesiana</a></li>
  </ul><div class="toc-actions"><ul class="collapse"><li><a href="https://github.com/ccaudek/utet-prob/blob/main/chapters/probability/09_sampling_distr.qmd" class="toc-action"><i class="bi bi-github"></i>Mostra il codice</a></li><li><a href="https://github.com/ccaudek/utet-prob/issues/new" class="toc-action"><i class="bi empty"></i>Segnala un problema</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../chapters/probability/introduction_probability.html">Probabilità</a></li><li class="breadcrumb-item"><a href="../../chapters/probability/09_sampling_distr.html"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Stime, stimatori e parametri</span></a></li></ol></nav><div class="quarto-title">
<h1 class="title"><span id="sec-prob-sampling-distr" class="quarto-section-identifier"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Stime, stimatori e parametri</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header><div class="epigraph">
<blockquote class="blockquote">
<p>“Lo scopo della statistica inferenziale è trarre conclusioni su una popolazione utilizzando le informazioni contenute in un campione. Lo stimatore è il nostro strumento formale per compiere questa induzione.”</p>
<p>– <strong>Sir David Cox</strong> <em>Principles of Statistical Inference</em> (2006)</p>
</blockquote>
</div>
<section id="introduzione" class="level2 unnumbered unlisted"><h2 class="unnumbered unlisted anchored" data-anchor-id="introduzione">Introduzione</h2>
<p>In psicologia – come in molte altre discipline – ci si trova spesso nella situazione di voler comprendere una particolare <em>caratteristica</em> di un’intera popolazione. Tuttavia, difficilmente è possibile raccogliere dati da <em>tutti</em> i membri di tale popolazione, a causa di limiti di tempo, risorse o accessibilità. Ad esempio, potremmo voler stimare la percentuale di persone che soffrono di un determinato disturbo d’ansia oppure la media di un punteggio di memoria a breve termine, ma non siamo in grado di testare ogni singolo individuo appartenente al gruppo di interesse. Per far fronte a questo limite, si sceglie di selezionare un <em>campione</em> di partecipanti (idealmente in modo casuale), dal quale si ricavano le informazioni utili a <em>inferire</em> la caratteristica dell’intera popolazione, riconoscendo un certo grado di incertezza.</p>
<p>Nel linguaggio statistico:</p>
<ul>
<li>
<strong>Popolazione</strong>: l’insieme completo degli individui (o unità) di interesse. Esempi: tutte le persone che soddisfano certi criteri diagnostici, tutti gli studenti di una scuola, tutte le misurazioni di reazione a uno stimolo sperimentale.</li>
<li>
<strong>Parametro</strong>: la quantità (sconosciuta) che descrive la caratteristica d’interesse nella popolazione (esempio: la “vera” proporzione di soggetti con un certo disturbo, oppure la “vera” media di un test cognitivo).</li>
<li>
<strong>Campione</strong>: un sottoinsieme di individui (idealmente estratto in modo casuale) dalla popolazione di interesse.</li>
<li>
<strong>Stima</strong>: il valore numerico, calcolato sul campione, che approssima il parametro.</li>
<li>
<strong>Stimatore</strong>: la regola o funzione matematica con cui, a partire dai dati del campione, si ottiene la stima.</li>
</ul>
<p>Come esempio, immaginiamo di voler conoscere la proporzione di adulti che manifestano un certo sintomo d’ansia, indicandola con <span class="math inline">\(p\)</span>. Poiché non possiamo (o non vogliamo) esaminare <em>tutta</em> la popolazione, estraiamo un campione casuale di <span class="math inline">\(N\)</span> individui, verifichiamo quanti di loro presentino il sintomo e calcoliamo:</p>
<p><span class="math display">\[
\hat{p} = \frac{\text{numero di individui con il sintomo}}{N}.
\]</span></p>
<p>Questo rapporto (detto <em>stima campionaria</em> di <span class="math inline">\(p\)</span>) difficilmente coinciderà <em>esattamente</em> con <span class="math inline">\(p\)</span>, ma la teoria probabilistica mostra che, in assenza di distorsioni sistematiche, <span class="math inline">\(\hat{p}\)</span> tenderà ad avvicinarsi al valore reale al crescere della dimensione del campione.</p>
<section id="panoramica-del-capitolo" class="level3 unnumbered unlisted"><h3 class="unnumbered unlisted anchored" data-anchor-id="panoramica-del-capitolo">Panoramica del capitolo</h3>
<ul>
<li>Come le stime dei parametri della popolazione variano da campione a campione.</li>
<li>Nozioni di popolazione, campione, parametro, stima e stimatore.</li>
<li>Connessione tra stime campionarie e parametri reali della popolazione.</li>
<li>Calcolare e interpretare il valore atteso e la varianza della media campionaria.</li>
<li>Utilizzare l’errore standard per rappresentare l’incertezza nelle stime dei parametri.</li>
<li>La convergenza delle medie campionarie alla media della popolazione.</li>
<li>Il teorema per approssimare distribuzioni campionarie con distribuzioni normali.</li>
</ul>
<div class="callout callout-style-simple callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Prerequisiti
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul>
<li>Leggere il capitolo <em>Sampling Distributions of Estimators</em> <span class="citation" data-cites="schervish2014probability">(<a href="#ref-schervish2014probability" role="doc-biblioref">Schervish &amp; DeGroot, 2014</a>)</span>.</li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-caution no-icon callout-titled" title="Preparazione del Notebook">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Preparazione del Notebook
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<div class="cell">
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">here</span><span class="fu">::</span><span class="fu"><a href="https://here.r-lib.org/reference/here.html">here</a></span><span class="op">(</span><span class="st">"code"</span>, <span class="st">"_common.R"</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/source.html">source</a></span><span class="op">(</span><span class="op">)</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</div>
</section></section><section id="popolazione-e-campione" class="level2" data-number="10.1"><h2 data-number="10.1" class="anchored" data-anchor-id="popolazione-e-campione">
<span class="header-section-number">10.1</span> Popolazione e campione</h2>
<p>Per rendere tutto più concreto, supponiamo di voler stimare la frequenza di un sintomo ansioso in un’ampia popolazione, ad esempio l’insieme di tutti gli studenti universitari di un paese. Non potendo sottoporre un questionario a ogni studente, scegliamo un sottoinsieme di individui in modo casuale (cioè il nostro <em>campione</em>) e a ciascuno somministriamo uno strumento standardizzato volto a rilevare la presenza/assenza del sintomo. Il nostro obiettivo finale è utilizzare i dati campionari per trarre inferenze sulla <em>popolazione</em> complessiva, cioè per stimare la vera proporzione <span class="math inline">\(p\)</span> di studenti che manifestano il sintomo.</p>
<p>Questa operazione di estrarre un sottogruppo rappresentativo si chiama <em>campionamento</em>. La proporzione di individui con il sintomo d’ansia calcolata nel campione è la nostra <em>stima campionaria</em> (simbolizzata con <span class="math inline">\(\bar{X}\)</span> o, più spesso in contesto di proporzioni, con <span class="math inline">\(\hat{p}\)</span>). Se il campione è selezionato in modo corretto e rappresentativo, ci aspettiamo che <span class="math inline">\(\bar{X}\)</span> rispecchi, con un certo margine di errore, il vero valore di <span class="math inline">\(p\)</span> (il <em>parametro</em>).</p>
<section id="lo-stimatore-la-proporzione-campionaria" class="level3" data-number="10.1.1"><h3 data-number="10.1.1" class="anchored" data-anchor-id="lo-stimatore-la-proporzione-campionaria">
<span class="header-section-number">10.1.1</span> Lo stimatore: la proporzione campionaria</h3>
<p>Per formalizzare ulteriormente, consideriamo un modello “urna” in cui la popolazione è immaginata come un’urna piena di “biglie” di due colori (ad esempio, “blu” per sintomo presente, “rosso” per sintomo assente). Estraendo a caso <span class="math inline">\(N\)</span> biglie (cioè selezionando <span class="math inline">\(N\)</span> soggetti), definiamo la variabile casuale <span class="math inline">\(X_i\)</span> come:</p>
<p><span class="math display">\[
X_i =
\begin{cases}
1 &amp; \text{se l’individuo } i \text{ presenta il sintomo (biglia blu),}\\
0 &amp; \text{se l’individuo } i \text{ non presenta il sintomo (biglia rossa).}
\end{cases}
\]</span></p>
<p>La proporzione campionaria – ossia la nostra stima empirica di <span class="math inline">\(p\)</span> – è data da:</p>
<p><span class="math display">\[
\bar{X} \;=\; \frac{1}{N}\sum_{i=1}^N X_i.
\]</span></p>
<p>Dal punto di vista interpretativo:</p>
<ul>
<li>
<span class="math inline">\(p\)</span> è la vera proporzione di studenti (biglie “blu”) nella popolazione;</li>
<li>
<span class="math inline">\(\bar{X}\)</span> è la proporzione di studenti con il sintomo riscontrata nel campione.</li>
</ul></section></section><section id="distribuzione-campionaria-valore-atteso-e-varianza" class="level2" data-number="10.2"><h2 data-number="10.2" class="anchored" data-anchor-id="distribuzione-campionaria-valore-atteso-e-varianza">
<span class="header-section-number">10.2</span> Distribuzione campionaria: valore atteso e varianza</h2>
<p>Il passo cruciale per il <em>ragionamento inferenziale</em> è capire come varia <span class="math inline">\(\bar{X}\)</span> se ripetiamo la procedura di campionamento molte volte. In altre parole, se estraessimo più volte (indipendentemente) un campione di ampiezza <span class="math inline">\(N\)</span>, otterremmo ogni volta un valore di <span class="math inline">\(\bar{X}\)</span> in genere diverso. La <em>collezione</em> di tutti questi possibili valori (con le rispettive probabilità) si chiama <em>distribuzione campionaria</em> di <span class="math inline">\(\bar{X}\)</span>.</p>
<section id="valore-atteso-della-media-o-proporzione-campionaria" class="level3" data-number="10.2.1"><h3 data-number="10.2.1" class="anchored" data-anchor-id="valore-atteso-della-media-o-proporzione-campionaria">
<span class="header-section-number">10.2.1</span> Valore atteso della media (o proporzione) campionaria</h3>
<p>Se <span class="math inline">\(X_1, X_2, \dots, X_n\)</span> sono variabili aleatorie indipendenti e identicamente distribuite (i.i.d.), ognuna con valore atteso <span class="math inline">\(\mathbb{E}[X_i] = \mu\)</span>, allora la loro <em>media</em> campionaria</p>
<p><span class="math display">\[
\bar{X} \;=\; \frac{1}{n}\sum_{i=1}^n X_i
\]</span></p>
<p>possiede a sua volta valore atteso</p>
<p><span class="math display">\[
\mathbb{E}[\bar{X}] \;=\; \mu.
\]</span></p>
<p>Questa semplice formula rivela che <span class="math inline">\(\bar{X}\)</span> è uno <em>stimatore non distorto</em> per <span class="math inline">\(\mu\)</span>: in media, se ripetessimo infinite volte lo stesso tipo di campionamento, otterremmo una stima che coincide con il vero valore del parametro. Nel caso di variabili 0-1 (come presenza/assenza di sintomo), abbiamo <span class="math inline">\(\mu \equiv p\)</span>.</p>
<div class="proof">
<p><span class="proof-title"><em>Dimostrazione</em>. </span>Consideriamo un campione casuale <span class="math inline">\(X_1, X_2, \dots, X_n\)</span> di variabili aleatorie <em>indipendenti e identicamente distribuite (i.i.d.)</em>, ognuna con valore atteso <span class="math inline">\(\mathbb{E}[X_i] = \mu\)</span>. Vogliamo dimostrare che il valore atteso della media campionaria <span class="math inline">\(\bar{X}\)</span> è uguale a <span class="math inline">\(\mu\)</span>:</p>
<p><span class="math display">\[
\mathbb{E}[\bar{X}] = \mu.
\]</span></p>
<p><strong>Passo 1: Definizione di media campionaria.</strong><br>
La media campionaria è definita come:<br><span class="math display">\[
\bar{X} = \frac{1}{n} \sum_{i=1}^n X_i.
\]</span></p>
<p><strong>Passo 2: Applicazione del valore atteso.</strong><br>
Calcoliamo il valore atteso di <span class="math inline">\(\bar{X}\)</span>, sfruttando la <em>linearità del valore atteso</em> (l’aspettativa di una somma è la somma delle aspettative):<br><span class="math display">\[
\mathbb{E}[\bar{X}] = \mathbb{E}\left[\frac{1}{n} \sum_{i=1}^n X_i\right].
\]</span></p>
<p><strong>Passo 3: Portare fuori le costanti.</strong><br>
Il fattore <span class="math inline">\(\frac{1}{n}\)</span> è una costante rispetto all’operatore <span class="math inline">\(\mathbb{E}\)</span>:<br><span class="math display">\[
\mathbb{E}[\bar{X}] = \frac{1}{n} \mathbb{E}\left[\sum_{i=1}^n X_i\right].
\]</span></p>
<p><strong>Passo 4: Separare la somma.</strong><br>
Per linearità, l’aspettativa della somma è la somma delle aspettative:<br><span class="math display">\[
\mathbb{E}\left[\sum_{i=1}^n X_i\right] = \sum_{i=1}^n \mathbb{E}[X_i].
\]</span></p>
<p><strong>Passo 5: Sfruttare l’identica distribuzione.</strong><br>
Poiché tutte le <span class="math inline">\(X_i\)</span> sono identicamente distribuite, <span class="math inline">\(\mathbb{E}[X_i] = \mu\)</span> per ogni <span class="math inline">\(i\)</span>:<br><span class="math display">\[
\sum_{i=1}^n \mathbb{E}[X_i] = \sum_{i=1}^n \mu = n\mu.
\]</span></p>
<p><strong>Passo 6: Combinare i risultati.</strong><br>
Sostituendo nel Passo 3:<br><span class="math display">\[
\mathbb{E}[\bar{X}] = \frac{1}{n} \cdot n\mu = \mu.
\]</span></p>
<p><strong>Interpretazione e Significato.</strong></p>
<ol type="1">
<li>
<em>Non distorsione (Unbiasedness)</em>:<br>
La dimostrazione mostra che <span class="math inline">\(\bar{X}\)</span> è uno <em>stimatore non distorto</em> di <span class="math inline">\(\mu\)</span>. Questo significa che, in media su infinite replicazioni del campionamento, <span class="math inline">\(\bar{X}\)</span> coincide con il vero valore <span class="math inline">\(\mu\)</span>.<br>
</li>
<li>
<em>Indipendenza non necessaria per l’aspettativa</em>:<br>
L’indipendenza tra le <span class="math inline">\(X_i\)</span> non è richiesta per questa dimostrazione. Bastano l’<em>identica distribuzione</em> (per garantire <span class="math inline">\(\mathbb{E}[X_i] = \mu\)</span>) e la <em>linearità</em> del valore atteso.<br>
</li>
<li>
<em>Caso speciale: proporzione campionaria</em><br>
Se le <span class="math inline">\(X_i\)</span> sono variabili di Bernoulli (0-1) con <span class="math inline">\(\mathbb{E}[X_i] = p\)</span>, allora <span class="math inline">\(\bar{X} = \frac{\text{numero di successi}}{n}\)</span> stima la proporzione <span class="math inline">\(p\)</span>, e <span class="math inline">\(\mathbb{E}[\bar{X}] = p\)</span>.</li>
</ol>
<p><strong>Perché è importante?</strong><br>
Questa proprietà è alla base dell’inferenza statistica:</p>
<ul>
<li>Giustifica l’uso della media campionaria come stima affidabile di <span class="math inline">\(\mu\)</span>.<br>
</li>
<li>È il fondamento della <em>Legge dei Grandi Numeri</em>: all’aumentare di <span class="math inline">\(n\)</span>, <span class="math inline">\(\bar{X}\)</span> converge a <span class="math inline">\(\mu\)</span>.</li>
</ul>
</div>
</section><section id="varianza-della-media-o-proporzione-campionaria" class="level3" data-number="10.2.2"><h3 data-number="10.2.2" class="anchored" data-anchor-id="varianza-della-media-o-proporzione-campionaria">
<span class="header-section-number">10.2.2</span> Varianza della media (o proporzione) campionaria</h3>
<p>Oltre al valore atteso, un’altra misura fondamentale è la <em>varianza</em> della distribuzione campionaria, che quantifica quanto <span class="math inline">\(\bar{X}\)</span> tenda a fluttuare attorno a <span class="math inline">\(\mu\)</span>. Se la varianza individuale di ciascun <span class="math inline">\(X_i\)</span> è <span class="math inline">\(\sigma^2\)</span>, allora per la media campionaria si ha:</p>
<p><span id="eq-err-standard-mean"><span class="math display">\[
\mathrm{Var}(\bar{X}) \;=\; \frac{\sigma^2}{n}.
\tag{10.1}\]</span></span></p>
<p>Nel caso Bernoulliano (variabili 0-1) con <span class="math inline">\(\mathbb{E}[X_i] = p\)</span>, sappiamo che</p>
<p><span class="math display">\[
\sigma^2 \;=\; p(1-p).
\]</span></p>
<p>Pertanto:</p>
<p><span class="math display">\[
\mathrm{Var}(\bar{X}) \;=\; \frac{p \bigl(1-p\bigr)}{n}.
\]</span></p>
<p>La radice quadrata di questa varianza prende il nome di <em>errore standard</em> (in inglese <em>Standard Error</em>, SE) della media (o della proporzione), e risulta:</p>
<p><span class="math display">\[
\mathrm{SE}(\bar{X}) \;=\; \sqrt{\frac{p\,(1-p)}{n}}.
\]</span></p>
<p>Con l’aumentare di <span class="math inline">\(n\)</span>, la varianza di <span class="math inline">\(\bar{X}\)</span> diminuisce, e quindi la nostra stima diventa più “precisa” (in un senso statistico). Ciò spiega perché, anche nella pratica psicologica, <em>aumentare la dimensione del campione</em> riduce l’incertezza nella stima e migliora l’affidabilità dei risultati.</p>
<p><strong>Osservazione</strong>: nella ricerca psicologica, l’errore standard fornisce un’indicazione chiara di quanto, in media, la nostra stima potrebbe deviare dal vero parametro, se ripetessimo il campionamento molte volte. Questo concetto è centrale in molte procedure inferenziali, come la costruzione di intervalli di confidenza o il test di ipotesi, e prepara il terreno per comprendere la cosiddetta <em>distribuzione campionaria della media</em> (argomento che il capitolo proseguirà a trattare).</p>
<div class="proof">
<p><span class="proof-title"><em>Dimostrazione</em>. </span>Forniamo qui la dimostrazione dell’<a href="#eq-err-standard-mean" class="quarto-xref">Equazione&nbsp;<span>10.1</span></a>. Assumiamo che <span class="math inline">\(X_1, X_2, \dots, X_n\)</span> siano variabili casuali <em>indipendenti e identicamente distribuite</em> (i.i.d.) con media <span class="math inline">\(\mu\)</span> e varianza <span class="math inline">\(\sigma^2\)</span>. Definiamo la media campionaria</p>
<p><span class="math display">\[
\bar{X} \;=\; \frac{1}{n}\sum_{i=1}^n X_i.
\]</span></p>
<p>Vogliamo calcolare <span class="math inline">\(\mathrm{Var}(\bar{X})\)</span>. Per prima cosa, notiamo che:</p>
<p><span class="math display">\[
\mathrm{Var}(a\,Y) \;=\; a^2 \,\mathrm{Var}(Y)
\]</span></p>
<p>per qualunque costante <span class="math inline">\(a\)</span>. Nel nostro caso, poniamo <span class="math inline">\(a = \frac{1}{n}\)</span> e <span class="math inline">\(Y = \sum_{i=1}^n X_i\)</span>. Otteniamo quindi:</p>
<p><span class="math display">\[
\mathrm{Var}(\bar{X})
\;=\;
\mathrm{Var}\!\Bigl(\tfrac{1}{n}\sum_{i=1}^n X_i\Bigr)
\;=\;
\frac{1}{n^2} \, \mathrm{Var}\!\Bigl(\sum_{i=1}^n X_i\Bigr).
\]</span></p>
<p>Ora sfruttiamo il fatto che <span class="math inline">\(X_1, X_2, \dots, X_n\)</span> siano indipendenti. In tal caso, la varianza della somma è la somma delle varianze:</p>
<p><span class="math display">\[
\mathrm{Var}\Bigl(\sum_{i=1}^n X_i\Bigr)
\;=\;
\sum_{i=1}^n \mathrm{Var}(X_i)
\;=\;
n \,\sigma^2,
\]</span></p>
<p>poiché <span class="math inline">\(\mathrm{Var}(X_i) = \sigma^2\)</span> per tutti gli <span class="math inline">\(i\)</span>. Combiniamo dunque i due risultati:</p>
<p><span class="math display">\[
\mathrm{Var}(\bar{X})
\;=\;
\frac{1}{n^2}\,\bigl(n \,\sigma^2\bigr)
\;=\;
\frac{\sigma^2}{n}.
\]</span></p>
<p>In sintesi, la chiave della dimostrazione sta nel fattore <span class="math inline">\(\tfrac{1}{n^2}\)</span> e nel fatto che, per variabili indipendenti, la varianza di una somma è la somma delle varianze. Questo ci consente di concludere che la varianza della media campionaria è <span class="math inline">\(\tfrac{\sigma^2}{n}\)</span>.</p>
</div>
<p>Questo risultato riflette un’importante proprietà statistica:</p>
<ul>
<li>all’aumentare di <span class="math inline">\(n\)</span>, la varianza della media campionaria diminuisce, rendendo la media campionaria una stima più precisa del valore atteso <span class="math inline">\(\mu\)</span>. La riduzione della varianza è proporzionale a <span class="math inline">\(1/n\)</span>, quindi raddoppiare il campione riduce la varianza della media campionaria di un fattore 2.</li>
</ul>
<p>In conclusione, la formula <span class="math inline">\(\text{Var}(\bar{X}) = \frac{\sigma^2}{n}\)</span> mostra che la precisione della media campionaria aumenta con la dimensione del campione, poiché la varianza diminuisce. Questo principio è alla base dell’importanza di campioni più grandi nella stima statistica.</p>
</section></section><section id="la-distribuzione-campionaria-della-media" class="level2" data-number="10.3"><h2 data-number="10.3" class="anchored" data-anchor-id="la-distribuzione-campionaria-della-media">
<span class="header-section-number">10.3</span> La distribuzione campionaria della media</h2>
<p>Per illustrare ulteriormente il concetto di distribuzione campionaria, consideriamo un caso semplice e specifico: una popolazione finita di dimensioni ridotte. Sebbene stiamo esaminando un caso particolare, è fondamentale notare che le proprietà e i principi che analizzeremo in questo contesto sono perfettamente applicabili a popolazioni di qualsiasi dimensione.</p>
<p>La distribuzione campionaria ci dà una visione della variazione che potremmo aspettarci nelle stime derivate da diversi campioni estratti dalla stessa popolazione. Ogni volta che preleviamo un campione, otteniamo una stima diversa per il parametro di interesse (come la media). La distribuzione campionaria ci mostra come queste stime sono distribuite e ci aiuta a comprendere quanto siano affidabili.</p>
<p>In termini pratici, se vogliamo calcolare la media della popolazione, non possiamo farlo direttamente (a meno di non avere accesso all’intera popolazione). Invece, possiamo estrarre un campione casuale e calcolare la media del campione come stima di <span class="math inline">\(\mu\)</span>. Tuttavia, un altro campione fornirà una stima leggermente diversa. La distribuzione campionaria ci aiuta a capire quanto queste stime varino da campione a campione e ci fornisce un quadro completo dell’incertezza legata al processo di stima.</p>
<p>Nella simulazione seguente, ipotizziamo la seguente popolazione:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">4.5</span>, <span class="fl">5</span>, <span class="fl">5.5</span><span class="op">)</span></span>
<span><span class="va">x</span></span>
<span><span class="co">#&gt; [1] 2.0 4.5 5.0 5.5</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>L’istogramma seguente descrive la distribuzione della popolazione.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">ggplot</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span><span class="op">)</span>, <span class="fu">aes</span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_histogram</span><span class="op">(</span></span>
<span>    bins <span class="op">=</span> <span class="fl">5</span>,</span>
<span>    <span class="fu">aes</span><span class="op">(</span>y <span class="op">=</span> <span class="fu">after_stat</span><span class="op">(</span><span class="va">density</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="op">)</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="09_sampling_distr_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:85.0%"></p>
</figure>
</div>
</div>
</div>
<p>Calcoliamo la media e la varianza della popolazione. Media:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">mean_x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="co"># Media della popolazione</span></span>
<span><span class="va">mean_x</span></span>
<span><span class="co">#&gt; [1] 4.25</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Varianza:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">var_x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/cor.html">var</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">*</span> <span class="op">(</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span> <span class="co"># Varianza popolazione</span></span>
<span><span class="va">var_x</span></span>
<span><span class="co">#&gt; [1] 1.81</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Consideriamo tutti i possibili campioni di dimensione <span class="math inline">\(n = 2\)</span> che possono essere estratti dalla popolazione rappresentata dal vettore <code>x</code>. Per generare questi campioni, utilizziamo la funzione <code>expand.grid</code> in R, che consente di creare tutte le combinazioni possibili di valori, includendo le ripetizioni.</p>
<p>Il risultato sarà un data frame con 16 righe e 2 colonne, dove ogni riga rappresenta una coppia possibile di valori estratti dal vettore <code>x</code>. Questo risultato è in linea con il principio del calcolo combinatorio: quando selezioniamo <span class="math inline">\(n\)</span> elementi da un insieme di <span class="math inline">\(k\)</span> elementi e permettiamo ripetizioni, il numero totale di combinazioni è dato da <span class="math inline">\(k^n\)</span>. Nel nostro caso, con <span class="math inline">\(k = 4\)</span> e <span class="math inline">\(n = 2\)</span>, otteniamo:</p>
<p><span class="math display">\[
4^2 = 16 \text{ combinazioni}.
\]</span></p>
<p>Utilizzando <code>expand.grid</code>, possiamo verificare questo risultato in R:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Generazione delle combinazioni con ripetizione</span></span>
<span><span class="va">samples</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/expand.grid.html">expand.grid</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">x</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Visualizzazione del risultato</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">samples</span><span class="op">)</span></span>
<span><span class="co">#&gt;    Var1 Var2</span></span>
<span><span class="co">#&gt; 1   2.0  2.0</span></span>
<span><span class="co">#&gt; 2   4.5  2.0</span></span>
<span><span class="co">#&gt; 3   5.0  2.0</span></span>
<span><span class="co">#&gt; 4   5.5  2.0</span></span>
<span><span class="co">#&gt; 5   2.0  4.5</span></span>
<span><span class="co">#&gt; 6   4.5  4.5</span></span>
<span><span class="co">#&gt; 7   5.0  4.5</span></span>
<span><span class="co">#&gt; 8   5.5  4.5</span></span>
<span><span class="co">#&gt; 9   2.0  5.0</span></span>
<span><span class="co">#&gt; 10  4.5  5.0</span></span>
<span><span class="co">#&gt; 11  5.0  5.0</span></span>
<span><span class="co">#&gt; 12  5.5  5.0</span></span>
<span><span class="co">#&gt; 13  2.0  5.5</span></span>
<span><span class="co">#&gt; 14  4.5  5.5</span></span>
<span><span class="co">#&gt; 15  5.0  5.5</span></span>
<span><span class="co">#&gt; 16  5.5  5.5</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Il data frame risultante mostrerà tutte le possibili coppie <span class="math inline">\((x_1, x_2)\)</span>, dove <span class="math inline">\(x_1\)</span> e <span class="math inline">\(x_2\)</span> possono essere scelti indipendentemente dalla popolazione <span class="math inline">\(x = \{2, 4.5, 5, 5.5\}\)</span>.</p>
<p>Per calcolare la media di ogni campione di ampiezza <span class="math inline">\(n = 2\)</span>, possiamo utilizzare la funzione <code>rowMeans</code>, che calcola la media per ogni riga di una matrice. In questo modo, otteniamo un vettore contenente la media di ciascuna coppia di valori. Questo insieme di valori costituisce la <em>distribuzione campionaria</em> delle medie dei campioni di ampiezza <span class="math inline">\(n = 2\)</span> che possono essere estratti dalla popolazione <code>x</code>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Calcolare la media di ciascun campione</span></span>
<span><span class="va">sample_means</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/colSums.html">rowMeans</a></span><span class="op">(</span><span class="va">samples</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">sample_means</span><span class="op">)</span></span>
<span><span class="co">#&gt;  [1] 2.00 3.25 3.50 3.75 3.25 4.50 4.75 5.00 3.50 4.75 5.00 5.25 3.75 5.00 5.25</span></span>
<span><span class="co">#&gt; [16] 5.50</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Una rappresentazione grafica della distribuzione campionaria delle medie dei campioni di ampiezza <span class="math inline">\(n = 2\)</span> che possono essere estratti dalla popolazione <code>x</code> è fornita qui sotto.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Istogramma delle medie campionarie</span></span>
<span><span class="fu">ggplot</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">sample_means</span><span class="op">)</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">sample_means</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_histogram</span><span class="op">(</span></span>
<span>    bins <span class="op">=</span> <span class="fl">5</span>,</span>
<span>    <span class="fu">aes</span><span class="op">(</span>y <span class="op">=</span> <span class="fu">after_stat</span><span class="op">(</span><span class="va">density</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="09_sampling_distr_files/figure-html/unnamed-chunk-8-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:85.0%"></p>
</figure>
</div>
</div>
</div>
<p>Mostriamo qui nuovamente la lista di tutti i possibili campioni di ampiezza 2 insieme alla media di ciascun campione.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Creare un data frame con i campioni e le loro medie</span></span>
<span><span class="va">df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span></span>
<span>  Samples <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">samples</span>, <span class="fl">1</span>, <span class="va">paste</span>, collapse <span class="op">=</span> <span class="st">", "</span><span class="op">)</span>,</span>
<span>  x_bar <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/colSums.html">rowMeans</a></span><span class="op">(</span><span class="va">samples</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">df</span><span class="op">)</span></span>
<span><span class="co">#&gt;     Samples x_bar</span></span>
<span><span class="co">#&gt; 1      2, 2  2.00</span></span>
<span><span class="co">#&gt; 2    4.5, 2  3.25</span></span>
<span><span class="co">#&gt; 3      5, 2  3.50</span></span>
<span><span class="co">#&gt; 4    5.5, 2  3.75</span></span>
<span><span class="co">#&gt; 5    2, 4.5  3.25</span></span>
<span><span class="co">#&gt; 6  4.5, 4.5  4.50</span></span>
<span><span class="co">#&gt; 7    5, 4.5  4.75</span></span>
<span><span class="co">#&gt; 8  5.5, 4.5  5.00</span></span>
<span><span class="co">#&gt; 9      2, 5  3.50</span></span>
<span><span class="co">#&gt; 10   4.5, 5  4.75</span></span>
<span><span class="co">#&gt; 11     5, 5  5.00</span></span>
<span><span class="co">#&gt; 12   5.5, 5  5.25</span></span>
<span><span class="co">#&gt; 13   2, 5.5  3.75</span></span>
<span><span class="co">#&gt; 14 4.5, 5.5  5.00</span></span>
<span><span class="co">#&gt; 15   5, 5.5  5.25</span></span>
<span><span class="co">#&gt; 16 5.5, 5.5  5.50</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Procediamo ora al calcolo della media della distribuzione campionaria delle medie di campioni di ampiezza <span class="math inline">\(n = 2\)</span> che possono essere estratti dalla popolazione <code>x</code>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Calcolare la media delle medie campionarie</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">sample_means</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 4.25</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Si noti che questo valore coincide con la media della popolazione.</p>
<p>La varianza delle medie campionarie, calcolata empiricamente, può essere ottenuta direttamente dai dati utilizzando la seguente formula:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/cor.html">var</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">*</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 0.453</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Questo calcolo riflette la formula teorica per la varianza della media campionaria, definita come la varianza dei dati divisa per la dimensione del campione <span class="math inline">\(n\)</span>. Tuttavia, poiché la funzione <code><a href="https://rdrr.io/r/stats/cor.html">var()</a></code> in R utilizza <span class="math inline">\(n-1\)</span> al denominatore per fornire una stima non distorta della varianza della popolazione, è necessario applicare un fattore di correzione <span class="math inline">\(\frac{n-1}{n}\)</span> per ottenere la varianza campionaria corretta. Successivamente, questa varianza viene divisa per <span class="math inline">\(n\)</span> per ottenere la varianza della media campionaria.</p>
<p>In alternativa, possiamo calcolare lo stesso valore prendendo la varianza delle medie di tutti i campioni (16 in questo caso):</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/cor.html">var</a></span><span class="op">(</span><span class="va">sample_means</span><span class="op">)</span> <span class="op">*</span> <span class="op">(</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">sample_means</span><span class="op">)</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">sample_means</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 0.906</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Anche in questo caso applichiamo il fattore di correzione <span class="math inline">\(\frac{n-1}{n}\)</span> per ottenere il calcolo corretto della varianza usando la funzione <code><a href="https://rdrr.io/r/stats/cor.html">var()</a></code> in R.</p>
<p>Entrambi i calcoli forniscono risultati coerenti con la teoria, dimostrando che la varianza delle medie campionarie è inferiore a quella della popolazione.</p>
<div class="callout callout-style-simple callout-note no-icon callout-titled" title="Collegamento con Bayes">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Collegamento con Bayes
</div>
</div>
<div class="callout-body-container callout-body">
<p>Nel paradigma frequentista, la distribuzione campionaria descrive la variabilità che avremmo se ripetessimo l’esperimento un gran numero di volte. In Bayes, invece, non ragioniamo su campioni ipotetici, ma sulla distribuzione a posteriori dei parametri, che riflette la nostra incertezza dati i dati osservati. In entrambi i casi il punto chiave è lo stesso: riconoscere che c’è variabilità e incertezza, non solo un numero singolo.</p>
</div>
</div>
</section><section id="sec-lln" class="level2" data-number="10.4"><h2 data-number="10.4" class="anchored" data-anchor-id="sec-lln">
<span class="header-section-number">10.4</span> Legge dei Grandi Numeri</h2>
<p>La <em>Legge dei Grandi Numeri</em> (LLN, dall’inglese <em>Law of Large Numbers</em>) è uno dei pilastri fondamentali della teoria della probabilità. Essa descrive come, all’aumentare del numero di osservazioni, la media campionaria si avvicini stabilmente al valore atteso teorico. In termini formali, se <span class="math inline">\(\bar{X}_n\)</span> rappresenta la media di <span class="math inline">\(n\)</span> osservazioni indipendenti e identicamente distribuite (i.i.d.) con valore atteso <span class="math inline">\(\mu\)</span>, allora <span class="math inline">\(\bar{X}_n \to \mu\)</span> quando <span class="math inline">\(n \to \infty\)</span>. Questo principio è cruciale per comprendere la relazione tra dati empirici e modelli teorici, come discusso nella sezione sull’interpretazione della probabilità (<a href="01_intro_prob.html" class="quarto-xref"><span>Capitolo 2</span></a>).</p>
<p>Esistono due versioni principali della Legge dei Grandi Numeri:</p>
<ol type="1">
<li><p><strong>Legge Forte</strong>: La media campionaria <span class="math inline">\(\bar{X}_n\)</span> converge <em>quasi certamente</em> a <span class="math inline">\(\mu\)</span>, il che significa che, con probabilità 1, la media osservata si avvicina indefinitamente al valore teorico al crescere di <span class="math inline">\(n\)</span>.</p></li>
<li>
<p><strong>Legge Debole</strong>: La media campionaria <span class="math inline">\(\bar{X}_n\)</span> converge a <span class="math inline">\(\mu\)</span> <em>in probabilità</em>, ovvero, per ogni <span class="math inline">\(\varepsilon &gt; 0\)</span>, la probabilità che la differenza tra <span class="math inline">\(\bar{X}_n\)</span> e <span class="math inline">\(\mu\)</span> superi <span class="math inline">\(\varepsilon\)</span> tende a zero al crescere di <span class="math inline">\(n\)</span>. Formalmente:</p>
<p><span class="math display">\[
\Pr\bigl(| \bar{X}_n - \mu| &gt; \varepsilon\bigr) \to 0 \quad \text{al crescere di }n.
\]</span></p>
</li>
</ol>
<section id="applicazioni-in-psicologia" class="level3" data-number="10.4.1"><h3 data-number="10.4.1" class="anchored" data-anchor-id="applicazioni-in-psicologia">
<span class="header-section-number">10.4.1</span> Applicazioni in psicologia</h3>
<p>In psicologia, la Legge dei Grandi Numeri ha implicazioni significative. Ad esempio, se si vuole stimare con precisione la proporzione di individui che manifestano un determinato comportamento o la media di un test cognitivo in una popolazione, è necessario raccogliere un <em>numero sufficiente di osservazioni</em>. Solo con un campione ampio la media campionaria si avvicinerà alla media “vera” della popolazione, riducendo l’incertezza e migliorando l’affidabilità delle stime.</p>
</section><section id="forma-debole-della-legge-dei-grandi-numeri" class="level3" data-number="10.4.2"><h3 data-number="10.4.2" class="anchored" data-anchor-id="forma-debole-della-legge-dei-grandi-numeri">
<span class="header-section-number">10.4.2</span> Forma debole della Legge dei Grandi Numeri</h3>
<p>La <em>forma debole</em> della LGN, dimostrata per la prima volta da Jacob Bernoulli nel suo lavoro <em>Ars Conjectandi</em>, afferma che la media campionaria converge in probabilità alla media teorica <span class="citation" data-cites="hacking2006emergence">(<a href="#ref-hacking2006emergence" role="doc-biblioref">Hacking, 2006</a>)</span>. In termini pratici, questo significa che, man mano che il numero di osservazioni aumenta, la probabilità che la differenza tra la media osservata e la media teorica superi un margine di errore <span class="math inline">\(\varepsilon\)</span> diventa sempre più piccola. Formalmente:</p>
<p><span class="math display">\[
\lim_{{n \to \infty}} P\left(\left|\frac{1}{n} \sum_{i=1}^n X_i - \mu\right| \geq \varepsilon\right) = 0,
\]</span> dove:</p>
<ul>
<li>
<span class="math inline">\(X_1, X_2, \ldots, X_n\)</span> sono variabili casuali indipendenti e identicamente distribuite (i.i.d.),</li>
<li>
<span class="math inline">\(\mu\)</span> è la media teorica,</li>
<li>
<span class="math inline">\(\varepsilon\)</span> è un numero positivo arbitrariamente piccolo.</li>
</ul></section><section id="forma-forte-della-legge-dei-grandi-numeri" class="level3" data-number="10.4.3"><h3 data-number="10.4.3" class="anchored" data-anchor-id="forma-forte-della-legge-dei-grandi-numeri">
<span class="header-section-number">10.4.3</span> Forma forte della Legge dei Grandi Numeri</h3>
<p>La <em>forma forte</em> della LGN, sviluppata successivamente da matematici come Kolmogorov, è un enunciato più potente. Essa stabilisce che la media campionaria converge <em>quasi sicuramente</em> alla media teorica. Questo implica che, con probabilità 1, la media osservata si avvicina indefinitamente al valore teorico man mano che il numero di prove tende all’infinito. Formalmente:</p>
<p><span class="math display">\[
P\left(\lim_{{n \to \infty}} \frac{1}{n} \sum_{i=1}^n X_i = \mu\right) = 1.
\]</span></p>
</section><section id="importanza-e-critiche" class="level3" data-number="10.4.4"><h3 data-number="10.4.4" class="anchored" data-anchor-id="importanza-e-critiche">
<span class="header-section-number">10.4.4</span> Importanza e critiche</h3>
<p>La Legge dei Grandi Numeri è fondamentale per garantire la validità delle stime empiriche, ma la sua applicazione pratica richiede attenzione. Ad esempio, in psicologia, la raccolta di un numero sufficiente di osservazioni può essere costosa o difficile, specialmente quando si studiano fenomeni rari o popolazioni specifiche. Inoltre, l’assunzione di indipendenza e identica distribuzione delle osservazioni potrebbe non essere sempre realistica in contesti applicativi complessi. Nonostante queste sfide, la LGN rimane un principio essenziale per comprendere come i dati empirici possano avvicinarsi alle proprietà teoriche di una popolazione.</p>
</section></section><section id="teorema-del-limite-centrale" class="level2" data-number="10.5"><h2 data-number="10.5" class="anchored" data-anchor-id="teorema-del-limite-centrale">
<span class="header-section-number">10.5</span> Teorema del Limite Centrale</h2>
<p>Oltre alla convergenza, un ulteriore risultato importante è che la distribuzione di <span class="math inline">\(\bar{X}_n\)</span> <em>si approssima alla normale</em> man mano che <span class="math inline">\(n\)</span> cresce, anche se i singoli <span class="math inline">\(X_i\)</span> non sono distribuiti normalmente.</p>
<div id="thm-" class="theorem">
<p><span class="theorem-title"><strong>Teorema 10.1</strong></span> Se <span class="math inline">\(X_1, X_2, \ldots, X_n\)</span> sono variabili iid con media <span class="math inline">\(\mu\)</span> e deviazione standard <span class="math inline">\(\sigma\)</span>, la distribuzione di</p>
<p><span class="math display">\[
\bar{X}_n = \frac{1}{n}\sum_{i=1}^n X_i
\]</span> diventa approssimativamente normale con media <span class="math inline">\(\mu\)</span> e deviazione standard <span class="math inline">\(\tfrac{\sigma}{\sqrt{n}}\)</span> quando <span class="math inline">\(n\)</span> è sufficientemente grande.</p>
</div>
<p>Per il caso 0-1 (presenza/assenza di un tratto), <span class="math inline">\(\bar{X}\)</span> è quindi circa normale con media <span class="math inline">\(p\)</span> e varianza <span class="math inline">\(\frac{p(1-p)}{n}\)</span>. Il TLC consente, tra l’altro, di costruire intervalli di confidenza e di calcolare probabilità che la stima si discosti di una certa quantità dal vero valore.</p>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Esempio 10.1</strong></span> Per visualizzare il Teorema del Limite Centrale (TLC) in azione, possiamo condurre una simulazione. Immaginiamo una popolazione distribuita in modo uniforme. Estraiamo 300 campioni di dimensione <span class="math inline">\(n = 30\)</span> da questa popolazione e osserviamo come la distribuzione campionaria delle medie di questi campioni converga a una distribuzione normale. Questa simulazione fornirà un’illustrazione concreta dell’efficacia del TLC nell’approssimare distribuzioni reali.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Impostiamo il seed per la riproducibilità dei risultati</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">42</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Generiamo una popolazione con distribuzione uniforme</span></span>
<span><span class="va">population</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span><span class="fl">5000</span>, min <span class="op">=</span> <span class="fl">0</span>, max <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Passo 1: Visualizziamo l'istogramma della popolazione utilizzando ggplot2</span></span>
<span><span class="fu">ggplot</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">population</span><span class="op">)</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">population</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_histogram</span><span class="op">(</span></span>
<span>    <span class="fu">aes</span><span class="op">(</span>y <span class="op">=</span> <span class="fu">after_stat</span><span class="op">(</span><span class="va">density</span><span class="op">)</span><span class="op">)</span>,</span>
<span>    bins <span class="op">=</span> <span class="fl">30</span></span>
<span>  <span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Valore"</span>, y <span class="op">=</span> <span class="st">"Densità"</span><span class="op">)</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="09_sampling_distr_files/figure-html/unnamed-chunk-13-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:85.0%"></p>
</figure>
</div>
</div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Passo 2 e 3: Estraiamo campioni casuali e calcoliamo le medie campionarie</span></span>
<span><span class="va">sample_size</span> <span class="op">&lt;-</span> <span class="fl">30</span></span>
<span><span class="va">num_samples</span> <span class="op">&lt;-</span> <span class="fl">300</span></span>
<span></span>
<span><span class="co"># Vettore vuoto per memorizzare le medie campionarie</span></span>
<span><span class="va">sample_means</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">num_samples</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="co"># Estraiamo un campione casuale</span></span>
<span>  <span class="va">sample</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="va">population</span>, size <span class="op">=</span> <span class="va">sample_size</span>, replace <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="co"># Calcoliamo la media del campione</span></span>
<span>  <span class="va">sample_means</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">sample</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Calcoliamo media e varianza delle medie campionarie</span></span>
<span><span class="va">x_bar</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">sample_means</span><span class="op">)</span></span>
<span><span class="va">std</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">sample_means</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="st">'Media e Varianza delle Medie Campionarie'</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] "Media e Varianza delle Medie Campionarie"</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">x_bar</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 0.501</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">std</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 0.00275</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Calcoliamo media e varianza della popolazione</span></span>
<span><span class="va">mu</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">population</span><span class="op">)</span></span>
<span><span class="va">sigma</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">population</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="st">'Media e Varianza della Popolazione'</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] "Media e Varianza della Popolazione"</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">mu</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 0.503</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="op">(</span><span class="va">sigma</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">/</span><span class="va">sample_size</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 0.00282</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Passo 4: Visualizziamo l'istogramma delle medie campionarie utilizzando ggplot2</span></span>
<span><span class="fu">ggplot</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">sample_means</span><span class="op">)</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">sample_means</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_histogram</span><span class="op">(</span></span>
<span>    <span class="fu">aes</span><span class="op">(</span>y <span class="op">=</span> <span class="fu">after_stat</span><span class="op">(</span><span class="va">density</span><span class="op">)</span><span class="op">)</span>,</span>
<span>    bins <span class="op">=</span> <span class="fl">30</span></span>
<span>  <span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">stat_function</span><span class="op">(</span></span>
<span>    fun <span class="op">=</span> <span class="va">dnorm</span>, args <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>mean <span class="op">=</span> <span class="va">x_bar</span>, sd <span class="op">=</span> <span class="va">std</span><span class="op">)</span>, color <span class="op">=</span> <span class="st">"black"</span>, size <span class="op">=</span> <span class="fl">1</span></span>
<span>  <span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span></span>
<span>    x <span class="op">=</span> <span class="st">"Media Campionaria"</span>, y <span class="op">=</span> <span class="st">"Densità"</span></span>
<span>  <span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme</span><span class="op">(</span>legend.position <span class="op">=</span> <span class="st">"top"</span><span class="op">)</span> </span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="09_sampling_distr_files/figure-html/unnamed-chunk-16-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:85.0%"></p>
</figure>
</div>
</div>
</div>
<p><strong>Spiegazione del codice e dei risultati</strong></p>
<ol type="1">
<li><p><strong>Popolazione</strong>: Abbiamo generato una popolazione di 5000 osservazioni distribuite uniformemente tra 0 e 1. La distribuzione uniforme è stata scelta perché è chiaramente non normale, il che rende più evidente l’effetto del TLC.</p></li>
<li><p><strong>Campionamento</strong>: Abbiamo estratto 300 campioni casuali, ciascuno di dimensione <span class="math inline">\(n = 30\)</span>, dalla popolazione. Per ogni campione, abbiamo calcolato la media.</p></li>
<li><p><strong>Distribuzione delle Medie Campionarie</strong>: Le medie dei campioni sono state raccolte e la loro distribuzione è stata visualizzata tramite un istogramma. Nonostante la popolazione originale non fosse normale, la distribuzione delle medie campionarie si avvicina a una distribuzione normale, dimostrando il TLC.</p></li>
<li><p><strong>Confronto tra Popolazione e Campioni</strong>: Abbiamo confrontato la media e la varianza della popolazione con quelle delle medie campionarie. Come previsto dal TLC, la media delle medie campionarie è molto vicina alla media della popolazione, mentre la varianza delle medie campionarie è ridotta di un fattore pari alla dimensione del campione (<span class="math inline">\(n = 30\)</span>).</p></li>
</ol>
<p>Questa simulazione illustra chiaramente come il TLC permetta di approssimare la distribuzione delle medie campionarie a una distribuzione normale, anche quando la popolazione originale non è normale. Questo risultato è fondamentale per molte applicazioni pratiche della statistica inferenziale.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Esempio 10.2</strong></span> Sebbene i risultati teorici siano solidi, è comune utilizzare la <em>simulazione Monte Carlo</em> per verificarne la validità in contesti pratici. Supponiamo, ad esempio, che la proporzione reale di individui che soffrono di un certo sintomo in una popolazione sia <span class="math inline">\(p = 0.45\)</span>. Possiamo simulare campioni di dimensione <span class="math inline">\(n\)</span> e calcolare la media campionaria <span class="math inline">\(\bar{X}\)</span> (ovvero la proporzione osservata in ciascun campione). Ripetendo questo processo molte volte, otteniamo una distribuzione empirica delle <span class="math inline">\(\bar{X}\)</span>. Se l’approssimazione normale fornita dal Teorema del Limite Centrale (TLC) è valida, ci aspettiamo che:</p>
<ol type="1">
<li>La media delle <span class="math inline">\(\bar{X}\)</span> sia molto vicina al valore teorico <span class="math inline">\(p = 0.45\)</span>.</li>
<li>La varianza delle <span class="math inline">\(\bar{X}\)</span> sia approssimativamente uguale a <span class="math inline">\(p(1-p)/n\)</span>, come previsto dalla teoria.</li>
</ol>
<p>Un esempio di codice in R per questa simulazione è il seguente:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">p</span> <span class="op">&lt;-</span> <span class="fl">0.45</span>  <span class="co"># Proporzione reale nella popolazione</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">1000</span>  <span class="co"># Dimensione del campione</span></span>
<span><span class="va">B</span> <span class="op">&lt;-</span> <span class="fl">10000</span> <span class="co"># Numero di campioni simulati</span></span>
<span></span>
<span><span class="co"># Simulazione Monte Carlo: generiamo B campioni e calcoliamo le medie campionarie</span></span>
<span><span class="va">x_hat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">replicate</a></span><span class="op">(</span><span class="va">B</span>, <span class="op">{</span></span>
<span>  <span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span>, size <span class="op">=</span> <span class="va">n</span>, replace <span class="op">=</span> <span class="cn">TRUE</span>, prob <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span><span class="op">-</span><span class="va">p</span>, <span class="va">p</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span>
<span><span class="op">}</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Media delle medie campionarie (dovrebbe essere vicina a p)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">x_hat</span><span class="op">)</span>  <span class="co"># Risultato atteso: ~ 0.45</span></span>
<span><span class="co">#&gt; [1] 0.45</span></span>
<span></span>
<span><span class="co"># Deviazione standard delle medie campionarie (dovrebbe essere vicina a sqrt(p*(1-p)/n))</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">x_hat</span><span class="op">)</span>    <span class="co"># Risultato atteso: ~ sqrt(0.45 * 0.55 / 1000)</span></span>
<span><span class="co">#&gt; [1] 0.0157</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Risultati attesi e interpretazione:</p>
<ul>
<li>
<strong>Media delle medie campionarie</strong>: Il valore medio di <code>x_hat</code> dovrebbe essere molto vicino a <span class="math inline">\(0.45\)</span>, confermando che la media campionaria è uno stimatore non distorto della proporzione reale <span class="math inline">\(p\)</span>.</li>
<li>
<strong>Deviazione standard delle medie campionarie</strong>: La deviazione standard di <code>x_hat</code> dovrebbe avvicinarsi a <span class="math inline">\(\sqrt{0.45 \times 0.55 / 1000} \approx 0.0157\)</span>, in linea con la formula teorica <span class="math inline">\(\sqrt{p(1-p)/n}\)</span>. Questo valore rappresenta l’incertezza associata alla stima della proporzione.</li>
</ul>
<p>Effetto della dimensione del campione:</p>
<ul>
<li>Aumentando la dimensione del campione <span class="math inline">\(n\)</span>, l’ampiezza della distribuzione delle medie campionarie (e quindi l’incertezza di <span class="math inline">\(\bar{X}\)</span>) diminuisce. Questo è coerente con la teoria, poiché la varianza delle medie campionarie è inversamente proporzionale a <span class="math inline">\(n\)</span>. In altre parole, campioni più grandi forniscono stime più precise del parametro della popolazione.</li>
</ul>
<p>Questa simulazione dimostra concretamente come il Teorema del Limite Centrale garantisca che, anche per popolazioni non normali (come in questo caso, dove i dati sono binari), la distribuzione delle medie campionarie si avvicini a una distribuzione normale con media <span class="math inline">\(p\)</span> e varianza <span class="math inline">\(p(1-p)/n\)</span>, purché <span class="math inline">\(n\)</span> sia sufficientemente grande.</p>
</div>
<section id="margine-di-errore-e-intervalli-di-confidenza" class="level3" data-number="10.5.1"><h3 data-number="10.5.1" class="anchored" data-anchor-id="margine-di-errore-e-intervalli-di-confidenza">
<span class="header-section-number">10.5.1</span> Margine di errore e intervalli di confidenza</h3>
<p>Se <span class="math inline">\(\bar{X}\)</span> è approssimato da <span class="math inline">\(\mathcal{N}(p, \frac{p(1-p)}{n})\)</span>, allora <span class="math display">\[
Z = \frac{\bar{X} - p}{\sqrt{p(1-p)/n}}
\]</span> segue (approssimativamente) la distribuzione normale standard <span class="math inline">\(\mathcal{N}(0,1)\)</span>. In pratica, non conoscendo <span class="math inline">\(p\)</span>, possiamo sostituirlo con <span class="math inline">\(\bar{X}\)</span> nello stimatore di errore standard (<span class="math inline">\(\mathrm{plug\text{-}in}\)</span>):</p>
<p><span class="math display">\[
\hat{\mathrm{SE}}(\bar{X}) = \sqrt{\frac{\bar{X}(1-\bar{X})}{n}}.
\]</span> Spesso si costruisce un intervallo di confidenza approssimato al 95% come:</p>
<p><span class="math display">\[
\bar{X} \,\pm\, 1.96 \times \hat{\mathrm{SE}}(\bar{X}),
\]</span> dove 1.96 deriva dal fatto che circa il 95% della distribuzione normale standard sta nell’intervallo <span class="math inline">\([-1.96,+1.96]\)</span>. Questo intervallo rappresenta la fascia di incertezza attorno alla stima, che si restringe all’aumentare di <span class="math inline">\(n\)</span>.</p>
</section></section><section id="oltre-la-media-altre-distribuzioni-campionarie" class="level2" data-number="10.6"><h2 data-number="10.6" class="anchored" data-anchor-id="oltre-la-media-altre-distribuzioni-campionarie">
<span class="header-section-number">10.6</span> Oltre la media: altre distribuzioni campionarie</h2>
<p>Finora ci siamo concentrati sulla <em>media campionaria</em> (o proporzione), ma in molti casi di interesse psicologico o più in generale statistico, potremmo voler studiare <em>altre</em> statistiche tratte da un campione. Due esempi importanti sono il <em>massimo campionario</em> (utile per analisi di eventi estremi, punteggi massimi nei test, tempi di reazione record, ecc.) e la <em>varianza campionaria</em> (fondamentale per misurare la variabilità dei punteggi in un test psicometrico, ad esempio).</p>
<section id="massimo-campionario" class="level3" data-number="10.6.1"><h3 data-number="10.6.1" class="anchored" data-anchor-id="massimo-campionario">
<span class="header-section-number">10.6.1</span> Massimo campionario</h3>
<p>Quando siamo interessati a misurare la performance “estrema” di un gruppo (ad esempio il punteggio più elevato in un test cognitivo, oppure la latenza di reazione più <em>veloce</em> se si ragiona in termini di minimi), la statistica di riferimento è il <em>massimo</em> (o il minimo) nel campione.</p>
<section id="teoria-e-concetti-chiave" class="level4" data-number="10.6.1.1"><h4 data-number="10.6.1.1" class="anchored" data-anchor-id="teoria-e-concetti-chiave">
<span class="header-section-number">10.6.1.1</span> Teoria e concetti chiave</h4>
<ul>
<li><p><strong>Definizione</strong>: Dato un campione <span class="math inline">\(\{X_1, X_2, \dots, X_n\}\)</span>, il <em>massimo campionario</em> è <span class="math display">\[
M = \max\{X_1, X_2, \dots, X_n\}.
\]</span> Questa variabile casuale dipende ovviamente dalla distribuzione dei singoli <span class="math inline">\(X_i\)</span>.</p></li>
<li>
<p><strong>Proprietà</strong>:</p>
<ul>
<li>La distribuzione di <span class="math inline">\(M\)</span> spesso risulta <em>asimmetrica</em> e “spostata a destra” rispetto alla distribuzione di partenza. Anche se la popolazione originaria fosse normalmente distribuita, la distribuzione del <em>massimo</em> non sarà normale.<br>
</li>
<li>Il valore atteso <span class="math inline">\(E[M]\)</span> supera la media <span class="math inline">\(\mu\)</span> della popolazione perché, fra i <span class="math inline">\(n\)</span> individui osservati, “vince” sempre il più grande.</li>
</ul>
</li>
<li>
<p><strong>Implicazioni pratiche</strong>:</p>
<ul>
<li>Analizzare i massimi (o i minimi) è cruciale nello studio di <em>fenomeni estremi</em> (per esempio, individuare il picco di stress in un compito cognitivo o la più alta temperatura registrata in una sperimentazione ambientale).</li>
<li>La cosiddetta <em>teoria degli estremi</em> si fonda proprio sull’analisi di come i massimi (o minimi) si distribuiscono al crescere di <span class="math inline">\(n\)</span>. Questa ha applicazioni in diverse discipline: dalla psicologia (prestazione massima) all’ingegneria (carichi estremi) fino alla finanza (rischi estremi).</li>
</ul>
</li>
</ul>
<div class="callout callout-style-simple callout-note no-icon callout-titled" title="Esercizio">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Esercizio
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Nel seguente esempio, simuliamo 10.000 esperimenti. In ognuno:</p>
<ol type="1">
<li>Generiamo <em>5 osservazioni</em> da una popolazione normale con media <span class="math inline">\(\mu = 100\)</span> e deviazione standard <span class="math inline">\(\sigma = 15\)</span>.<br>
</li>
<li>Ne calcoliamo il <em>massimo campionario</em>.</li>
</ol>
<p>Infine, confrontiamo la distribuzione di questi massimi con la densità della distribuzione di partenza (cioè la normale <span class="math inline">\(\mathcal{N}(100, 15^2)\)</span>).</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Impostazioni iniziali</span></span>
<span><span class="va">mu</span> <span class="op">&lt;-</span> <span class="fl">100</span></span>
<span><span class="va">sigma</span> <span class="op">&lt;-</span> <span class="fl">15</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="va">mu</span> <span class="op">-</span> <span class="fl">3</span> <span class="op">*</span> <span class="va">sigma</span>, <span class="va">mu</span> <span class="op">+</span> <span class="fl">3</span> <span class="op">*</span> <span class="va">sigma</span>, length.out <span class="op">=</span> <span class="fl">100</span><span class="op">)</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">x</span>, mean <span class="op">=</span> <span class="va">mu</span>, sd <span class="op">=</span> <span class="va">sigma</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Simulazione di 10.000 esperimenti con campioni di 5 osservazioni</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span>  <span class="co"># Per riproducibilità</span></span>
<span><span class="va">sample_maxes</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">replicate</a></span><span class="op">(</span><span class="fl">10000</span>, <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">5</span>, mean <span class="op">=</span> <span class="va">mu</span>, sd <span class="op">=</span> <span class="va">sigma</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Creiamo un data frame per il grafico</span></span>
<span><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>SampleMaxes <span class="op">=</span> <span class="va">sample_maxes</span><span class="op">)</span></span>
<span><span class="va">density_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="va">y</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Grafico con ggplot2</span></span>
<span><span class="fu">ggplot</span><span class="op">(</span><span class="va">data</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">SampleMaxes</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_histogram</span><span class="op">(</span></span>
<span>    <span class="fu">aes</span><span class="op">(</span>y <span class="op">=</span> <span class="fu">after_stat</span><span class="op">(</span><span class="va">density</span><span class="op">)</span><span class="op">)</span>,</span>
<span>    bins <span class="op">=</span> <span class="fl">30</span>,</span>
<span>    alpha <span class="op">=</span> <span class="fl">0.7</span></span>
<span>  <span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_line</span><span class="op">(</span>data <span class="op">=</span> <span class="va">density_data</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="va">y</span><span class="op">)</span>, size <span class="op">=</span> <span class="fl">1</span>, color <span class="op">=</span> <span class="st">"black"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span></span>
<span>    x <span class="op">=</span> <span class="st">"Massimo campionario"</span>,</span>
<span>    y <span class="op">=</span> <span class="st">"Densità"</span></span>
<span>  <span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme</span><span class="op">(</span></span>
<span>    plot.title <span class="op">=</span> <span class="fu">element_text</span><span class="op">(</span>hjust <span class="op">=</span> <span class="fl">0.5</span>, face <span class="op">=</span> <span class="st">"bold"</span><span class="op">)</span>,</span>
<span>    plot.subtitle <span class="op">=</span> <span class="fu">element_text</span><span class="op">(</span>hjust <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span></span>
<span>  <span class="op">)</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="09_sampling_distr_files/figure-html/unnamed-chunk-18-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:85.0%"></p>
</figure>
</div>
</div>
</div>
<p><strong>Osservazioni</strong>:</p>
<ul>
<li>L’istogramma, che rappresenta la distribuzione dei massimi campionari, <em>è spostato a destra</em> rispetto alla distribuzione della popolazione (tracciata in rosso).</li>
<li>Ciò evidenzia che <span class="math inline">\(M\)</span> tende a fornire valori <em>più alti</em> della media <span class="math inline">\(\mu = 100\)</span>. Se ripetessimo l’esperimento con campioni di dimensione maggiore di 5, questo effetto si accentuerebbe ulteriormente.</li>
</ul>
</div>
</div>
</div>
</section></section><section id="varianza-campionaria" class="level3" data-number="10.6.2"><h3 data-number="10.6.2" class="anchored" data-anchor-id="varianza-campionaria">
<span class="header-section-number">10.6.2</span> 2. Varianza campionaria</h3>
<p>Lo studio della <em>varianza</em> (o in generale della variabilità) è un altro esempio cruciale in contesti psicologici. Se vogliamo descrivere quanto differiscono i punteggi di un test di personalità, o di un test cognitivo, non basta guardare solo alla media campionaria: ci interessa anche la dispersione.</p>
<section id="teoria-e-concetti-chiave-1" class="level4" data-number="10.6.2.1"><h4 data-number="10.6.2.1" class="anchored" data-anchor-id="teoria-e-concetti-chiave-1">
<span class="header-section-number">10.6.2.1</span> Teoria e concetti chiave</h4>
<ul>
<li><p><strong>Stima della varianza</strong>:<br>
Stimare la varianza <span class="math inline">\(\sigma^2\)</span> di una popolazione non è banale. La formula <span class="math display">\[
S^2 = \frac{1}{n} \sum_{i=1}^n (Y_i - \bar{Y})^2
\]</span> tende a <em>sottostimare</em> <span class="math inline">\(\sigma^2\)</span>. Per ottenere uno <em>stimatore non distorto</em>, si usa invece: <span class="math display">\[
S^2 = \frac{1}{n-1} \sum_{i=1}^n (Y_i - \bar{Y})^2.
\]</span> L’uso di <span class="math inline">\(n-1\)</span> serve a correggere la perdita di un grado di libertà (poiché <span class="math inline">\(\bar{Y}\)</span> è calcolata sui dati) e garantisce che <span class="math inline">\(E[S^2] = \sigma^2\)</span>.</p></li>
<li><p><strong>Concetto di distorsione</strong>:<br>
Chiamiamo uno stimatore <span class="math inline">\(\hat{\theta}\)</span> <em>non distorto</em> se il suo valore atteso è uguale al parametro vero <span class="math inline">\(\theta\)</span>: <span class="math inline">\(E[\hat{\theta}] = \theta\)</span>. Con la formula a denominatore <span class="math inline">\(n-1\)</span>, la varianza campionaria risulta appunto non distorta.</p></li>
</ul>
<div class="callout callout-style-simple callout-note no-icon callout-titled" title="Esercizio">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Esercizio
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Simuliamo 10.000 esperimenti, ognuno con <span class="math inline">\(n=5\)</span> osservazioni generate da <span class="math inline">\(\mathcal{N}(100, 15^2)\)</span>. Per ciascun campione, calcoliamo: 1. La varianza “distorta” <span class="math inline">\(\frac{1}{n}\sum_i (X_i - \bar{X})^2\)</span>. 2. La varianza “corretta” con <span class="math inline">\(n-1\)</span>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span>  <span class="co"># Per riproducibilità</span></span>
<span></span>
<span><span class="co"># Funzione per calcolare varianze con n e con n-1</span></span>
<span><span class="va">calc_vars</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">n</span> <span class="op">=</span> <span class="fl">5</span>, <span class="va">mu</span> <span class="op">=</span> <span class="fl">100</span>, <span class="va">sigma</span> <span class="op">=</span> <span class="fl">15</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">sample_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span>, mean <span class="op">=</span> <span class="va">mu</span>, sd <span class="op">=</span> <span class="va">sigma</span><span class="op">)</span></span>
<span>  <span class="va">var_n</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="op">(</span><span class="va">sample_data</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">sample_data</span><span class="op">)</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span> <span class="op">/</span> <span class="va">n</span></span>
<span>  <span class="va">var_n_minus_1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/cor.html">var</a></span><span class="op">(</span><span class="va">sample_data</span><span class="op">)</span>  <span class="co"># In R, var() usa di default n-1</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">var_n</span>, <span class="va">var_n_minus_1</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Simuliamo 10.000 campioni</span></span>
<span><span class="va">B</span> <span class="op">&lt;-</span> <span class="fl">10000</span></span>
<span><span class="va">vars_matrix</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">replicate</a></span><span class="op">(</span><span class="va">B</span>, <span class="fu">calc_vars</span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">sample_vars_n</span> <span class="op">&lt;-</span> <span class="va">vars_matrix</span><span class="op">[</span><span class="fl">1</span>, <span class="op">]</span></span>
<span><span class="va">sample_vars_n_minus_1</span> <span class="op">&lt;-</span> <span class="va">vars_matrix</span><span class="op">[</span><span class="fl">2</span>, <span class="op">]</span></span>
<span></span>
<span><span class="co"># Confrontiamo graficamente</span></span>
<span><span class="va">data_n</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>SampleVars <span class="op">=</span> <span class="va">sample_vars_n</span>, Type <span class="op">=</span> <span class="st">"Con n"</span><span class="op">)</span></span>
<span><span class="va">data_n_minus_1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>SampleVars <span class="op">=</span> <span class="va">sample_vars_n_minus_1</span>, Type <span class="op">=</span> <span class="st">"Con n-1"</span><span class="op">)</span></span>
<span><span class="va">combined_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">rbind</a></span><span class="op">(</span><span class="va">data_n</span>, <span class="va">data_n_minus_1</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">ggplot</span><span class="op">(</span><span class="va">combined_data</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">SampleVars</span>, color <span class="op">=</span> <span class="va">Type</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_density</span><span class="op">(</span>size <span class="op">=</span> <span class="fl">1.1</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span></span>
<span>    x <span class="op">=</span> <span class="st">"Varianza campionaria"</span>,</span>
<span>    y <span class="op">=</span> <span class="st">"Densità"</span></span>
<span>  <span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme</span><span class="op">(</span></span>
<span>    plot.title <span class="op">=</span> <span class="fu">element_text</span><span class="op">(</span>hjust <span class="op">=</span> <span class="fl">0.5</span>, face <span class="op">=</span> <span class="st">"bold"</span><span class="op">)</span>,</span>
<span>    plot.subtitle <span class="op">=</span> <span class="fu">element_text</span><span class="op">(</span>hjust <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span></span>
<span>  <span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">scale_color_manual</span><span class="op">(</span>values <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Con n"</span> <span class="op">=</span> <span class="st">"gray"</span>, <span class="st">"Con n-1"</span> <span class="op">=</span> <span class="st">"black"</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="09_sampling_distr_files/figure-html/unnamed-chunk-19-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:85.0%"></p>
</figure>
</div>
</div>
</div>
<p><strong>Osservazioni</strong>:</p>
<ul>
<li><p>La curva corrispondente a “Con <span class="math inline">\(n\)</span>” tende a sottostimare la varianza, mentre quella “Con <span class="math inline">\(n-1\)</span>” si centra meglio attorno a <span class="math inline">\(\sigma^2 = 15^2 = 225\)</span>.</p></li>
<li>
<p>Se verifichiamo le medie delle due distribuzioni:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">sample_vars_n</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 181</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">sample_vars_n_minus_1</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 226</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>troveremo che la prima è sensibilmente inferiore a 225, mentre la seconda si avvicina di più al valore vero.</p>
</li>
</ul>
</div>
</div>
</div>
<p>Sia il <em>massimo campionario</em> sia la <em>varianza campionaria</em> dimostrano come non tutte le distribuzioni campionarie ereditino le stesse proprietà della media. Nel caso del massimo, la variabile risulta spostata verso valori elevati e non segue una forma gaussiana; nel caso della varianza, si deve porre attenzione alla formula usata, per evitare distorsioni sistematiche.</p>
<p>In sintesi:</p>
<ol type="1">
<li>
<strong>Massimo campionario</strong>: utile per l’analisi di fenomeni estremi (o massimi prestazionali), con una distribuzione tipicamente asimmetrica.<br>
</li>
<li>
<strong>Varianza campionaria</strong>: richiede la <em>correzione di Bessel</em> (denominatore <span class="math inline">\(n-1\)</span>) per essere uno stimatore non distorto di <span class="math inline">\(\sigma^2\)</span>.</li>
</ol>
<p>Capire le proprietà di queste (e altre) distribuzioni campionarie consente allo sperimentatore di valutare correttamente le incertezze nelle stime, di evitare errori di interpretazione e di utilizzare gli stimatori più appropriati in base al tipo di fenomeno studiato.</p>
</section></section></section><section id="errore-standard-incertezza-inferenziale-e-bias" class="level2" data-number="10.7"><h2 data-number="10.7" class="anchored" data-anchor-id="errore-standard-incertezza-inferenziale-e-bias">
<span class="header-section-number">10.7</span> Errore standard, incertezza inferenziale e bias</h2>
<section id="errore-standard-e-incertezza" class="level3" data-number="10.7.1"><h3 data-number="10.7.1" class="anchored" data-anchor-id="errore-standard-e-incertezza">
<span class="header-section-number">10.7.1</span> Errore standard e incertezza</h3>
<p>L’<em>errore standard (SE)</em> è la misura di quanto una data statistica (ad esempio la media) può variare da un campione all’altro per pura casualità di campionamento. In un contesto psicologico, può essere usato per mostrare graficamente l’affidabilità di una misura. Esporre i risultati di un test psicometrico riportando solo la media, senza un’idea dell’errore standard o di un intervallo di confidenza, rischia di dare un’illusione di precisione non giustificata.</p>
</section><section id="bias-perché-non-basta-un-campione-grandissimo" class="level3" data-number="10.7.2"><h3 data-number="10.7.2" class="anchored" data-anchor-id="bias-perché-non-basta-un-campione-grandissimo">
<span class="header-section-number">10.7.2</span> Bias: perché non basta un campione grandissimo</h3>
<p>Aumentare la dimensione campionaria <span class="math inline">\(n\)</span> riduce l’errore standard, ma <em>non elimina</em> possibili bias sistematici (si veda, ad esempio, la <a href="https://statmodeling.stat.columbia.edu/2023/01/06/god-is-in-every-leaf-of-every-tree-bathroom-scale-edition/">disussione</a> fornita dal Andrew Gelman su questo tema). Ad esempio:</p>
<ul>
<li>Se i partecipanti più ansiosi evitano di partecipare allo studio (<em>bias di selezione</em>), la proporzione <span class="math inline">\(\bar{X}\)</span> sarà sistematicamente sottostimata.</li>
<li>Se qualcuno falsifica le risposte per desiderabilità sociale (<em>bias di risposta</em>), la media misurata può allontanarsi dal valore vero in maniera non corretta da un semplice aumento del campione.</li>
<li>Se lo strumento di misura (ad es. un questionario) è mal tarato o concettualmente scorretto, l’intero studio può soffrirne (<em>misurazione errata</em>).</li>
</ul>
<p>Quando è presente un bias, <em>nessun</em> aumento del numero di partecipanti potrà rimuoverlo: si otterranno stime molto “precise” (varianza piccola) ma sistematicamente lontane dal valore reale.</p>
<div class="callout callout-style-simple callout-note no-icon callout-titled" title="Nota bayesiana">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Nota bayesiana
</div>
</div>
<div class="callout-body-container callout-body">
<p>L’errore standard è una misura frequentista di precisione della stima. Nell’approccio bayesiano, la precisione si legge direttamente dalla dispersione della distribuzione a posteriori del parametro. Quindi il concetto di “quanto è precisa la stima” resta, ma lo esprimiamo in modo diverso.</p>
</div>
</div>
</section></section><section id="la-prospettiva-bayesiana" class="level2" data-number="10.8"><h2 data-number="10.8" class="anchored" data-anchor-id="la-prospettiva-bayesiana">
<span class="header-section-number">10.8</span> La prospettiva bayesiana</h2>
<p>Nelle sezioni precedenti abbiamo discusso il concetto di distribuzione campionaria da una prospettiva frequentista. Questo approccio considera il parametro della popolazione (come la proporzione <span class="math inline">\(p\)</span> o la media <span class="math inline">\(\mu\)</span>) come una quantità fissa, sebbene sconosciuta. L’incertezza deriva esclusivamente dalla variabilità del processo di campionamento ripetuto.</p>
<p>La statistica bayesiana, invece, offre una prospettiva complementare e interpretativamente diversa:</p>
<ul>
<li><p><strong>Parametri come variabili casuali</strong>: Nel quadro bayesiano, i parametri non sono considerati quantità fisse, ma variabili aleatorie descritte da una distribuzione di probabilità. Questa distribuzione riflette il grado di convinzione (o conoscenza) del ricercatore rispetto al valore del parametro, prima di osservare i dati (distribuzione a priori), e viene aggiornata alla luce dei dati osservati per produrre una distribuzione a posteriori.</p></li>
<li><p><strong>Distribuzione a posteriori</strong>: Dopo aver osservato i dati campionari, la distribuzione a posteriori descrive completamente l’incertezza sul parametro. A differenza dell’approccio frequentista, in cui l’incertezza è quantificata considerando ripetizioni ipotetiche dell’esperimento, l’incertezza bayesiana riflette direttamente lo stato attuale della nostra conoscenza.</p></li>
</ul>
<div class="callout callout-style-simple callout-note no-icon callout-titled" title="Esercizio">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-7-contents" aria-controls="callout-7" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Esercizio
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-7" class="callout-7-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Riprendiamo l’esempio precedente sulla proporzione di adulti che manifestano un certo sintomo ansioso. Consideriamo che prima di raccogliere i dati dal campione, abbiamo una credenza iniziale (a priori) sulla proporzione <span class="math inline">\(p\)</span>. Potremmo assumere una distribuzione a priori Beta(<span class="math inline">\(\alpha\)</span>, <span class="math inline">\(\beta\)</span>), scelta comunemente perché flessibile e comoda da aggiornare (si veda il <a href="14_cont_rv_distr.html" class="quarto-xref"><span>Capitolo 15</span></a>):</p>
<p><span class="math display">\[
p \sim \text{Beta}(\alpha, \beta).
\]</span></p>
<p>Supponiamo ora di estrarre un campione di dimensione <span class="math inline">\(N\)</span> e osservare <span class="math inline">\(y\)</span> individui che manifestano il sintomo. La distribuzione a posteriori sarà allora:</p>
<p><span class="math display">\[
p \mid y, N \sim \text{Beta}(\alpha + y, \beta + N - y) .
\]</span></p>
<p>Questa distribuzione incorpora sia le informazioni iniziali sia i dati osservati (si veda il <span class="quarto-unresolved-ref">?sec-bayesian-inference-conjugate-1</span>). Aumentando il numero di osservazioni, l’influenza della distribuzione a priori si riduce, e la distribuzione a posteriori converge verso il valore effettivo di <span class="math inline">\(p\)</span>, riflettendo un comportamento analogo alla Legge dei Grandi Numeri.</p>
<p><strong>Interpretazione bayesiana dei risultati.</strong></p>
<ul>
<li><p><em>Intervallo di credibilità</em>: Al posto dell’intervallo di confidenza frequentista (si veda il <span class="quarto-unresolved-ref">?sec-frequentism-confidence-intervals</span>), che descrive la probabilità di copertura considerando ripetizioni ipotetiche del campionamento, il bayesiano utilizza un intervallo di credibilità (si veda il <span class="quarto-unresolved-ref">?sec-bayesian-inference-summary-posterior</span>), il quale indica direttamente l’intervallo entro cui il parametro cade con una data probabilità, date le osservazioni effettivamente raccolte.</p></li>
<li><p><em>Convergenza della distribuzione a posteriori</em>: In analogia alla Legge dei Grandi Numeri e al Teorema del Limite Centrale, anche nel quadro bayesiano, all’aumentare della dimensione del campione, la distribuzione a posteriori diventa sempre più concentrata intorno al parametro vero, riducendo l’incertezza.</p></li>
</ul>
</div>
</div>
</div>
</section><section id="riflessioni-conclusive" class="level2 unnumbered unlisted"><h2 class="unnumbered unlisted anchored" data-anchor-id="riflessioni-conclusive">Riflessioni conclusive</h2>
<p>Il percorso qui delineato mette in luce come, nell’ambito dell’inferenza frequentista, risulti fondamentale operare una chiara distinzione tra due piani concettuali: da un lato la popolazione e i suoi parametri — entità teoriche, come la vera proporzione di un sintomo psicologico o la media di un punteggio nella popolazione generale, che per loro natura non sono direttamente osservabili — e dall’altro il campione e le sue stime, ovvero i dati empirici effettivamente raccolti e le statistiche — come la media campionaria — da essi calcolate.</p>
<p>La nozione di distribuzione campionaria, in particolare per statistiche quali la media o la proporzione, consente di comprendere alcune proprietà cruciali dell’inferenza statistica. La media campionaria, ad esempio, è uno stimatore non distorto, il cui valore atteso coincide con il parametro della popolazione che intende stimare. La sua precisione, definita come l’inverso della varianza, aumenta al crescere della numerosità campionaria. Inoltre, grazie al Teorema del Limite Centrale, è possibile approssimare la distribuzione della media campionaria a una normale per campioni sufficientemente ampi, fatto che costituisce la base per la costruzione di intervalli di confidenza e per la valutazione probabilistica delle stime. È altrettanto importante notare come l’errore standard quantifichi esclusivamente la variabilità attribuibile al campionamento, mentre eventuali bias sistematici — legati per esempio al disegno sperimentale o alla misura — permangono anche al crescere della dimensione campionaria.</p>
<p>Complementare alla prospettiva frequentista è l’approccio bayesiano, il quale concepisce l’incertezza inferenziale non solo in termini di variabilità campionaria, ma come riflesso diretto del nostro stato di conoscenza. Tale stato viene rappresentato esplicitamente mediante la distribuzione a posteriori, che aggiorna le credenze iniziali alla luce dei nuovi dati. Questa caratteristica rende il framework bayesiano particolarmente adatto a contesti applicativi in psicologia, dove l’obiettivo è spesso quello di revisionare in modo incrementale la comprensione di un fenomeno man mano che nuove evidenze diventano disponibili.</p>
<p>In sintesi, una ricerca psicologica rigorosa richiede la consapevolezza di due fonti distinte di incertezza: quella casuale, riconducibile alla variabilità del campionamento e quantificabile attraverso strumenti come l’errore standard, e quella sistematica, riconducibile a distorsioni metodologiche o concettuali. Solo un’interpretazione che tenga conto di entrambe queste componenti permette di valutare con appropriatezza la solidità delle conclusioni tratte dai dati, sia in ambito teorico sia in setting applicativi e clinici.</p>
<div class="callout callout-style-simple callout-important no-icon callout-titled" title="Problemi">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-8-contents" aria-controls="callout-8" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Problemi
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-8" class="callout-8-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Esercizi sulla distribuzione campionaria sono disponibili sulla seguente <a href="https://stats.libretexts.org/Bookshelves/Introductory_Statistics/Introductory_Statistics_(Shafer_and_Zhang)/06%3A_Sampling_Distributions/6.E%3A_Sampling_Distributions_(Exercises)">pagina web</a>.</p>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-note no-icon callout-titled" title="Informazioni sull'ambiente di sviluppo">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-9-contents" aria-controls="callout-9" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Informazioni sull’ambiente di sviluppo
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-9" class="callout-9-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/sessionInfo.html">sessionInfo</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">#&gt; R version 4.5.1 (2025-06-13)</span></span>
<span><span class="co">#&gt; Platform: aarch64-apple-darwin20</span></span>
<span><span class="co">#&gt; Running under: macOS Sequoia 15.6.1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Matrix products: default</span></span>
<span><span class="co">#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib </span></span>
<span><span class="co">#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; locale:</span></span>
<span><span class="co">#&gt; [1] C/UTF-8/C/C/C/C</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; time zone: Europe/Rome</span></span>
<span><span class="co">#&gt; tzcode source: internal</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; attached base packages:</span></span>
<span><span class="co">#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; other attached packages:</span></span>
<span><span class="co">#&gt;  [1] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      </span></span>
<span><span class="co">#&gt;  [4] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     </span></span>
<span><span class="co">#&gt;  [7] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     </span></span>
<span><span class="co">#&gt; [10] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         </span></span>
<span><span class="co">#&gt; [13] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           </span></span>
<span><span class="co">#&gt; [16] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        </span></span>
<span><span class="co">#&gt; [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         </span></span>
<span><span class="co">#&gt; [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            </span></span>
<span><span class="co">#&gt; [25] here_1.0.1           </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; loaded via a namespace (and not attached):</span></span>
<span><span class="co">#&gt;  [1] svUnit_1.0.8          tidyselect_1.2.1      farver_2.1.2         </span></span>
<span><span class="co">#&gt;  [4] fastmap_1.2.0         TH.data_1.1-4         tensorA_0.36.2.1     </span></span>
<span><span class="co">#&gt;  [7] digest_0.6.37         timechange_0.3.0      estimability_1.5.1   </span></span>
<span><span class="co">#&gt; [10] lifecycle_1.0.4       survival_3.8-3        magrittr_2.0.3       </span></span>
<span><span class="co">#&gt; [13] compiler_4.5.1        rlang_1.1.6           tools_4.5.1          </span></span>
<span><span class="co">#&gt; [16] knitr_1.50            labeling_0.4.3        bridgesampling_1.1-2 </span></span>
<span><span class="co">#&gt; [19] htmlwidgets_1.6.4     curl_7.0.0            pkgbuild_1.4.8       </span></span>
<span><span class="co">#&gt; [22] RColorBrewer_1.1-3    abind_1.4-8           multcomp_1.4-28      </span></span>
<span><span class="co">#&gt; [25] withr_3.0.2           purrr_1.1.0           grid_4.5.1           </span></span>
<span><span class="co">#&gt; [28] stats4_4.5.1          colorspace_2.1-1      xtable_1.8-4         </span></span>
<span><span class="co">#&gt; [31] inline_0.3.21         emmeans_1.11.2-8      scales_1.4.0         </span></span>
<span><span class="co">#&gt; [34] MASS_7.3-65           cli_3.6.5             mvtnorm_1.3-3        </span></span>
<span><span class="co">#&gt; [37] rmarkdown_2.29        ragg_1.5.0            generics_0.1.4       </span></span>
<span><span class="co">#&gt; [40] RcppParallel_5.1.11-1 cachem_1.1.0          stringr_1.5.1        </span></span>
<span><span class="co">#&gt; [43] splines_4.5.1         parallel_4.5.1        vctrs_0.6.5          </span></span>
<span><span class="co">#&gt; [46] V8_7.0.0              Matrix_1.7-4          sandwich_3.1-1       </span></span>
<span><span class="co">#&gt; [49] jsonlite_2.0.0        arrayhelpers_1.1-0    systemfonts_1.2.3    </span></span>
<span><span class="co">#&gt; [52] glue_1.8.0            codetools_0.2-20      distributional_0.5.0 </span></span>
<span><span class="co">#&gt; [55] lubridate_1.9.4       stringi_1.8.7         gtable_0.3.6         </span></span>
<span><span class="co">#&gt; [58] QuickJSR_1.8.0        htmltools_0.5.8.1     Brobdingnag_1.2-9    </span></span>
<span><span class="co">#&gt; [61] R6_2.6.1              textshaping_1.0.3     rprojroot_2.1.1      </span></span>
<span><span class="co">#&gt; [64] evaluate_1.0.5        lattice_0.22-7        backports_1.5.0      </span></span>
<span><span class="co">#&gt; [67] memoise_2.0.1         broom_1.0.9           snakecase_0.11.1     </span></span>
<span><span class="co">#&gt; [70] rstantools_2.5.0      coda_0.19-4.1         gridExtra_2.3        </span></span>
<span><span class="co">#&gt; [73] nlme_3.1-168          checkmate_2.3.3       xfun_0.53            </span></span>
<span><span class="co">#&gt; [76] zoo_1.8-14            pkgconfig_2.0.3</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</div>
</section><section id="bibliografia" class="level2 unnumbered unlisted"><h2 class="unnumbered unlisted anchored" data-anchor-id="bibliografia">Bibliografia</h2>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" data-line-spacing="2" role="list">
<div id="ref-hacking2006emergence" class="csl-entry" role="listitem">
Hacking, I. (2006). <em>The emergence of probability: A philosophical study of early ideas about probability, induction and statistical inference</em>. Cambridge University Press.
</div>
<div id="ref-schervish2014probability" class="csl-entry" role="listitem">
Schervish, M. J., &amp; DeGroot, M. H. (2014). <em>Probability and statistics</em> (Vol. 563). Pearson Education London, UK:
</div>
</div>
</section></main><!-- /main --><script>
document.body.classList.add('classic-book');
document.addEventListener('DOMContentLoaded', function() {
  const paragraphs = document.querySelectorAll('p');
  paragraphs.forEach(p => {
    if (p.textContent.length > 200) {
      p.style.hyphens = 'auto';
      p.style.hyphenateCharacter = '-';
    }
  });
  const headings = document.querySelectorAll('h1, h2, h3, h4, h5, h6');
  headings.forEach(h => {
    h.style.fontFeatureSettings = '"liga" 1, "dlig" 1, "smcp" 1';
  });
});
</script><script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copiato!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copiato!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/ccaudek\.github\.io\/utet-prob\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
            // default icon
            link.classList.add("external");
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="../../chapters/probability/08_expval_var.html" class="pagination-link" aria-label="Proprietà delle variabili casuali">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Proprietà delle variabili casuali</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../chapters/probability/10_joint_prob.html" class="pagination-link" aria-label="Probabilità congiunta">
        <span class="nav-page-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Probabilità congiunta</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer"><div class="nav-footer">
    <div class="nav-footer-left">
<p><strong>Probabilità per la psicologia</strong> — Modulo di richiamo del progetto UTET a supporto del manuale <em>Metodi bayesiani in psicologia</em>.</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/ccaudek/utet-prob/blob/main/chapters/probability/09_sampling_distr.qmd" class="toc-action"><i class="bi bi-github"></i>Mostra il codice</a></li><li><a href="https://github.com/ccaudek/utet-prob/issues/new" class="toc-action"><i class="bi empty"></i>Segnala un problema</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>Realizzato con <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>


<script src="../../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>