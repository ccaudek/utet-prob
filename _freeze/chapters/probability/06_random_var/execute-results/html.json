{
  "hash": "5be32b413430172399c214375551eae9",
  "result": {
    "engine": "knitr",
    "markdown": "# Variabili casuali {#sec-prob-random-var}\n\n::: {.epigraph}\n> “A random variable is a real valued function on the measure space X.”\n>\n> — **Paul R. Halmos**, *Measure Theory*.\n:::\n\n\n## Introduzione {.unnumbered .unlisted}\n\nFino ad ora abbiamo studiato le probabilità associate a eventi, come la possibilità di vincere il gioco di Monty Hall o di avere una rara condizione medica in seguito a un test positivo. Tuttavia, in molte situazioni pratiche vogliamo conoscere aspetti più dettagliati. Ad esempio, potremmo chiederci:\n\n- quanti tentativi occorrono affinché, in un gioco simile a Monty Hall, un concorrente vinca?\n- quanto durerà un determinato evento o condizione?\n- qual è la perdita attesa giocando d'azzardo con un dado sbilanciato per molte ore?\n\nPer rispondere a tali domande è necessario lavorare con le *variabili casuali*. In questo capitolo introdurremo il concetto di variabile casuale e ne analizzeremo le proprietà fondamentali.\n\n### Panoramica del capitolo {.unnumbered .unlisted}\n\n- Le definizioni e le caratteristiche delle variabili casuali discrete e continue, e le relative distribuzioni di probabilità;\n- Come calcolare e interpretare il valore atteso di variabili casuali, sia discrete che continue.\n- Determinare e comprendere la varianza e la deviazione standard di variabili casuali.\n\n::: {.callout-tip collapse=true}\n## Prerequisiti\n\nPer seguire al meglio questo capitolo, è consigliato aver letto i seguenti riferimenti:  \n\n- l'appendice @sec-apx-calculus;\n- il capitolo *Random Variables and Probability Distributions* in @kroese2025statistical;\n- il capitolo *Random variables and their distributions* in @blitzstein2019introduction;  \n- il capitolo *Random Variables and Distributions* in @schervish2014probability.\n:::\n\n::: {.callout-caution collapse=true title=\"Preparazione del Notebook\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhere::here(\"code\", \"_common.R\") |> \n  source()\n```\n:::\n\n:::\n\n\n## Definizione di variabile casuale\n\nUna *variabile casuale* è una funzione che associa ogni elemento di uno spazio campionario a un valore numerico. Questo strumento permette di trasformare esiti qualitativi (ad esempio, il risultato di un lancio di carte, come cuori, quadri, fiori, picche) in valori numerici, facilitando così l’analisi matematica.\n\n::: {#def-}  \nSia $S$ lo spazio campionario di un esperimento aleatorio. Una variabile casuale $X$ è una funzione  \n$$\nX: S \\longrightarrow \\mathbb{R},\n$$\nche associa ad ogni esito $s \\in S$ un numero reale $X(s)$.\n:::\n\n::: {.callout-note collapse=\"true\" title=\"Esempio\"}\nLanciamo due dadi equilibrati e annotiamo la somma dei valori delle loro facce. Ogni lancio genera una coppia di valori $(i,j)$, dove $i$ è il risultato del primo dado e $j$ il risultato del secondo dado. Lo spazio campionario completo dei possibili esiti è:\n\n$$\n\\Omega = \\{(1,1), (1,2), \\dots, (6,5), (6,6)\\}.\n$$\n\nDefiniamo una *variabile casuale* $X$ che associa ciascun esito $(i,j)$ alla somma dei valori ottenuti dai due dadi, cioè:\n\n$$\nX(i,j) = i + j.\n$$\n\nAd esempio, se il primo dado mostra 4 e il secondo dado mostra 4, allora l'esito è $(4,4)$ e la variabile casuale $X$ assume il valore 8.\n\n![La variabile aleatoria $X$ rappresenta la somma di due dadi [figura tratta da @kroese2025statistical].](../../figures/random_variable_definition.png){ width=70% }\n\nConsideriamo il valore specifico $X=8$: questo valore può essere ottenuto attraverso cinque diversi esiti dello spazio campionario: $(2,6), (3,5), (4,4), (5,3), (6,2)$. Indichiamo con $\\{X=8\\}$ l'insieme di questi esiti. Poiché tutti gli esiti in $\\Omega$ sono equiprobabili, possiamo calcolare la probabilità di ottenere una somma pari a 8 come:\n\n$$\nP(X=8) = \\frac{5}{36}.\n$$\n::: \n\n## Tipologie di variabili casuali\n\nLe variabili casuali si dividono in due categorie principali:\n\n### Variabili casuali discrete\n\nUna *variabile casuale discreta* assume un insieme finito o numerabile di valori. Gli esempi includono il numero di teste ottenute in lanci di moneta o la somma dei risultati di due dadi. Per queste variabili, la *funzione di massa di probabilità (PMF)* assegna a ciascun valore $x$ la probabilità $P(X = x)$.\n\n::: {#exm-}\nNel lancio di due dadi, la variabile $X$ (somma dei punti) può assumere valori interi da 2 a 12. La distribuzione di $X$ si ottiene contando i casi favorevoli per ciascun valore e dividendo per il numero totale di esiti (36).\n:::\n\n### Variabili casuali continue\n\nUna *variabile casuale continua* può assumere infiniti valori in un intervallo (ad esempio, l’altezza di una persona). In questo caso non si assegna una probabilità a un singolo valore (che risulterebbe essere zero), ma si definisce una *funzione di densità di probabilità (PDF)*, tale che l’integrale della funzione su un intervallo fornisce la probabilità che la variabile cada in quell’intervallo.\n\n::: {#exm-}\nConsidera una variabile $X$ che rappresenta l’altezza in centimetri. Invece di $P(X = 170)$, calcoliamo probabilità come $P(170 \\leq X \\leq 180)$ mediante l’integrale della PDF in quell’intervallo.\n:::\n\n## Notazione convenzionale\n\nNella teoria della probabilità si adotta una convenzione chiara per distinguere una variabile casuale dal suo valore osservato o realizzato:\n\n- la variabile casuale viene indicata con lettere maiuscole (es. $X$);\n- il valore specifico assunto dalla variabile casuale viene indicato con lettere minuscole (es. $x$).\n\nQuesta convenzione aiuta a evitare ambiguità, soprattutto quando si definiscono:\n\n- probabilità cumulative: $P(X \\leq x)$;\n- valore atteso: $E[X]$;\n- funzioni di densità o massa di probabilità: $f_X(x)$.\n\n## Variabili casuali multiple\n\nIn molti esperimenti, è utile considerare contemporaneamente più variabili casuali. Ad esempio, supponiamo di lanciare una moneta equilibrata tre volte. Definiamo tre variabili casuali indipendenti $X_1$, $X_2$ e $X_3$, ciascuna associata all'esito di un lancio:\n\n$$\nP(X_n = 1) = 0.5 \\quad (\\text{testa}), \\qquad P(X_n = 0) = 0.5 \\quad (\\text{croce}), \\quad n = 1, 2, 3.\n$$\n\nPossiamo poi definire una nuova variabile casuale derivata, ad esempio:\n\n$$\nZ = X_1 + X_2 + X_3,\n$$\n\nche rappresenta il numero totale di teste ottenute nei tre lanci. In questo scenario, $Z$ è una variabile casuale discreta che può assumere esclusivamente i valori 0, 1, 2 o 3.\n\n\n## Distribuzione di probabilità\n\n::: {#def-}\nLa *distribuzione di probabilità* di una variabile casuale descrive come le probabilità sono assegnate ai possibili valori (o intervalli di valori) della variabile.\n:::\n\n### Funzione di massa di probabilità (PMF) per variabili discrete\n\nPer una variabile casuale discreta $X$, la distribuzione è definita tramite la funzione di massa di probabilità (PMF), indicata con $f(x)$, dove:\n\n$$\nf(x) = P(X = x).\n$$\n\nNota la PMF, è possibile calcolare la probabilità di qualsiasi evento associato a $X$. Ad esempio, per un insieme $B$ di valori:\n\n$$\nP(X \\in B) = \\sum_{x \\in B} f(x).\n$$\n\n::: {.callout-note collapse=\"true\" title=\"Esempio\"}\nConsideriamo nuovamente il lancio di due dadi, definendo $X$ come la somma dei loro valori. La tabella seguente mostra chiaramente tutti i casi possibili, il numero di combinazioni per ogni somma, e la relativa probabilità:\n\n| $X$ | Casi Favorevoli                           | Numero di Casi | $P(X = x)$                      |\n|:---:|-------------------------------------------|:--------------:|---------------------------------|\n| 2   | $(1,1)$                                   | 1              | $\\frac{1}{36}$                  |\n| 3   | $(1,2), (2,1)$                            | 2              | $\\frac{2}{36} = \\frac{1}{18}$   |\n| 4   | $(1,3), (2,2), (3,1)$                     | 3              | $\\frac{3}{36} = \\frac{1}{12}$   |\n| 5   | $(1,4), (2,3), (3,2), (4,1)$              | 4              | $\\frac{4}{36} = \\frac{1}{9}$    |\n| 6   | $(1,5), (2,4), (3,3), (4,2), (5,1)$       | 5              | $\\frac{5}{36}$                  |\n| 7   | $(1,6), (2,5), (3,4), (4,3), (5,2), (6,1)$| 6              | $\\frac{6}{36} = \\frac{1}{6}$    |\n| 8   | $(2,6), (3,5), (4,4), (5,3), (6,2)$       | 5              | $\\frac{5}{36}$                  |\n| 9   | $(3,6), (4,5), (5,4), (6,3)$              | 4              | $\\frac{4}{36} = \\frac{1}{9}$    |\n| 10  | $(4,6), (5,5), (6,4)$                     | 3              | $\\frac{3}{36} = \\frac{1}{12}$   |\n| 11  | $(5,6), (6,5)$                            | 2              | $\\frac{2}{36} = \\frac{1}{18}$   |\n| 12  | $(6,6)$                                   | 1              | $\\frac{1}{36}$                  |\n\nPer esempio, la probabilità di ottenere una somma pari a 7 è $\\frac{1}{6}$ perché ci sono 6 combinazioni favorevoli su 36 possibili.\n:::\n\n### Funzione di distribuzione cumulativa (CDF)\n\n::: {#def-}\nLa *funzione di distribuzione cumulativa (CDF)* di una variabile casuale $X$ è definita come:\n$$\nF(x) = P(X \\leq x).\n$$\nLa CDF indica la probabilità che $X$ assuma valori minori o uguali a un valore specifico $x$.\n:::\n\n\n### Proprietà della CDF (funzione di ripartizione)\n\nLa CDF descrive la probabilità che una variabile casuale $X$ assuma un valore *minore o uguale* a $x$. Per capirla in psicologia (ad esempio, per analizzare dati di test, questionari, o esperimenti), bastano tre idee chiave:\n\n1. *Non diminuisce mai:*  \n   Se consideriamo valori $x$ sempre più grandi, la probabilità cumulata *non può diminuire*.  \n   - **Esempio:** Se la CDF a $x = 50$ in un test è $0.7$, a $x = 60$ sarà almeno $0.7$ (potrebbe salire, ma non scendere).  \n   - *Perché?* Aggiungendo nuovi risultati (es.: punteggi più alti), la probabilità totale può solo aumentare o restare uguale.\n\n2. *Estremi prevedibili:*  \n   - Per valori *molto bassi* (es.: $x \\to -\\infty$), la probabilità cumulata è *0*: non esistono punteggi infinitamente bassi.  \n   - Per valori *molto alti* (es.: $x \\to +\\infty$), la probabilità cumulata è **1**: tutti i possibili risultati sono inclusi.  \n   - **Esempio:** In una scala Likert da 1 a 5, la CDF a $x = 0$ è 0, e a $x = 10$ è 1.\n\n3. *Niente salti \"a sorpresa\" verso destra:*  \n   La CDF è costruita in modo che, se ci spostiamo di pochissimo a destra di un punto $x$, la probabilità cumulata *non crolla improvvisamente*.  \n   - **Esempio:**  \n     Supponiamo che in un questionario, il punteggio $x = 10$ corrisponda a una certa probabilità cumulata (es.: $0.8$). Se ci spostiamo di un millesimo a destra (es.: $x = 10.001$), la probabilità rimane $0.8$, a meno che $10.001$ non sia un punteggio valido.  \n   - *A cosa serve?* Garantisce coerenza: se un punteggio $x$ ha una certa probabilità, questa non viene \"persa\" spostandosi di poco a destra.\n\n\n### CDF per variabili discrete \n\nIn psicologia, spesso lavoriamo con dati discreti (es.: risposte a item di un test, come \"1 = Mai\" a \"5 = Sempre\"). In questi casi:  \n\n- La CDF si calcola *sommando le probabilità* di tutti i valori $\\leq x$.  \n- **Esempio:** Se in una scala da 1 a 5, il 30% degli studenti risponde 1 o 2, allora $F(2) = 0.3$.  \n- **Graficamente:** La CDF avrà \"gradini\" nei punti corrispondenti ai valori possibili (es.: 1, 2, 3, 4, 5).\n\n#### Perché serve saperlo?  \n\nQueste proprietà aiutano a:  \n\n1. Interpretare grafici cumulativi (es.: quanto è probabile che un partecipante abbia un punteggio $\\leq$ 20?).  \n2. Evitare errori logici (es.: non ha senso aspettarsi un calo della probabilità cumulata all’aumentare di $x$).  \n3. Leggere correttamente salti nei dati discreti (es.: un gradino in $x = 4$ indica un accumulo di probabilità in quel punto).\n\n::: {.callout-note collapse=\"true\" title=\"Esempio\"}\nRiprendendo l'esempio della variabile casuale $X$ definita come la somma di due dadi, possiamo riassumere PMF e CDF in una tabella unica:\n\n| $x$ | $P(X = x)$    | $F(x)$                       |\n|:---:|:-------------:|:-----------------------------:|\n| 2   | $\\frac{1}{36}$| $\\frac{1}{36}$                |\n| 3   | $\\frac{2}{36}$| $\\frac{3}{36}$                |\n| 4   | $\\frac{3}{36}$| $\\frac{6}{36}$                |\n| 5   | $\\frac{4}{36}$| $\\frac{10}{36}$               |\n| 6   | $\\frac{5}{36}$| $\\frac{15}{36}$               |\n| 7   | $\\frac{6}{36}$| $\\frac{21}{36}$               |\n| 8   | $\\frac{5}{36}$| $\\frac{26}{36}$               |\n| 9   | $\\frac{4}{36}$| $\\frac{30}{36}$               |\n| 10  | $\\frac{3}{36}$| $\\frac{33}{36}$               |\n| 11  | $\\frac{2}{36}$| $\\frac{35}{36}$               |\n| 12  | $\\frac{1}{36}$| $1$                           |\n:::\n\n### Simulazione della distribuzione di probabilità\n\nSpesso, anche se è possibile calcolare analiticamente la distribuzione di probabilità (come nel caso dei due dadi), può essere utile ottenere una stima empirica attraverso la simulazione. Questo approccio prevede di ripetere l’esperimento molte volte e di analizzare le frequenze relative dei risultati ottenuti.\n\n::: {.callout-note collapse=\"true\" title=\"Esempio\"}\nSimulazione del lancio di due dadi in R.\n\n**1. Simulare il lancio di un singolo dado**\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Funzione per simulare un dado a sei facce\nlancia_dado <- function() {\n  sample(1:6, 1)\n}\n```\n:::\n\n\n**2. Simulare il lancio di due dadi**\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Funzione per simulare il lancio di due dadi ripetuto n volte\nlancia_due_dadi <- function(n) {\n  risultati <- numeric(n)\n  \n  for (i in 1:n) {\n    risultati[i] <- lancia_dado() + lancia_dado()\n  }\n  \n  risultati\n}\n```\n:::\n\n\n**3. Eseguire la simulazione**\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Numero totale di simulazioni\nnumero_lanci <- 100000\n\n# Simulazione dei lanci\nrisultati_simulazione <- lancia_due_dadi(numero_lanci)\n\n# Visualizza i primi 20 risultati\ncat(\"Primi 20 risultati:\", risultati_simulazione[1:20], \"\\n\")\n#> Primi 20 risultati: 8 6 7 9 8 10 5 6 9 10 7 4 7 12 8 7 6 4 4 4\n```\n:::\n\n\n**4. Calcolare e visualizzare la distribuzione empirica**\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Calcola la frequenza assoluta per ciascuna somma\nfrequenze_assolute <- table(risultati_simulazione)\nfrequenze_assolute\n#> risultati_simulazione\n#>     2     3     4     5     6     7     8     9    10    11    12 \n#>  2837  5540  8349 10945 13924 16831 13894 11034  8295  5559  2792\n\n# Calcola direttamente le frequenze relative (probabilità empiriche)\nprobabilita_empiriche <- frequenze_assolute / numero_lanci\nprobabilita_empiriche\n#> risultati_simulazione\n#>      2      3      4      5      6      7      8      9     10     11     12 \n#> 0.0284 0.0554 0.0835 0.1095 0.1392 0.1683 0.1389 0.1103 0.0829 0.0556 0.0279\n\n# Crea una tabella finale chiara e semplice\ndistribuzione_empirica <- data.frame(\n  Somma = as.numeric(names(probabilita_empiriche)),\n  Probabilita = as.vector(probabilita_empiriche)\n)\n\n# Mostra la distribuzione empirica\nprint(distribuzione_empirica)\n#>    Somma Probabilita\n#> 1      2      0.0284\n#> 2      3      0.0554\n#> 3      4      0.0835\n#> 4      5      0.1095\n#> 5      6      0.1392\n#> 6      7      0.1683\n#> 7      8      0.1389\n#> 8      9      0.1103\n#> 9     10      0.0829\n#> 10    11      0.0556\n#> 11    12      0.0279\n```\n:::\n\n\n**Chiarimento sintetico dei concetti chiave.**\n\n- *Cos'è una simulazione?*  \n  È un esperimento realizzato al computer che replica più volte un evento casuale per osservare i possibili risultati e la loro frequenza.\n\n- *Distribuzione empirica*  \n  È la frequenza con cui ogni risultato (in questo caso, la somma di due dadi) appare nella simulazione. Con più simulazioni, questa distribuzione si avvicina sempre di più a quella prevista dalla teoria.\n\n- *Probabilità teorica ed empirica*  \n  La probabilità *teorica* è calcolata matematicamente: ad esempio, la somma \"7\" è teoricamente più frequente perché ci sono più modi di ottenerla (6+1, 5+2, 4+3, ecc.).  \n  La probabilità *empirica*, invece, si ottiene dalla simulazione pratica, ed è una buona approssimazione della probabilità teorica quando il numero di prove è grande.\n:::\n\n## Distribuzioni per variabili continue\n\n::: {#def-}\nUna *variabile casuale continua* è una variabile aleatoria $X$ caratterizzata da una distribuzione di probabilità continua. Formalmente, $X$ si definisce continua se soddisfa le seguenti proprietà:\n\n1. *Esistenza della funzione di densità (pdf):*  \n   Esiste una funzione non negativa $f(x)$, detta *funzione di densità di probabilità* (pdf, dall'inglese *probability density function*), tale che:  \n   \n   - $f(x) \\geq 0$ per ogni $x \\in \\mathbb{R}$;  \n   - L’area totale sotto la curva di $f(x)$ è pari a 1:  \n     $$\n     \\int_{-\\infty}^{+\\infty} f(x) \\, dx = 1.\n     $$\n\n2. *Calcolo delle probabilità tramite integrazione:*  \n   Per ogni intervallo $(a, b] \\subseteq \\mathbb{R}$ (con $a < b$), la probabilità che $X$ assuma valori in $(a, b]$ è data dall’integrale della pdf su tale intervallo:  \n   \n   $$\n   P(a < X \\leq b) = \\int_{a}^{b} f(x) \\, dx.\n   $$ \n   \n   Questa probabilità coincide anche con la differenza della *funzione di ripartizione* (CDF, *cumulative distribution function*) $F(x) = P(X \\leq x)$ agli estremi dell’intervallo:  \n   \n   $$\n   P(a < X \\leq b) = F(b) - F(a).\n   $$\n:::\n\n### Proprietà chiave delle variabili continue\n\n- *Probabilità in un punto nulla:*  \n  A differenza delle variabili discrete, per una variabile continua la probabilità di assumere un *valore esatto* $x_0$ è sempre zero:  \n  \n  $$\n  P(X = x_0) = 0.\n  $$  \n  \n  Questo avviene perché la probabilità è legata all’*area* sotto la curva $f(x)$, e un singolo punto ha \"larghezza zero\", risultando in un’area nulla. Di conseguenza, per variabili continue:  \n  \n  $$\n  P(a \\leq X \\leq b) = P(a < X \\leq b) = P(a \\leq X < b) = P(a < X < b).\n  $$\n\n- *Interpretazione della densità:*  \n  La funzione $f(x)$ non rappresenta direttamente una probabilità, ma descrive come la probabilità si distribuisce nello spazio campionario. Valori maggiori di $f(x)$ indicano regioni in cui è più probabile che $X$ assuma valori (*densità di probabilità*).\n\n- *Modellizzazione di fenomeni continui:*  \n  Le distribuzioni continue sono utilizzate per rappresentare grandezze misurabili con precisione arbitraria, come tempo, lunghezze, o temperature. Esempi comuni includono la distribuzione normale, esponenziale e uniforme continua.\n\n\n## Riflessioni conclusive {.unnumbered .unlisted}\n\nIn questo capitolo abbiamo introdotto e approfondito il concetto fondamentale di variabile casuale, illustrando come questo strumento permetta di formalizzare e analizzare matematicamente fenomeni casuali complessi. Attraverso esempi intuitivi, come il lancio di dadi o la simulazione di situazioni reali, abbiamo osservato come le variabili casuali consentano di tradurre domande astratte in analisi concrete e interpretabili.\n\nAbbiamo esaminato le due principali tipologie di variabili casuali—discrete e continue—e discusso le relative distribuzioni di probabilità. Le distribuzioni discrete, caratterizzate da una funzione di massa di probabilità (PMF), si prestano particolarmente bene a modellare situazioni in cui gli eventi possono essere enumerati (come punteggi in test psicologici o risultati di giochi). Al contrario, le distribuzioni continue, descritte dalla funzione di densità di probabilità (PDF), sono essenziali per modellare misure precise, come l'altezza o il tempo, dove il numero di possibili valori è teoricamente infinito.\n\nUn aspetto importante trattato è la funzione di distribuzione cumulativa (CDF), che fornisce una descrizione completa della distribuzione di una variabile casuale, facilitando la comprensione intuitiva della probabilità che un evento accada entro certi limiti. Conoscere le proprietà della CDF aiuta a prevenire errori comuni nella sua interpretazione e a trarre conclusioni più affidabili dai dati empirici.\n\nInfine, attraverso l'utilizzo della simulazione, abbiamo mostrato come sia possibile avvicinarsi empiricamente a una distribuzione teorica, confermando e visualizzando in modo pratico e immediato concetti astratti. Questa capacità di simulare e verificare empiricamente le distribuzioni è estremamente utile, soprattutto quando i modelli teorici diventano troppo complessi da risolvere analiticamente.\n\nNei prossimi capitoli approfondiremo ulteriormente questi concetti, esaminando alcune distribuzioni di probabilità specifiche che sono comunemente usate nella ricerca psicologica e nelle applicazioni pratiche. Questo ci permetterà di passare da una conoscenza teorica delle variabili casuali a una competenza concreta nel loro utilizzo e nella loro interpretazione, sviluppando strumenti che miglioreranno le nostre capacità di analisi e di decisione in ambito psicologico e statistico.\n\n\n::: {.callout-important title=\"Problemi 1\" collapse=\"true\"}\nConsiglio gli esercizi di base disponibili nella seguente [pagina web](https://stats.libretexts.org/Bookshelves/Introductory_Statistics/Introductory_Statistics_(Shafer_and_Zhang)/04%3A_Discrete_Random_Variables/4.E%3A_Discrete_Random_Variables_(Exercises)).\n:::\n\n::: {.callout-important title=\"Problemi 2\" collapse=\"true\"}\nEsercizi sulla distribuzione normale, risolvibili usando R, sono disponibili sulla seguente [pagina web](https://mathcenter.oxford.emory.edu/site/math117/probSetNormalDistribution/).\n:::\n\n::: {.callout-note collapse=true title=\"Informazioni sull'ambiente di sviluppo\"}\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.5.1 (2025-06-13)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.6.1\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#>  [4] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#>  [7] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#> [10] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#> [13] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#> [16] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#> [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#> [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#> [25] here_1.0.1           \n#> \n#> loaded via a namespace (and not attached):\n#>  [1] svUnit_1.0.8          tidyselect_1.2.1      farver_2.1.2         \n#>  [4] fastmap_1.2.0         TH.data_1.1-4         tensorA_0.36.2.1     \n#>  [7] digest_0.6.37         timechange_0.3.0      estimability_1.5.1   \n#> [10] lifecycle_1.0.4       survival_3.8-3        magrittr_2.0.3       \n#> [13] compiler_4.5.1        rlang_1.1.6           tools_4.5.1          \n#> [16] knitr_1.50            bridgesampling_1.1-2  htmlwidgets_1.6.4    \n#> [19] curl_7.0.0            pkgbuild_1.4.8        RColorBrewer_1.1-3   \n#> [22] abind_1.4-8           multcomp_1.4-28       withr_3.0.2          \n#> [25] purrr_1.1.0           grid_4.5.1            stats4_4.5.1         \n#> [28] colorspace_2.1-1      xtable_1.8-4          inline_0.3.21        \n#> [31] emmeans_1.11.2-8      scales_1.4.0          MASS_7.3-65          \n#> [34] cli_3.6.5             mvtnorm_1.3-3         rmarkdown_2.29       \n#> [37] ragg_1.5.0            generics_0.1.4        RcppParallel_5.1.11-1\n#> [40] cachem_1.1.0          stringr_1.5.1         splines_4.5.1        \n#> [43] parallel_4.5.1        vctrs_0.6.5           V8_7.0.0             \n#> [46] Matrix_1.7-4          sandwich_3.1-1        jsonlite_2.0.0       \n#> [49] arrayhelpers_1.1-0    systemfonts_1.2.3     glue_1.8.0           \n#> [52] codetools_0.2-20      distributional_0.5.0  lubridate_1.9.4      \n#> [55] stringi_1.8.7         gtable_0.3.6          QuickJSR_1.8.0       \n#> [58] htmltools_0.5.8.1     Brobdingnag_1.2-9     R6_2.6.1             \n#> [61] textshaping_1.0.3     rprojroot_2.1.1       evaluate_1.0.5       \n#> [64] lattice_0.22-7        backports_1.5.0       memoise_2.0.1        \n#> [67] broom_1.0.9           snakecase_0.11.1      rstantools_2.5.0     \n#> [70] coda_0.19-4.1         gridExtra_2.3         nlme_3.1-168         \n#> [73] checkmate_2.3.3       xfun_0.53             zoo_1.8-14           \n#> [76] pkgconfig_2.0.3\n```\n:::\n\n:::\n\n## Bibliografia {.unnumbered .unlisted}\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}