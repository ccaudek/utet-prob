{
  "hash": "7e3cd10ddc05d476ad3ad1d90e70f8a5",
  "result": {
    "engine": "knitr",
    "markdown": "# La verosimiglianza {#sec-prob-likelihood}\n\n::: {.epigraph}\n> “In Bayesian inference the likelihood plays the central role: it tells us how to update our prior beliefs in the light of observed data.”\n>\n> -- **Dennis V. Lindley**, Making Decisions (1971)\n:::\n\n## Introduzione {.unnumbered .unlisted}\n\nI ricercatori utilizzano modelli matematici per descrivere e prevedere il comportamento dei dati osservati. Questi modelli si distinguono per la loro struttura funzionale, che definisce le relazioni tra variabili osservate e parametri teorici. La selezione del modello ottimale avviene attraverso un confronto sistematico tra le previsioni teoriche generate dai diversi modelli e l'evidenza empirica. Il modello che mostra il miglior accordo con i dati sperimentali viene considerato la rappresentazione più adeguata del fenomeno studiato.\n\nIn questo processo di valutazione, la funzione di verosimiglianza svolge un ruolo fondamentale: per ogni possibile valore dei parametri, essa quantifica quanto siano plausibili i dati osservati sotto l'ipotesi che siano stati generati da quel specifico modello. In altre parole, la verosimiglianza costruisce una mappa di plausibilità parametrica, identificando le combinazioni di parametri che massimizzano la coerenza tra modello e realtà osservata.\n\n### Panoramica del capitolo {.unnumbered .unlisted}\n\n- Misura della plausibilità dei parametri alla luce dei dati osservati\n- Applicazione a distribuzioni binomiali (lancio di monete) e gaussiane (misura del QI)\n- Metodi per identificare i parametri più plausibili con implementazioni in R\n- Utilizzo del rapporto di verosimiglianze e criteri aggiustati (AIC)\n- La verosimiglianza come componente fondamentale per l'inferenza bayesiana\n\n::: {.callout-tip collapse=true}\n## Prerequisiti\n\n- Capitolo *Estimation* [@schervish2014probability]\n- Capitolo *Bayes' rule* [@Johnson2022bayesrules]\n:::\n\n::: {.callout-caution collapse=true title=\"Preparazione del Notebook\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhere::here(\"code\", \"_common.R\") |> \n  source()\n```\n:::\n\n:::\n\n### Il principio della verosimiglianza\n\nIl principio della verosimiglianza costituisce il fondamento dell'inferenza statistica moderna, fornendo un metodo per quantificare la plausibilità di un valore parametrico (come la media di una popolazione o l'effetto di una terapia) alla luce dei dati osservati.\n\nConcettualmente, la verosimiglianza non misura la probabilità che un'ipotesi sia vera, ma valuta quanto i dati osservati siano coerenti con una specifica ipotesi sul parametro. Rappresenta una misura di sostegno empirico: valori parametrici che rendono i dati più probabili ricevono maggiore supporto dall'evidenza.\n\n::: {#def-}  \nSia $Y$ un vettore aleatorio (come l'insieme dei punteggi dei partecipanti a un test) la cui distribuzione dipende da un parametro sconosciuto $\\theta$ (ad esempio, il punteggio medio nella popolazione). La distribuzione è descritta da una funzione di densità di probabilità (per variabili continue) o di massa di probabilità (per variabili discrete), indicata con $f(y \\mid \\theta)$, dove $\\theta \\in \\Theta$ e $\\Theta$ rappresenta lo spazio dei possibili valori parametrici.\n\nDopo aver osservato un campione di dati $y$, la *funzione di verosimiglianza* è definita come:\n\n$$\nL(\\theta; y) = f(y \\mid \\theta)\n$$\n\nSi noti che in questa funzione:\n\n- *$y$ è fissato*: corrisponde ai dati effettivamente raccolti\n- *$\\theta$ è variabile*: rappresenta il parametro incognito oggetto di inferenza\n\nLa funzione $L(\\theta; y)$ assegna quindi a ogni possibile valore di $\\theta$ un grado di supporto basato sui dati, indicando quali valori rendono le osservazioni più plausibili.\n:::\n\n### Relazione tra verosimiglianza e funzione di probabilità\n\nSebbene la funzione di probabilità (o densità) e la funzione di verosimiglianza condividano la stessa forma matematica $f(y \\mid \\theta)$, il loro significato concettuale differisce sostanzialmente in base al contesto inferenziale.\n\n#### Due prospettive a confronto\n\n1. **Funzione di probabilità (densità/massa)**\n   - *Parametri ($\\theta$) fissi*: assumiamo che siano noti o ipotizzati\n   - *Dati ($y$) aleatori*: descrive la distribuzione dei possibili risultati\n   - *Interpretazione*: $f(y \\mid \\theta)$ quantifica la probabilità (o densità) di osservare $y$ sotto un modello con parametri $\\theta$\n   - *Domanda chiave*: \"Se il modello fosse $\\theta$, quanto sarebbero probabili questi dati?\"\n\n2. **Funzione di verosimiglianza**\n   - *Dati ($y$) fissi*: corrispondono alle osservazioni effettive\n   - *Parametri ($\\theta$) variabili*: rappresentano l'incertezza da risolvere\n   - *Interpretazione*: $L(\\theta; y) = f(y \\mid \\theta)$ misura la plausibilità relativa di $\\theta$ alla luce di $y$\n   - *Domanda chiave*: \"Alla luce di questi dati, quanto sono credibili i diversi $\\theta$?\"\n\n\n#### Implicazioni per l'inferenza statistica\n\n- **Approccio frequentista**: la verosimiglianza è uno strumento per stimare i parametri (es. stima di massima verosimiglianza), senza assegnare loro una distribuzione di probabilità\n\n- **Approccio bayesiano**: la verosimiglianza funge da ponte tra dati e parametri, combinando l'informazione empirica con le credenze iniziali (*prior*) per derivare la distribuzione a posteriori:\n\n$$\nP(\\theta \\mid y) \\propto L(\\theta; y) \\cdot P(\\theta)\n$$\n\nIn questa prospettiva, i dati aggiornano la nostra conoscenza su $\\theta$ attraverso la verosimiglianza.\n\n#### Sintesi delle differenze\n\n| Caratteristica          | Funzione di probabilità | Funzione di verosimiglianza |\n|-------------------------|-------------------------|-----------------------------|\n| *Variabile di interesse* | $y$ (aleatoria)         | $\\theta$ (incognita)        |\n| *Ruolo epistemologico*  | Genera dati ipotetici   | Valuta parametri plausibili |\n| *Contesto d'uso*        | Modellistica predittiva | Inferenza parametrica       |\n\nQuesta dualità riflette un principio fondamentale: la stessa formula matematica assume significati distinti a seconda che l'obiettivo sia la descrizione del processo generativo o l'inferenza sui suoi parametri. La verosimiglianza, in particolare, è il motore dell'apprendimento statistico, trasformando dati in conoscenza.\n\n\n### La log-verosimiglianza\n\nIn ambito statistico e computazionale, risulta spesso vantaggioso lavorare con la *log-verosimiglianza*, definita come il logaritmo naturale della funzione di verosimiglianza:\n\n$$\n\\ell(\\theta; y) = \\log L(\\theta; y) = \\log f(y \\mid \\theta).\n$$\n\nQuesta trasformazione apporta significativi vantaggi sia dal punto di vista computazionale che analitico.\n\nDal punto di vista computazionale, la log-verosimiglianza offre una maggiore stabilità numerica. Il prodotto di probabilità molto piccole, tipico delle funzioni di verosimiglianza, può infatti portare a valori numericamente instabili (un fenomeno noto come *underflow*). La conversione logaritmica trasforma questi prodotti in somme, molto più gestibili per i calcolatori. Questo vantaggio diventa particolarmente evidente nel caso di osservazioni indipendenti e identicamente distribuite (i.i.d.), dove la log-verosimiglianza complessiva si esprime come la somma dei contributi individuali:\n\n$$\n\\ell(\\theta; y_1, \\dots, y_n) = \\sum_{i=1}^n \\log f(y_i \\mid \\theta),\n$$\nsemplificando notevolmente i calcoli.\n\nSul piano analitico, la log-verosimiglianza facilita l'ottimizzazione grazie alle proprietà del logaritmo che trasformano prodotti in somme. Le derivate risultano infatti matematicamente più semplici da trattare rispetto a quelle della verosimiglianza originale. Questa semplificazione risulta particolarmente vantaggiosa nei metodi di ottimizzazione numerica come la massimizzazione della verosimiglianza (MLE), dove la stima dei parametri avviene risolvendo il sistema di equazioni ottenuto uguagliando a zero il gradiente. La forma additiva della log-verosimiglianza si dimostra inoltre particolarmente utile nei modelli gerarchici o nei casi in cui i dati provengano da più fonti indipendenti.\n\nÈ importante sottolineare che, poiché il logaritmo è una funzione monotona crescente, massimizzare la log-verosimiglianza $\\ell(\\theta; y)$ equivale perfettamente a massimizzare la verosimiglianza $L(\\theta; y)$. Pertanto, le stime di massima verosimiglianza (MLE) possono essere ottenute indifferentemente dall'una o dall'altra funzione.\n\nIn sintesi, la log-verosimiglianza combina efficienza computazionale e semplicità analitica, rendendola uno strumento fondamentale per l'inferenza statistica e l'analisi dati moderna. La sua adozione consente di affrontare problemi complessi con maggiore stabilità numerica e minore complessità computazionale, mantenendo inalterate le proprietà inferenziali della verosimiglianza originale.\n\n\n## Modellazione statistica del lancio di una moneta\n\nUn esempio classico per introdurre il concetto di *verosimiglianza* è quello del lancio di una moneta.\nChiamiamo $\\theta$ la probabilità (incognita) di ottenere “testa”.\n\n\n### Il modello probabilistico\n\nPer semplicità assumiamo:\n\n1. ogni lancio è *indipendente* dagli altri;\n2. la probabilità $\\theta$ resta *costante* in tutti i lanci.\n\nSe in $n$ lanci otteniamo $y$ teste, la probabilità di osservare esattamente quei dati è:\n\n$$\nP(\\text{dati}\\mid \\theta) = \\theta^y (1-\\theta)^{n-y}.\n$$\n\n\n### La funzione di verosimiglianza\n\nLa *funzione di verosimiglianza* si ottiene considerando l’espressione precedente non più come funzione dei dati, ma come funzione di $\\theta$:\n\n$$\nL(\\theta \\mid \\text{dati}) \\propto \\theta^y (1-\\theta)^{n-y}.\n$$\n\nEssa indica quali valori di $\\theta$ sono più compatibili con i dati osservati.\nIl valore che massimizza questa funzione è lo *stimatore di massima verosimiglianza (MLE)*.\n\n\n### Esempio 1: due lanci\n\nSupponiamo di osservare due lanci con esito: una testa e una croce ($n=2, y=1$).\n\n* Se $\\theta = 0.5$:\n\n  $$\n  L(0.5) = 0.5^1 \\cdot 0.5^1 = 0.25\n  $$\n* Se $\\theta = 0.4$:\n\n  $$\n  L(0.4) = 0.4^1 \\cdot 0.6^1 = 0.24\n  $$\n\nIn questo caso $\\theta=0.5$ spiega leggermente meglio i dati.\n\nCon R possiamo calcolare la verosimiglianza per tutta la gamma di valori di $\\theta$:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nn <- 2\ny <- 1\np_H <- seq(0, 1, length.out = 100)\nlikelihood <- p_H^y * (1 - p_H)^(n - y)\n```\n:::\n\n\nLa curva risultante ha il massimo in corrispondenza di $\\hat\\theta = y/n = 0.5$.\n\n\n### Esempio 2: tre lanci\n\nConsideriamo ora tre lanci con esito: una testa e due croci ($n=3, y=1$).\n\n* Se $\\theta = 0.5$:\n\n  $$\n  L(0.5) = 0.5^1 \\cdot 0.5^2 = 0.125\n  $$\n* Se $\\theta = 0.4$:\n\n  $$\n  L(0.4) = 0.4^1 \\cdot 0.6^2 = 0.144\n  $$\n\nQui il valore $\\theta = 0.4$ è più plausibile di 0.5.\n\nCon R:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nn <- 3\ny <- 1\np_H <- seq(0, 1, length.out = 100)\nlikelihood <- p_H^y * (1 - p_H)^(n - y)\n```\n:::\n\n\nLa curva raggiunge il massimo in $\\hat\\theta = y/n = 1/3 \\approx 0.33$.\nRispetto al caso precedente, la curva è più *stretta*, segnalando una maggiore precisione della stima grazie al numero maggiore di osservazioni.\n\n\n### Interpretazione complessiva\n\n* Lo *stimatore di massima verosimiglianza* $\\hat\\theta$ corrisponde sempre alla *proporzione osservata di teste* ($y/n$).\n* All’aumentare del numero di lanci, la curva di verosimiglianza diventa più appuntita: significa che abbiamo *maggiore certezza* sul valore di $\\theta$.\n* I valori estremi ($\\theta \\approx 0$ o $\\theta \\approx 1$) risultano poco compatibili con i dati, perché non potrebbero spiegare l’osservazione sia di teste che di croci.\n\nIn sintesi: la verosimiglianza traduce l’idea intuitiva che “il valore migliore del parametro è quello che rende i dati osservati più probabili”. Questo principio, applicato in modo generale, costituisce la base della *stima per massima verosimiglianza*.\n\n\n### Confronto tra due e tre lanci\n\nMettiamo ora a confronto le due situazioni:\n\n* **Caso 1**: 2 lanci con 1 testa ($n=2, y=1$, proporzione osservata $\\hat\\theta = 0.5$).\n* **Caso 2**: 3 lanci con 1 testa ($n=3, y=1$, proporzione osservata $\\hat\\theta \\approx 0.33$).\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Dati per 2 lanci\nn1 <- 2; y1 <- 1\ntheta_seq <- seq(0, 1, length.out = 200)\nlik1 <- theta_seq^y1 * (1 - theta_seq)^(n1 - y1)\n\n# Dati per 3 lanci\nn2 <- 3; y2 <- 1\nlik2 <- theta_seq^y2 * (1 - theta_seq)^(n2 - y2)\n\n# Creiamo un unico dataframe\ndf <- data.frame(\n  theta = rep(theta_seq, 2),\n  likelihood = c(lik1, lik2),\n  caso = rep(c(\"2 lanci (1 testa)\", \"3 lanci (1 testa)\"), each = length(theta_seq))\n)\n\n# Grafico comparativo\nggplot(df, aes(x = theta, y = likelihood, color = caso)) +\n  geom_line(linewidth = 1.2) +\n  labs(\n    x = expression(theta),\n    y = \"Verosimiglianza\"\n  ) +\n  scale_color_manual(values = c(\"steelblue\", \"darkorange\"))\n```\n\n::: {.cell-output-display}\n![](16_likelihood_files/figure-html/unnamed-chunk-4-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n### Interpretazione del grafico\n\n* Nel *caso dei 2 lanci*, la curva ha un massimo in $\\hat\\theta = 0.5$, ma è *molto larga*: la stima è poco precisa.\n* Nel *caso dei 3 lanci*, la curva ha un massimo in $\\hat\\theta = 1/3$, ed è *più stretta*: significa che, con più dati, la stima diventa più affidabile.\n* I valori estremi ($\\theta \\approx 0$ o $\\theta \\approx 1$) hanno verosimiglianza quasi nulla in entrambi i casi, perché non spiegherebbero la presenza di almeno una testa e di almeno una croce.\n\nQuesto semplice confronto mostra visivamente come *aumentare la quantità di dati restringe l’incertezza* e rende la stima più precisa.\n\n\n## Verosimiglianza binomiale\n\nConsideriamo ora un esperimento più ampio: lanciamo una moneta $n = 30$ volte e osserviamo $y = 23$ teste. Per modellare il numero totale di successi utilizziamo la distribuzione binomiale, che descrive la probabilità di ottenere esattamente $y$ successi in $n$ prove indipendenti, con probabilità di successo $\\theta$ costante:\n\n$$\nP(Y = y \\mid \\theta) = \\binom{n}{y} \\theta^y (1 - \\theta)^{n - y}.\n$$\n\nIn questo contesto, $Y$ rappresenta la variabile casuale \"numero di teste\", $y = 23$ è il valore osservato, e $\\theta$ (o $p_H$) è la probabilità incognita di ottenere testa in un singolo lancio.\n\n### Dalla distribuzione di probabilità alla verosimiglianza\n\nDopo aver osservato i dati ($y = 23$), possiamo valutare la compatibilità dei diversi valori del parametro $\\theta$ con l'evidenza sperimentale. A questo scopo, utilizziamo la formula della distribuzione binomiale trattandola come funzione di $\\theta$ anziché di $y$:\n\n$$\nL(\\theta \\mid y = 23) = \\binom{30}{23} \\theta^{23} (1 - \\theta)^7.\n$$\n\nQuesta funzione di verosimiglianza quantifica la plausibilità di ciascun valore di $\\theta$ alla luce dei dati osservati. A differenza degli esempi precedenti, in questo caso manteniamo la costante moltiplicativa $\\binom{30}{23}$ poiché lavoreremo con la verosimiglianza completa.\n\n### Visualizzazione della funzione di verosimiglianza\n\nIl codice seguente genera il grafico della funzione di verosimiglianza, calcolando per ogni valore di $\\theta$ la probabilità di osservare 23 successi su 30 prove:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Parametri osservati\nn <- 30  # Numero totale di lanci\ny <- 23  # Numero di teste osservate\n\n# Griglia di valori possibili per theta\ntheta <- seq(0, 1, length.out = 1000)\n\n# Calcolo della verosimiglianza binomiale\nlikelihood <- dbinom(y, size = n, prob = theta)\n\n# Preparazione dei dati per la visualizzazione\ndata <- data.frame(theta, likelihood)\n\n# Rappresentazione grafica\nggplot(data, aes(x = theta, y = likelihood)) +\n  geom_line(linewidth = 1.2, color = \"steelblue\") +\n  labs(\n    x = expression(theta),\n    y = \"Verosimiglianza\"\n  ) \n```\n\n::: {.cell-output-display}\n![](16_likelihood_files/figure-html/unnamed-chunk-5-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n### Interpretazione dei risultati\n\nL'analisi grafica rivele che:\n\n- La funzione di verosimiglianza raggiunge il suo massimo in corrispondenza di $\\theta \\approx 0.77$\n- Questo valore rappresenta la stima di massima verosimiglianza (MLE) per la probabilità di successo\n- La stima corrisponde esattamente alla proporzione campionaria: $\\hat{\\theta} = \\frac{23}{30} \\approx 0.767$\n- La curva mostra una dispersione limitata, indicando una relativa precisione nella stima\n- I valori estremi di $\\theta$ (vicini a 0 o 1) presentano verosimiglianze trascurabili\n\n### Implementazione computazionale\n\nIn R, il calcolo della verosimiglianza binomiale può essere efficientemente implementato utilizzando la funzione `dbinom()`, che calcola la funzione di massa di probabilità della distribuzione binomiale:\n\n```r\n# Calcolo della verosimiglianza\nlikelihood <- dbinom(y, size = n, prob = theta)\n```\ndove:\n\n- `y` è il numero di successi osservati (23)\n- `n` è il numero totale di prove (30)\n- `theta` è il vettore dei valori parametrici da valutare\n\nQuesto approccio dimostra come la verosimiglianza possa essere costruita direttamente a partire dalla distribuzione di probabilità sottostante, utilizzando strumenti computazionali standard. La funzione `dbinom()` calcola automaticamente l'intera espressione binomiale, inclusa la costante moltiplicativa, fornendo così la verosimiglianza completa per ogni valore di $\\theta$.\n\nLa metodologia presentata mostra come concetti teorici di inferenza statistica possano essere efficacemente implementati e visualizzati attraverso strumenti computazionali, facilitando la comprensione intuitiva dei principi di verosimiglianza e stima parametrica.\n\n\n## La Stima di Massima Verosimiglianza\n\nQuando osserviamo dati sperimentali e desideriamo stimare un parametro incognito – come la probabilità $\\theta$ che una moneta produca \"testa\" – un approccio fondamentale è rappresentato dalla *stima di massima verosimiglianza* (Maximum Likelihood Estimation, MLE). Sebbene l'approccio bayesiano si concentri sulla distribuzione completa dei valori plausibili del parametro piuttosto che su una singola stima puntuale, la comprensione del concetto di MLE rimane essenziale. Questo metodo identifica il valore di $\\theta$ che massimizza la compatibilità tra il modello e i dati osservati. In contesti bayesiani, sotto specifiche condizioni di prior, la MLE coincide con il massimo della distribuzione a posteriori.\n\n### Il principio fondamentale\n\nLa logica sottostante la MLE è intuitiva: tra tutti i possibili valori del parametro, selezioniamo quello che rende i dati osservati più probabili. Immaginiamo di testare sistematicamente diversi valori di $\\theta$, chiedendoci per ciascuno: \"Se questo fosse il vero valore del parametro, quanto sarebbero plausibili i dati che abbiamo effettivamente osservato?\" Il valore che massimizza questa plausibilità costituisce la nostra stima ottimale.\n\n### Esempio applicativo: il lancio della moneta\n\nConsideriamo una moneta lanciata 30 volte che produce 23 teste. Un risultato così marcato solleva naturalmente dubbi sull'equità della moneta. Per stimare la vera probabilità $\\theta$ di ottenere testa, costruiamo la funzione di verosimiglianza, che quantifica la compatibilità di ciascun possibile valore di $\\theta$ con l'evidenza sperimentale. Valori più elevati di verosimiglianza indicano una maggiore plausibilità del parametro dato i dati osservati.\n\n### Rappresentazione grafica e interpretazione\n\nLa funzione di verosimiglianza $L(\\theta)$ può essere visualizzata come una curva che descrive l'andamento della plausibilità al variare di $\\theta$. Questa curva presenta tipicamente un massimo globale ben definito, corrispondente alla stima MLE. Geometricamente, questo punto rappresenta il vertice della \"collina\" di verosimiglianza.\n\nLa forma della curva fornisce preziose informazioni:\n\n- una curva appuntita indica alta certezza nella stima,\n- una curva più piatta suggerisce maggiore incertezza parametrica,\n- la pendenza della curva riflette la sensibilità della verosimiglianza alle variazioni del parametro.\n\n### Determinazione analitica del massimo\n\nMatematicamente, il massimo della funzione di verosimiglianza corrisponde al punto in cui la sua derivata si annulla. Utilizzando la trasformazione in log-verosimiglianza:\n\n$$\n\\ell(\\theta) = y \\log \\theta + (n - y) \\log(1 - \\theta),\n$$\n\nla soluzione analitica si ottiene ponendo la derivata uguale a zero:\n\n$$\n\\hat{\\theta} = \\frac{y}{n}.\n$$\n\nNel nostro esempio, questo risulta in $\\hat{\\theta} = \\frac{23}{30} \\approx 0.767$, dimostrando come la MLE corrisponda alla proporzione campionaria osservata.\n\n### Relazione con l'inferenza bayesiana\n\nNella statistica bayesiana, l'obiettivo principale è la caratterizzazione completa dell'incertezza parametrica attraverso la distribuzione a posteriori. Tuttavia, il punto di massimo di questa distribuzione, noto come stima MAP (Maximum A Posteriori), coincide con la MLE quando si assume una distribuzione a priori uniforme. Questa connessione evidenzia come la MLE rappresenti un caso particolare dell'approccio bayesiano, fornendo un ponte concettuale tra i due paradigmi inferenziali.\n\nLa comprensione della MLE non solo facilita l'interpretazione dei risultati statistici, ma costituisce anche una base essenziale per l'apprendimento dei metodi bayesiani più avanzati, mostrando come il concetto di verosimiglianza unifichi diversi approcci all'inferenza statistica.\n\n## Calcolo della Stima di Massima Verosimiglianza in R\n\n### Metodo 1: Valutazione su Griglia\n\nIl primo approccio consiste nel valutare sistematicamente la verosimiglianza per un'ampia gamma di valori del parametro θ:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Definizione dei parametri osservati\nn <- 30\ny <- 23\ntheta <- seq(0, 1, length.out = 10000)\n\n# Calcolo della funzione di verosimiglianza\nlikelihood <- dbinom(y, size = n, prob = theta)\n\n# Identificazione del massimo\nmax_index <- which.max(likelihood)\noptimal_theta <- theta[max_index]\n\n# Visualizzazione del risultato\noptimal_theta\n#> [1] 0.767\n```\n:::\n\n\nQuesto metodo offre una soluzione numerica precisa attraverso:\n\n- la generazione di una griglia densa di valori possibili per $\\theta$,\n- il calcolo diretto della verosimiglianza per ogni punto della griglia,\n- l'identificazione del valore ottimale mediante ricerca del massimo.\n\n### Metodo 2: Ottimizzazione Numerica\n\nUn approccio più efficiente dal punto di vista computazionale utilizza algoritmi di ottimizzazione:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Definizione della funzione di log-verosimiglianza negativa\nneg_log_likelihood <- function(theta) {\n  - (y * log(theta) + (n - y) * log(1 - theta))\n}\n\n# Ottimizzazione numerica\nresult <- optim(\n  par = 0.5,              # Valore iniziale\n  fn = neg_log_likelihood, # Funzione da minimizzare\n  method = \"Brent\",       # Algoritmo per ottimizzazione unidimensionale\n  lower = 1e-6,           # Limite inferiore\n  upper = 1 - 1e-6        # Limite superiore\n)\n\noptimal_theta_numerical <- result$par\noptimal_theta_numerical\n#> [1] 0.767\n```\n:::\n\n\nL'utilizzo della log-verosimiglianza negativa è necessario poiché la funzione `optim()` è progettata per la minimizzazione. Questo approccio risulta particolarmente vantaggioso per modelli complessi dove una valutazione su griglia sarebbe computazionalmente costosa.\n\n### Confronto dei risultati\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Confronto tra i diversi metodi\nc(\n  \"Griglia\" = optimal_theta, \n  \"Ottimizzazione\" = optimal_theta_numerical, \n  \"Analitica\" = y / n\n)\n#>        Griglia Ottimizzazione      Analitica \n#>          0.767          0.767          0.767\n```\n:::\n\n\nTutti e tre i metodi convergono allo stesso risultato:\n\n$$\n\\hat{\\theta} = \\frac{23}{30} \\approx 0.767 .\n$$\n\nQuesta coincidenza dimostra la robustezza del metodo di massima verosimiglianza e conferma che, nel caso della distribuzione binomiale, la stima ottimale corrisponde alla proporzione campionaria osservata.\n\n**Osservazioni metodologiche:**\n\n- Il metodo della griglia offre una visualizzazione completa della funzione di verosimiglianza.\n- L'ottimizzazione numerica è più efficiente per problemi multidimensionali.\n- La soluzione analitica fornisce un riferimento teorico esatto.\n- La scelta del metodo dipende dalle specifiche esigenze analitiche e computazionali.\n\nL'implementazione in R dimostra come concetti statistici avanzati possano essere efficacemente applicati attraverso strumenti computazionali, facilitando sia l'analisi che l'interpretazione dei risultati.\n\n## Verosimiglianza congiunta\n\nIl concetto di verosimiglianza si estende naturalmente al caso di osservazioni multiple, dando origine alla verosimiglianza congiunta. Questo approccio consente di combinare informazioni provenienti da diverse fonti o esperimenti per ottenere stime parametriche più robuste.\n\n### Dalla binomiale alla verosimiglianza congiunta\n\nNel caso di $n$ lanci di moneta, la verosimiglianza basata sul numero totale di successi segue la distribuzione binomiale:\n\n$$\n\\mathcal{L}(\\theta) = \\binom{n}{y} \\theta^y (1 - \\theta)^{n - y}.\n$$\n\nTuttavia, possiamo concettualizzare il problema considerando ogni lancio come un'osservazione indipendente Bernoulli. Per una singola osservazione:\n\n$$\n\\mathcal{L}(\\theta \\mid y_i) = \\theta^{y_i} (1 - \\theta)^{1 - y_i}.\n$$\n\nPer $n$ osservazioni indipendenti, la verosimiglianza congiunta diventa:\n\n$$\n\\mathcal{L}(\\theta \\mid y_1, y_2, \\dots, y_n) = \\prod_{i=1}^{n} \\theta^{y_i} (1 - \\theta)^{1 - y_i} = \\theta^y (1 - \\theta)^{n - y}.\n$$\n\ndove $y = \\sum_{i=1}^{n} y_i$. Questo dimostra l'equivalenza tra l'approccio basato sulle osservazioni individuali e quello basato sulla statistica sufficiente binomiale.\n\n### Importanza della verosimiglianza congiunta\n\nLa verosimiglianza congiunta rappresenta uno strumento fondamentale per:\n\n- Integrare informazioni da multiple osservazioni indipendenti.\n- Costruire modelli statistici complessi.\n- Effettuare stime parametriche basate sull'intero set di dati.\n- Generalizzare il concetto di verosimiglianza a contesti multivariati.\n\n### Esempio applicativo: gruppi di osservazioni binomiali\n\nConsideriamo quattro gruppi indipendenti di osservazioni binomiali:\n\n- Gruppo 1: 23 successi su 30 prove.\n- Gruppo 2: 20 successi su 28 prove.\n- Gruppo 3: 29 successi su 40 prove.\n- Gruppo 4: 29 successi su 36 prove.\n\nAssumendo che tutti i gruppi condividano lo stesso parametro $\\theta$, la log-verosimiglianza congiunta è data da:\n\n$$\n\\log \\mathcal{L}(\\theta) = \\sum_{i=1}^{4} \\left[ y_i \\log(\\theta) + (n_i - y_i) \\log(1 - \\theta) \\right]\n$$\n\nSviluppando l'espressione:\n\n$$\n\\begin{aligned}\n\\log \\mathcal{L}(\\theta) = &23\\log(\\theta) + 7\\log(1 - \\theta) + \\\\\n&20\\log(\\theta) + 8\\log(1 - \\theta) + \\\\\n&29\\log(\\theta) + 11\\log(1 - \\theta) + \\\\\n&29\\log(\\theta) + 7\\log(1 - \\theta)\n\\end{aligned}\n$$\n\nQuesta formulazione permette di valutare la plausibilità del parametro $\\theta$ considerando simultaneamente tutte le informazioni disponibili dai quattro gruppi sperimentali.\n\n### Implementazione computazionale\n\nIn R, la verosimiglianza congiunta può essere calcolata efficientemente:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Definizione dei parametri dei gruppi\nsuccessi <- c(23, 20, 29, 29)\nprove <- c(30, 28, 40, 36)\n\n# Funzione di log-verosimiglianza congiunta\nlog_verosimiglianza_congiunta <- function(theta) {\n  sum(successi * log(theta) + (prove - successi) * log(1 - theta))\n}\n\n# Calcolo per un valore specifico di theta\nlog_verosimiglianza_congiunta(0.7)\n#> [1] -75.8\n```\n:::\n\n\n## La Verosimiglianza marginale nell'inferenza bayesiana\n\nLa verosimiglianza marginale rappresenta un concetto fondamentale nell'inferenza bayesiana, permettendo di valutare la compatibilità complessiva di un modello con i dati osservati, considerando l'intera distribuzione dei parametri. A differenza della verosimiglianza classica che valuta la plausibilità dei dati per valori fissi dei parametri, la verosimiglianza marginal integra l'incertezza parametrica attraverso la distribuzione a priori.\n\n\n### Caso di parametri discreti\n\nSupponiamo di osservare $k = 7$ successi su $n = 10$ tentativi, con il parametro $\\theta$ che può assumere solo tre valori discreti:\n\n$$\n\\theta \\in \\{0.1,\\; 0.5,\\; 0.9\\}.\n$$\n\n1. **Assegnazione della distribuzione a priori** sui valori di $\\theta$:\n\n   * Prior uniforme:\n\n     $$\n     p(\\theta = 0.1) = p(\\theta = 0.5) = p(\\theta = 0.9) = \\tfrac{1}{3}.\n     $$\n   * Prior non uniforme:\n\n     $$\n     p(\\theta = 0.1) = \\tfrac{1}{4}, \\quad \n     p(\\theta = 0.5) = \\tfrac{1}{2}, \\quad \n     p(\\theta = 0.9) = \\tfrac{1}{4}.\n     $$\n\n2. **Calcolo della verosimiglianza** per ogni valore di $\\theta$:\n\n   $$\n   p(k=7 \\mid \\theta) = \\binom{10}{7}\\,\\theta^{7}(1-\\theta)^{3}.\n   $$\n\n3. **Marginalizzazione tramite somma pesata**:\n\n   $$\n   p(k=7 \\mid n=10) = \\sum_{i=1}^{3} p(k=7 \\mid \\theta_i)\\, p(\\theta_i).\n   $$\n\n\n### Caso di parametri continui\n\nNella maggior parte delle applicazioni, il parametro $\\theta$ varia in modo continuo.\nPer $\\theta \\in [0,1]$, la verosimiglianza marginale si calcola integrando:\n\n$$\np(k=7 \\mid n=10) \n= \\int_{0}^{1} \\binom{10}{7}\\,\\theta^{7}(1-\\theta)^{3}\\, p(\\theta)\\, d\\theta,\n$$\n\ndove $p(\\theta)$ è la distribuzione a priori.\n\nAd esempio, con una prior $\\text{Beta}(2,2)$:\n\n$$\np(\\theta) = \\frac{\\theta(1-\\theta)}{B(2,2)},\n$$\n\nsi ottiene:\n\n$$\np(k=7 \\mid n=10) \n= \\int_{0}^{1} \\binom{10}{7}\\, \\theta^{7}(1-\\theta)^{3} \\,\\frac{\\theta(1-\\theta)}{B(2,2)} \\, d\\theta.\n$$\n\n\n### Implementazione computazionale in R\n\n#### Parametri discreti\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Valori discreti di θ e prior uniforme\ntheta_vals <- c(0.1, 0.5, 0.9)\nprior_probs <- rep(1/3, 3)\n\n# Calcolo della verosimiglianza marginale\nlikelihoods <- dbinom(7, size = 10, prob = theta_vals)\nmarginal_likelihood <- sum(likelihoods * prior_probs)\nprint(marginal_likelihood)\n#> [1] 0.0582\n```\n:::\n\n\nIn questo caso, il calcolo corrisponde alla formula\n\n$$\np(k=7 \\mid n=10) = \\sum_{i=1}^3 p(k=7 \\mid \\theta_i)\\, p(\\theta_i).\n$$\n\n\n#### Parametri continui\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Integrazione numerica con prior Beta(2,2)\nintegrand <- function(theta) {\n  dbinom(7, size = 10, prob = theta) * dbeta(theta, 2, 2)\n}\n\nmarginal_likelihood <- integrate(integrand, 0, 1)$value\nprint(marginal_likelihood)\n#> [1] 0.112\n```\n:::\n\n\nQui la verosimiglianza marginale viene calcolata come\n\n$$\np(k=7 \\mid n=10) = \\int_0^1 \\binom{10}{7}\\, \\theta^7 (1-\\theta)^3 \\, p(\\theta)\\, d\\theta,\n$$\n\ndove, con una prior $\\text{Beta}(2,2)$, vale\n\n$$\np(\\theta) = \\frac{\\theta(1-\\theta)}{B(2,2)}.\n$$\n\n### Interpretazione\n\nLa *verosimiglianza marginale* $p(D)$ quantifica la probabilità complessiva dei dati $D$ tenendo conto di tutte le possibili configurazioni parametriche:  \n\n- valori *più alti* indicano maggiore compatibilità tra modello e dati;  \n- valori *più bassi* suggeriscono che i dati siano poco plausibili sotto quel modello;  \n- il *confronto tra modelli* si basa sul *fattore di Bayes*:  \n  $$\n  BF_{12} = \\frac{p(D \\mid M_1)}{p(D \\mid M_2)}.\n  $$\n\n### Ruolo nell’inferenza bayesiana\n\nNella formula di Bayes\n\n$$\np(\\theta \\mid D) = \\frac{p(D \\mid \\theta)\\,p(\\theta)}{p(D)},\n$$\n\nla quantità $p(D)$, ossia la verosimiglianza marginale:  \n\n- funge da *fattore di normalizzazione* per ottenere la distribuzione a posteriori;  \n- costituisce la *base del confronto tra modelli*;  \n- rappresenta una *misura complessiva dell’evidenza* fornita dai dati.  \n\n\n### Considerazioni pratiche\n\nIl calcolo di $p(D)$ presenta spesso difficoltà:  \n\n- l’integrazione diventa rapidamente *multidimensionale* per modelli complessi;  \n- i risultati possono essere *sensibili alla scelta della prior*;  \n- sono necessari *metodi approssimati* (MCMC, bridge sampling, ecc.) per modelli realistici.  \n\nNonostante queste complessità, la verosimiglianza marginale resta un concetto fondamentale:  \n- permette di valutare la bontà di adattamento dei modelli,  \n- guida la *selezione bayesiana dei modelli*,  \n- e garantisce un’inferenza che integra in modo coerente l’incertezza sui parametri.  \n\n\n## Verosimiglianza gaussiana\n\nLa distribuzione gaussiana (o normale) è uno degli strumenti fondamentali della statistica.\nLa sua importanza deriva dalla capacità di descrivere in modo efficace molte variabili continue di interesse psicologico e scientifico, come il *quoziente intellettivo (QI)*, i *tempi di reazione* o diverse *misurazioni psicofisiologiche*.\n\n\n### Caso di una singola osservazione\n\nConsideriamo la misurazione del QI di un individuo. Supponiamo che il QI segua una distribuzione normale con media incognita $\\mu$ e deviazione standard nota $\\sigma = 15$.\n\nLa funzione di densità di probabilità (pdf) è:\n\n$$\nf(y \\mid \\mu, \\sigma) \\;=\\; \\frac{1}{\\sigma \\sqrt{2\\pi}} \n\\exp\\!\\left(-\\frac{(y-\\mu)^2}{2\\sigma^2}\\right),\n$$\n\ndove $y$ rappresenta il valore osservato (nel nostro caso $y=114$), $\\mu$ è il parametro da stimare e $\\sigma$ è noto.\n\nLa *funzione di verosimiglianza* per una singola osservazione è data dalla stessa espressione, considerata ora come funzione di $\\mu$, fissato $y$.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Osservazione e parametro noto\ny_obs <- 114\nsigma <- 15\nmu_values <- seq(70, 160, length.out = 1000)\n\n# Calcolo della verosimiglianza\nlikelihood <- dnorm(y_obs, mean = mu_values, sd = sigma)\n\n# Visualizzazione\nggplot(data.frame(mu = mu_values, likelihood = likelihood), \n       aes(x = mu, y = likelihood)) +\n  geom_line(linewidth = 1.2, color = \"steelblue\") +\n  labs(\n    x = \"Media μ\",\n    y = \"Verosimiglianza\"\n  )\n```\n\n::: {.cell-output-display}\n![](16_likelihood_files/figure-html/unnamed-chunk-12-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\nIl valore di $\\mu$ che massimizza la verosimiglianza coincide con l’osservazione stessa:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmu_optimal <- mu_values[which.max(likelihood)]\ncat(\"Stima di massima verosimiglianza per μ:\", mu_optimal)\n#> Stima di massima verosimiglianza per μ: 114\n```\n:::\n\n\n\n### Ottimizzazione tramite log-verosimiglianza\n\nL’uso della *log-verosimiglianza* è preferibile per ragioni numeriche:\n\n* trasforma prodotti di probabilità in somme,\n* evita problemi di *underflow* con valori molto piccoli,\n* semplifica il calcolo delle derivate.\n\nPer una singola osservazione da una normale:\n\n$$\n\\ell(\\mu \\mid y, \\sigma) \\;=\\; -\\tfrac{1}{2}\\log(2\\pi)\\;-\\;\\log(\\sigma)\\;-\\;\\frac{(y-\\mu)^2}{2\\sigma^2}.\n$$\n\n\n#### Implementazione in R\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Definizione della funzione di log-verosimiglianza negativa\nnegative_log_likelihood <- function(mu, y, sigma) {\n  -dnorm(y, mean = mu, sd = sigma, log = TRUE)\n}\n\n# Ottimizzazione numerica\nresult <- optim(\n  par = 100,                 # Valore iniziale per μ\n  fn = negative_log_likelihood,\n  y = y_obs,\n  sigma = sigma,\n  method = \"L-BFGS-B\",\n  lower = 70,\n  upper = 160\n)\n\n# Estrazione della stima\nmu_mle <- result$par\ncat(\"Stima di massima verosimiglianza per μ:\", round(mu_mle, 2))\n#> Stima di massima verosimiglianza per μ: 114\n```\n:::\n\n\n\n### Vantaggi della log-verosimiglianza\n\n1. *Stabilità numerica*: riduce i rischi di underflow.\n2. *Efficienza computazionale*: la somma di log-probabilità è più stabile del prodotto di probabilità.\n3. *Proprietà additive*: la log-verosimiglianza totale è la somma dei contributi dei singoli dati.\n4. *Derivazioni semplificate*: le derivate della log-verosimiglianza hanno forma più semplice.\n\n\n### Interpretazione del risultato\n\nLa stima di massima verosimiglianza (MLE) per $\\mu$ risulta:\n\n$$\n\\hat{\\mu} = 114,\n$$\n\nossia il valore osservato. Questo era atteso: per una singola osservazione da una normale con deviazione standard nota, la stima MLE della media coincide esattamente con il dato osservato.\n\n\n## Campione di osservazioni indipendenti\n\nSupponiamo di avere i punteggi *BDI-II* raccolti su un campione di $n=30$ partecipanti. Assumiamo che ciascun punteggio sia un’osservazione indipendente da una distribuzione normale con media incognita $\\mu$ e deviazione standard nota $\\sigma = 6.5$.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Dati osservati (punteggi BDI-II)\ny <- c(\n  26, 35, 30, 25, 44, 30, 33, 43, 22, 43, 24, 19, 39, 31, 25, \n  28, 35, 30, 26, 31, 41, 36, 26, 35, 33, 28, 27, 34, 27, 22\n)\n\nsigma <- 6.5  # Deviazione standard nota\n```\n:::\n\n\n---\n\n### Log-verosimiglianza\n\nPer un campione di $n$ osservazioni indipendenti, la log-verosimiglianza del parametro $\\mu$ è\n\n$$\n\\ell(\\mu \\mid y, \\sigma) \\;=\\; \\sum_{i=1}^n \\log f(y_i \\mid \\mu, \\sigma),\n$$\n\ndove $f(y_i \\mid \\mu, \\sigma)$ è la densità normale.\n\nIn R:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlog_likelihood <- function(mu, y, sigma) {\n  sum(dnorm(y, mean = mu, sd = sigma, log = TRUE))\n}\n```\n:::\n\n\nCalcoliamo $\\ell(\\mu)$ per valori di $\\mu$ attorno alla media campionaria:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmu_range <- seq(mean(y) - 2 * sigma, mean(y) + 2 * sigma, length.out = 1000)\nlog_lik_values <- sapply(mu_range, function(mu_val) log_likelihood(mu_val, y, sigma))\n```\n:::\n\n\n---\n\n### Visualizzazione\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(ggplot2)\n\nggplot(\n  data.frame(mu = mu_range, log_likelihood = log_lik_values),\n  aes(x = mu, y = log_likelihood)\n) +\n  geom_line(linewidth = 1.2, color = \"steelblue\") +\n  geom_vline(xintercept = mean(y), linetype = \"dashed\", color = \"red\", linewidth = 1) +\n  labs(\n    x = expression(mu),\n    y = \"Log-verosimiglianza\"\n  ) +\n  annotate(\"text\", x = mean(y) + 2, y = max(log_lik_values) - 5,\n           label = paste0(\"Media campionaria = \", round(mean(y), 2)),\n           color = \"red\", hjust = 0)\n```\n\n::: {.cell-output-display}\n![](16_likelihood_files/figure-html/unnamed-chunk-18-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n### Interpretazione\n\nLa curva mostra come varia la log-verosimiglianza al variare di $\\mu$:\n\n* il massimo si ottiene *in corrispondenza della media campionaria*, come previsto;\n* la forma è *concava e parabolica*, tipica del modello normale;\n* la *larghezza della curva* riflette l’incertezza della stima.\n\nIn altre parole, lo stimatore di massima verosimiglianza (MLE) di $\\mu$ è la media campionaria:\n\n$$\n\\hat{\\mu}_{\\text{MLE}} = \\bar{y}.\n$$\n\n---\n\n### Ottimizzazione numerica\n\nPossiamo verificare la stima tramite algoritmi di ottimizzazione:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nnegative_log_likelihood <- function(mu, y, sigma) {\n  -sum(dnorm(y, mean = mu, sd = sigma, log = TRUE))\n}\n\nresult <- optim(\n  par = mean(y),\n  fn = negative_log_likelihood,\n  y = y,\n  sigma = sigma,\n  method = \"L-BFGS-B\",\n  lower = min(mu_range),\n  upper = max(mu_range)\n)\n\nmu_optimal <- result$par\ncat(\"Stima numerica di massima verosimiglianza per μ:\", round(mu_optimal, 4))\n#> Stima numerica di massima verosimiglianza per μ: 30.9\n```\n:::\n\n\nConfronto con la media campionaria:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsample_mean <- mean(y)\n\ndata.frame(\n  Metodo = c(\"Ottimizzazione numerica\", \"Media campionaria\"),\n  Valore = c(mu_optimal, sample_mean),\n  Differenza = c(NA, abs(mu_optimal - sample_mean))\n)\n#>                    Metodo Valore Differenza\n#> 1 Ottimizzazione numerica   30.9         NA\n#> 2       Media campionaria   30.9    1.1e-11\n```\n:::\n\n\nIn conclusione, la stima ottenuta con l’ottimizzazione coincide perfettamente con la media campionaria. Questo conferma il risultato teorico: *per un campione indipendente da una normale con varianza nota, lo stimatore MLE della media è la media campionaria*.\n\n\n## Il rapporto di verosimiglianze\n\nIn statistica capita spesso di dover *confrontare modelli alternativi* che cercano di spiegare gli stessi dati osservati.\nAd esempio, nella stima della media di una variabile psicologica (punteggi ai test, tempi di reazione, ecc.), potremmo avere due ipotesi contrastanti:\n\n* **Modello nullo ($H_0$)**: la media assume un valore fissato $\\mu_1$ (tipicamente un valore di riferimento o assenza di effetto);\n* **Modello alternativo ($H_1$)**: la media assume un valore diverso $\\mu_2$ (indicativo di un effetto o cambiamento).\n\nIl *rapporto di verosimiglianze (Likelihood Ratio, LR)* fornisce una misura quantitativa dell’evidenza relativa a favore di un modello rispetto all’altro, basandosi direttamente sui dati.\n\n\n### Definizione formale\n\nIl rapporto di verosimiglianze è definito come\n\n$$\n\\lambda \\;=\\; \\frac{L(\\mu_2 \\mid \\text{dati})}{L(\\mu_1 \\mid \\text{dati})},\n$$\n\ndove:\n\n* $L(\\mu_2 \\mid \\text{dati})$ è la verosimiglianza sotto l’ipotesi alternativa,\n* $L(\\mu_1 \\mid \\text{dati})$ è la verosimiglianza sotto l’ipotesi nulla.\n\n\n### Interpretazione\n\n* $\\lambda > 1$: i dati favoriscono il modello alternativo;\n* $\\lambda < 1$: i dati favoriscono il modello nullo;\n* $\\lambda \\approx 1$: i dati non discriminano tra i modelli.\n\nLa distanza dall’unità indica *quanto più probabili* sono i dati sotto un modello rispetto all’altro.\n\n\n### Esempio: lancio di una moneta\n\nSupponiamo di osservare $x = 7$ successi su $n = 10$ lanci.\nConfrontiamo due modelli:\n\n* $H_0$: moneta equa ($\\theta = 0.5$)\n* $H_1$: moneta sbilanciata verso il successo ($\\theta = 0.7$)\n\n#### Calcolo analitico\n\nLa verosimiglianza binomiale è:\n\n$$\nL(\\theta \\mid x, n) \\;=\\; \\binom{n}{x}\\,\\theta^x(1-\\theta)^{n-x}.\n$$\n\nSostituendo i valori:\n\n* $L(0.5) = 120 \\cdot (0.5)^{10} \\approx 0.117$\n* $L(0.7) = 120 \\cdot (0.7)^7 (0.3)^3 \\approx 0.267$\n\nQuindi:\n\n$$\n\\lambda = \\frac{0.267}{0.117} \\;\\approx\\; 2.28.\n$$\n\n\n#### Implementazione in R\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Parametri osservati\nn <- 10\nx <- 7\n\n# Verosimiglianze\nL_null <- dbinom(x, n, 0.5)\nL_alt  <- dbinom(x, n, 0.7)\nlambda <- L_alt / L_null\n\ncat(\"L(H0, θ=0.5):\", round(L_null, 3), \"\\n\")\n#> L(H0, θ=0.5): 0.117\ncat(\"L(H1, θ=0.7):\", round(L_alt, 3), \"\\n\")\n#> L(H1, θ=0.7): 0.267\ncat(\"Rapporto di verosimiglianze λ:\", round(lambda, 2), \"\\n\")\n#> Rapporto di verosimiglianze λ: 2.28\n```\n:::\n\n\n\n#### Visualizzazione grafica\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntheta_seq <- seq(0, 1, length.out = 1000)\nlikelihood_vals <- dbinom(x, n, theta_seq)\n\ndf <- data.frame(theta = theta_seq, likelihood = likelihood_vals)\n\nggplot(df, aes(x = theta, y = likelihood)) +\n  geom_line(linewidth = 1.2, color = \"steelblue\") +\n  geom_vline(xintercept = c(0.5, 0.7), linetype = \"dashed\",\n             color = c(\"red\", \"darkgreen\"), linewidth = 1) +\n  geom_point(aes(x = 0.5, y = L_null), color = \"red\", size = 3) +\n  geom_point(aes(x = 0.7, y = L_alt), color = \"darkgreen\", size = 3) +\n  labs(\n    x = expression(theta),\n    y = \"Verosimiglianza\"\n  ) +\n  annotate(\"text\", x = 0.5, y = L_null + 0.01, label = \"H₀: θ = 0.5\",\n           color = \"red\", hjust = -0.1) +\n  annotate(\"text\", x = 0.7, y = L_alt + 0.01, label = \"H₁: θ = 0.7\",\n           color = \"darkgreen\", hjust = -0.1) \n```\n\n::: {.cell-output-display}\n![](16_likelihood_files/figure-html/unnamed-chunk-22-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n\n### Interpretazione dei risultati\n\nIl valore $\\lambda \\approx 2.28$ indica che i dati sono circa *2.3 volte più probabili sotto l’ipotesi alternativa* rispetto all’ipotesi nulla.\nSi tratta di un’evidenza *moderata ma non decisiva* a favore dell’ipotesi che la moneta sia predisposta verso il successo.\n\n\n### Considerazioni metodologiche\n\n1. **Evidenza relativa**: il rapporto di verosimiglianze non misura la bontà assoluta del modello, ma solo la preferenza relativa.\n2. **Scala di interpretazione**: valori tra 1 e 3 suggeriscono un’evidenza debole-moderata, mentre valori più grandi indicano supporto crescente.\n3. **Generalità**: la logica del LR si applica a qualsiasi modello parametrico.\n4. **Connessione bayesiana**: con prior poco informative, $\\lambda$ si avvicina al *fattore di Bayes*, strumento principe della selezione di modelli in ottica bayesiana.\n\n\n## Rapporti di verosimiglianza aggiustati e criterio di Akaike\n\nQuando si confrontano modelli statistici, occorre tenere presente che i modelli più complessi, dotati di un numero maggiore di parametri, tendono *naturalmente* a produrre un miglior adattamento ai dati osservati. Questo vantaggio, tuttavia, può dipendere solo dalla maggiore flessibilità del modello, senza riflettere una reale capacità esplicativa. Il fenomeno, noto come *sovradattamento* (*overfitting*), richiede quindi criteri che penalizzino opportunamente la complessità.\n\n### Il ruolo dell’AIC\n\nIl *Criterio di Informazione di Akaike (AIC)* rappresenta una soluzione semplice ed efficace. La sua formulazione è:\n\n$$\n\\text{AIC} = 2k - 2 \\log(L),\n$$\ndove:\n\n* $k$ è il numero di parametri del modello,\n* $L$ è la massima verosimiglianza del modello.\n\nIn questo modo l’AIC combina due aspetti:\n\n* la bontà di adattamento, catturata da $-2 \\log(L)$;\n* la parsimonia, garantita dal termine di penalizzazione $2k$.\n\n\n### Esempio: memoria visiva ed emozione\n\nSupponiamo di voler valutare l’effetto del contenuto emotivo delle immagini sulla memoria visiva. In un esperimento, 30 partecipanti per condizione hanno ottenuto:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsuccessi_neutro <- 14\nsuccessi_emozione <- 22\nprove <- 30\n```\n:::\n\n\n\n#### Modello nullo ($H_0$): probabilità comune\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Probabilità congiunta stimata\np_null <- (successi_neutro + successi_emozione) / (2 * prove)\n\n# Log-verosimiglianza\nll_null <- dbinom(successi_neutro, prove, p_null, log = TRUE) +\n           dbinom(successi_emozione, prove, p_null, log = TRUE)\n```\n:::\n\n\n\n#### Modello alternativo ($H_1$): probabilità distinte\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Probabilità stimate separatamente\np_neutro <- successi_neutro / prove\np_emozione <- successi_emozione / prove\n\n# Log-verosimiglianza\nll_alt <- dbinom(successi_neutro, prove, p_neutro, log = TRUE) +\n          dbinom(successi_emozione, prove, p_emozione, log = TRUE)\n```\n:::\n\n\n\n#### Confronto tramite AIC\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nAIC_null <- 2 * 1 - 2 * ll_null  # Modello con 1 parametro\nAIC_alt  <- 2 * 2 - 2 * ll_alt   # Modello con 2 parametri\n\ndelta_AIC <- AIC_alt - AIC_null\n```\n:::\n\n\n* Un valore di AIC più basso indica il modello preferito.\n* Differenze $> 2$ suggeriscono evidenza sostanziale a favore del modello migliore.\n* Differenze $> 10$ forniscono evidenza decisiva.\n\n\n#### Test del rapporto di verosimiglianza\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nLR_stat <- -2 * (ll_null - ll_alt)\np_value <- pchisq(LR_stat, df = 1, lower.tail = FALSE)\n```\n:::\n\n\n\n### Interpretazione\n\nIl confronto tra modelli fornisce due prospettive complementari:\n\n1. *AIC*: valuta la qualità relativa dei modelli, bilanciando adattamento e complessità.\n2. *Rapporto di verosimiglianza*: consente un test formale della differenza tra modelli.\n\nNell’esempio, il test produce $p \\approx 0.034$, mentre l’AIC mostra una chiara preferenza per il modello alternativo. Entrambi i criteri concordano: il modello che assegna probabilità distinte ai due gruppi descrive meglio i dati, suggerendo che il *contenuto emotivo delle immagini facilita la memoria visiva*.\n\nIn conclusione, l’uso integrato di *AIC* e *rapporti di verosimiglianza* permette di prendere decisioni modellistiche fondate, evitando il rischio di sovradattamento. In psicologia, dove i dati sono spesso rumorosi e complessi, questo approccio consente di mantenere un equilibrio cruciale tra *capacità esplicativa* e *parsimonia*.\n\n\n\n## Riflessioni conclusive {.unnumbered .unlisted}\n\nLa funzione di verosimiglianza rappresenta il fondamento concettuale e operativo dell'inferenza statistica moderna, fornendo un ponte metodologico tra modelli teorici ed evidenza empirica. La sua efficacia deriva dalla capacità di quantificare sistematicamente la plausibilità dei parametri di un modello condizionatamente ai dati osservati, creando così un collegamento formale tra astrazione teorica e osservazione sperimentale.\n\nL'impianto teorico della verosimiglianza si basa su tre componenti essenziali: la specificazione del modello probabilistico generatore dei dati, la definizione dello spazio parametrico e l'incorporazione delle osservazioni empiriche. Questo framework si dimostra particolarmente efficace nei modelli binomiali e gaussiani, dove assume forme analiticamente trattabili che facilitano sia la stima puntuale che la verifica di ipotesi.\n\nNel contesto della distribuzione normale, la stima di massima verosimiglianza del parametro μ coincide elegantemente con la media campionaria, mentre la rappresentazione grafica della funzione di verosimiglianza offre una visualizzazione immediata della precisione della stima. L'adozione della log-verosimiglianza, oltre a semplificare i calcoli analitici, garantisce una maggiore stabilità numerica, particolarmente valuable in contesti con campioni di grandi dimensioni o modelli complessi.\n\nIl rapporto di verosimiglianza si configura come uno strumento particolarmente versatile, in grado di bilanciare sofisticatamente la bontà di adattamento con il principio di parsimonia modellistica. Questo bilanciamento trova la sua espressione formale in criteri di selezione modellistica come l'AIC, che penalizzano appropriatamente la complessità parametrica evitando il sovradattamento.\n\nLa verosimiglianza, nelle sue molteplici manifestazioni, non si limita a collegare modelli teorici e dati empirici, ma costituisce il motore propulsivo dell'inferenza bayesiana. Attraverso il teorema di Bayes, la verosimiglianza trasforma sistematicamente l'informazione a priori in distribuzioni posteriori, aggiornando razionalmente le nostre credenze alla luce dell'evidenza osservata. Questo duplice ruolo - sia nell'ambito frequentista che in quello bayesiano - testimonia la profondità e l'utilità di questo strumento statistico fondamentale.\n\nLa padronanza dei concetti di verosimiglianza e log-verosimiglianza rappresenta quindi una competenza essenziale per lo psicologo ricercatore, permettendo non solo l'analisi appropriata dei dati sperimentali, ma anche la comprensione critica dei modelli teorici che sottendono i processi psicologici investigati.\n\n\n::: {.callout-important title=\"Problemi\" collapse=\"true\"}\n\nSpiega ciascuno dei concetti seguenti con una frase:\n\n- probabilità.\n- funzione di massa di probabilità.\n- funzione di densità di probabilità.\n- distribuzione di probabilità.\n- distribuzione di probabilità discreta.\n- distribuzione di probabilità continua.\n- funzione di distribuzione cumulativa (cdf).\n- verosimiglianza\n\n:::\n\n\n::: {.callout-important title=\"Problemi\" collapse=\"true\"}\n\nSupponi di aver misurato il livello di ansia (ad esempio usando una scala standardizzata) in un campione di 15 persone con i seguenti punteggi:\n\n```r\nansia <- c(23, 27, 30, 29, 25, 28, 26, 24, 31, 29, 27, 26, 28, 30, 25)\n```\n\nAssumendo che la deviazione standard sia nota e pari a 3.5, svolgi le seguenti attività in R:\n\n1. Calcola la funzione di verosimiglianza gaussiana per diversi valori di $\\mu$ nell'intervallo da 20 a 35.\n2. Trova numericamente il valore di $\\mu$ che rende massima la verosimiglianza (stima di massima verosimiglianza, MLE).\n3. Disegna un grafico della funzione di verosimiglianza per visualizzare il risultato.\n\n:::\n\n\n::: {.callout-note collapse=true title=\"Informazioni sull'ambiente di sviluppo\"}\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.5.1 (2025-06-13)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.6.1\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#>  [4] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#>  [7] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#> [10] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#> [13] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#> [16] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#> [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#> [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#> [25] here_1.0.1           \n#> \n#> loaded via a namespace (and not attached):\n#>  [1] svUnit_1.0.8          tidyselect_1.2.1      farver_2.1.2         \n#>  [4] fastmap_1.2.0         TH.data_1.1-4         tensorA_0.36.2.1     \n#>  [7] digest_0.6.37         timechange_0.3.0      estimability_1.5.1   \n#> [10] lifecycle_1.0.4       survival_3.8-3        magrittr_2.0.3       \n#> [13] compiler_4.5.1        rlang_1.1.6           tools_4.5.1          \n#> [16] knitr_1.50            labeling_0.4.3        bridgesampling_1.1-2 \n#> [19] htmlwidgets_1.6.4     curl_7.0.0            pkgbuild_1.4.8       \n#> [22] RColorBrewer_1.1-3    abind_1.4-8           multcomp_1.4-28      \n#> [25] withr_3.0.2           purrr_1.1.0           grid_4.5.1           \n#> [28] stats4_4.5.1          colorspace_2.1-1      xtable_1.8-4         \n#> [31] inline_0.3.21         emmeans_1.11.2-8      scales_1.4.0         \n#> [34] MASS_7.3-65           cli_3.6.5             mvtnorm_1.3-3        \n#> [37] rmarkdown_2.29        ragg_1.5.0            generics_0.1.4       \n#> [40] RcppParallel_5.1.11-1 cachem_1.1.0          stringr_1.5.1        \n#> [43] splines_4.5.1         parallel_4.5.1        vctrs_0.6.5          \n#> [46] V8_7.0.0              Matrix_1.7-4          sandwich_3.1-1       \n#> [49] jsonlite_2.0.0        arrayhelpers_1.1-0    systemfonts_1.2.3    \n#> [52] glue_1.8.0            codetools_0.2-20      distributional_0.5.0 \n#> [55] lubridate_1.9.4       stringi_1.8.7         gtable_0.3.6         \n#> [58] QuickJSR_1.8.0        htmltools_0.5.8.1     Brobdingnag_1.2-9    \n#> [61] R6_2.6.1              textshaping_1.0.3     rprojroot_2.1.1      \n#> [64] evaluate_1.0.5        lattice_0.22-7        backports_1.5.0      \n#> [67] memoise_2.0.1         broom_1.0.9           snakecase_0.11.1     \n#> [70] rstantools_2.5.0      coda_0.19-4.1         gridExtra_2.3        \n#> [73] nlme_3.1-168          checkmate_2.3.3       xfun_0.53            \n#> [76] zoo_1.8-14            pkgconfig_2.0.3\n```\n:::\n\n:::\n\n## Bibliografia {.unnumbered .unlisted}\n\n",
    "supporting": [
      "16_likelihood_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}