{
  "hash": "2557896493aad74a76d417485f7648f2",
  "result": {
    "engine": "knitr",
    "markdown": "# Stime, stimatori e parametri {#sec-prob-sampling-distr}\n\n::: {.epigraph}\n> “Lo scopo della statistica inferenziale è trarre conclusioni su una popolazione utilizzando le informazioni contenute in un campione. Lo stimatore è il nostro strumento formale per compiere questa induzione.”\n>\n> -- **Sir David Cox** *Principles of Statistical Inference* (2006)\n:::\n\n\n## Introduzione {.unnumbered .unlisted} \n\nIn psicologia – come in molte altre discipline – ci si trova spesso nella situazione di voler comprendere una particolare *caratteristica* di un’intera popolazione. Tuttavia, difficilmente è possibile raccogliere dati da *tutti* i membri di tale popolazione, a causa di limiti di tempo, risorse o accessibilità. Ad esempio, potremmo voler stimare la percentuale di persone che soffrono di un determinato disturbo d’ansia oppure la media di un punteggio di memoria a breve termine, ma non siamo in grado di testare ogni singolo individuo appartenente al gruppo di interesse. Per far fronte a questo limite, si sceglie di selezionare un *campione* di partecipanti (idealmente in modo casuale), dal quale si ricavano le informazioni utili a *inferire* la caratteristica dell’intera popolazione, riconoscendo un certo grado di incertezza.\n\nNel linguaggio statistico:\n\n- **Popolazione**: l’insieme completo degli individui (o unità) di interesse. Esempi: tutte le persone che soddisfano certi criteri diagnostici, tutti gli studenti di una scuola, tutte le misurazioni di reazione a uno stimolo sperimentale.\n- **Parametro**: la quantità (sconosciuta) che descrive la caratteristica d’interesse nella popolazione (esempio: la “vera” proporzione di soggetti con un certo disturbo, oppure la “vera” media di un test cognitivo).\n- **Campione**: un sottoinsieme di individui (idealmente estratto in modo casuale) dalla popolazione di interesse.\n- **Stima**: il valore numerico, calcolato sul campione, che approssima il parametro.\n- **Stimatore**: la regola o funzione matematica con cui, a partire dai dati del campione, si ottiene la stima.\n\nCome esempio, immaginiamo di voler conoscere la proporzione di adulti che manifestano un certo sintomo d’ansia, indicandola con $p$. Poiché non possiamo (o non vogliamo) esaminare *tutta* la popolazione, estraiamo un campione casuale di $N$ individui, verifichiamo quanti di loro presentino il sintomo e calcoliamo:\n\n$$\n\\hat{p} = \\frac{\\text{numero di individui con il sintomo}}{N}.\n$$\n\nQuesto rapporto (detto *stima campionaria* di $p$) difficilmente coinciderà *esattamente* con $p$, ma la teoria probabilistica mostra che, in assenza di distorsioni sistematiche, $\\hat{p}$ tenderà ad avvicinarsi al valore reale al crescere della dimensione del campione.\n\n### Panoramica del capitolo {.unnumbered .unlisted}\n\n- Come le stime dei parametri della popolazione variano da campione a campione.\n- Nozioni di popolazione, campione, parametro, stima e stimatore.\n- Connessione tra stime campionarie e parametri reali della popolazione.\n- Calcolare e interpretare il valore atteso e la varianza della media campionaria.\n- Utilizzare l'errore standard per rappresentare l'incertezza nelle stime dei parametri.\n- La convergenza delle medie campionarie alla media della popolazione.\n- Il teorema per approssimare distribuzioni campionarie con distribuzioni normali.\n\n::: {.callout-tip collapse=true}\n## Prerequisiti\n\n- Leggere il capitolo *Sampling Distributions of Estimators* [@schervish2014probability].\n:::\n\n::: {.callout-caution collapse=true title=\"Preparazione del Notebook\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhere::here(\"code\", \"_common.R\") |> \n  source()\n```\n:::\n\n:::\n\n\n## Popolazione e campione\n\nPer rendere tutto più concreto, supponiamo di voler stimare la frequenza di un sintomo ansioso in un’ampia popolazione, ad esempio l’insieme di tutti gli studenti universitari di un paese. Non potendo sottoporre un questionario a ogni studente, scegliamo un sottoinsieme di individui in modo casuale (cioè il nostro *campione*) e a ciascuno somministriamo uno strumento standardizzato volto a rilevare la presenza/assenza del sintomo. Il nostro obiettivo finale è utilizzare i dati campionari per trarre inferenze sulla *popolazione* complessiva, cioè per stimare la vera proporzione $p$ di studenti che manifestano il sintomo.\n\nQuesta operazione di estrarre un sottogruppo rappresentativo si chiama *campionamento*. La proporzione di individui con il sintomo d’ansia calcolata nel campione è la nostra *stima campionaria* (simbolizzata con $\\bar{X}$ o, più spesso in contesto di proporzioni, con $\\hat{p}$). Se il campione è selezionato in modo corretto e rappresentativo, ci aspettiamo che $\\bar{X}$ rispecchi, con un certo margine di errore, il vero valore di $p$ (il *parametro*).\n\n### Lo stimatore: la proporzione campionaria\n\nPer formalizzare ulteriormente, consideriamo un modello “urna” in cui la popolazione è immaginata come un’urna piena di “biglie” di due colori (ad esempio, “blu” per sintomo presente, “rosso” per sintomo assente). Estraendo a caso $N$ biglie (cioè selezionando $N$ soggetti), definiamo la variabile casuale $X_i$ come:\n\n$$\nX_i =\n\\begin{cases}\n1 & \\text{se l’individuo } i \\text{ presenta il sintomo (biglia blu),}\\\\\n0 & \\text{se l’individuo } i \\text{ non presenta il sintomo (biglia rossa).}\n\\end{cases}\n$$\n\nLa proporzione campionaria – ossia la nostra stima empirica di $p$ – è data da:\n\n$$\n\\bar{X} \\;=\\; \\frac{1}{N}\\sum_{i=1}^N X_i.\n$$\n\nDal punto di vista interpretativo:\n\n- $p$ è la vera proporzione di studenti (biglie “blu”) nella popolazione;\n- $\\bar{X}$ è la proporzione di studenti con il sintomo riscontrata nel campione.\n\n\n## Distribuzione campionaria: valore atteso e varianza\n\nIl passo cruciale per il *ragionamento inferenziale* è capire come varia $\\bar{X}$ se ripetiamo la procedura di campionamento molte volte. In altre parole, se estraessimo più volte (indipendentemente) un campione di ampiezza $N$, otterremmo ogni volta un valore di $\\bar{X}$ in genere diverso. La *collezione* di tutti questi possibili valori (con le rispettive probabilità) si chiama *distribuzione campionaria* di $\\bar{X}$.\n\n### Valore atteso della media (o proporzione) campionaria\n\nSe $X_1, X_2, \\dots, X_n$ sono variabili aleatorie indipendenti e identicamente distribuite (i.i.d.), ognuna con valore atteso $\\mathbb{E}[X_i] = \\mu$, allora la loro *media* campionaria\n\n$$\n\\bar{X} \\;=\\; \\frac{1}{n}\\sum_{i=1}^n X_i\n$$\n\npossiede a sua volta valore atteso\n\n$$\n\\mathbb{E}[\\bar{X}] \\;=\\; \\mu.\n$$\n\nQuesta semplice formula rivela che $\\bar{X}$ è uno *stimatore non distorto* per $\\mu$: in media, se ripetessimo infinite volte lo stesso tipo di campionamento, otterremmo una stima che coincide con il vero valore del parametro. Nel caso di variabili 0-1 (come presenza/assenza di sintomo), abbiamo $\\mu \\equiv p$.\n\n::: {.proof}\n\n\nConsideriamo un campione casuale $X_1, X_2, \\dots, X_n$ di variabili aleatorie *indipendenti e identicamente distribuite (i.i.d.)*, ognuna con valore atteso $\\mathbb{E}[X_i] = \\mu$. Vogliamo dimostrare che il valore atteso della media campionaria $\\bar{X}$ è uguale a $\\mu$:\n\n$$\n\\mathbb{E}[\\bar{X}] = \\mu.\n$$\n\n**Passo 1: Definizione di media campionaria.**    \nLa media campionaria è definita come:  \n$$\n\\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i.\n$$\n\n**Passo 2: Applicazione del valore atteso.**    \nCalcoliamo il valore atteso di $\\bar{X}$, sfruttando la *linearità del valore atteso* (l’aspettativa di una somma è la somma delle aspettative):  \n$$\n\\mathbb{E}[\\bar{X}] = \\mathbb{E}\\left[\\frac{1}{n} \\sum_{i=1}^n X_i\\right].\n$$\n\n**Passo 3: Portare fuori le costanti.**    \nIl fattore $\\frac{1}{n}$ è una costante rispetto all’operatore $\\mathbb{E}$:  \n$$\n\\mathbb{E}[\\bar{X}] = \\frac{1}{n} \\mathbb{E}\\left[\\sum_{i=1}^n X_i\\right].\n$$\n\n**Passo 4: Separare la somma.**    \nPer linearità, l’aspettativa della somma è la somma delle aspettative:  \n$$\n\\mathbb{E}\\left[\\sum_{i=1}^n X_i\\right] = \\sum_{i=1}^n \\mathbb{E}[X_i].\n$$\n\n**Passo 5: Sfruttare l’identica distribuzione.**    \nPoiché tutte le $X_i$ sono identicamente distribuite, $\\mathbb{E}[X_i] = \\mu$ per ogni $i$:  \n$$\n\\sum_{i=1}^n \\mathbb{E}[X_i] = \\sum_{i=1}^n \\mu = n\\mu.\n$$\n\n**Passo 6: Combinare i risultati.**   \nSostituendo nel Passo 3:  \n$$\n\\mathbb{E}[\\bar{X}] = \\frac{1}{n} \\cdot n\\mu = \\mu.\n$$\n\n**Interpretazione e Significato.**  \n\n1. *Non distorsione (Unbiasedness)*:  \n   La dimostrazione mostra che $\\bar{X}$ è uno *stimatore non distorto* di $\\mu$. Questo significa che, in media su infinite replicazioni del campionamento, $\\bar{X}$ coincide con il vero valore $\\mu$.  \n2. *Indipendenza non necessaria per l’aspettativa*:  \n   L’indipendenza tra le $X_i$ non è richiesta per questa dimostrazione. Bastano l’*identica distribuzione* (per garantire $\\mathbb{E}[X_i] = \\mu$) e la *linearità* del valore atteso.  \n3. *Caso speciale: proporzione campionaria*  \n   Se le $X_i$ sono variabili di Bernoulli (0-1) con $\\mathbb{E}[X_i] = p$, allora $\\bar{X} = \\frac{\\text{numero di successi}}{n}$ stima la proporzione $p$, e $\\mathbb{E}[\\bar{X}] = p$.\n\n**Perché è importante?**  \nQuesta proprietà è alla base dell’inferenza statistica:  \n\n- Giustifica l’uso della media campionaria come stima affidabile di $\\mu$.  \n- È il fondamento della *Legge dei Grandi Numeri*: all’aumentare di $n$, $\\bar{X}$ converge a $\\mu$.\n:::\n\n### Varianza della media (o proporzione) campionaria\n\nOltre al valore atteso, un’altra misura fondamentale è la *varianza* della distribuzione campionaria, che quantifica quanto $\\bar{X}$ tenda a fluttuare attorno a $\\mu$. Se la varianza individuale di ciascun $X_i$ è $\\sigma^2$, allora per la media campionaria si ha:\n\n$$\n\\mathrm{Var}(\\bar{X}) \\;=\\; \\frac{\\sigma^2}{n}.\n$$ {#eq-err-standard-mean}\n\nNel caso Bernoulliano (variabili 0-1) con $\\mathbb{E}[X_i] = p$, sappiamo che\n\n$$\n\\sigma^2 \\;=\\; p(1-p).\n$$\n\nPertanto:\n\n$$\n\\mathrm{Var}(\\bar{X}) \\;=\\; \\frac{p \\bigl(1-p\\bigr)}{n}.\n$$\n\nLa radice quadrata di questa varianza prende il nome di *errore standard* (in inglese *Standard Error*, SE) della media (o della proporzione), e risulta:\n\n$$\n\\mathrm{SE}(\\bar{X}) \\;=\\; \\sqrt{\\frac{p\\,(1-p)}{n}}.\n$$\n\nCon l’aumentare di $n$, la varianza di $\\bar{X}$ diminuisce, e quindi la nostra stima diventa più “precisa” (in un senso statistico). Ciò spiega perché, anche nella pratica psicologica, *aumentare la dimensione del campione* riduce l’incertezza nella stima e migliora l’affidabilità dei risultati.\n\n**Osservazione**: nella ricerca psicologica, l’errore standard fornisce un’indicazione chiara di quanto, in media, la nostra stima potrebbe deviare dal vero parametro, se ripetessimo il campionamento molte volte. Questo concetto è centrale in molte procedure inferenziali, come la costruzione di intervalli di confidenza o il test di ipotesi, e prepara il terreno per comprendere la cosiddetta *distribuzione campionaria della media* (argomento che il capitolo proseguirà a trattare).\n\n::: {.proof}\n\nForniamo qui la dimostrazione dell'@eq-err-standard-mean. Assumiamo che $X_1, X_2, \\dots, X_n$ siano variabili casuali *indipendenti e identicamente distribuite* (i.i.d.) con media $\\mu$ e varianza $\\sigma^2$. Definiamo la media campionaria\n\n$$\n\\bar{X} \\;=\\; \\frac{1}{n}\\sum_{i=1}^n X_i.\n$$\n\nVogliamo calcolare $\\mathrm{Var}(\\bar{X})$. Per prima cosa, notiamo che:\n\n$$\n\\mathrm{Var}(a\\,Y) \\;=\\; a^2 \\,\\mathrm{Var}(Y)\n$$\n\nper qualunque costante $a$. Nel nostro caso, poniamo $a = \\frac{1}{n}$ e $Y = \\sum_{i=1}^n X_i$. Otteniamo quindi:\n\n$$\n\\mathrm{Var}(\\bar{X})\n\\;=\\;\n\\mathrm{Var}\\!\\Bigl(\\tfrac{1}{n}\\sum_{i=1}^n X_i\\Bigr)\n\\;=\\;\n\\frac{1}{n^2} \\, \\mathrm{Var}\\!\\Bigl(\\sum_{i=1}^n X_i\\Bigr).\n$$\n\nOra sfruttiamo il fatto che $X_1, X_2, \\dots, X_n$ siano indipendenti. In tal caso, la varianza della somma è la somma delle varianze:\n\n$$\n\\mathrm{Var}\\Bigl(\\sum_{i=1}^n X_i\\Bigr)\n\\;=\\;\n\\sum_{i=1}^n \\mathrm{Var}(X_i)\n\\;=\\;\nn \\,\\sigma^2,\n$$\n\npoiché $\\mathrm{Var}(X_i) = \\sigma^2$ per tutti gli $i$. Combiniamo dunque i due risultati:\n\n$$\n\\mathrm{Var}(\\bar{X})\n\\;=\\;\n\\frac{1}{n^2}\\,\\bigl(n \\,\\sigma^2\\bigr)\n\\;=\\;\n\\frac{\\sigma^2}{n}.\n$$\n\nIn sintesi, la chiave della dimostrazione sta nel fattore $\\tfrac{1}{n^2}$ e nel fatto che, per variabili indipendenti, la varianza di una somma è la somma delle varianze. Questo ci consente di concludere che la varianza della media campionaria è $\\tfrac{\\sigma^2}{n}$.\n:::\n\nQuesto risultato riflette un'importante proprietà statistica:\n\n- all'aumentare di $n$, la varianza della media campionaria diminuisce, rendendo la media campionaria una stima più precisa del valore atteso $\\mu$. La riduzione della varianza è proporzionale a $1/n$, quindi raddoppiare il campione riduce la varianza della media campionaria di un fattore 2.\n\nIn conclusione, la formula $\\text{Var}(\\bar{X}) = \\frac{\\sigma^2}{n}$ mostra che la precisione della media campionaria aumenta con la dimensione del campione, poiché la varianza diminuisce. Questo principio è alla base dell'importanza di campioni più grandi nella stima statistica.\n\n\n## La distribuzione campionaria della media\n\nPer illustrare ulteriormente il concetto di distribuzione campionaria, consideriamo un caso semplice e specifico: una popolazione finita di dimensioni ridotte. Sebbene stiamo esaminando un caso particolare, è fondamentale notare che le proprietà e i principi che analizzeremo in questo contesto sono perfettamente applicabili a popolazioni di qualsiasi dimensione.\n\nLa distribuzione campionaria ci dà una visione della variazione che potremmo aspettarci nelle stime derivate da diversi campioni estratti dalla stessa popolazione. Ogni volta che preleviamo un campione, otteniamo una stima diversa per il parametro di interesse (come la media). La distribuzione campionaria ci mostra come queste stime sono distribuite e ci aiuta a comprendere quanto siano affidabili.\n\nIn termini pratici, se vogliamo calcolare la media della popolazione, non possiamo farlo direttamente (a meno di non avere accesso all'intera popolazione). Invece, possiamo estrarre un campione casuale e calcolare la media del campione come stima di $\\mu$. Tuttavia, un altro campione fornirà una stima leggermente diversa. La distribuzione campionaria ci aiuta a capire quanto queste stime varino da campione a campione e ci fornisce un quadro completo dell'incertezza legata al processo di stima.\n\nNella simulazione seguente, ipotizziamo la seguente popolazione:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nx <- c(2, 4.5, 5, 5.5)\nx\n#> [1] 2.0 4.5 5.0 5.5\n```\n:::\n\n\nL'istogramma seguente descrive la distribuzione della popolazione.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(data.frame(x = x), aes(x)) +\n  geom_histogram(\n    bins = 5,\n    aes(y = after_stat(density))\n  )\n```\n\n::: {.cell-output-display}\n![](09_sampling_distr_files/figure-html/unnamed-chunk-3-1.png){fig-align='center' width=85%}\n:::\n:::\n\nCalcoliamo la media e la varianza della popolazione. Media:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmean_x <- mean(x) # Media della popolazione\nmean_x\n#> [1] 4.25\n```\n:::\n\n\nVarianza:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nvar_x <- var(x) * ((length(x) - 1) / length(x)) # Varianza popolazione\nvar_x\n#> [1] 1.81\n```\n:::\n\n\nConsideriamo tutti i possibili campioni di dimensione $n = 2$ che possono essere estratti dalla popolazione rappresentata dal vettore `x`. Per generare questi campioni, utilizziamo la funzione `expand.grid` in R, che consente di creare tutte le combinazioni possibili di valori, includendo le ripetizioni.\n\nIl risultato sarà un data frame con 16 righe e 2 colonne, dove ogni riga rappresenta una coppia possibile di valori estratti dal vettore `x`. Questo risultato è in linea con il principio del calcolo combinatorio: quando selezioniamo $n$ elementi da un insieme di $k$ elementi e permettiamo ripetizioni, il numero totale di combinazioni è dato da $k^n$. Nel nostro caso, con $k = 4$ e $n = 2$, otteniamo:\n\n$$\n4^2 = 16 \\text{ combinazioni}.\n$$  \n\nUtilizzando `expand.grid`, possiamo verificare questo risultato in R:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Generazione delle combinazioni con ripetizione\nsamples <- expand.grid(x, x)\n\n# Visualizzazione del risultato\nprint(samples)\n#>    Var1 Var2\n#> 1   2.0  2.0\n#> 2   4.5  2.0\n#> 3   5.0  2.0\n#> 4   5.5  2.0\n#> 5   2.0  4.5\n#> 6   4.5  4.5\n#> 7   5.0  4.5\n#> 8   5.5  4.5\n#> 9   2.0  5.0\n#> 10  4.5  5.0\n#> 11  5.0  5.0\n#> 12  5.5  5.0\n#> 13  2.0  5.5\n#> 14  4.5  5.5\n#> 15  5.0  5.5\n#> 16  5.5  5.5\n```\n:::\n\n\nIl data frame risultante mostrerà tutte le possibili coppie $(x_1, x_2)$, dove $x_1$ e $x_2$ possono essere scelti indipendentemente dalla popolazione $x = \\{2, 4.5, 5, 5.5\\}$.\n\nPer calcolare la media di ogni campione di ampiezza $n = 2$, possiamo utilizzare la funzione `rowMeans`, che calcola la media per ogni riga di una matrice. In questo modo, otteniamo un vettore contenente la media di ciascuna coppia di valori. Questo insieme di valori costituisce la *distribuzione campionaria* delle medie dei campioni di ampiezza $n = 2$ che possono essere estratti dalla popolazione `x`.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Calcolare la media di ciascun campione\nsample_means <- rowMeans(samples)\nprint(sample_means)\n#>  [1] 2.00 3.25 3.50 3.75 3.25 4.50 4.75 5.00 3.50 4.75 5.00 5.25 3.75 5.00 5.25\n#> [16] 5.50\n```\n:::\n\n\nUna rappresentazione grafica della distribuzione campionaria delle medie dei campioni di ampiezza $n = 2$ che possono essere estratti dalla popolazione `x` è fornita qui sotto.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Istogramma delle medie campionarie\nggplot(data.frame(sample_means), aes(x = sample_means)) +\n  geom_histogram(\n    bins = 5,\n    aes(y = after_stat(density))\n)\n```\n\n::: {.cell-output-display}\n![](09_sampling_distr_files/figure-html/unnamed-chunk-8-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\nMostriamo qui nuovamente la lista di tutti i possibili campioni di ampiezza 2 insieme alla media di ciascun campione.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Creare un data frame con i campioni e le loro medie\ndf <- data.frame(\n  Samples = apply(samples, 1, paste, collapse = \", \"),\n  x_bar = rowMeans(samples)\n)\nprint(df)\n#>     Samples x_bar\n#> 1      2, 2  2.00\n#> 2    4.5, 2  3.25\n#> 3      5, 2  3.50\n#> 4    5.5, 2  3.75\n#> 5    2, 4.5  3.25\n#> 6  4.5, 4.5  4.50\n#> 7    5, 4.5  4.75\n#> 8  5.5, 4.5  5.00\n#> 9      2, 5  3.50\n#> 10   4.5, 5  4.75\n#> 11     5, 5  5.00\n#> 12   5.5, 5  5.25\n#> 13   2, 5.5  3.75\n#> 14 4.5, 5.5  5.00\n#> 15   5, 5.5  5.25\n#> 16 5.5, 5.5  5.50\n```\n:::\n\n\nProcediamo ora al calcolo della media della distribuzione campionaria delle medie di campioni di ampiezza $n = 2$ che possono essere estratti dalla popolazione `x`. \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Calcolare la media delle medie campionarie\nmean(sample_means)\n#> [1] 4.25\n```\n:::\n\n\nSi noti che questo valore coincide con la media della popolazione. \n\nLa varianza delle medie campionarie, calcolata empiricamente, può essere ottenuta direttamente dai dati utilizzando la seguente formula:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nvar(x) * (length(x) - 1) / length(x) / length(x)\n#> [1] 0.453\n```\n:::\n\n\nQuesto calcolo riflette la formula teorica per la varianza della media campionaria, definita come la varianza dei dati divisa per la dimensione del campione $n$. Tuttavia, poiché la funzione `var()` in R utilizza $n-1$ al denominatore per fornire una stima non distorta della varianza della popolazione, è necessario applicare un fattore di correzione $\\frac{n-1}{n}$ per ottenere la varianza campionaria corretta. Successivamente, questa varianza viene divisa per $n$ per ottenere la varianza della media campionaria.\n\nIn alternativa, possiamo calcolare lo stesso valore prendendo la varianza delle medie di tutti i campioni (16 in questo caso):\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nvar(sample_means) * ((length(sample_means) - 1) / length(sample_means))\n#> [1] 0.906\n```\n:::\n\n\nAnche in questo caso applichiamo il fattore di correzione $\\frac{n-1}{n}$ per ottenere il calcolo corretto della varianza usando la funzione `var()` in R.\n\nEntrambi i calcoli forniscono risultati coerenti con la teoria, dimostrando che la varianza delle medie campionarie è inferiore a quella della popolazione.\n\n\n::: {.callout-note title=\"Collegamento con Bayes\"}\nNel paradigma frequentista, la distribuzione campionaria descrive la variabilità che avremmo se ripetessimo l’esperimento un gran numero di volte.\nIn Bayes, invece, non ragioniamo su campioni ipotetici, ma sulla distribuzione a posteriori dei parametri, che riflette la nostra incertezza dati i dati osservati.\nIn entrambi i casi il punto chiave è lo stesso: riconoscere che c’è variabilità e incertezza, non solo un numero singolo.\n:::\n\n\n## Legge dei Grandi Numeri {#sec-lln}\n\nLa *Legge dei Grandi Numeri* (LLN, dall'inglese *Law of Large Numbers*) è uno dei pilastri fondamentali della teoria della probabilità. Essa descrive come, all'aumentare del numero di osservazioni, la media campionaria si avvicini stabilmente al valore atteso teorico. In termini formali, se $\\bar{X}_n$ rappresenta la media di $n$ osservazioni indipendenti e identicamente distribuite (i.i.d.) con valore atteso $\\mu$, allora $\\bar{X}_n \\to \\mu$ quando $n \\to \\infty$. Questo principio è cruciale per comprendere la relazione tra dati empirici e modelli teorici, come discusso nella sezione sull'interpretazione della probabilità (@sec-prob-interpretation).\n\nEsistono due versioni principali della Legge dei Grandi Numeri:\n\n1. **Legge Forte**: La media campionaria $\\bar{X}_n$ converge *quasi certamente* a $\\mu$, il che significa che, con probabilità 1, la media osservata si avvicina indefinitamente al valore teorico al crescere di $n$.\n2. **Legge Debole**: La media campionaria $\\bar{X}_n$ converge a $\\mu$ *in probabilità*, ovvero, per ogni $\\varepsilon > 0$, la probabilità che la differenza tra $\\bar{X}_n$ e $\\mu$ superi $\\varepsilon$ tende a zero al crescere di $n$. Formalmente:\n\n   $$\n   \\Pr\\bigl(| \\bar{X}_n - \\mu| > \\varepsilon\\bigr) \\to 0 \\quad \\text{al crescere di }n.\n   $$\n\n### Applicazioni in psicologia\n\nIn psicologia, la Legge dei Grandi Numeri ha implicazioni significative. Ad esempio, se si vuole stimare con precisione la proporzione di individui che manifestano un determinato comportamento o la media di un test cognitivo in una popolazione, è necessario raccogliere un *numero sufficiente di osservazioni*. Solo con un campione ampio la media campionaria si avvicinerà alla media \"vera\" della popolazione, riducendo l'incertezza e migliorando l'affidabilità delle stime.\n\n### Forma debole della Legge dei Grandi Numeri\n\nLa *forma debole* della LGN, dimostrata per la prima volta da Jacob Bernoulli nel suo lavoro *Ars Conjectandi*, afferma che la media campionaria converge in probabilità alla media teorica [@hacking2006emergence]. In termini pratici, questo significa che, man mano che il numero di osservazioni aumenta, la probabilità che la differenza tra la media osservata e la media teorica superi un margine di errore $\\varepsilon$ diventa sempre più piccola. Formalmente:\n\n$$\n\\lim_{{n \\to \\infty}} P\\left(\\left|\\frac{1}{n} \\sum_{i=1}^n X_i - \\mu\\right| \\geq \\varepsilon\\right) = 0,\n$$\ndove:\n\n- $X_1, X_2, \\ldots, X_n$ sono variabili casuali indipendenti e identicamente distribuite (i.i.d.),\n- $\\mu$ è la media teorica,\n- $\\varepsilon$ è un numero positivo arbitrariamente piccolo.\n\n### Forma forte della Legge dei Grandi Numeri\n\nLa *forma forte* della LGN, sviluppata successivamente da matematici come Kolmogorov, è un enunciato più potente. Essa stabilisce che la media campionaria converge *quasi sicuramente* alla media teorica. Questo implica che, con probabilità 1, la media osservata si avvicina indefinitamente al valore teorico man mano che il numero di prove tende all’infinito. Formalmente:\n\n$$\nP\\left(\\lim_{{n \\to \\infty}} \\frac{1}{n} \\sum_{i=1}^n X_i = \\mu\\right) = 1.\n$$\n\n### Importanza e critiche\n\nLa Legge dei Grandi Numeri è fondamentale per garantire la validità delle stime empiriche, ma la sua applicazione pratica richiede attenzione. Ad esempio, in psicologia, la raccolta di un numero sufficiente di osservazioni può essere costosa o difficile, specialmente quando si studiano fenomeni rari o popolazioni specifiche. Inoltre, l'assunzione di indipendenza e identica distribuzione delle osservazioni potrebbe non essere sempre realistica in contesti applicativi complessi. Nonostante queste sfide, la LGN rimane un principio essenziale per comprendere come i dati empirici possano avvicinarsi alle proprietà teoriche di una popolazione.\n\n## Teorema del Limite Centrale\n\nOltre alla convergenza, un ulteriore risultato importante è che la distribuzione di $\\bar{X}_n$ *si approssima alla normale* man mano che $n$ cresce, anche se i singoli $X_i$ non sono distribuiti normalmente. \n\n::: {#thm-}\nSe $X_1, X_2, \\ldots, X_n$ sono variabili iid con media $\\mu$ e deviazione standard $\\sigma$, la distribuzione di\n\n$$\n\\bar{X}_n = \\frac{1}{n}\\sum_{i=1}^n X_i\n$$\ndiventa approssimativamente normale con media $\\mu$ e deviazione standard $\\tfrac{\\sigma}{\\sqrt{n}}$ quando $n$ è sufficientemente grande.\n:::\n\nPer il caso 0-1 (presenza/assenza di un tratto), $\\bar{X}$ è quindi circa normale con media $p$ e varianza $\\frac{p(1-p)}{n}$. Il TLC consente, tra l’altro, di costruire intervalli di confidenza e di calcolare probabilità che la stima si discosti di una certa quantità dal vero valore.\n\n::: {#exm-}\nPer visualizzare il Teorema del Limite Centrale (TLC) in azione, possiamo condurre una simulazione. Immaginiamo una popolazione distribuita in modo uniforme. Estraiamo 300 campioni di dimensione $n = 30$ da questa popolazione e osserviamo come la distribuzione campionaria delle medie di questi campioni converga a una distribuzione normale. Questa simulazione fornirà un'illustrazione concreta dell'efficacia del TLC nell'approssimare distribuzioni reali.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Impostiamo il seed per la riproducibilità dei risultati\nset.seed(42)\n\n# Generiamo una popolazione con distribuzione uniforme\npopulation <- runif(5000, min = 0, max = 1)\n\n# Passo 1: Visualizziamo l'istogramma della popolazione utilizzando ggplot2\nggplot(data.frame(population), aes(x = population)) +\n  geom_histogram(\n    aes(y = after_stat(density)),\n    bins = 30\n  ) +\n  labs(x = \"Valore\", y = \"Densità\")\n```\n\n::: {.cell-output-display}\n![](09_sampling_distr_files/figure-html/unnamed-chunk-13-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Passo 2 e 3: Estraiamo campioni casuali e calcoliamo le medie campionarie\nsample_size <- 30\nnum_samples <- 300\n\n# Vettore vuoto per memorizzare le medie campionarie\nsample_means <- c()\n\nfor (i in 1:num_samples) {\n  # Estraiamo un campione casuale\n  sample <- sample(population, size = sample_size, replace = TRUE)\n  \n  # Calcoliamo la media del campione\n  sample_means[i] <- mean(sample)\n}\n\n# Calcoliamo media e varianza delle medie campionarie\nx_bar <- mean(sample_means)\nstd <- sd(sample_means)\n\nprint('Media e Varianza delle Medie Campionarie')\n#> [1] \"Media e Varianza delle Medie Campionarie\"\nprint(x_bar)\n#> [1] 0.501\nprint(std^2)\n#> [1] 0.00275\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Calcoliamo media e varianza della popolazione\nmu <- mean(population)\nsigma <- sd(population)\n\nprint('Media e Varianza della Popolazione')\n#> [1] \"Media e Varianza della Popolazione\"\nprint(mu)\n#> [1] 0.503\nprint((sigma^2)/sample_size)\n#> [1] 0.00282\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Passo 4: Visualizziamo l'istogramma delle medie campionarie utilizzando ggplot2\nggplot(data.frame(sample_means), aes(x = sample_means)) +\n  geom_histogram(\n    aes(y = after_stat(density)),\n    bins = 30\n  ) +\n  stat_function(\n    fun = dnorm, args = list(mean = x_bar, sd = std), color = \"black\", size = 1\n  ) +\n  labs(\n    x = \"Media Campionaria\", y = \"Densità\"\n  ) +\n  theme(legend.position = \"top\") \n```\n\n::: {.cell-output-display}\n![](09_sampling_distr_files/figure-html/unnamed-chunk-16-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n**Spiegazione del codice e dei risultati**\n\n1. **Popolazione**: Abbiamo generato una popolazione di 5000 osservazioni distribuite uniformemente tra 0 e 1. La distribuzione uniforme è stata scelta perché è chiaramente non normale, il che rende più evidente l'effetto del TLC.\n\n2. **Campionamento**: Abbiamo estratto 300 campioni casuali, ciascuno di dimensione $n = 30$, dalla popolazione. Per ogni campione, abbiamo calcolato la media.\n\n3. **Distribuzione delle Medie Campionarie**: Le medie dei campioni sono state raccolte e la loro distribuzione è stata visualizzata tramite un istogramma. Nonostante la popolazione originale non fosse normale, la distribuzione delle medie campionarie si avvicina a una distribuzione normale, dimostrando il TLC.\n\n4. **Confronto tra Popolazione e Campioni**: Abbiamo confrontato la media e la varianza della popolazione con quelle delle medie campionarie. Come previsto dal TLC, la media delle medie campionarie è molto vicina alla media della popolazione, mentre la varianza delle medie campionarie è ridotta di un fattore pari alla dimensione del campione ($n = 30$).\n\nQuesta simulazione illustra chiaramente come il TLC permetta di approssimare la distribuzione delle medie campionarie a una distribuzione normale, anche quando la popolazione originale non è normale. Questo risultato è fondamentale per molte applicazioni pratiche della statistica inferenziale.\n:::\n\n::: {#exm-}\nSebbene i risultati teorici siano solidi, è comune utilizzare la *simulazione Monte Carlo* per verificarne la validità in contesti pratici. Supponiamo, ad esempio, che la proporzione reale di individui che soffrono di un certo sintomo in una popolazione sia $p = 0.45$. Possiamo simulare campioni di dimensione $n$ e calcolare la media campionaria $\\bar{X}$ (ovvero la proporzione osservata in ciascun campione). Ripetendo questo processo molte volte, otteniamo una distribuzione empirica delle $\\bar{X}$. Se l'approssimazione normale fornita dal Teorema del Limite Centrale (TLC) è valida, ci aspettiamo che:\n\n1. La media delle $\\bar{X}$ sia molto vicina al valore teorico $p = 0.45$.\n2. La varianza delle $\\bar{X}$ sia approssimativamente uguale a $p(1-p)/n$, come previsto dalla teoria.\n\nUn esempio di codice in R per questa simulazione è il seguente:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\np <- 0.45  # Proporzione reale nella popolazione\nn <- 1000  # Dimensione del campione\nB <- 10000 # Numero di campioni simulati\n\n# Simulazione Monte Carlo: generiamo B campioni e calcoliamo le medie campionarie\nx_hat <- replicate(B, {\n  x <- sample(c(0, 1), size = n, replace = TRUE, prob = c(1-p, p))\n  mean(x)\n})\n\n# Media delle medie campionarie (dovrebbe essere vicina a p)\nmean(x_hat)  # Risultato atteso: ~ 0.45\n#> [1] 0.45\n\n# Deviazione standard delle medie campionarie (dovrebbe essere vicina a sqrt(p*(1-p)/n))\nsd(x_hat)    # Risultato atteso: ~ sqrt(0.45 * 0.55 / 1000)\n#> [1] 0.0157\n```\n:::\n\n\nRisultati attesi e interpretazione:\n\n- **Media delle medie campionarie**: Il valore medio di `x_hat` dovrebbe essere molto vicino a $0.45$, confermando che la media campionaria è uno stimatore non distorto della proporzione reale $p$.\n- **Deviazione standard delle medie campionarie**: La deviazione standard di `x_hat` dovrebbe avvicinarsi a $\\sqrt{0.45 \\times 0.55 / 1000} \\approx 0.0157$, in linea con la formula teorica $\\sqrt{p(1-p)/n}$. Questo valore rappresenta l'incertezza associata alla stima della proporzione.\n\nEffetto della dimensione del campione: \n\n- Aumentando la dimensione del campione $n$, l'ampiezza della distribuzione delle medie campionarie (e quindi l'incertezza di $\\bar{X}$) diminuisce. Questo è coerente con la teoria, poiché la varianza delle medie campionarie è inversamente proporzionale a $n$. In altre parole, campioni più grandi forniscono stime più precise del parametro della popolazione.\n\nQuesta simulazione dimostra concretamente come il Teorema del Limite Centrale garantisca che, anche per popolazioni non normali (come in questo caso, dove i dati sono binari), la distribuzione delle medie campionarie si avvicini a una distribuzione normale con media $p$ e varianza $p(1-p)/n$, purché $n$ sia sufficientemente grande.\n:::\n\n### Margine di errore e intervalli di confidenza\n\nSe $\\bar{X}$ è approssimato da $\\mathcal{N}(p, \\frac{p(1-p)}{n})$, allora\n$$\nZ = \\frac{\\bar{X} - p}{\\sqrt{p(1-p)/n}}\n$$\nsegue (approssimativamente) la distribuzione normale standard $\\mathcal{N}(0,1)$. In pratica, non conoscendo $p$, possiamo sostituirlo con $\\bar{X}$ nello stimatore di errore standard ($\\mathrm{plug\\text{-}in}$):\n\n$$\n\\hat{\\mathrm{SE}}(\\bar{X}) = \\sqrt{\\frac{\\bar{X}(1-\\bar{X})}{n}}.\n$$\nSpesso si costruisce un intervallo di confidenza approssimato al 95% come:\n\n$$\n\\bar{X} \\,\\pm\\, 1.96 \\times \\hat{\\mathrm{SE}}(\\bar{X}),\n$$\ndove 1.96 deriva dal fatto che circa il 95% della distribuzione normale standard sta nell’intervallo $[-1.96,+1.96]$. Questo intervallo rappresenta la fascia di incertezza attorno alla stima, che si restringe all’aumentare di $n$.\n\n## Oltre la media: altre distribuzioni campionarie\n\nFinora ci siamo concentrati sulla *media campionaria* (o proporzione), ma in molti casi di interesse psicologico o più in generale statistico, potremmo voler studiare *altre* statistiche tratte da un campione. Due esempi importanti sono il *massimo campionario* (utile per analisi di eventi estremi, punteggi massimi nei test, tempi di reazione record, ecc.) e la *varianza campionaria* (fondamentale per misurare la variabilità dei punteggi in un test psicometrico, ad esempio).\n\n### Massimo campionario\n\nQuando siamo interessati a misurare la performance “estrema” di un gruppo (ad esempio il punteggio più elevato in un test cognitivo, oppure la latenza di reazione più *veloce* se si ragiona in termini di minimi), la statistica di riferimento è il *massimo* (o il minimo) nel campione.\n\n#### Teoria e concetti chiave\n\n- **Definizione**: Dato un campione $\\{X_1, X_2, \\dots, X_n\\}$, il *massimo campionario* è\n  $$\n  M = \\max\\{X_1, X_2, \\dots, X_n\\}.\n  $$\n  Questa variabile casuale dipende ovviamente dalla distribuzione dei singoli $X_i$.\n\n- **Proprietà**: \n\n  - La distribuzione di $M$ spesso risulta *asimmetrica* e “spostata a destra” rispetto alla distribuzione di partenza. Anche se la popolazione originaria fosse normalmente distribuita, la distribuzione del *massimo* non sarà normale.  \n  - Il valore atteso $E[M]$ supera la media $\\mu$ della popolazione perché, fra i $n$ individui osservati, “vince” sempre il più grande.\n\n- **Implicazioni pratiche**:  \n\n  - Analizzare i massimi (o i minimi) è cruciale nello studio di *fenomeni estremi* (per esempio, individuare il picco di stress in un compito cognitivo o la più alta temperatura registrata in una sperimentazione ambientale).\n  - La cosiddetta *teoria degli estremi* si fonda proprio sull’analisi di come i massimi (o minimi) si distribuiscono al crescere di $n$. Questa ha applicazioni in diverse discipline: dalla psicologia (prestazione massima) all’ingegneria (carichi estremi) fino alla finanza (rischi estremi).\n\n\n::: {.callout-note collapse=\"true\" title=\"Esercizio\"}\nNel seguente esempio, simuliamo 10.000 esperimenti. In ognuno:\n\n1. Generiamo *5 osservazioni* da una popolazione normale con media $\\mu = 100$ e deviazione standard $\\sigma = 15$.  \n2. Ne calcoliamo il *massimo campionario*.  \n\nInfine, confrontiamo la distribuzione di questi massimi con la densità della distribuzione di partenza (cioè la normale $\\mathcal{N}(100, 15^2)$).\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Impostazioni iniziali\nmu <- 100\nsigma <- 15\nx <- seq(mu - 3 * sigma, mu + 3 * sigma, length.out = 100)\ny <- dnorm(x, mean = mu, sd = sigma)\n\n# Simulazione di 10.000 esperimenti con campioni di 5 osservazioni\nset.seed(123)  # Per riproducibilità\nsample_maxes <- replicate(10000, max(rnorm(5, mean = mu, sd = sigma)))\n\n# Creiamo un data frame per il grafico\ndata <- data.frame(SampleMaxes = sample_maxes)\ndensity_data <- data.frame(x = x, y = y)\n\n# Grafico con ggplot2\nggplot(data, aes(x = SampleMaxes)) +\n  geom_histogram(\n    aes(y = after_stat(density)),\n    bins = 30,\n    alpha = 0.7\n  ) +\n  geom_line(data = density_data, aes(x = x, y = y), size = 1, color = \"black\") +\n  labs(\n    x = \"Massimo campionario\",\n    y = \"Densità\"\n  ) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = \"bold\"),\n    plot.subtitle = element_text(hjust = 0.5)\n  )\n```\n\n::: {.cell-output-display}\n![](09_sampling_distr_files/figure-html/unnamed-chunk-18-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n**Osservazioni**:\n\n- L’istogramma, che rappresenta la distribuzione dei massimi campionari, *è spostato a destra* rispetto alla distribuzione della popolazione (tracciata in rosso).\n- Ciò evidenzia che $M$ tende a fornire valori *più alti* della media $\\mu = 100$. Se ripetessimo l’esperimento con campioni di dimensione maggiore di 5, questo effetto si accentuerebbe ulteriormente.\n:::\n\n### 2. Varianza campionaria\n\nLo studio della *varianza* (o in generale della variabilità) è un altro esempio cruciale in contesti psicologici. Se vogliamo descrivere quanto differiscono i punteggi di un test di personalità, o di un test cognitivo, non basta guardare solo alla media campionaria: ci interessa anche la dispersione.\n\n#### Teoria e concetti chiave\n\n- **Stima della varianza**:  \n  Stimare la varianza $\\sigma^2$ di una popolazione non è banale. La formula\n  $$\n  S^2 = \\frac{1}{n} \\sum_{i=1}^n (Y_i - \\bar{Y})^2\n  $$\n  tende a *sottostimare* $\\sigma^2$. Per ottenere uno *stimatore non distorto*, si usa invece:\n  $$\n  S^2 = \\frac{1}{n-1} \\sum_{i=1}^n (Y_i - \\bar{Y})^2.\n  $$\n  L’uso di $n-1$ serve a correggere la perdita di un grado di libertà (poiché $\\bar{Y}$ è calcolata sui dati) e garantisce che $E[S^2] = \\sigma^2$.\n\n- **Concetto di distorsione**:  \n  Chiamiamo uno stimatore $\\hat{\\theta}$ *non distorto* se il suo valore atteso è uguale al parametro vero $\\theta$: $E[\\hat{\\theta}] = \\theta$. Con la formula a denominatore $n-1$, la varianza campionaria risulta appunto non distorta.\n\n\n::: {.callout-note collapse=\"true\" title=\"Esercizio\"}\nSimuliamo 10.000 esperimenti, ognuno con $n=5$ osservazioni generate da $\\mathcal{N}(100, 15^2)$. Per ciascun campione, calcoliamo:\n1. La varianza “distorta” $\\frac{1}{n}\\sum_i (X_i - \\bar{X})^2$.\n2. La varianza “corretta” con $n-1$.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(123)  # Per riproducibilità\n\n# Funzione per calcolare varianze con n e con n-1\ncalc_vars <- function(n = 5, mu = 100, sigma = 15) {\n  sample_data <- rnorm(n, mean = mu, sd = sigma)\n  var_n <- sum((sample_data - mean(sample_data))^2) / n\n  var_n_minus_1 <- var(sample_data)  # In R, var() usa di default n-1\n  c(var_n, var_n_minus_1)\n}\n\n# Simuliamo 10.000 campioni\nB <- 10000\nvars_matrix <- replicate(B, calc_vars())\nsample_vars_n <- vars_matrix[1, ]\nsample_vars_n_minus_1 <- vars_matrix[2, ]\n\n# Confrontiamo graficamente\ndata_n <- data.frame(SampleVars = sample_vars_n, Type = \"Con n\")\ndata_n_minus_1 <- data.frame(SampleVars = sample_vars_n_minus_1, Type = \"Con n-1\")\ncombined_data <- rbind(data_n, data_n_minus_1)\n\nggplot(combined_data, aes(x = SampleVars, color = Type)) +\n  geom_density(size = 1.1) +\n  labs(\n    x = \"Varianza campionaria\",\n    y = \"Densità\"\n  ) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = \"bold\"),\n    plot.subtitle = element_text(hjust = 0.5)\n  ) +\n  scale_color_manual(values = c(\"Con n\" = \"gray\", \"Con n-1\" = \"black\"))\n```\n\n::: {.cell-output-display}\n![](09_sampling_distr_files/figure-html/unnamed-chunk-19-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n**Osservazioni**:\n\n- La curva corrispondente a “Con $n$” tende a sottostimare la varianza, mentre quella “Con $n-1$” si centra meglio attorno a $\\sigma^2 = 15^2 = 225$.\n- Se verifichiamo le medie delle due distribuzioni:\n\n\n  ::: {.cell layout-align=\"center\"}\n  \n  ```{.r .cell-code}\n  mean(sample_vars_n)\n  #> [1] 181\n  mean(sample_vars_n_minus_1)\n  #> [1] 226\n  ```\n  :::\n\n  troveremo che la prima è sensibilmente inferiore a 225, mentre la seconda si avvicina di più al valore vero.\n:::\n\nSia il *massimo campionario* sia la *varianza campionaria* dimostrano come non tutte le distribuzioni campionarie ereditino le stesse proprietà della media. Nel caso del massimo, la variabile risulta spostata verso valori elevati e non segue una forma gaussiana; nel caso della varianza, si deve porre attenzione alla formula usata, per evitare distorsioni sistematiche.  \n\nIn sintesi:\n\n1. **Massimo campionario**: utile per l’analisi di fenomeni estremi (o massimi prestazionali), con una distribuzione tipicamente asimmetrica.  \n2. **Varianza campionaria**: richiede la *correzione di Bessel* (denominatore $n-1$) per essere uno stimatore non distorto di $\\sigma^2$.  \n\nCapire le proprietà di queste (e altre) distribuzioni campionarie consente allo sperimentatore di valutare correttamente le incertezze nelle stime, di evitare errori di interpretazione e di utilizzare gli stimatori più appropriati in base al tipo di fenomeno studiato.\n\n\n## Errore standard, incertezza inferenziale e bias\n\n### Errore standard e incertezza\n\nL’*errore standard (SE)* è la misura di quanto una data statistica (ad esempio la media) può variare da un campione all’altro per pura casualità di campionamento. In un contesto psicologico, può essere usato per mostrare graficamente l’affidabilità di una misura. Esporre i risultati di un test psicometrico riportando solo la media, senza un’idea dell’errore standard o di un intervallo di confidenza, rischia di dare un’illusione di precisione non giustificata.\n\n### Bias: perché non basta un campione grandissimo\n\nAumentare la dimensione campionaria $n$ riduce l’errore standard, ma *non elimina* possibili bias sistematici (si veda, ad esempio, la [disussione](https://statmodeling.stat.columbia.edu/2023/01/06/god-is-in-every-leaf-of-every-tree-bathroom-scale-edition/) fornita dal Andrew Gelman su questo tema). Ad esempio:\n\n- Se i partecipanti più ansiosi evitano di partecipare allo studio (*bias di selezione*), la proporzione $\\bar{X}$ sarà sistematicamente sottostimata.\n- Se qualcuno falsifica le risposte per desiderabilità sociale (*bias di risposta*), la media misurata può allontanarsi dal valore vero in maniera non corretta da un semplice aumento del campione.\n- Se lo strumento di misura (ad es. un questionario) è mal tarato o concettualmente scorretto, l’intero studio può soffrirne (*misurazione errata*).\n\nQuando è presente un bias, *nessun* aumento del numero di partecipanti potrà rimuoverlo: si otterranno stime molto “precise” (varianza piccola) ma sistematicamente lontane dal valore reale.\n\n\n::: {.callout-note title=\"Nota bayesiana\"}\nL’errore standard è una misura frequentista di precisione della stima.\nNell’approccio bayesiano, la precisione si legge direttamente dalla dispersione della distribuzione a posteriori del parametro.\nQuindi il concetto di “quanto è precisa la stima” resta, ma lo esprimiamo in modo diverso.\n:::\n\n\n## La prospettiva bayesiana\n\nNelle sezioni precedenti abbiamo discusso il concetto di distribuzione campionaria da una prospettiva frequentista. Questo approccio considera il parametro della popolazione (come la proporzione $p$ o la media $\\mu$) come una quantità fissa, sebbene sconosciuta. L'incertezza deriva esclusivamente dalla variabilità del processo di campionamento ripetuto.\n\nLa statistica bayesiana, invece, offre una prospettiva complementare e interpretativamente diversa:\n\n- **Parametri come variabili casuali**: Nel quadro bayesiano, i parametri non sono considerati quantità fisse, ma variabili aleatorie descritte da una distribuzione di probabilità. Questa distribuzione riflette il grado di convinzione (o conoscenza) del ricercatore rispetto al valore del parametro, prima di osservare i dati (distribuzione a priori), e viene aggiornata alla luce dei dati osservati per produrre una distribuzione a posteriori.\n\n- **Distribuzione a posteriori**: Dopo aver osservato i dati campionari, la distribuzione a posteriori descrive completamente l'incertezza sul parametro. A differenza dell’approccio frequentista, in cui l’incertezza è quantificata considerando ripetizioni ipotetiche dell’esperimento, l’incertezza bayesiana riflette direttamente lo stato attuale della nostra conoscenza.\n\n\n::: {.callout-note collapse=\"true\" title=\"Esercizio\"}\n\nRiprendiamo l'esempio precedente sulla proporzione di adulti che manifestano un certo sintomo ansioso. Consideriamo che prima di raccogliere i dati dal campione, abbiamo una credenza iniziale (a priori) sulla proporzione $p$. Potremmo assumere una distribuzione a priori Beta($\\alpha$, $\\beta$), scelta comunemente perché flessibile e comoda da aggiornare (si veda il @sec-prob-cont-prob-distr):\n\n$$\np \\sim \\text{Beta}(\\alpha, \\beta).\n$$\n\nSupponiamo ora di estrarre un campione di dimensione $N$ e osservare $y$ individui che manifestano il sintomo. La distribuzione a posteriori sarà allora:\n\n$$\np \\mid y, N \\sim \\text{Beta}(\\alpha + y, \\beta + N - y) .\n$$\n\nQuesta distribuzione incorpora sia le informazioni iniziali sia i dati osservati (si veda il @sec-bayesian-inference-conjugate-1). Aumentando il numero di osservazioni, l'influenza della distribuzione a priori si riduce, e la distribuzione a posteriori converge verso il valore effettivo di $p$, riflettendo un comportamento analogo alla Legge dei Grandi Numeri.\n\n**Interpretazione bayesiana dei risultati.**\n\n- *Intervallo di credibilità*: Al posto dell’intervallo di confidenza frequentista (si veda il @sec-frequentism-confidence-intervals), che descrive la probabilità di copertura considerando ripetizioni ipotetiche del campionamento, il bayesiano utilizza un intervallo di credibilità (si veda il @sec-bayesian-inference-summary-posterior), il quale indica direttamente l’intervallo entro cui il parametro cade con una data probabilità, date le osservazioni effettivamente raccolte.\n\n- *Convergenza della distribuzione a posteriori*: In analogia alla Legge dei Grandi Numeri e al Teorema del Limite Centrale, anche nel quadro bayesiano, all'aumentare della dimensione del campione, la distribuzione a posteriori diventa sempre più concentrata intorno al parametro vero, riducendo l’incertezza.\n:::\n\n## Riflessioni conclusive {.unnumbered .unlisted}\n\nIl percorso qui delineato mette in luce come, nell’ambito dell’inferenza frequentista, risulti fondamentale operare una chiara distinzione tra due piani concettuali: da un lato la popolazione e i suoi parametri — entità teoriche, come la vera proporzione di un sintomo psicologico o la media di un punteggio nella popolazione generale, che per loro natura non sono direttamente osservabili — e dall’altro il campione e le sue stime, ovvero i dati empirici effettivamente raccolti e le statistiche — come la media campionaria — da essi calcolate.\n\nLa nozione di distribuzione campionaria, in particolare per statistiche quali la media o la proporzione, consente di comprendere alcune proprietà cruciali dell’inferenza statistica. La media campionaria, ad esempio, è uno stimatore non distorto, il cui valore atteso coincide con il parametro della popolazione che intende stimare. La sua precisione, definita come l’inverso della varianza, aumenta al crescere della numerosità campionaria. Inoltre, grazie al Teorema del Limite Centrale, è possibile approssimare la distribuzione della media campionaria a una normale per campioni sufficientemente ampi, fatto che costituisce la base per la costruzione di intervalli di confidenza e per la valutazione probabilistica delle stime. È altrettanto importante notare come l’errore standard quantifichi esclusivamente la variabilità attribuibile al campionamento, mentre eventuali bias sistematici — legati per esempio al disegno sperimentale o alla misura — permangono anche al crescere della dimensione campionaria.\n\nComplementare alla prospettiva frequentista è l’approccio bayesiano, il quale concepisce l’incertezza inferenziale non solo in termini di variabilità campionaria, ma come riflesso diretto del nostro stato di conoscenza. Tale stato viene rappresentato esplicitamente mediante la distribuzione a posteriori, che aggiorna le credenze iniziali alla luce dei nuovi dati. Questa caratteristica rende il framework bayesiano particolarmente adatto a contesti applicativi in psicologia, dove l’obiettivo è spesso quello di revisionare in modo incrementale la comprensione di un fenomeno man mano che nuove evidenze diventano disponibili.\n\nIn sintesi, una ricerca psicologica rigorosa richiede la consapevolezza di due fonti distinte di incertezza: quella casuale, riconducibile alla variabilità del campionamento e quantificabile attraverso strumenti come l’errore standard, e quella sistematica, riconducibile a distorsioni metodologiche o concettuali. Solo un’interpretazione che tenga conto di entrambe queste componenti permette di valutare con appropriatezza la solidità delle conclusioni tratte dai dati, sia in ambito teorico sia in setting applicativi e clinici.\n\n::: {.callout-important title=\"Problemi\" collapse=\"true\"}\nEsercizi sulla distribuzione campionaria sono disponibili sulla seguente [pagina web](https://stats.libretexts.org/Bookshelves/Introductory_Statistics/Introductory_Statistics_(Shafer_and_Zhang)/06%3A_Sampling_Distributions/6.E%3A_Sampling_Distributions_(Exercises)).\n:::\n\n::: {.callout-note collapse=true title=\"Informazioni sull'ambiente di sviluppo\"}\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.5.1 (2025-06-13)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.6.1\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#>  [4] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#>  [7] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#> [10] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#> [13] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#> [16] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#> [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#> [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#> [25] here_1.0.1           \n#> \n#> loaded via a namespace (and not attached):\n#>  [1] svUnit_1.0.8          tidyselect_1.2.1      farver_2.1.2         \n#>  [4] fastmap_1.2.0         TH.data_1.1-4         tensorA_0.36.2.1     \n#>  [7] digest_0.6.37         timechange_0.3.0      estimability_1.5.1   \n#> [10] lifecycle_1.0.4       survival_3.8-3        magrittr_2.0.3       \n#> [13] compiler_4.5.1        rlang_1.1.6           tools_4.5.1          \n#> [16] knitr_1.50            labeling_0.4.3        bridgesampling_1.1-2 \n#> [19] htmlwidgets_1.6.4     curl_7.0.0            pkgbuild_1.4.8       \n#> [22] RColorBrewer_1.1-3    abind_1.4-8           multcomp_1.4-28      \n#> [25] withr_3.0.2           purrr_1.1.0           grid_4.5.1           \n#> [28] stats4_4.5.1          colorspace_2.1-1      xtable_1.8-4         \n#> [31] inline_0.3.21         emmeans_1.11.2-8      scales_1.4.0         \n#> [34] MASS_7.3-65           cli_3.6.5             mvtnorm_1.3-3        \n#> [37] rmarkdown_2.29        ragg_1.5.0            generics_0.1.4       \n#> [40] RcppParallel_5.1.11-1 cachem_1.1.0          stringr_1.5.1        \n#> [43] splines_4.5.1         parallel_4.5.1        vctrs_0.6.5          \n#> [46] V8_7.0.0              Matrix_1.7-4          sandwich_3.1-1       \n#> [49] jsonlite_2.0.0        arrayhelpers_1.1-0    systemfonts_1.2.3    \n#> [52] glue_1.8.0            codetools_0.2-20      distributional_0.5.0 \n#> [55] lubridate_1.9.4       stringi_1.8.7         gtable_0.3.6         \n#> [58] QuickJSR_1.8.0        htmltools_0.5.8.1     Brobdingnag_1.2-9    \n#> [61] R6_2.6.1              textshaping_1.0.3     rprojroot_2.1.1      \n#> [64] evaluate_1.0.5        lattice_0.22-7        backports_1.5.0      \n#> [67] memoise_2.0.1         broom_1.0.9           snakecase_0.11.1     \n#> [70] rstantools_2.5.0      coda_0.19-4.1         gridExtra_2.3        \n#> [73] nlme_3.1-168          checkmate_2.3.3       xfun_0.53            \n#> [76] zoo_1.8-14            pkgconfig_2.0.3\n```\n:::\n\n:::\n\n\n## Bibliografia {.unnumbered .unlisted}\n\n",
    "supporting": [
      "09_sampling_distr_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}