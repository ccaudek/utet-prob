{
  "hash": "1dc69ffe7d633c696220c3c35960a22e",
  "result": {
    "engine": "knitr",
    "markdown": "# Modelli probabilistici {#sec-prob-models}\n\n::: {.epigraph}\n> “La probabilità è il calcolo più importante nella vita civile. Tuttavia, è il più soggetto a errori e paradossi; anche le menti più brillanti possono ingannarsi su questioni che, dopo essere state spiegate, appaiono così ovvie da far vergognare di non averle capite prima.”\n>\n> -- **Pierre-Simon Laplace**, *Saggio filosofico sulle probabilità* (1814)\n:::\n\n\n## Introduzione {.unnumbered .unlisted}\n\nDopo aver esaminato il *significato filosofico* della probabilità nel @sec-prob-interpretation, questo capitolo ne sviluppa una trattazione più formale, creando un collegamento tra la riflessione teorica e gli strumenti operativi. Partendo dalla definizione di *esperimento casuale* – come il lancio di una moneta o la somministrazione di un test psicologico – costruiremo un framework matematico per analizzare e quantificare le proprietà di tali esperimenti. In particolare, approfondiremo i concetti di *spazio campionario*, *eventi* e *proprietà della probabilità*, fornendo le basi per un’interpretazione rigorosa dei fenomeni complessi in psicologia e nelle scienze sociali.\n\n### Panoramica del capitolo {.unnumbered .unlisted}\n\n- Nozioni di spazio campionario, eventi e operazioni su eventi.\n- Definizione di probabilità.\n- Spazi discreti o continui.\n- Teorema della somma.\n\n::: {.callout-tip collapse=true}\n## Prerequisiti\n\n- Leggere il capitolo *Probability Models* del testo di @kroese2025statistical.\n- Studiare l'@sec-apx-sets.\n- Studiare l'@sec-apx-combinatorics. \n:::\n\n::: {.callout-caution collapse=true title=\"Preparazione del Notebook\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhere::here(\"code\", \"_common.R\") |>\n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(readr, VennDiagram)\n```\n:::\n\n:::\n\n::: {.callout-tip collapse=\"true\"}\n## Domande introduttive\n\nPrima di esaminare in maniera più formale le basi della teoria della probabilità, consideriamo un classico problema della teoria della probabilità: \n\n*\"Quante persone servono in una stanza perché ci sia almeno il 50% di probabilità che due condividano lo stesso compleanno?\"*  \n\nQuesto problema, noto come *problema dei compleanni*, fu introdotto dal matematico Richard von Mises nel 1932. La sua soluzione sfida l’intuizione e rivela quanto le probabilità combinatorie possano essere ingannevoli.\n\nRispondi alle seguenti domande. \n\n1. Con quante persone pensi si superi il 50% di probabilità? (23? 100? 180?)\n2. Con 30 persone, quale probabilità stimi? (10%? 50%? 70%?)\n\nScrivi le tue risposte su un foglietto senza condividere con i compagni.\n\n*Per svolgere un esercizio in classe*, compila il seguente [modulo](https://docs.google.com/forms/d/e/1FAIpQLScRZBPFsdT2P13BmcT5N6z7aQLf8YCkBcvc_jQXEM6x8SdcJg/viewform?usp=header) su Google Forms. \n:::\n\n\n## Esperimenti casuali\n\nIl concetto fondamentale della probabilità è l’*esperimento casuale*, ovvero un procedimento il cui esito non può essere previsto con certezza, ma che può essere analizzato quantitativamente. Alcuni esempi di esperimenti casuali includono: lanciare un dado e osservare il numero ottenuto sulla faccia superiore; estrarre una carta a caso da un mazzo e registrarne il seme e il valore; misurare il livello di stress percepito da un gruppo di individui in un determinato contesto, come durante un esame o un evento stressante; contare il numero di risposte corrette fornite dai partecipanti a un test di memoria entro un tempo prestabilito; eccetera.\n\nL’analisi probabilistica ha lo scopo di comprendere il comportamento di tali esperimenti attraverso la costruzione di modelli matematici. Una volta formalizzato matematicamente un esperimento casuale, è possibile calcolare grandezze di interesse, come probabilità ed aspettative. Questi modelli possono essere implementati al computer per simulare l’esperimento e analizzarne i risultati. Inoltre, la modellizzazione matematica degli esperimenti casuali costituisce la base della statistica, disciplina che permette di confrontare diversi modelli e identificare quello più adeguato ai dati osservati.\n\n\n### Il lancio di una moneta\n\nUno degli esperimenti casuali più semplici e fondamentali è il *lancio ripetuto di una moneta*. Molti concetti chiave della teoria della probabilità possono essere illustrati partendo da questo esperimento elementare. Per studiarne il comportamento, possiamo simularlo al computer utilizzando il linguaggio R. \n\nDi seguito, un semplice script in R simula *100 lanci* di una moneta equa (cioè con probabilità uguali di ottenere Testa o Croce) e rappresenta graficamente la distribuzione dei risultati mediante un diagramma a barre.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(123) # Imposta il seed per garantire la riproducibilità\nx <- runif(100) < 0.5 # Genera 100 numeri casuali e verifica se sono minori di 0.5\nx\n#>   [1]  TRUE FALSE  TRUE FALSE FALSE  TRUE FALSE FALSE FALSE  TRUE FALSE  TRUE\n#>  [13] FALSE FALSE  TRUE FALSE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE\n#>  [25] FALSE FALSE FALSE FALSE  TRUE  TRUE FALSE FALSE FALSE FALSE  TRUE  TRUE\n#>  [37] FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n#>  [49]  TRUE FALSE  TRUE  TRUE FALSE  TRUE FALSE  TRUE  TRUE FALSE FALSE  TRUE\n#>  [61] FALSE  TRUE  TRUE  TRUE FALSE  TRUE FALSE FALSE FALSE  TRUE FALSE FALSE\n#>  [73] FALSE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE FALSE  TRUE FALSE\n#>  [85]  TRUE  TRUE FALSE FALSE FALSE  TRUE  TRUE FALSE  TRUE FALSE  TRUE  TRUE\n#>  [97] FALSE  TRUE  TRUE FALSE\n```\n:::\n\n\nNel codice, la funzione `runif` genera 100 numeri casuali distribuiti uniformemente nell'intervallo [0, 1]. Confrontando ciascun numero con 0.5, otteniamo un vettore logico che rappresenta il risultato di ogni lancio: *Testa* (TRUE) o *Croce* (FALSE). \n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nt <- 1:100 # Sequenza degli indici dei lanci\n\n# Creazione del dataframe per ggplot2\ndat <- tibble(\n  Lancio = t,\n  Risultato = ifelse(x, \"Testa\", \"Croce\")\n)\nhead(dat)\n#> # A tibble: 6 × 2\n#>   Lancio Risultato\n#>    <int> <chr>    \n#> 1      1 Testa    \n#> 2      2 Croce    \n#> 3      3 Testa    \n#> 4      4 Croce    \n#> 5      5 Croce    \n#> 6      6 Testa\n```\n:::\n\n\nIl grafico a barre mostra la distribuzione osservata degli esiti.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Creazione del grafico a barre della distribuzione dei risultati\ndat |>\n  ggplot(aes(x = Risultato)) +\n  geom_bar(aes(y = after_stat(prop), group = 1), width = 0.5) +\n  labs(\n    x = \"Risultato\",\n    y = \"Frequenza relativa\"\n  )\n```\n\n::: {.cell-output-display}\n![](02_probability_models_files/figure-html/unnamed-chunk-4-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\nUn aspetto rilevante di questo esperimento è l'*andamento della proporzione osservata di esiti \"Testa\"* in funzione del numero di lanci. Il grafico riportato di seguito illustra l’evoluzione della *media cumulativa* degli esiti \"Testa\", che, in accordo con la legge dei grandi numeri, dovrebbe convergere al valore teorico di *0.5*.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ny <- cumsum(x) / t # Calcola la media cumulativa delle Teste\n\n# Creazione del dataframe per il grafico della media mobile\ndata_mean <- tibble(\n  Lancio = t, \n  Media_Testa = y\n)\n\n# Creazione del grafico della media cumulativa\ndata_mean |>\n  ggplot(\n    aes(x = Lancio, y = Media_Testa)\n  ) +\n  geom_line(linewidth = 1.5) +\n  geom_hline(yintercept = 0.5, linetype = \"dashed\", color = \"red\") +\n  labs(\n    x = \"Numero di lanci\",\n    y = \"Frequenza cumulativa di Teste\"\n  )\n```\n\n::: {.cell-output-display}\n![](02_probability_models_files/figure-html/unnamed-chunk-5-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n::: {.callout-tip title=\"Media cumulata\" collapse=\"true\"}\nLa *media cumulata* (o *cumulativa*) è una media che si calcola progressivamente, aggiungendo un nuovo dato alla volta e ricalcolando la media considerando *tutti i valori precedenti* insieme al nuovo.  \nIn pratica, mostra come la media si evolve man mano che vengono inclusi nuovi dati nella serie.\n\n*Come si calcola?*  \n\n1. Al primo dato, la media cumulata è il dato stesso.  \n2. Al secondo dato, è la media tra il primo e il secondo.  \n3. Al terzo dato, è la media tra il primo, il secondo e il terzo.  \n4. E così via...  \n\n*Formula intuitiva*:  \n\n$$\n\\text{Media cumulata al passo } n = \\frac{\\text{somma di tutti i dati fino al passo } n}{n}\n$$\n\n*Esempio pratico*:  \nSupponiamo di avere i voti di uno studente in 3 verifiche:  \n\n- Verifica 1: 7  \n- Verifica 2: 6  \n- Verifica 3: 8  \n\nLe *medie cumulate* saranno:  \n\n- Dopo la 1ª verifica: $\\frac{7}{1} = 7$.  \n- Dopo la 2ª verifica: $\\frac{7 + 6}{2} = 6.5$.  \n- Dopo la 3ª verifica: $\\frac{7 + 6 + 8}{3} = 7$.\n\n*A cosa serve?*  \n\n- *Tracciare l'andamento* nel tempo (es.: mostrare come la frequenza di \"Testa\" si avvicina gradualmente al 50% teorico man mano che aumentano i lanci).  \n- *Lisciare le fluttuazioni*: riduce l’impatto di picchi temporanei, mostrando un trend più stabile.  \n- *Valutare prestazioni progressive* (es.: un atleta che migliora gradualmente).  \n:::\n\nIl grafico mostra come la media delle Teste oscilla inizialmente a causa della variabilità intrinseca dell'esperimento, ma *tende progressivamente a stabilizzarsi intorno a 0.5*. Questo fenomeno è un esempio della *Legge dei Grandi Numeri*, secondo cui, ripetendo un esperimento casuale un numero sempre maggiore di volte, la frequenza relativa di un evento si avvicina alla sua probabilità teorica.\n\n### Domande di interesse\n\nL’esperimento casuale del lancio di una moneta porta a numerose domande, tra cui:\n\n- Qual è la probabilità di ottenere un certo numero $x$ di Teste in 100 lanci?\n- Qual è il numero atteso di Teste in un esperimento di 100 lanci?\n\nDal punto di vista statistico, quando osserviamo i risultati di un esperimento reale (ad esempio, 100 lanci di una moneta), possiamo anche porci domande come:\n\n- La moneta è davvero equa o è sbilanciata?\n- Qual è il miglior metodo per stimare la probabilità $p$ di ottenere Testa dalla sequenza osservata di lanci?\n- Quanto è precisa la stima ottenuta e con quale livello di incertezza?\n\nQuesti interrogativi costituiscono la base della *statistica inferenziale*, che permette di testare ipotesi sulla probabilità di un evento e stimare parametri sconosciuti sulla base di dati osservati.\n\n### Modellizzazione\n\nLa descrizione matematica di un esperimento casuale si basa su tre elementi fondamentali:\n\n1. **Lo spazio campionario**: rappresenta l'insieme di tutti i possibili esiti dell'esperimento. Nel caso di esperimenti semplici, lo spazio campionario è immediato da individuare, mentre in situazioni più complesse è necessario applicare i principi del calcolo combinatorio.  \n\n2. **Gli eventi**: sono sottoinsiemi dello spazio campionario e rappresentano gli esiti di interesse. Per analizzare e manipolare gli eventi, utilizziamo gli strumenti della teoria degli insiemi.  \n\n3. **La probabilità**: assegna un valore numerico a ciascun evento, indicando la sua probabilità di verificarsi. L'assegnazione delle probabilità avviene secondo gli assiomi di Kolmogorov.  \n\nNei paragrafi seguenti, analizzeremo ciascuna di queste componenti in dettaglio.\n\n## Spazio campionario\n\nAnche se non possiamo prevedere con esattezza l’esito di un singolo esperimento casuale, possiamo comunque definire tutti i risultati che potrebbero verificarsi. L’insieme completo di questi esiti possibili si chiama *spazio campionario*.\n\n::: {#def-}\nLo *spazio campionario* $\\Omega$ di un esperimento casuale è l’insieme di tutti i possibili esiti dell’esperimento.\n:::\n\n### Esempi di spazi campionari\n\nConsideriamo lo spazio campionario di alcuni esperimenti casuali.\n\n1. Lancio di due dadi consecutivi:\n   $$\n   \\Omega = \\{(1,1), (1,2), \\dots, (6,6)\\}.\n   $$\n\n2. Tempo di reazione a uno stimolo visivo:\n   $$\\Omega = \\mathbb{R}^+,$$\n   ovvero l’insieme dei numeri reali positivi.\n\n3. Numero di errori in un test di memoria a breve termine:\n   $$\\Omega = \\{0, 1, 2, \\dots\\}.$$\n\n4. Misurazione delle altezze di dieci persone:\n   $$\\Omega = \\{(x_1, \\dots, x_{10}) : x_i \\ge 0, \\; i=1,\\dots,10\\} \\subset \\mathbb{R}^{10}.$$\n\n## Eventi\n\nSolitamente non siamo interessati a un singolo esito, ma a un insieme di essi. Un *evento* è un sottoinsieme dello spazio campionario a cui possiamo assegnare una probabilità.\n\n::: {#def-}\nUn *evento* è un sottoinsieme $A \\subseteq \\Omega$ al quale viene assegnata una probabilità. Indichiamo gli eventi con lettere maiuscole $A, B, C, \\dots$. Diciamo che l’evento $A$ si verifica se l’esito dell’esperimento appartiene a $A$.\n:::\n\n### Esempi di eventi\n\nConsideriamo alcuni possibili eventi definiti sugli spazi campionari descritti sopra.\n\n1. Lancio di due dadi consecutivi.  \n   *Evento:* \"La somma dei due dadi è uguale a 7\"  \n   $$\n   A = \\{(1,6), (2,5), (3,4), (4,3), (5,2), (6,1)\\}.\n   $$\n\n2. Tempo di reazione a uno stimolo visivo.  \n   *Evento:* \"Il tempo di reazione è inferiore a 2 secondi\"  \n   $$\n   A = [0, 2).\n   $$\n\n3. Numero di errori in un test di memoria a breve termine.  \n   *Evento:* \"Il numero di errori è al massimo 3\"  \n   $$\n   A = \\{0, 1, 2, 3\\}.\n   $$\n\n4. Misurazione delle altezze di dieci persone.  \n   *Evento:* \"Almeno due persone hanno un’altezza superiore a 180 cm\"  \n   $$\n   A = \\{(x_1, \\dots, x_{10}) : \\text{almeno due } x_i > 180\\}.\n   $$\n\nQuesti esempi mostrano come gli eventi possano essere definiti in modo diverso a seconda della natura dello spazio campionario e del contesto di interesse.\n\n::: {.callout-note collapse=\"true\" title=\"Esempio\"}\nSupponiamo di lanciare una moneta tre volte e di annotare se esce Testa ($H$) o Croce ($T$) in ogni lancio. Lo spazio campionario è:\n\n$$\n\\Omega = \\{HHH, HHT, HTH, HTT, THH, THT, TTH, TTT\\},\n$$\n\ndove, ad esempio, $HTH$ indica che il primo lancio dà Testa, il secondo Croce e il terzo Testa.\n\nUn’alternativa è rappresentare lo spazio campionario come l’insieme dei vettori binari di lunghezza 3, $\\{0,1\\}^3$, dove Testa ($H$) corrisponde a 1 e Croce ($T$) a 0.\n\nL’evento $A$ \"il terzo lancio è Testa\" si esprime come:\n\n$$\nA = \\{HHH, HTH, THH, TTH\\}.\n$$\n:::\n\n## Operazioni sugli eventi\n\nPoiché gli eventi sono definiti come insiemi, possiamo applicare loro le classiche operazioni insiemistiche.\n\n**Unione** ($\\cup$). \nL'unione di due eventi $A$ e $B$ è l'insieme di tutti gli esiti che appartengono almeno a uno dei due:\n\n$$\nA \\cup B = \\{\\omega \\in \\Omega : \\omega \\in A \\text{ oppure } \\omega \\in B\\}.\n$$\n\n**Intersezione** ($\\cap$).\nL'intersezione di due eventi è l'insieme degli esiti comuni:\n\n$$\nA \\cap B = \\{\\omega \\in \\Omega : \\omega \\in A \\text{ e } \\omega \\in B\\}.\n$$\n\n**Complemento** ($A^c$). \nIl complemento di un evento $A$ è l'insieme di tutti gli esiti che non appartengono ad $A$:\n\n$$\nA^c = \\{\\omega \\in \\Omega : \\omega \\notin A\\}.\n$$\n\n**Eventi mutuamente esclusivi.**\nDue eventi sono *mutuamente esclusivi* se non hanno esiti in comune, ovvero:\n\n$$\nA \\cap B = \\emptyset.\n$$\n\n::: {.callout-note collapse=\"true\" title=\"Esempio\"}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Universo\nU <- 1:10  \n\n# Definizione degli insiemi A e B\nA <- c(1, 2, 3, 4, 5)\nB <- c(4, 5, 6, 7, 8)\n\n# Calcolare l'unione, l'intersezione e il complemento relativo a un universo U\nunion_AB <- union(A, B)\nintersect_AB <- intersect(A, B)\ncomplement_A <- setdiff(U, A)\ncomplement_B <- setdiff(U, B)\n\n# Visualizzazione testuale\ncat(\"Unione A ∪ B:\", union_AB, \"\\n\")\n#> Unione A ∪ B: 1 2 3 4 5 6 7 8\ncat(\"Intersezione A ∩ B:\", intersect_AB, \"\\n\")\n#> Intersezione A ∩ B: 4 5\ncat(\"Complemento di A:\", complement_A, \"\\n\")\n#> Complemento di A: 6 7 8 9 10\ncat(\"Complemento di B:\", complement_B, \"\\n\")\n#> Complemento di B: 1 2 3 9 10\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Visualizzazione con diagrammi di Venn\nvenn.plot <- draw.pairwise.venn(\n  area1 = length(A),\n  area2 = length(B),\n  cross.area = length(intersect(A, B)),  # Corretto: usa intersect() invece di intersect_AB\n  category = c(\"A\", \"B\"),\n  fill = c(\"orange\", \"blue\"),\n  alpha = 0.5,\n  cat.col = c(\"orange\", \"blue\")  # Corretto: allineato con i colori di fill\n)\n\n# Visualizza il diagramma\ngrid.draw(venn.plot)\n```\n\n::: {.cell-output-display}\n![](02_probability_models_files/figure-html/unnamed-chunk-7-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Esempio di eventi mutualmente esclusivi\nC <- c(9, 10)  # Insieme disgiunto da A e B\nintersect_AC <- intersect(A, C)  # Deve essere vuoto\n\ncat(\"Intersezione A ∩ C (eventi mutualmente esclusivi):\", intersect_AC, \"\\n\")\n#> Intersezione A ∩ C (eventi mutualmente esclusivi):\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Visualizzazione di eventi mutualmente esclusivi\nvenn.plot2 <- draw.pairwise.venn(\n  area1 = length(A),\n  area2 = length(C),\n  cross.area = 0,  # Nessuna intersezione\n  category = c(\"A\", \"C\"),\n  fill = c(\"blue\", \"orange\"),\n  alpha = 0.5,\n  cat.col = c(\"blue\", \"orange\")\n)\ngrid.draw(venn.plot2)\n```\n\n::: {.cell-output-display}\n![](02_probability_models_files/figure-html/unnamed-chunk-9-1.png){fig-align='center' width=85%}\n:::\n:::\n\n:::\n\n\n### Proprietà fondamentali delle operazioni su eventi\n\n- **Idempotenza:**\n  $$\n  A \\cup A = A, \\quad A \\cap A = A.\n  $$\n\n- **Leggi di De Morgan:**\n  $$\n  (A \\cup B)^c = A^c \\cap B^c, \\quad (A \\cap B)^c = A^c \\cup B^c.\n  $$\n\n- **Unione e Intersezione con l’insieme vuoto:**\n  $$\n  A \\cup \\emptyset = A, \\quad A \\cap \\emptyset = \\emptyset.\n  $$\n\n- **Unione e Intersezione con lo spazio campionario:**\n  $$\n  A \\cup \\Omega = \\Omega, \\quad A \\cap \\Omega = A.\n  $$\n\nQueste operazioni forniscono la base per costruire e manipolare eventi in contesti probabilistici, permettendo di calcolare probabilità e prendere decisioni basate sull’analisi degli esiti possibili.\n\n::: {.callout-note collapse=\"true\" title=\"Esempio\"}\n\nPer gli insiemi definiti nell'esempio precedente, possiamo verificare la prima legge di De Morgan in R confrontando il complemento dell'unione con l'intersezione dei complementi:\n\n- complemento dell'unione: $(A \\cup B)^c$,\n- intersezione dei complementi: $A^c \\cap B^c$.\n\nEseguiamo i calcoli in R:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Complemento dell'unione: (A ∪ B)^c\nsetdiff(U, union(A, B))\n#> [1]  9 10\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Intersezione dei complementi: A^c ∩ B^c\nintersect(setdiff(U, A), setdiff(U, B))\n#> [1]  9 10\n```\n:::\n\n\nSecondo la legge di De Morgan, i due risultati devono coincidere.\n:::\n\n\n::: {.callout-note collapse=\"true\" title=\"Esempio\"}\n\nConsideriamo l'esperimento del lancio di due dadi. Lo spazio campionario $\\Omega$ è costituito da tutte le possibili coppie di risultati che possono verificarsi. Ogni dado ha 6 facce, quindi lo spazio campionario è:\n\n$$\n\\Omega = \\{(1,1), (1,2), \\dots, (6,6)\\},\n$$\n\nper un totale di $6 \\times 6 = 36$ esiti possibili.\n\nSiamo interessati all'evento $A$: \"la somma dei due dadi è almeno 10\". Questo evento include tutte le coppie di risultati la cui somma è 10, 11 o 12. Gli esiti che soddisfano questa condizione sono:\n\n$$\nA = \\{(4,6), (5,5), (5,6), (6,4), (6,5), (6,6)\\}.\n$$\n\nEcco come generare lo spazio campionario in R in modo algoritmico e definire l'evento \"la somma dei due dadi è almeno 10\":\n\nLo spazio campionario $\\Omega$ è costituito da tutte le possibili coppie di risultati del lancio di due dadi. In R, possiamo generarlo utilizzando la funzione `expand.grid`, che crea tutte le combinazioni possibili tra i valori dei due dadi.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Generazione dello spazio campionario Omega\ndado <- 1:6 # Facce di un dado\nOmega <- expand.grid(Dado1 = dado, Dado2 = dado) # Tutte le combinazioni possibili\n```\n:::\n\n\nL'output sarà una tabella con 36 righe, una per ogni combinazione possibile:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Visualizzazione dello spazio campionario\nprint(Omega)\n#>    Dado1 Dado2\n#> 1      1     1\n#> 2      2     1\n#> 3      3     1\n#> 4      4     1\n#> 5      5     1\n#> 6      6     1\n#> 7      1     2\n#> 8      2     2\n#> 9      3     2\n#> 10     4     2\n#> 11     5     2\n#> 12     6     2\n#> 13     1     3\n#> 14     2     3\n#> 15     3     3\n#> 16     4     3\n#> 17     5     3\n#> 18     6     3\n#> 19     1     4\n#> 20     2     4\n#> 21     3     4\n#> 22     4     4\n#> 23     5     4\n#> 24     6     4\n#> 25     1     5\n#> 26     2     5\n#> 27     3     5\n#> 28     4     5\n#> 29     5     5\n#> 30     6     5\n#> 31     1     6\n#> 32     2     6\n#> 33     3     6\n#> 34     4     6\n#> 35     5     6\n#> 36     6     6\n```\n:::\n\n\nL'evento $A$ è definito come \"la somma dei due dadi è almeno 10\". Per identificare queste combinazioni, aggiungiamo una colonna che calcola la somma dei due dadi e filtriamo le righe in cui la somma è maggiore o uguale a 10.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Aggiunta di una colonna per la somma dei due dadi\nOmega$Somma <- Omega$Dado1 + Omega$Dado2\n\n# Definizione dell'evento A: somma dei due dadi almeno 10\nA <- Omega[Omega$Somma >= 10, ]\n```\n:::\n\n\nL'output sarà un data frame con le combinazioni in cui la somma è almeno 10:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Visualizzazione dell'evento A\nprint(A)\n#>    Dado1 Dado2 Somma\n#> 24     6     4    10\n#> 29     5     5    10\n#> 30     6     5    11\n#> 34     4     6    10\n#> 35     5     6    11\n#> 36     6     6    12\n```\n:::\n\n\nIn sintesi, \n\n- lo spazio campionario $\\Omega$ è stato generato algoritmicamente utilizzando `expand.grid`;\n- l'evento $A$ è stato definito filtrando le combinazioni in cui la somma dei due dadi è almeno 10.\n:::\n\n::: {.callout-note collapse=\"true\" title=\"Esempio\"}\n\nConsideriamo un esperimento in cui lanciamo una moneta tre volte consecutivamente. Ogni lancio può risultare in *Testa (H)* o *Croce (T)*. Lo spazio campionario $\\Omega$ è costituito da tutte le possibili sequenze di risultati dei tre lanci. Ci sono $2^3 = 8$ possibili esiti, che possono essere rappresentati come:\n\n$$\n\\Omega = \\{\\text{HHH}, \\text{HHT}, \\text{HTH}, \\text{HTT}, \\text{THH}, \\text{THT}, \\text{TTH}, \\text{TTT}\\}.\n$$\n\nVogliamo definire in R l'evento $A$: \"Il terzo lancio della moneta dia Testa (H)\". Questo evento include tutte le sequenze in cui il terzo carattere è \"H\".\n\nIn R, possiamo rappresentare lo spazio campionario $\\Omega$ come un vettore di stringhe, dove ogni stringa corrisponde a una sequenza di risultati.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Definizione dello spazio campionario Omega\nomega <- c(\"HHH\", \"HHT\", \"HTH\", \"HTT\", \"THH\", \"THT\", \"TTH\", \"TTT\")\nomega\n#> [1] \"HHH\" \"HHT\" \"HTH\" \"HTT\" \"THH\" \"THT\" \"TTH\" \"TTT\"\n```\n:::\n\n\nL'evento $A$ è costituito da tutte le sequenze in cui il *terzo lancio è Testa (H)*. Per identificare queste sequenze, utilizziamo la funzione `substr`, che estrae il terzo carattere da ciascuna stringa e verifica se è uguale a \"H\".\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Definizione dell'evento A: terzo lancio è Testa (H)\nA <- omega[substr(omega, 3, 3) == \"H\"]\n```\n:::\n\n\nSpiegazione del codice:\n\n- `substr(omega, 3, 3)` estrae il terzo carattere da ciascuna stringa nel vettore `omega`.\n- `substr(omega, 3, 3) == \"H\"` crea un vettore logico (vero/falso) che indica se il terzo carattere è \"H\".\n- `omega[...]` filtra il vettore `omega`, mantenendo solo le sequenze che soddisfano la condizione.\n\nL'output sarà:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Visualizzazione dell'evento A\nA\n#> [1] \"HHH\" \"HTH\" \"THH\" \"TTH\"\n```\n:::\n\n\nQueste sono le sequenze in cui il terzo lancio è Testa (H).\n\nIn sintesi, \n\n- lo spazio campionario $\\Omega$ è stato definito come un vettore di stringhe in R;\n- l'evento $A$ è stato costruito filtrando le sequenze in cui il terzo carattere è \"H\", utilizzando la funzione `substr(x, start, stop)`;\n- l'evento $A$ corrisponde alle sequenze: *HHH*, *HTH*, *THH*, *TTH*.\n\nQuesto esercizio illustra come definire e manipolare eventi in R, utilizzando operazioni di base su stringhe e vettori.\n:::\n\n::: {.callout-note collapse=\"true\" title=\"Esempio\"}\nConsideriamo l’esperimento del lancio consecutivo di due dadi. Lo spazio campionario $\\Omega$ è costituito da tutte le possibili coppie di risultati:\n\n$$\n\\Omega = \\{(1, 1), (1, 2), \\dots, (6, 6)\\}.\n$$\n\nDefiniamo due eventi:\n\n1. **Evento $A$**: \"Il primo dado mostra un 6\".  \n   Questo evento include tutte le coppie in cui il primo dado è 6:  \n   $$\n   A = \\{(6, 1), (6, 2), (6, 3), (6, 4), (6, 5), (6, 6)\\}.\n   $$\n\n2. **Evento $B$**: \"Il secondo dado mostra un 6\".  \n   Questo evento include tutte le coppie in cui il secondo dado è 6:  \n   $$\n   B = \\{(1, 6), (2, 6), (3, 6), (4, 6), (5, 6), (6, 6)\\}.\n   $$\n\nL’*intersezione $A \\cap B$* rappresenta l’evento in cui *entrambi i dadi mostrano un 6*:\n\n$$\nA \\cap B = \\{(6, 6)\\}.\n$$\n\n**Implementazione in R**\n\nPer analizzare gli eventi legati al lancio di due dadi, utilizziamo R per simulare lo spazio campionario e manipolare gli eventi.\n\n**1. Generazione dello spazio campionario**  \nLa funzione `expand.grid` crea tutte le combinazioni possibili tra gli elementi di due vettori. Nel nostro caso, generiamo tutte le coppie (Dado1, Dado2):\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Definizione delle facce dei dadi (1-6)\ndado <- 1:6\n\n# Creazione di tutte le 36 combinazioni possibili\nOmega <- expand.grid(\n  Dado1 = dado,\n  Dado2 = dado\n)\n\n# Visualizzazione delle prime 6 righe\nhead(Omega)\n#>   Dado1 Dado2\n#> 1     1     1\n#> 2     2     1\n#> 3     3     1\n#> 4     4     1\n#> 5     5     1\n#> 6     6     1\n```\n:::\n\n\n**2. Definizione degli eventi**  \n\n**Evento A** - \"Primo dado = 6\":  \nFiltriamo le righe dove la colonna `Dado1` è uguale a 6:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nA <- Omega[Omega$Dado1 == 6, ] # Selezione condizionale\nprint(\"Evento A:\")\n#> [1] \"Evento A:\"\nA\n#>    Dado1 Dado2\n#> 6      6     1\n#> 12     6     2\n#> 18     6     3\n#> 24     6     4\n#> 30     6     5\n#> 36     6     6\n```\n:::\n\n\n**Evento B** - \"Secondo dado = 6\":  \nFiltriamo le righe dove la colonna `Dado2` è uguale a 6:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nB <- Omega[Omega$Dado2 == 6, ]\nprint(\"Evento B:\")\n#> [1] \"Evento B:\"\nB\n#>    Dado1 Dado2\n#> 31     1     6\n#> 32     2     6\n#> 33     3     6\n#> 34     4     6\n#> 35     5     6\n#> 36     6     6\n```\n:::\n\n\n**3. Calcolo dell'intersezione A ∩ B**  \n\n**Metodo 1: Funzione `intersect()`**  \nLa funzione base `intersect()` confronta intere righe tra due dataframe e restituisce quelle comuni:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nA_intersezione_B <- intersect(A, B)\nprint(\"Intersezione con intersect():\")\n#> [1] \"Intersezione con intersect():\"\nA_intersezione_B\n#>   Dado1 Dado2\n#> 1     6     6\n```\n:::\n\n\n**Metodo 2: Funzione `merge()`**  \nLa funzione base `merge()` esegue una join naturale sulle colonne con lo stesso nome:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nA_intersezione_B <- merge(A, B)\nprint(\"Intersezione con merge():\")\n#> [1] \"Intersezione con merge():\"\nA_intersezione_B\n#>   Dado1 Dado2\n#> 1     6     6\n```\n:::\n\n\n**Metodo 3: Pacchetto `dplyr`**  \nLa funzione `inner_join()` mantiene solo le righe presenti in entrambi i dataframe:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nA_intersezione_B <- inner_join(A, B, by = c(\"Dado1\", \"Dado2\"))\nprint(\"Intersezione con dplyr:\")\n#> [1] \"Intersezione con dplyr:\"\nA_intersezione_B\n#>   Dado1 Dado2\n#> 1     6     6\n```\n:::\n\n\nIn sintesi,\n\n- lo spazio campionario $\\Omega$ è stato generato algoritmicamente in R;\n- gli eventi $A$ e $B$ sono stati definiti filtrando lo spazio campionario;\n- l'intersezione $A \\cap B$ corrisponde all'evento in cui entrambi i dadi mostrano un 6: $\\{(6, 6)\\}.$\n:::\n\n\n## Probabilità {#sec-probabilita}\n\nIl terzo elemento fondamentale del modello probabilistico è la *funzione di probabilità*, che quantifica numericamente la possibilità di occorrenza degli eventi.\n\n::: {.definition title=\"Funzione di Probabilità (Kolmogorov)\" #def-probabilita}\nUna *probabilità* $P$ è una funzione $P: \\mathcal{F} \\to [0,1]$ definita su una $\\sigma$-algebra $\\mathcal{F}$ di sottoinsiemi di $\\Omega$. A ogni evento $A \\in \\mathcal{F}$, la funzione assegna un valore reale compreso tra 0 e 1, rispettando i seguenti *assiomi di Kolmogorov*:\n\n1. **Non-negatività.**  Per ogni $A \\subseteq \\Omega$, si richiede che $0 \\leq P(A) \\leq 1$.\n\n2. **Normalizzazione (evento certo).**  $P(\\Omega) = 1$.\n\n3. **Additività numerabile.** Se $A_1, A_2, \\dots$ sono eventi mutuamente esclusivi (cioè $A_i \\cap A_j = \\emptyset$ per $i \\neq j$), allora:\n\n   $$\n   P\\!\\Bigl(\\bigcup_{i=1}^{\\infty} A_i\\Bigr) \\;=\\; \\sum_{i=1}^{\\infty} P(A_i).\n   $$\n\nIn altre parole, una misura di probabilità non solo assegna numeri nell’intervallo $[0,1]$ a ogni evento, ma richiede che l’evento “certo” $\\Omega$ abbia probabilità 1 e che la probabilità di un’unione numerabile di eventi disgiunti sia la somma delle loro probabilità. Queste condizioni garantiscono la coerenza formale e l’interpretazione intuitiva del concetto di probabilità.\n:::\n\n### Interpretazione degli assiomi di Kolmogorov\n\n1. **Assioma 1 (Non-negatività e limiti 0–1)**  \n   La probabilità di un evento è sempre un numero reale compreso tra 0 e 1. Se la probabilità è 0, l’evento può considerarsi *impossibile*; se è 1, l’evento è *certo*.  \n   **Esempio**: Nel lancio di un dado a sei facce, l’evento *“Esce 7”* non può verificarsi e ha probabilità 0, mentre l’evento *“Esce un numero tra 1 e 6”* ha probabilità 1.\n\n2. **Assioma 2 (Evento certo)**  \n   Lo *spazio campionario* $\\Omega$ è l’insieme di tutti i possibili esiti dell’esperimento. Poiché in ogni prova deve accadere almeno uno degli esiti contenuti in $\\Omega$, la probabilità di $\\Omega$ è necessariamente 1.  \n   **Esempio**: Nel lancio di un dado, lo spazio campionario $\\Omega$ è $\\{1,2,3,4,5,6\\}$. L’evento “esce un numero tra 1 e 6” coincide con l’intero spazio campionario, quindi $P(\\Omega) = 1$.\n\n3. **Assioma 3 (Additività per eventi incompatibili)**  \n   Se due o più eventi sono mutuamente esclusivi (o incompatibili) — cioè non possono verificarsi contemporaneamente — la probabilità della loro unione è la somma delle probabilità di ciascuno.  \n   **Esempio**: Con un dado, l’evento *“esce un numero pari”* e l’evento *“esce un numero dispari”* non possono verificarsi nello stesso lancio. Di conseguenza,  \n   \n   $$\n   P(\\text{“pari”} \\cup \\text{“dispari”}) \\;=\\; P(\\text{“pari”}) + P(\\text{“dispari”})\\,.\n   $$ \n\nQuesti assiomi assicurano che la probabilità, intesa come funzione che assegna valori tra 0 e 1 a ogni evento, rispetti la coerenza matematica e l’interpretazione intuitiva: non esistono eventi “negativi” o “più che certi”, e la probabilità totale dell’intero spazio dei possibili risultati deve sempre essere uguale a 1.\n\n### Proprietà fondamentali {#subsec-proprieta}\n\nDagli assiomi di Kolmogorov discendono alcune proprietà fondamentali che descrivono come la probabilità si comporti in varie situazioni. Le principali sono elencate di seguito.\n\n::: {.theorem #thm-proprieta-probabilita}\nSiano $A$ e $B$ eventi qualsiasi nello spazio campionario $\\Omega$. Allora valgono le seguenti relazioni:\n\n1. **Probabilità dell’evento impossibile**  \n   $$\n   P(\\emptyset) = 0.\n   $$\n   Poiché l’insieme vuoto non include alcun esito sperimentale, non può mai verificarsi.\n\n2. **Monotonicità**  \n   $$\n   A \\subseteq B \\quad \\Longrightarrow \\quad P(A) \\le P(B).\n   $$\n   Se un evento è interamente contenuto in un altro, non può avere probabilità maggiore dell’evento che lo comprende.\n\n3. **Probabilità del complementare**  \n   $$\n   P(A^c) = 1 - P(A).\n   $$\n   Poiché $A$ e il suo complementare $A^c$ coprono l’intero spazio $\\Omega$, la probabilità di $A^c$ è la parte “rimanente” fino a 1.\n\n4. **Regola dell’inclusione–esclusione**  \n   $$\n   P(A \\cup B) \\;=\\; P(A) + P(B) \\;-\\; P(A \\cap B).\n   $$\n   Per calcolare la probabilità dell’unione di due eventi qualsiasi, si sommano le probabilità di ciascun evento e si sottrae la probabilità della loro intersezione (altrimenti verrebbe conteggiata due volte).\n:::\n\n## Spazi discreti e continui {#case-discreto-continuo}\n\nLa natura dello spazio campionario determina come definiamo e calcoliamo le probabilità. Distinguiamo i due casi fondamentali: lo spazio campionario *discreto* \n\n$$\n\\Omega = \\{a_1, a_2, \\dots, a_n\\} \\quad \\text{oppure} \\quad \\Omega = \\{a_1, a_2, \\dots\\}\n$$\n\ne lo spazio campionario *continuo*\n\n$$\n\\Omega = \\mathbb{R} .\n$$\n\n### Spazi campionari discreti\n\n**Caratteristiche**:  \n\n- Gli esiti sono *numerabili* (finiti o infiniti ma separabili).  \n- Esempi:  \n  - Lancio di un dado: $\\Omega = \\{1, 2, 3, 4, 5, 6\\}$.  \n  - Numero di clienti in un negozio in un'ora: $\\Omega = \\{0, 1, 2, \\dots\\}$.  \n\n**Definizione di Probabilità**:  \n\n- Assegniamo una *probabilità puntuale* $p_i \\geq 0$ a ogni esito $\\omega_i$, con: \n\n  $$\n  \\sum_{\\text{tutti gli } i} p_i = 1 \\quad \\text{(normalizzazione)}.\n  $$  \n  \n- La probabilità di un evento $A$ si ottiene *sommando* le probabilità degli esiti in $A$:  \n\n  $$\n  P(A) = \\sum_{\\omega_i \\in A} p_i.\n  $$  \n\n::: {.callout-note collapse=\"true\" title=\"Esempio\"}\n\n**Lancio di un dado equilibrato.**\n\n- La probabilità di ciascuna faccia è uniforme: $p_i = \\frac{1}{6}$, con $i = 1, 2, \\dots, 6$.\n- Consideriamo l’evento $A = \\text{“Esce un numero pari\"}$.  \n- Pertanto, calcoliamo la probabilità di $A$:\n\n$$\nP(A) = p_2 + p_4 + p_6 = \\frac{1}{6} + \\frac{1}{6} + \\frac{1}{6} = \\frac{3}{6} = \\frac{1}{2}.\n$$\n\nL’evento $A$ ha dunque probabilità $\\frac{1}{2}$.\n:::\n\n### Spazi campionari continui\n\n**Caratteristiche**:  \n\n- Gli esiti sono *non numerabili* (infiniti e \"densi\").  \n- Esempi:  \n  - tempo di attesa all’autobus: $\\Omega = [0, \\infty)$;  \n  - altezza di una persona: $\\Omega = [50\\, \\text{cm}, 250\\, \\text{cm}]$.  \n\n**Definizione di Probabilità**:  \n\n- Usiamo una *funzione di densità di probabilità (PDF)* $f(x) \\geq 0$, con:  \n  $$\n  \\int_{-\\infty}^{\\infty} f(x)\\, dx = 1 \\quad \\text{(normalizzazione)}.\n  $$  \n- La probabilità di un evento $A$ si ottiene *integrando* la PDF su $A$:  \n  $$\n  P(A) = \\int_{A} f(x)\\, dx.\n  $$  \n\n::: {.callout-note collapse=\"true\" title=\"Esempio\"}\n\n**Misurazione dell’altezza** degli uomini adulti, modellata come variabile aleatoria continua $X$ (in cm) con distribuzione normale $\\mathcal{N}(170, 7^2)$ (si veda la Sezione [@sec-prob-cont-prob-distr]):\n\nLa *funzione di densità* (PDF) corrispondente è:\n\n$$\nf(x) \n= \\frac{1}{7\\sqrt{2\\pi}} \\exp\\!\\Bigl(-\\frac{(x - 170)^2}{2 \\cdot 7^2}\\Bigr),\n\\quad\nX \\sim \\mathcal{N}(170,\\, 7^2).\n$$\n\n**Evento di interesse:**  \n$$\nA = \\text{“Altezza compresa tra 160 cm e 180 cm”}.\n$$\n\n**Calcolo della probabilità:**  \nLa probabilità di $A$ è l’area sotto la curva della densità tra 160 cm e 180 cm:\n\n$$\nP(A) \\;=\\; \\int_{160}^{180} \\frac{1}{7\\sqrt{2\\pi}}\n\\exp\\!\\Bigl(-\\frac{(x - 170)^2}{98}\\Bigr)\\,\\mathrm{d}x.\n$$\n\nIn alternativa, si può scrivere:\n\n$$\nP(160 \\leq X \\leq 180) \\;\\approx\\; 0.847 \\quad (84.7\\%).\n$$\n\nPiù avanti vedremo come calcolare facilmente questa probabilità tramite R, ad esempio con il comando:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npnorm(180, 170, 7) - pnorm(160, 170, 7)\n#> [1] 0.847\n```\n:::\n\n\nQuesto codice restituisce la differenza tra le funzioni di ripartizione (CDF) a 180 e a 160, corrispondente proprio all’area desiderata sotto la PDF.\n:::\n\n### Confronto chiave\n\n| Caratteristica               | Spazio Discreto                     | Spazio Continuo                     |  \n|-------------------------------|--------------------------------------|--------------------------------------|  \n| **Esiti**                     | Numerabili (es: 1, 2, 3)            | Non numerabili (es: intervalli)     |  \n| **Probabilità di un singolo punto** | $P(\\{\\omega_i\\}) = p_i$ ($\\geq$ 0)       | $P(\\{x\\}) = 0$ (sempre zero)        |  \n| **Strumento matematico**      | Somma $\\sum$                         | Integrale $\\int$                     |  \n| **Esempi comuni**             | Dadi, monete, conteggi              | Misure fisiche, tempi, temperature  |  \n\n::: {.callout-warning}\n## Proprietà della PDF\n\n- Negli spazi continui, la PDF *non è una probabilità* (può essere > 1), ma la sua area sottesa su un intervallo fornisce la probabilità.  \n- Per eventi continui, ha senso solo calcolare probabilità su *intervalli* (es: $P(160 \\leq X \\leq 180)$).  \n:::\n\n### Dai concetti base alle proprietà fondamentali della probabilità\n\nAbbiamo visto come un esperimento casuale possa essere formalizzato matematicamente attraverso tre elementi chiave:\n\n- **Spazio campionario** ($\\Omega$): l'insieme di tutti i possibili esiti dell'esperimento.\n- **Eventi**: sottoinsiemi di $\\Omega$ che rappresentano combinazioni di esiti di interesse.\n- **Probabilità**: una funzione $P$ che assegna a ogni evento un valore numerico compreso tra 0 e 1, misurandone il grado di verosimiglianza.\n\nPartendo da queste definizioni, è possibile derivare proprietà essenziali per il calcolo e l'analisi probabilistica. Queste proprietà consentono di determinare la probabilità di eventi complessi a partire da eventi elementari e di stabilire relazioni logiche tra di essi.\n\nIn questo corso, approfondiremo quattro teoremi fondamentali:\n\n1. teorema della somma;\n2. teorema del prodotto;\n3. teorema della probabilità totale; \n4. teorema di Bayes.\n\nL’introduzione di operazioni sugli eventi (unione, intersezione, complemento) e delle proprietà della probabilità (teorema della somma, probabilità condizionata, teorema della probabilità totale, ...) ci consente di costruire modelli probabilistici più complessi e applicabili a problemi reali.  \n\nQui di seguito, approfondiamo il teorema della somma.\n\n## Teorema della somma\n\nIl teorema della somma (o *regola additiva*) permette di determinare la probabilità che si verifichi *almeno uno* tra due eventi $A$ e $B$. La sua formulazione dipende dalla relazione tra i due eventi:\n\n**Caso 1: Eventi Mutuamente Esclusivi.** \nSe $A$ e $B$ *non possono verificarsi insieme* (ossia $A \\cap B = \\emptyset$), la probabilità dell'unione è la somma delle singole probabilità: \n\n$$\nP(A \\cup B) = P(A) + P(B).\n$$ {#eq-theorem-sum-disjoint}\n\n**Caso 2: Eventi Non Esclusivi.**\nSe $A$ e $B$ *possono coesistere*, è necessario evitare di contare due volte la loro intersezione: \n\n$$\nP(A \\cup B) = P(A) + P(B) - P(A \\cap B).\n$$ {#eq-theorem-sum-not-disjoint}\n\n**Perché questa differenza?**  \nLa probabilità è una funzione d'insieme coerente con le operazioni insiemistiche. L'addizione diretta $P(A) + P(B)$ conteggia due volte gli esiti comuni a $A$ e $B$ (rappresentati da $A \\cap B$). La sottrazione di $P(A \\cap B)$ garantisce che ogni esito sia considerato una sola volta.\n\nIl teorema della somma sottolinea come le operazioni logiche tra eventi (unione, intersezione) si riflettano in relazioni algebriche tra le loro probabilità, fornendo uno strumento operativo per modellare scenari reali.\n\n::: {.callout-note collapse=\"true\" title=\"Esempio\"}\n\nIn uno studio sulla salute mentale, supponiamo di avere i seguenti dati relativi a un campione di partecipanti:  \n\n- la probabilità che un individuo soffra di *ansia* è $P(A) = 0.30$;  \n- la probabilità che un individuo soffra di *depressione* è $P(B) = 0.25$; \n- la probabilità che un individuo soffra *contemporaneamente* di ansia e depressione è $P(A \\cap B) = 0.15$.  \n\nVogliamo calcolare la probabilità che un individuo soffra di *almeno uno* dei due disturbi (ansia o depressione), ovvero $P(A \\cup B)$.  \n\nUtilizziamo la *regola della somma per eventi non mutuamente esclusivi*:  \n\n$$\nP(A \\cup B) = P(A) + P(B) - P(A \\cap B)\n$$\n\nSvolgiamo questo calcolo in R:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Definiamo le probabilità\nP_A <- 0.30 # Probabilità di soffrire di ansia\nP_B <- 0.25 # Probabilità di soffrire di depressione\nP_A_intersect_B <- 0.15 # Probabilità di soffrire di entrambi i disturbi\n\n# Applichiamo la formula della regola della somma\nP_A_union_B <- P_A + P_B - P_A_intersect_B\nP_A_union_B\n#> [1] 0.4\n```\n:::\n\n\n**Interpretazione:**\nil *40%* dei partecipanti soffre di almeno uno tra ansia e depressione. L’intersezione $P(A \\cap B) = 0.15$ è fondamentale, poiché senza sottrarla avremmo contato due volte i soggetti che soffrono contemporaneamente di entrambi i disturbi.\n:::\n\n## Probabilità, calcolo combinatorio e simulazioni\n\nIn molti problemi di probabilità, soprattutto quelli di taglio scolastico o introduttivo, si assume che ogni *evento elementare* abbia la *stessa probabilità* di verificarsi (*equiprobabilità*). In queste situazioni, il *calcolo combinatorio* risulta particolarmente utile per determinare la probabilità di un evento, poiché basta:\n\n1. **Definire gli eventi di successo**: identificare tutte le configurazioni compatibili con l’evento di interesse.  \n2. **Contare le possibilità**: calcolare il numero di eventi di successo e rapportarlo al numero totale di eventi nello spazio campionario.\n\n::: {.callout-note collapse=\"true\" title=\"Esempio\"}\n\n**Estrazione di una pallina da un’urna**\n\nSupponiamo di avere un’urna con 10 palline numerate da 1 a 10, da cui estraiamo una sola pallina in modo casuale. Assumendo che ogni pallina abbia la stessa probabilità di essere estratta, calcoliamo la probabilità di estrarre un numero pari.\n\n- **Eventi di successo**: $\\{\\;2, 4, 6, 8, 10\\}$ (5 casi)  \n- **Eventi totali**: $\\{\\;1, 2, 3, 4, 5, 6, 7, 8, 9, 10\\}$ (10 casi)\n\nLa probabilità cercata è quindi:\n\n$$\nP(\\text{numero pari}) \\;=\\; \\frac{\\text{numero di eventi di successo}}{\\text{numero totale di eventi}}\n\\;=\\; \\frac{5}{10} \\;=\\; 0.5.\n$$\n:::\n\nNelle applicazioni più complesse, come il calcolo della probabilità di ottenere una determinata combinazione di carte o il formare gruppi specifici partendo da una popolazione, utilizzeremo tecniche combinatorie più avanzate — ad esempio permutazioni e combinazioni (si veda la Sezione [@sec-apx-combinatorics]) — che consentono di contare in modo sistematico gli eventi possibili e quelli di successo.\n\n### Simulazioni Monte Carlo\n\nUno degli aspetti più impegnativi della probabilità è che molti problemi non si prestano a soluzioni immediate o intuitive. Per affrontarli, si possono adottare due approcci principali. Il primo consiste nell'applicare i teoremi della teoria della probabilità, un metodo rigoroso ma spesso controintuitivo. Il secondo approccio è quello della simulazione Monte Carlo, che permette di ottenere una soluzione approssimata, ma molto vicina al valore reale, seguendo una procedura più accessibile e intuitiva. Questo metodo prende il nome dal famoso Casinò di Monte Carlo a Monaco, anche se può essere semplicemente definito come \"metodo di simulazione.\"\n\nLa simulazione Monte Carlo appartiene a una classe generale di metodi stocastici che si contrappongono ai metodi deterministici. Questi metodi consentono di risolvere approssimativamente problemi analitici attraverso la generazione casuale delle quantità di interesse. Tra le tecniche comunemente utilizzate troviamo il *campionamento con reinserimento*, in cui la stessa unità può essere selezionata più volte, e il *campionamento senza reinserimento*, dove ogni unità può essere selezionata una sola volta. Questi strumenti rappresentano un mezzo potente e pratico per affrontare problemi complessi.\n\n::: {.callout-note collapse=\"true\" title=\"Il problema dei complenni\"}\n\nUn esempio classico di applicazione del metodo Monte Carlo è il calcolo delle probabilità relative a vari eventi definiti attraverso il modello dell'urna. Tra questi, abbiamo il celebre *problema dei compleanni*. \n\nIl *problema dei compleanni* esplora la probabilità che, in un gruppo di $n$ persone, almeno due persone condividano la stessa data di nascita. Supponendo che i compleanni siano distribuiti uniformemente su 365 giorni (ignorando anni bisestili), il problema sorprende molte persone per il fatto che già con 23 persone la probabilità di una coincidenza è superiore al 50%.\n\n#### Soluzione analitica\n\nQuesto problema può essere risolto utilizzando il concetto di *probabilità complementari*. Infatti, il problema può essere visto da due prospettive complementari:\n\n- **Caso 1**: tutti i compleanni sono *diversi* (nessuna persona condivide il compleanno con un'altra);\n- **Caso 2**: *almeno due persone* condividono lo stesso compleanno.\n\nQuesti due casi sono *mutuamente esclusivi* (non possono verificarsi contemporaneamente) ed *esaustivi* (coprono tutte le possibilità). Pertanto, la somma delle loro probabilità deve essere uguale a 1:\n\n$$\nP(\\text{almeno un compleanno in comune}) = 1 - P(\\text{nessun compleanno in comune}).\n$$\n\nIn altre parole, per calcolare la probabilità che *almeno due persone abbiano lo stesso compleanno*, possiamo prima calcolare la probabilità che *tutti i compleanni siano diversi* e poi sottrarre questo valore da 1.\n\n**Caso 1: probabilità che tutti i compleanni siano diversi.**\n\nPer calcolare $P(\\text{nessun compleanno in comune})$, seguiamo questo ragionamento:\n\n- **Prima persona**: Può scegliere liberamente un giorno del calendario. Ci sono *365 possibilità* (ignoriamo gli anni bisestili per semplicità).\n  \n- **Seconda persona**: Deve avere un compleanno diverso dalla prima persona. Quindi, ci sono *364 giorni disponibili*.\n\n- **Terza persona**: Deve avere un compleanno diverso dai primi due. Ci sono *363 giorni disponibili*.\n\nQuesto processo continua fino alla $n$-esima persona, che avrà $365 - n + 1$ giorni disponibili.\n\nLa probabilità che *tutti i compleanni siano diversi* si ottiene moltiplicando le probabilità individuali di ogni persona di avere un compleanno diverso dai precedenti. Poiché ogni scelta è indipendente, possiamo scrivere:\n\n$$\nP(\\text{nessun compleanno in comune}) = \\frac{365}{365} \\cdot \\frac{364}{365} \\cdot \\frac{363}{365} \\cdot \\ldots \\cdot \\frac{365-n+1}{365}.\n$$\n\nQuesto prodotto può essere espresso in forma compatta utilizzando il fattoriale:\n\n$$\nP(\\text{nessun compleanno in comune}) = \\frac{365!}{(365-n)! \\cdot 365^n} ,\n$$\n\ndove:\n\n- $365!$ è il fattoriale di 365 (il prodotto di tutti i numeri interi da 1 a 365).\n- $(365-n)!$ è il fattoriale di $365 - n$.\n- $365^n$ rappresenta tutte le possibili combinazioni di compleanni per $n$ persone.\n\n**Caso 2. Probabilità di almeno un compleanno in comune.**\n\nOra che abbiamo calcolato la probabilità che tutti i compleanni siano diversi, possiamo trovare la probabilità che *almeno due persone abbiano lo stesso compleanno* come il complemento:\n\n$$\nP(\\text{almeno un compleanno in comune}) = 1 - P(\\text{nessun compleanno in comune}).\n$$\n\nSostituendo l'espressione precedente, otteniamo:\n\n$$\nP(\\text{almeno un compleanno in comune}) = 1 - \\frac{365!}{(365-n)! \\cdot 365^n}.\n$$\n\nOra che abbiamo le formule per i due eventi complementari, come funzione di $n$, applichiamole al caso specifico in cui $n$ = 23. Questo è un valore interessante perché, come vedremo, la probabilità che almeno due persone su 23 condividano lo stesso compleanno supera il 50%.\n\nLa formula per la probabilità che tutti i compleanni siano diversi è:\n\n$$\nP(\\text{nessun compleanno in comune}) = \\frac{365!}{(365-n)! \\cdot 365^n}.\n$$\n\nPer $n = 23$, sostituiamo il valore nella formula:\n\n$$\nP(\\text{nessun compleanno in comune}) = \\frac{365!}{(365-23)! \\cdot 365^{23}}.\n$$\n\nSemplifichiamo:\n\n$$\nP(\\text{nessun compleanno in comune}) = \\frac{365!}{342! \\cdot 365^{23}}.\n$$\n\nUtilizzando R, troviamo:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Numero di persone\nn <- 23\n\n# Calcolo della probabilità che tutti abbiano compleanni diversi\nnumeratore <- prod(365:(365 - n + 1))\ndenominatore <- 365^n\n\nP_diversi <- numeratore / denominatore\nP_diversi  # stampa la probabilità\n#> [1] 0.493\n```\n:::\n\n\n$$\nP(\\text{nessun compleanno in comune}) \\approx 0{,}4927.\n$$\n\nCiò implica che la probabilità che *23 persone* abbiano *compleanni distinti* sia approssimativamente *0.4927* (pari al *49.27%*).  \n\nLa probabilità che *almeno due persone* (su 23) condividano lo stesso compleanno corrisponde al complemento della probabilità appena calcolata:  \n\n$$\nP(\\text{almeno un compleanno in comune}) = 1 - P(\\text{nessun compleanno in comune}).\n$$  \n\nSostituendo il valore ottenuto:  \n\n$$\nP(\\text{almeno un compleanno in comune}) = 1 - 0{.}4927 = 0{.}5073.\n$$  \n\n**Risultato finale:**  \nCon $n = 23$, la probabilità che *almeno una coppia* condivida il compleanno supera il *50%*, attestandosi intorno a *0.5073* (50.73%). Questo esito è spesso sorprendente, poiché intuitivamente si tende a sottostimare l’effetto della *combinatoria*: sebbene 23 possano sembrare poche, le $\\binom{23}{2} = 253$ possibili coppie rendono statisticamente probabile una corrispondenza.  \n\n\n#### Soluzione con simulazione in R\n\nPer risolvere il problema tramite simulazione, possiamo generare gruppi casuali di $n$ persone, assegnando loro un compleanno casuale tra 1 e 365. Per ogni gruppo, verifichiamo se almeno due persone condividono lo stesso compleanno.\n\nEcco il codice R:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Numero di simulazioni\nnum_simulazioni <- 10000\n\n# Funzione per simulare il problema del compleanno\nsimula_compleanno <- function(n) {\n  # Conta il numero di successi (almeno un compleanno in comune)\n  successi <- 0\n\n  # Loop per il numero di simulazioni\n  for (i in 1:num_simulazioni) {\n    # Genera n compleanni casuali\n    compleanni <- sample(1:365, n, replace = TRUE)\n\n    # Verifica se ci sono duplicati\n    if (any(duplicated(compleanni))) {\n      successi <- successi + 1\n    }\n  }\n\n  # Calcola la probabilità stimata\n  return(successi / num_simulazioni)\n}\n```\n:::\n\n\nProviamo con diversi valori di n.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(123) # Fissiamo il seme per la riproducibilità\nrisultati <- sapply(1:50, simula_compleanno)\n\n# Creiamo un data frame con i risultati\ndf <- data.frame(\n  n = 1:50,\n  prob = risultati\n)\n\n# Creiamo il grafico\nggplot(df, aes(x = n, y = prob)) +\n  geom_line(color = \"blue\") +\n  geom_point(color = \"blue\") +\n  geom_hline(yintercept = 0.5, color = \"red\", linetype = \"dashed\") +\n  labs(\n    x = \"Numero di persone (n)\",\n    y = \"Probabilità stimata\",\n    title = \"Problema del Compleanno (Simulazione)\"\n  )\n```\n\n::: {.cell-output-display}\n![](02_probability_models_files/figure-html/unnamed-chunk-29-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n1. **Simulazioni**: Per ogni gruppo di $n$, si eseguono 10000 simulazioni, in cui si generano $n$ compleanni casuali tra 1 e 365.\n2. **Duplicati**: La funzione duplicated() verifica se ci sono compleanni ripetuti.\n3. **Calcolo della probabilità**: La proporzione di simulazioni in cui si verifica almeno un compleanno condiviso rappresenta la probabilità stimata.\n4. **Visualizzazione**: Si tracciano le probabilità per diversi valori di $n$, evidenziando il punto in cui la probabilità supera il 50%.\n\nRisultati attesi:\n\n- con circa 23 persone, la probabilità stimata sarà superiore a 0.5;\n- il grafico mostra una curva crescente con un rapido aumento della probabilità per $n$ piccoli e un asintoto vicino a 1 per $n$ grandi.\n\nQuesto approccio permette di comprendere intuitivamente il problema e di verificare i risultati teorici con la simulazione.\n\n#### Assunzioni\n\nIl problema dei compleanni evidenzia non solo l'efficacia dell'approccio simulativo nel semplificare la soluzione rispetto all'analisi formale, ma anche l'importanza delle assunzioni che entrambi i metodi condividono. In questo caso, l'assunzione è che la probabilità di nascita sia *uniformemente distribuita* nei 365 giorni dell'anno — un'[ipotesi semplificativa](https://www.ons.gov.uk/peoplepopulationandcommunity/birthsdeathsandmarriages/livebirths/articles/howpopularisyourbirthday/2015-12-18) che non rispecchia la realtà.\n\nQuesto esempio sottolinea un principio fondamentale dei modelli probabilistici (e scientifici in generale): *ogni modello si basa su un insieme di assunzioni che ne delimitano la validità e l'applicabilità*. Valutare criticamente la plausibilità di tali assunzioni è dunque essenziale per garantire che il modello fornisca una rappresentazione utile del fenomeno studiato. \n:::\n\n\n## Riflessioni conclusive {.unnumbered .unlisted}\n\nLa teoria della probabilità fornisce un quadro rigoroso per descrivere e analizzare fenomeni caratterizzati dall’incertezza. In questo capitolo abbiamo introdotto i concetti fondamentali del calcolo delle probabilità, evidenziando come la modellazione matematica degli esperimenti casuali consenta di quantificare e prevedere eventi incerti. Abbiamo esplorato strumenti essenziali come la *definizione di spazio campionario*, la *nozione di evento* e le *regole della probabilità*, illustrando il loro utilizzo sia attraverso esempi teorici sia mediante simulazioni computazionali.  \n\nUn aspetto cruciale della modellazione probabilistica è il ruolo delle *assunzioni* su cui si basano i modelli. Ogni modello probabilistico si fonda su ipotesi specifiche riguardanti la natura del fenomeno studiato e il modo in cui gli esiti vengono generati. Queste ipotesi determinano non solo la validità del modello, ma anche il tipo di risposte che esso può fornire. Ad esempio, nel problema del compleanno, abbiamo ipotizzato che i compleanni siano distribuiti in modo uniforme nei 365 giorni dell'anno. Sebbene questa assunzione semplifichi notevolmente i calcoli, sappiamo che nella realtà esistono fluttuazioni stagionali nelle nascite che possono influenzare le probabilità effettive.  \n\nQuesto ci porta a una considerazione più ampia: *la probabilità non è solo un insieme di formule, ma uno strumento per rappresentare l’incertezza e prendere decisioni informate*. Tuttavia, l’accuratezza di qualsiasi modello probabilistico dipende strettamente dalla plausibilità delle ipotesi adottate. Modelli diversi, basati su ipotesi differenti, possono portare a risultati diversi, e l’interpretazione dei risultati deve sempre tenere conto di queste assunzioni.  \n\nIn definitiva, lo studio della probabilità non si limita alla manipolazione di formule, ma richiede un’attenta riflessione sulla relazione tra modelli teorici e fenomeni reali. Una comprensione critica delle assunzioni alla base di un modello è essenziale per applicare correttamente i concetti probabilistici in contesti pratici, sia in ambito scientifico che nelle decisioni quotidiane.\n\n::: {.callout-tip collapse=\"true\"}\n## Risposte alle domande iniziali\n\nIl 92% delle persone sovrastima il numero necessario per la prima domanda e sottostima la seconda probabilità. Questo problema mostra come l’intuizione umana fallisca con eventi apparentemente \"rari\".\n\n1. La risposta è 23 persone.\n2. La probabilità è $\\sim 0.7$\n:::\n\n## Esercizi {.unnumbered .unlisted}\n\n::: {.callout-tip title=\"Esercizio\" collapse=\"true\"}\nQui di seguito sono presentati una serie di esercizi sbasati sulla **Satisfaction with Life Scale (SWLS)**. \n\n**Esercizi sullo Spazio Campionario e Eventi**\n\n1. **Definizione dello Spazio Campionario**  \n   Supponiamo che i punteggi della Satisfaction with Life Scale (SWLS) siano numeri interi compresi tra **5 e 35**.  \n   \n   - Qual è lo **spazio campionario** $\\Omega$ per questo esperimento?\n   - Se hai raccolto i dati di **15 studenti**, come potresti rappresentare lo spazio campionario con i loro punteggi osservati?\n\n2. **Definizione di un Evento**  \n   Consideriamo l’evento **A**: \"Uno studente ha un punteggio SWLS superiore a 25\". \n   \n   - Esprimi l’evento A come un sottoinsieme dello spazio campionario.\n   - Se tra i 15 studenti osservati, 4 hanno punteggi superiori a 25, qual è la proporzione sperimentale per l’evento A?\n\n3. **Eventi Complementari**  \n   Definiamo l’evento **B**: \"Uno studente ha un punteggio SWLS inferiore o uguale a 25\".  \n   \n   - Scrivi l’evento **B** in relazione all’evento **A**.\n   - Qual è la probabilità empirica di **B**, sapendo che 4 studenti hanno punteggi superiori a 25?\n\n**Esercizi sulle Operazioni tra Eventi**\n\n4. **Unione di Eventi**  \n   Definiamo due eventi:  \n   \n   - **A**: \"Il punteggio SWLS è superiore a 25\".  \n   - **C**: \"Il punteggio SWLS è inferiore a 15\".  \n   - Scrivi l’evento **A ∪ C** (\"Lo studente ha un punteggio **maggiore di 25 o minore di 15**\").\n   - Se nel campione di 15 studenti, **4 studenti hanno punteggi superiori a 25** e **3 hanno punteggi inferiori a 15**, qual è la proporzione empirica di **A ∪ C**?\n\n5. **Intersezione di Eventi e Eventi Disgiunti**  \n   Supponiamo che l’evento **D** sia: \"Uno studente ha un punteggio pari a 20\".  \n   \n   - L’evento **D** e l’evento **A** sono disgiunti?\n   - Se nessuno degli studenti ha ottenuto esattamente 20, qual è la probabilità empirica di **A ∩ D**?\n\n**Esercizi sulle Regole della Probabilità**\n6. **Probabilità dell’Unione di Eventi**  \n   Supponiamo di avere:  \n   \n   - **P(A) = 0.3** (probabilità che un punteggio sia superiore a 25).  \n   - **P(C) = 0.2** (probabilità che un punteggio sia inferiore a 15).  \n   - **P(A ∩ C) = 0** (perché un punteggio non può essere contemporaneamente superiore a 25 e inferiore a 15).  \n   - Usa la regola dell’unione per calcolare **P(A ∪ C)**.\n\n7. **Probabilità Condizionata**  \n   Consideriamo:  \n   \n   - **P(A) = 0.3** (probabilità che un punteggio sia superiore a 25).  \n   - **P(E) = 0.5** (probabilità che uno studente abbia più di 20 anni).  \n   - **P(A | E) = 0.4** (probabilità che un soggetto con più di 20 anni abbia un punteggio superiore a 25).  \n   - Usa la formula della probabilità condizionata per calcolare **P(A ∩ E)**.\n\n**Esercizi su Permutazioni e Combinazioni**\n\n8. **Selezione Casuale di Studenti**  \n   Dal campione di **15 studenti**, supponiamo di voler selezionare casualmente **3 studenti** per partecipare a un’intervista sulla loro soddisfazione di vita.  \n   \n   - Quanti modi ci sono per selezionare **3 studenti su 15**?\n\n9. **Ordinare gli Studenti per Discussione**  \n   Supponiamo di voler formare un piccolo gruppo di discussione con **3 studenti**, scegliendoli **in ordine di intervento**.  \n   - Quante diverse sequenze di 3 studenti possiamo ottenere?\n\n10. **Formare Coppie di Studenti**  \n    Se vogliamo formare **coppie di studenti** per un esercizio collaborativo, senza considerare l’ordine, quanti modi ci sono per farlo?\n:::\n\n::: {.callout-tip title=\"Soluzione\" collapse=\"true\"}\n**1. Definizione dello Spazio Campionario**  \n\n- Lo **spazio campionario** $\\Omega$ per questo esperimento è l'insieme di tutti i possibili punteggi della Satisfaction with Life Scale (SWLS), quindi:  \n\n  $$ \\Omega = \\{5, 6, 7, ..., 35\\} $$\n  \n- Se abbiamo raccolto i dati di 15 studenti con punteggi osservati $\\{27, 21, 15, 30, 18, 23, 26, 35, 20, 22, 19, 25, 32, 29, 28\\}$, possiamo considerare $\\Omega$ come questo insieme specifico.\n\n**2. Definizione di un Evento**  \n\n- L’evento $A$ \"Uno studente ha un punteggio SWLS superiore a 25\" è il sottoinsieme: \n\n  $$ A = \\{27, 30, 26, 35, 32, 29, 28\\}$$\n  \n- Se 7 studenti su 15 hanno punteggi superiori a 25, la probabilità empirica è:  \n\n  $$ P(A) = \\frac{7}{15} = 0.467 $$\n\n**3. Eventi Complementari** \n\n- L’evento complementare $B$ \"Uno studente ha un punteggio SWLS inferiore o uguale a 25\" è:  \n\n  $$ B = \\{21, 15, 18, 23, 20, 22, 19, 25\\}$$\n  \n- Se 8 studenti su 15 rientrano in $B$, la probabilità empirica è:  \n\n  $$ P(B) = 1 - P(A) = \\frac{8}{15} = 0.533 $$\n\n**Soluzioni agli Esercizi sulle Operazioni tra Eventi**\n\n**4. Unione di Eventi**  \n\n- L’evento $A \\cup C$ (\"Lo studente ha un punteggio maggiore di 25 o minore di 15\") è:  \n\n  $$ A \\cup C = \\{27, 30, 26, 35, 32, 29, 28, 15\\}$$\n  \n- Se 8 studenti su 15 appartengono a $A \\cup C$, la probabilità empirica è:  \n\n  $$ P(A \\cup C) = \\frac{8}{15} = 0.533 $$\n\n**5. Intersezione di Eventi e Eventi Disgiunti**  \n\n- L’evento $D$ \"Uno studente ha un punteggio pari a 20\" è $D = \\{20\\}$.\n- L’evento $A \\cap D$ è l’insieme degli elementi comuni a $A$ e $D$, ma $D$ non ha elementi in $A$, quindi:  \n\n  $$ A \\cap D = \\emptyset $$  \n  \n- Essendo $A \\cap D = \\emptyset$, gli eventi sono **disgiunti** e $P(A \\cap D) = 0$.\n\n**Soluzioni agli Esercizi sulle Regole della Probabilità**\n\n**6. Probabilità dell’Unione di Eventi**  \n\nUsiamo la formula:  \n\n$$ P(A \\cup C) = P(A) + P(C) - P(A \\cap C) $$\n\nDato che $P(A \\cap C) = 0$, abbiamo:  \n\n$$ P(A \\cup C) = 0.3 + 0.2 - 0 = 0.5 $$\n\n**7. Probabilità Condizionata**  \n\nLa probabilità congiunta $P(A \\cap E)$ si calcola con:  \n\n$$ P(A \\cap E) = P(A | E) \\cdot P(E) $$\n\nSostituendo i valori:  \n\n$$ P(A \\cap E) = 0.4 \\times 0.5 = 0.2 $$\n\n**Soluzioni agli Esercizi su Permutazioni e Combinazioni**\n\n**8. Selezione Casuale di Studenti**  \n\nIl numero di modi per scegliere 3 studenti su 15 (combinazioni) è: \n\n$$ C_{15,3} = \\frac{15!}{3!(15-3)!} = \\frac{15!}{3!12!} = \\frac{15 \\times 14 \\times 13}{3 \\times 2 \\times 1} = 455 $$\n\n**9. Ordinare gli Studenti per Discussione**  \n\nIl numero di modi per scegliere e ordinare 3 studenti su 15 (disposizioni) è:\n\n$$ D_{15,3} = \\frac{15!}{(15-3)!} = \\frac{15!}{12!} = 15 \\times 14 \\times 13 = 2730 $$\n\n**10. Formare Coppie di Studenti**  \n\nIl numero di modi per formare coppie (combinazioni di 2 studenti su 15) è: \n\n$$ C_{15,2} = \\frac{15!}{2!(15-2)!} = \\frac{15 \\times 14}{2 \\times 1} = 105 $$\n:::\n\n## Bibliografia {.unnumbered .unlisted}\n",
    "supporting": [
      "02_probability_models_files/figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}