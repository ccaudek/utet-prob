{
  "hash": "7782df817d743f468e1c629f5c162429",
  "result": {
    "engine": "knitr",
    "markdown": "# Proprietà delle variabili casuali {#sec-prob-random-var-properties}\n\n::: {.epigraph}\n> “If I expect *a* or *b*, and have an equal chance of gaining either of them, my Expectation is worth $(a+b)/2$.”\n>\n> — **Christiaan Huygens**, *De ratiociniis in ludo aleae* (1657).\n::: \n\n\n## Introduzione {.unnumbered .unlisted}\n\nSpesso è molto utile sintetizzare la distribuzione di una variabile casuale attraverso indicatori caratteristici. Questi indicatori consentono di cogliere le principali proprietà della distribuzione, come la posizione centrale (ovvero il \"baricentro\") e la variabilità (ossia la dispersione attorno al centro). In questo modo, è possibile ottenere una descrizione sintetica e significativa della distribuzione di probabilità della variabile casuale. \n\nIn questo capitolo, introdurremo i concetti fondamentali di valore atteso e varianza di una variabile casuale, che sono strumenti essenziali per comprendere e riassumere le proprietà di una distribuzione probabilistica.\n\n### Panoramica del capitolo {.unnumbered .unlisted}\n\n- Concetti di valore atteso e varianza per variabili casuali discrete.\n- Proprietà del valore atteso e della varianza.\n- Valore atteso e varianza per variabili casuali continue.\n- Utilizzare R per calcolare valore atteso e varianza.\n\n::: {.callout-tip collapse=true}\n## Prerequisiti\n\nPer affrontare al meglio questo capitolo, assicurati di avere familiarità con i seguenti argomenti:\n\n- È fondamentale aver letto la sezione @sec-apx-calculus.\n- Si consiglia la lettura del capitolo *Expectation* in @schervish2014probability.\n:::\n\n::: {.callout-caution collapse=true title=\"Preparazione del Notebook\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhere::here(\"code\", \"_common.R\") |> \n  source()\n```\n:::\n\n:::\n\n\n## Tendenza centrale\n\nQuando vogliamo comprendere il comportamento tipico di una variabile casuale, ci interessa spesso determinare il suo \"valore tipico\". Tuttavia, questa nozione può essere interpretata in diversi modi:\n\n- *Media*: La somma dei valori divisa per il numero dei valori.\n- *Mediana*: Il valore centrale della distribuzione, quando i dati sono ordinati in senso crescente o decrescente.\n- *Moda*: Il valore che si verifica con maggiore frequenza.\n\nAd esempio, per il set di valori $\\{3, 1, 4, 1, 5\\}$, la media è $\\frac{3+1+4+1+5}{5} = 2.8$, la mediana è 3, e la moda è 1. Tuttavia, quando ci occupiamo di variabili casuali, anziché di semplici sequenze di numeri, diventa necessario chiarire cosa intendiamo per \"valore tipico\" in questo contesto. Questo ci porta alla definizione formale del valore atteso.\n\n\n## Valore atteso\n\n::: {#def-}\nSia $X$ una variabile casuale discreta che assume i valori $x_1, \\dots, x_n$ con probabilità $P(X = x_i) = p(x_i)$. Il *valore atteso* di $X$, denotato con $\\mathbb{E}(X)$, è definito come:\n\n$$\n\\mathbb{E}(X) = \\sum_{i=1}^n x_i \\cdot p(x_i).\n$$\n\n:::\n\nIn altre parole, il valore atteso (noto anche come speranza matematica o aspettazione) di una variabile casuale è la somma di tutti i valori che la variabile può assumere, ciascuno ponderato dalla probabilità con cui esso si verifica.\n\n\n::: {.callout-note collapse=\"true\" title=\"Esercizio\"}\n\nCalcoliamo il valore atteso della variabile casuale $X$ corrispondente al lancio di una moneta equilibrata, dove *testa* corrisponde a $X = 1$ e *croce* corrisponde a $X = 0$:\n\n$$\n\\mathbb{E}(X) = \\sum_{i=1}^{2} x_i \\cdot P(x_i) = 0 \\cdot \\frac{1}{2} + 1 \\cdot \\frac{1}{2} = 0.5.\n$$\n:::\n\n\n::: {.callout-note collapse=\"true\" title=\"Esercizio\"}\nCalcoliamo il valore atteso della variabile casuale $X$ che rappresenta la somma dei punti ottenuti dal lancio di due dadi equilibrati a sei facce.\n\nLa variabile casuale $X$ può assumere i seguenti valori:\n\n$$\n\\{2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12\\}.\n$$\n\nLa probabilità associata a ciascun valore è data dalla distribuzione di massa di probabilità. Ad esempio, il valore $X = 2$ si ottiene solo se entrambi i dadi mostrano 1, quindi ha probabilità:\n\n$$\nP(X = 2) = \\frac{1}{36}.\n$$\n\nAnalogamente, $X = 7$ può essere ottenuto con sei combinazioni diverse: (1,6), (2,5), (3,4), (4,3), (5,2), (6,1), quindi:\n\n$$\nP(X = 7) = \\frac{6}{36}.\n$$\n\nLa distribuzione di massa di probabilità completa è:\n\n$$\nP(X) = \\left\\{\\frac{1}{36}, \\frac{2}{36}, \\frac{3}{36}, \\frac{4}{36}, \\frac{5}{36}, \\frac{6}{36}, \\frac{5}{36}, \\frac{4}{36}, \\frac{3}{36}, \\frac{2}{36}, \\frac{1}{36}\\right\\}.\n$$\n\nIl valore atteso $\\mathbb{E}[X]$ è definito come:\n\n$$\n\\mathbb{E}[X] = \\sum_{x} x \\cdot P(X = x).\n$$\n\nApplicando questa formula:\n\n$$\n\\mathbb{E}[X] = 2 \\cdot \\frac{1}{36} + 3 \\cdot \\frac{2}{36} + 4 \\cdot \\frac{3}{36} + \\cdots + 12 \\cdot \\frac{1}{36} = 7.\n$$\n\nEcco come calcolarlo utilizzando R:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Valori di X e le loro probabilità\nvalori <- 2:12\nprob <- c(1, 2, 3, 4, 5, 6, 5, 4, 3, 2, 1) / 36\n\n# Calcolo del valore atteso\nvalore_atteso <- sum(valori * prob)\nvalore_atteso\n#> [1] 7\n```\n:::\n\n\nIl risultato sarà:\n$$\n\\mathbb{E}[X] = 7.\n$$\n\nPer rappresentare graficamente la distribuzione di massa di probabilità:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Creazione di un data frame\ndati <- data.frame(Valore = valori, Probabilità = prob)\n\n# Plot\nggplot(dati, aes(x = Valore, y = Probabilità)) +\n  geom_col(fill = \"lightblue\") +\n  labs(\n    title = \"Distribuzione di Massa di Probabilità per X\",\n    x = \"Valore della Somma (X)\",\n    y = \"Probabilità\"\n  ) \n```\n\n::: {.cell-output-display}\n![](08_expval_var_files/figure-html/unnamed-chunk-3-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n:::\n\n\nNel suo [Ars conjectandi](https://en.wikipedia.org/wiki/Ars_Conjectandi), Bernoulli  introduce la nozione di valore atteso con le seguenti parole:\n\n> il termine \"aspettativa\" non deve essere inteso nel suo significato comune [...], bensì come la speranza di ottenere il meglio diminuita dalla paura di ottenere il peggio. Pertanto, il valore della nostra aspettativa rappresenta sempre qualcosa di intermedio tra il meglio che possiamo sperare e il peggio che possiamo temere [@hacking2006emergence].\n\nIn termini moderni, questa intuizione può essere rappresentata in modo più chiaro attraverso una simulazione. Possiamo affermare, infatti, che il valore atteso di una variabile casuale corrisponde alla media aritmetica di un gran numero di realizzazioni indipendenti della variabile stessa.\n\n::: {.callout-note collapse=\"true\" title=\"Esercizio\"}\nPer fare un esempio concreto, consideriamo nuovamente il caso del lancio di due dadi bilanciati a sei facce, dove la variabile casuale $X$ rappresenta la \"somma dei due dadi\". Simuliamo un numero elevato di realizzazioni indipendenti di $X$.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(123)  \nx_samples <- sample(valori, size = 1e6, replace = TRUE, prob = prob)\n```\n:::\n\n\nL'istruzione `sample(x, size = 1e6, replace = TRUE, prob = px))` utilizza R per generare un array di 1.000.000 di elementi (specificato dal parametro `size`), selezionati casualmente dall'array `x` secondo le probabilità specificate nell'array `px`.\n\nQuando il numero di realizzazioni indipendenti è sufficientemente grande, la media aritmetica dei campioni generati si avvicina al valore atteso della variabile casuale:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmean(x_samples)\n#> [1] 7\n```\n:::\n\n\nQuesto risultato conferma che il valore atteso $\\mathbb{E}[X] = 7$ rappresenta la somma media dei punti ottenuti nel lancio di due dadi equilibrati su un numero elevato di prove. Anche se ogni singola somma può variare tra 2 e 12, in media ci aspettiamo una somma di 7.\n\nL'aspettativa può anche essere interpretata come un **centro di massa**. Immagina che delle masse puntiformi con pesi $p_1, p_2, \\dots, p_n$ siano posizionate alle posizioni $x_1, x_2, \\dots, x_n$ sulla retta reale. Il centro di massa—il punto in cui i pesi sono bilanciati—è dato da:\n\n$$\n\\text{centro di massa} = x_1 p_1 + x_2 p_2 + \\dots + x_n p_n,\n$$\n\nche corrisponde esattamente all'aspettativa della variabile discreta $X$, che assume valori $x_1, \\dots, x_n$ con probabilità $p_1, \\dots, p_n$. Una conseguenza ovvia di questa interpretazione è che, per una funzione di densità di probabilità (pdf) simmetrica, l'aspettativa coincide con il punto di simmetria (a patto che l'aspettativa esista).\n\n::: {#fig-exp-val}\n![](../../figures/expected_value.png){width=\"80%\"}\n\nL'aspettativa come centro di massa [figura tratta da @kroese2025statistical].\n:::\n\n:::\n\n\n### Proprietà del valore atteso\n\nUna delle proprietà più importanti del valore atteso è la sua **linearità**: il valore atteso della somma di due variabili casuali è uguale alla somma dei loro rispettivi valori attesi:\n\n$$\n\\mathbb{E}(X + Y) = \\mathbb{E}(X) + \\mathbb{E}(Y).\n$$ {#eq-prop-expval-linearity}\n\nQuesta proprietà, espressa dalla formula sopra, è intuitiva quando $X$ e $Y$ sono variabili casuali indipendenti, ma è valida anche nel caso in cui $X$ e $Y$ siano correlate.\n\nInoltre, se moltiplichiamo una variabile casuale per una costante $c$, il valore atteso del prodotto è uguale alla costante moltiplicata per il valore atteso della variabile casuale:\n\n$$\n\\mathbb{E}(cY) = c \\mathbb{E}(Y).\n$$  {#eq-prop-expval-const}\n\nQuesta proprietà ci dice che una costante può essere \"estratta\" dall'operatore di valore atteso, e si applica a qualunque numero di variabili casuali.\n\nUn'altra proprietà significativa riguarda il prodotto di variabili casuali indipendenti. Se $X$ e $Y$ sono indipendenti, allora il valore atteso del loro prodotto è uguale al prodotto dei loro valori attesi:\n\n$$\n\\mathbb{E}(XY) = \\mathbb{E}(X) \\mathbb{E}(Y).\n$$ {#eq-expval-prod-ind-rv}\n\nInfine, consideriamo la media aritmetica $\\bar{X} = \\frac{X_1 + \\ldots + X_n}{n}$ di $n$ variabili casuali indipendenti con la stessa distribuzione e con valore atteso $\\mu$. Il valore atteso della media aritmetica è:\n\n$$\n\\mathbb{E}(\\bar{X}) = \\frac{1}{n} \\left(\\mathbb{E}(X_1) + \\dots + \\mathbb{E}(X_n)\\right) = \\frac{1}{n} \\cdot n \\cdot \\mathbb{E}(X) = \\mu.\n$$\n\nQuesto risultato conferma che la media aritmetica di un campione di variabili casuali indipendenti ha lo stesso valore atteso della distribuzione originaria, rendendo il valore atteso uno strumento cruciale per l'analisi statistica e probabilistica.\n\n\n::: {.callout-note collapse=\"true\" title=\"Esercizio\"}\n\nConsideriamo il seguente esperimento casuale. Sia $Y$ il numero che si ottiene dal lancio di un dado equilibrato a sei facce e $Y$ il numero di teste prodotto dal lancio di una moneta equilibrata (0 oppure 1). Troviamo il valore atteso di $X+Y$.\n\nPer risolvere il problema iniziamo a costruire lo spazio campione dell'esperimento casuale.\n\n| $x /\\ y$ |   1    |   2    |   3    |   4    |   5    |   6    |\n|:--------------------:|:------:|:------:|:------:|:------:|:------:|:------:|\n|          0           | (0, 1) | (0, 2) | (0, 3) | (0, 4) | (0, 5) | (0, 6) |\n|          1           | (1, 1) | (1, 2) | (1, 3) | (1, 4) | (1, 5) | (1, 6) |\n\novvero\n\n| $x /\\ y$ |  1  |  2  |  3  |  4  |  5  |  6  |\n|:--------------------:|:---:|:---:|:---:|:---:|:---:|:---:|\n|          0           |  1  |  2  |  3  |  4  |  5  |  6  |\n|          1           |  2  |  3  |  4  |  5  |  6  |  7  |\n\nIl risultato del lancio del dado è indipendente dal risultato del lancio della moneta. Pertanto, ciascun evento elementare dello spazio campione avrà la stessa probabilità di verificarsi, ovvero $P(\\omega) = \\frac{1}{12}$. Il valore atteso di $X+Y$ è dunque uguale a:\n\n$$\n\\mathbb{E}(X+Y) = 1 \\cdot \\frac{1}{12} + 2 \\cdot \\frac{1}{12} + \\dots + 7 \\cdot \\frac{1}{12} = 4.0.\n$$\n\nSi ottiene lo stesso risultato usando l'@eq-prop-expval-linearity:\n\n$$\n\\mathbb{E}(X+Y) = \\mathbb{E}(X) + E(Y) = 3.5 + 0.5 = 4.0.\n$$\n:::\n\n\n::: {.callout-note collapse=\"true\" title=\"Esercizio\"}\nSvolgiamo ora l'esercizio in R\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncoin <- 0:1  # Valori della moneta: testa (0) e croce (1)\ndie <- 1:6   # Valori del dado: da 1 a 6\n\n# Creazione del campione come combinazione di valori (moneta, dado)\nsample <- expand.grid(coin = coin, die = die)\nprint(sample)\n#>    coin die\n#> 1     0   1\n#> 2     1   1\n#> 3     0   2\n#> 4     1   2\n#> 5     0   3\n#> 6     1   3\n#> 7     0   4\n#> 8     1   4\n#> 9     0   5\n#> 10    1   5\n#> 11    0   6\n#> 12    1   6\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npx <- numeric()  # Vettore per memorizzare le probabilità\n\nfor (i in 1:7) {\n  # Filtrare le combinazioni in cui la somma è uguale a 'i'\n  event <- subset(sample, coin + die == i)\n  # Calcolare la probabilità\n  prob <- nrow(event) / nrow(sample)\n  px <- c(px, prob)\n  \n  # Stampare la probabilità\n  cat(sprintf(\"P(X + Y = %d) = %d / %d\\n\", i, nrow(event), nrow(sample)))\n}\n#> P(X + Y = 1) = 1 / 12\n#> P(X + Y = 2) = 2 / 12\n#> P(X + Y = 3) = 2 / 12\n#> P(X + Y = 4) = 2 / 12\n#> P(X + Y = 5) = 2 / 12\n#> P(X + Y = 6) = 2 / 12\n#> P(X + Y = 7) = 1 / 12\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nx <- 1:7  # Valori della variabile casuale (somma di moneta e dado)\nexpected_value <- sum(x * px)\nexpected_value\n#> [1] 4\n```\n:::\n\n:::\n\n\n::: {.callout-note collapse=\"true\" title=\"Esercizio\"}\nConsideriamo le variabili casuali $X$ e $Y$ definite nel caso del lancio di tre monete equilibrate, dove $X$ conta il numero delle teste nei tre lanci e $Y$ conta il numero delle teste al primo lancio. Si calcoli il valore atteso di $Z = X \\cdot Y$.\n\nLa distribuzione di probabilità congiunta $P(X, Y)$ è fornita nella tabella seguente.\n\n| $x /\\ y$ |  0  |  1  | $p(Y)$ |\n|:--------------------:|:---:|:---:|:------:|\n|          0           | 1/8 |  0  |  1/8   |\n|          1           | 2/8 | 1/8 |  3/8   |\n|          2           | 1/8 | 2/8 |  3/8   |\n|          3           |  0  | 1/8 |  1/8   |\n|        $p(y)$        | 4/8 | 4/8 |  1.0   |\n\nIl calcolo del valore atteso di $XY$ si riduce a\n\n$$\n\\mathbb{E}(Z) = 1 \\cdot \\frac{1}{8} + 2 \\cdot \\frac{2}{8} + 3 \\cdot \\frac{1}{8} = 1.0.\n$$\n\nSi noti che le variabili casuali $Y$ e $Y$ non sono indipendenti. Dunque non possiamo usare l'@eq-expval-prod-ind-rv. Infatti, il valore atteso di $X$ è\n\n$$\n\\mathbb{E}(X) = 1 \\cdot \\frac{3}{8} + 2 \\cdot \\frac{3}{8} + 3 \\cdot \\frac{1}{8} = 1.5\n$$\n\ne il valore atteso di $Y$ è\n\n$$\n\\mathbb{E}(Y) = 0 \\cdot \\frac{4}{8} + 1 \\cdot \\frac{4}{8} = 0.5.\n$$\n\nPerciò\n\n$$\n1.5 \\cdot 0.5 \\neq 1.0.\n$$\n:::\n\n\n### Valore atteso di una variabile casuale continua\n\nNel caso di una variabile casuale continua $X$, il valore atteso è definito come:\n\n$$\n\\mathbb{E}(X) = \\int_{-\\infty}^{+\\infty} x \\cdot p(x) \\, \\mathrm{d}x.\n$$\n\nAnche in questo contesto, il valore atteso rappresenta una media ponderata dei valori di $x$, dove ogni possibile valore di $x$ è ponderato in base alla densità di probabilità $p(x)$. \n\nL'integrale può essere interpretato analogamente a una somma continua, in cui $x$ rappresenta la posizione delle barre infinitamente strette di un istogramma, e $p(x)$ rappresenta l'altezza di tali barre. La notazione $\\int_{-\\infty}^{+\\infty}$ indica che si sta sommando il contributo di ogni valore possibile di $x$ lungo l'intero asse reale.\n\nQuesta interpretazione rende chiaro come l'integrale calcoli una somma ponderata che si estende su tutti i possibili valori di $x$, fornendo una misura centrale della distribuzione della variabile casuale continua. Per ulteriori dettagli sulla notazione dell'integrale, si veda l'@sec-calculus.\n\n\n#### Moda\n\nUn'altra misura di tendenza centrale delle variabili casuali continue è la moda. La moda di $Y$ individua il valore $y$ più plausibile, ovvero il valore $y$ che massimizza la funzione di densità $p(y)$:\n\n$$\nMo(Y) = \\text{argmax}_y p(y).\n$$ {#eq-def-mode}\n\n::: {.callout-note}\nLa notazione $\\text{argmax}_y p(y)$ significa: il valore $y$ tale per cui la funzione $p(y)$ assume il suo valore massimo.\n:::\n\n\n## Varianza\n\nDopo il valore atteso, la seconda proprietà più importante di una variabile casuale è la *varianza*.\n\n::: {#def-}\nSe $X$ è una variabile casuale discreta con distribuzione $p(x)$, la varianza di $X$, denotata con $\\mathbb{V}(X)$, è definita come:\n\n$$\n\\mathbb{V}(X) = \\mathbb{E}\\Big[\\big(X - \\mathbb{E}(X)\\big)^2\\Big].\n$$ {#eq-def-var-rv}\n:::\n\nIn altre parole, la varianza misura la deviazione media quadratica dei valori della variabile rispetto alla sua media. Se denotiamo il valore atteso di $X$ con $\\mu = \\mathbb{E}(X)$, la varianza $\\mathbb{V}(X)$ diventa il valore atteso di $(X - \\mu)^2$.\n\nLa varianza rappresenta una misura della \"dispersione\" dei valori di $X$ intorno al suo valore atteso. Quando calcoliamo la varianza, stiamo effettivamente misurando quanto i valori di $X$ tendono a differire dalla media $\\mu$. \n\nPer capire meglio, consideriamo la variabile casuale $X - \\mathbb{E}(X)$, detta *scarto* o *deviazione* dalla media. Questa variabile rappresenta le \"distanze\" tra i valori di $X$ e il valore atteso $\\mathbb{E}(X)$. Tuttavia, poiché lo scarto può essere positivo o negativo, la media dello scarto è sempre zero, il che lo rende inadatto a quantificare la dispersione. \n\nPer risolvere questo problema, eleviamo al quadrato gli scarti, ottenendo $(X - \\mathbb{E}(X))^2$, che rende tutte le deviazioni positive. La varianza è quindi la media di questi scarti al quadrato, fornendo una misura efficace della dispersione complessiva dei valori di $X$ rispetto alla sua media. \n\nQuesto concetto è fondamentale per comprendere la variabilità di una distribuzione e per applicare strumenti statistici che richiedono una conoscenza approfondita della distribuzione dei dati.\n\n\n::: {.callout-note collapse=\"true\" title=\"Esercizio\"}\nPosta $S$ uguale alla somma dei punti ottenuti nel lancio di due dadi equilibrati, si calcoli la varianza di $S$.\n\nLa variabile casuale $S$ ha la seguente distribuzione di probabilità:\n\n|    $s$     |       2        |       3        |       4        |       5        |       6        |       7        |       8        |       9        |       10       |       11       |       12       |\n|:----------:|:--------------:|:--------------:|:--------------:|:--------------:|:--------------:|:--------------:|:--------------:|:--------------:|:--------------:|:--------------:|:--------------:|\n| $P(S = s)$ | $\\frac{1}{36}$ | $\\frac{2}{36}$ | $\\frac{3}{36}$ | $\\frac{4}{36}$ | $\\frac{5}{36}$ | $\\frac{6}{36}$ | $\\frac{5}{36}$ | $\\frac{4}{36}$ | $\\frac{3}{36}$ | $\\frac{2}{36}$ | $\\frac{1}{36}$ |\n\nEssendo $\\mathbb{E}(S) = 7$, la varianza diventa\n\n$$\n\\begin{aligned}\n\\mathbb{V}(S) &= \\sum \\left(s - \\mathbb{E}(S)\\right)^2 \\cdot P(s) \\notag\\\\\n&= (2 - 7)^2 \\cdot \\frac{1}{36} + (3-7)^2 \\cdot \\frac{3}{36} + \\dots + (12 - 7)^2 \\cdot \\frac{1}{36} \\notag\\\\\n&= 5.8333.\\notag\n\\end{aligned}\n$$\n\n:::\n\n\n::: {.callout-note collapse=\"true\" title=\"Esercizio\"}\nSvolgiamo l'esercizio in R\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Definire i valori di x e le loro probabilità px\nx <- 2:12\npx <- c(\n  1 / 36, 2 / 36, 3 / 36, 4 / 36, 5 / 36, 6 / 36,\n  5 / 36, 4 / 36, 3 / 36, 2 / 36, 1 / 36\n)\n\n# Calcolare il valore atteso\nex <- sum(x * px)\nex\n#> [1] 7\n```\n:::\n\n\nApplichiamo l'@eq-def-var-rv:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Calcolo della varianza utilizzando la definizione\nvariance <- sum((x - ex)^2 * px)\nvariance\n#> [1] 5.83\n```\n:::\n\n\nUsiamo la funzione `var()` di `rv_discrete`:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Calcolo della varianza con pesi\nvariance_check <- weighted.mean((x - ex)^2, w = px)\nvariance_check\n#> [1] 5.83\n```\n:::\n\n\n:::\n\n\n### Formula alternativa per la varianza\n\nLa varianza di una variabile casuale $X$, indicata come $\\mathbb{V}(X)$, misura la dispersione dei valori attorno alla media. La definizione classica è:\n\n$$\n\\mathbb{V}(X) = \\mathbb{E}\\Big[\\big(X - \\mathbb{E}(X)\\big)^2\\Big].\n$$\n\nEsiste però una formula alternativa che semplifica il calcolo. \n\n::: {.proof}\n\n1. **Espansione del quadrato**  \n   Consideriamo la varianza, definita come $\\mathbb{V}(X) = \\mathbb{E}\\big[(X - \\mathbb{E}(X))^2\\big]$.  \n   Espandiamo il quadrato $(X - \\mathbb{E}(X))^2$ utilizzando la regola $(a - b)^2 = a^2 - 2ab + b^2$:\n   $$\n   (X - \\mathbb{E}(X))^2 = X^2 - 2\\,X\\,\\mathbb{E}(X) + \\big(\\mathbb{E}(X)\\big)^2.\n   $$\n\n2. **Applicazione dell’aspettativa**  \n   Applichiamo $\\mathbb{E}[\\cdot]$ a ciascun termine, ricordando che l’aspettativa è un operatore lineare:\n   $$\n   \\mathbb{E}\\big[(X - \\mathbb{E}(X))^2\\big]\n   = \\mathbb{E}\\big[X^2\\big]\n     \\;-\\; 2 \\,\\mathbb{E}\\big[X\\,\\mathbb{E}(X)\\big]\n     \\;+\\; \\mathbb{E}\\big[\\big(\\mathbb{E}(X)\\big)^2\\big].\n   $$\n\n3. **Gestione dei termini costanti**  \n   L’aspettativa $\\mathbb{E}(X)$ è una costante (indipendente da $X$). Indichiamola con $\\mu$. Quindi:\n   - $\\mathbb{E}(X^2)$ resta com’è.\n   - $\\mathbb{E}[X \\cdot \\mu] = \\mu \\, \\mathbb{E}[X] = \\mu \\cdot \\mu = \\mu^2$.\n   - $\\mathbb{E}\\big(\\mu^2\\big) = \\mu^2$.\n\n4. **Sostituzione e semplificazione**  \n   Rimpiazzando i risultati nel secondo passaggio si ottiene:\n   $$\n   \\mathbb{E}(X^2) \\;-\\; 2\\,\\mu^2 \\;+\\; \\mu^2\n   \\;=\\; \\mathbb{E}(X^2) - \\mu^2.\n   $$  \n   Poiché $\\mu = \\mathbb{E}(X)$, la varianza può quindi essere scritta come:\n   \n   $$\n   \\boxed{\n   \\mathbb{V}(X) = \\mathbb{E}(X^2) \\;-\\; \\bigl(\\mathbb{E}(X)\\bigr)^2.\n   }\n   $$ {#eq-variance-alt-formula}\n:::\n\nQuesta forma risulta molto utile per ragioni di efficienza computazionale: invece di calcolare gli scarti $(X - \\mu)$ per ogni osservazione, è sufficiente trovare $\\mathbb{E}(X^2)$ e poi sottrarre $\\mu^2$. In tal modo si riducono i passaggi intermedi e, di conseguenza, si minimizzano gli errori pratici. Inoltre, nelle dimostrazioni che richiedono manipolazioni algebriche – come quelle tipiche della Teoria Classica dei Test – questa espressione semplifica notevolmente le trasformazioni.\n\n\n::: {.callout-note collapse=\"true\" title=\"Esercizio\"}\nConsideriamo la variabile casuale $X$ che corrisponde al numero di teste che si osservano nel lancio di una moneta truccata con probabilità di testa uguale a 0.8. Si trovi la varianza di $Y$.\n\nIl valore atteso di $X$ è\n\n$$\n\\mathbb{E}(X) = 0 \\cdot 0.2 + 1 \\cdot 0.8 = 0.8.\n$$\n\nUsando la formula tradizionale della varianza otteniamo:\n\n$$\n\\mathbb{V}(X) = (0 - 0.8)^2 \\cdot 0.2 + (1 - 0.8)^2 \\cdot 0.8 = 0.16.\n$$\n\nLo stesso risultato si trova con la formula alternativa della varianza. Il valore atteso di $X^2$ è\n\n$$\n\\mathbb{E}(X^2) = 0^2 \\cdot 0.2 + 1^2 \\cdot 0.8 = 0.8.\n$$\n\ne la varianza diventa\n\n$$\n\\mathbb{V}(X) = \\mathbb{E}(X^2) - \\big(\\mathbb{E}(Y) \\big)^2 = 0.8 - 0.8^2 = 0.16.\n$$\n\n:::\n\n\n::: {.callout-note collapse=\"true\" title=\"Esercizio\"}\nSvolgiamo l'esercizio in R:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Definire i valori di x e le probabilità px\nx <- c(0, 1)\npx <- c(0.2, 0.8)\n\n# Calcolare il risultato\nresult <- sum(x^2 * px) - (sum(x * px))^2\nresult\n#> [1] 0.16\n```\n:::\n\n\n:::\n\n### Proprietà\n\n**Segno della varianza.** La varianza di una variabile aleatoria non è mai negativa, ed è zero solamente quando la variabile assume  un solo valore.\n\n**Invarianza per traslazione.** La varianza è invariante per traslazione, che lascia fisse le distanze dalla media, e cambia quadraticamente per riscalamento:\n  \n$$\n\\mathbb{V}(a + bX) = b^2\\mathbb{V}(X).\n$$\n\n*Dimostrazione.* Iniziamo a scrivere\n\n$$\n(aX+b)-{\\mathbb{E}}[aX+b]=aX+b-a{\\mathbb{E}}[X]-b=a(X-{\\mathbb  {E}}[X]).\n$$\n\nQuindi\n\n$$\n\\sigma _{{aX+b}}^{2}={\\mathbb{E}}[a^{2}(X-{\\mathbb  {E}}[X])^{2}]=a^{2}\\sigma _{X}^{2}.\n$$\n\nEsaminiamo una dimostrazione numerica.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Definire i valori di x\nx <- c(2, 1, 4, 7)\n\n# Calcolare y\ny <- 100 + 2 * x\n\n# Verificare la relazione tra le varianze\nresult <- var(y) == 2^2 * var(x)\nresult\n#> [1] TRUE\n```\n:::\n\n\n**Varianza della somma di due variabili indipendenti.** La varianza della somma di due variabili indipendenti o anche solo incorrelate è pari alla somma delle loro varianze:\n\n$$\n\\mathbb{V}(X+Y) = \\mathbb{V}(X) + \\mathbb{V}(Y).\n$$\n\n*Dimostrazione.* Se $\\mathbb{E}(X) = \\mathbb{E}(Y) = 0$, allora $\\mathbb{E}(X+Y) = 0$ e \n\n$$\\mathbb{V}(X+Y) = \\mathbb{E}((X+Y)^2) = \\mathbb{E}(X^2) + 2 \\mathbb{E}(XY) + \\mathbb{E}(Y^2).$$ \n\nSiccome le variabili sono indipendenti risulta $\\mathbb{E}(XY) = \\mathbb{E}(X)\\mathbb{E}(Y) = 0$. \n\n**Varianza della differenza di due variabili indipendenti.** La varianza della differenza di due variabili indipendenti è pari alla somma delle loro varianze:\n\n$$\n\\mathbb{V}(X-Y) = \\mathbb{V}(X) + \\mathbb{V}(Y).\n$$\n\n*Dimostrazione.*\n\n$$\n\\mathbb{V}(X-Y) = \\mathbb{V}(X +(-Y)) = \\mathbb{V}(X) + \\mathbb{V}(-Y) = \\mathbb{V}(X) + \\mathbb{V}(Y).\n$$\n\n**Varianza della somma di due variabili non indipendenti.** Se $X$ e $Y$ non sono indipendenti, la formula viene corretta dalla loro covarianza:\n\n$$\n\\mathbb{V}(X+Y) = \\mathbb{V}(X) + \\mathbb{V}(Y) + 2 Cov(X,Y),\n$$\n\ndove $Cov(X,Y) = \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y)$.\n\nUna dimostrazione numerica di questo principio è fornita sotto.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Definire i valori di x e y\nx <- c(2, 1, 4, 7)\ny <- c(1, 3, 5, 11)\n\n# Calcolare la varianza di x + y con ddof = 0\nvar_x_y <- mean((x + y - mean(x + y))^2)\nvar_x_y\n#> [1] 35.2\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Definire i valori di x e y\nx <- c(2, 1, 4, 7)\ny <- c(1, 3, 5, 11)\n\n# Calcolo della varianza combinata\nresult <- mean((x - mean(x))^2) + \n          mean((y - mean(y))^2) + \n          2 * cov(x, y) * (length(x) - 1) / length(x)\nresult\n#> [1] 35.2\n```\n:::\n\n\n**Varianza della media di variabili indipendenti.** La media aritmetica \n$\\textstyle {\\bar  {X}}={\\frac  {X_{1}+\\ldots +X_{n}}{n}}$ di $n$ variabili casuali indipendenti aventi la medesima distribuzione, ha varianza \n\n$$\n\\mathbb{V}(\\bar{X}) = \\frac{1}{n^2} \\mathbb{V}(X_1)+ \\dots \\mathbb{V}(X_n) = \\frac{1}{n^2} n \\mathbb{V}(X) = \\frac{1}{n} \\mathbb{V}(X).\n$$\n\n::: {.callout-note collapse=\"true\" title=\"Esercizio\"}\nIl principio precedente è illustrato dalla seguente simulazione.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Creare la popolazione\nset.seed(123)  # Per riproducibilità\npopulation <- rnorm(10000, mean = 50, sd = 10)\n\n# Definire dimensione del campione e numero di campioni\nsample_size <- 30\nnum_samples <- 100000\n\n# Creare un vettore per memorizzare le medie campionarie\nsample_means <- numeric(num_samples)\n\n# Generare i campioni e calcolare le medie\nfor (i in 1:num_samples) {\n  sample <- sample(population, size = sample_size, replace = TRUE)\n  sample_means[i] <- mean(sample)\n}\n\n# Calcolare la varianza delle medie campionarie\nsampling_dist_mean_var <- var(sample_means) * ((num_samples - 1) / num_samples)  # ddof = 0\nsampling_dist_mean_var\n#> [1] 3.33\n```\n:::\n\n\nIl valore teorico della varianza della distribuzione campionaria della media è\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n10^2 / 30\n#> [1] 3.33\n```\n:::\n\n:::\n\n\n### Varianza di una variabile casuale continua\n\nPer una variabile casuale continua $X$, la varianza è definita come:\n\n$$\n\\mathbb{V}(X) = \\int_{-\\infty}^{+\\infty} \\large[x - \\mathbb{E}(X)\\large]^2 p(x) \\,\\operatorname {d}\\!x.\n$$ {#eq-def-var-rv-cont}\n\nAnalogamente al caso discreto, la varianza di una variabile casuale continua $X$ una misura della dispersione, ovvero la \"distanza\" media quadratica attesa dei valori $x$ rispetto alla loro media \n$\\mathbb{E}(X)$. In altre parole, la varianza quantifica quanto i valori della variabile casuale si discostano tipicamente dal loro valore medio.\n\n\n### Deviazione standard\n\nQuando si lavora con le varianze, i valori sono elevati al quadrato, il che può rendere i numeri significativamente più grandi (o più piccoli) rispetto ai dati originali. Per riportare questi valori all'unità di misura della scala originale, si prende la radice quadrata della varianza. Il risultato ottenuto è chiamato *deviazione standard* ed è comunemente indicato con la lettera greca $\\sigma$.\n\n::: {#def-}\nLa deviazione standard, o scarto quadratico medio, è definita come la radice quadrata della varianza:\n\n$$\n\\sigma_X = \\sqrt{\\mathbb{V}(X)}.\n$$ {#eq-standard-deviation-def}\n:::\n\nCome nella statistica descrittiva, la deviazione standard di una variabile casuale fornisce una misura della dispersione, ossia la \"distanza\" tipica o prevista dei valori $x$ rispetto alla loro media.\n\n\n::: {.callout-note collapse=\"true\" title=\"Esercizio\"}\nPer i dadi equilibrati dell'esempio precedente, la deviazione standard della variabile casuale $S$ è pari a $\\sqrt{5.833} = 2.415$. Questo valore indica quanto i risultati della somma dei due dadi tendono a variare attorno alla loro media.\n:::\n\n\n## Standardizzazione\n\n::: {#def-}\nData una variabile casuale $X$, si dice *variabile standardizzata* di $X$ l'espressione\n\n$$\nZ = \\frac{X - \\mathbb{E}(X)}{\\sigma_X}.\n$$ {#eq-standardization}\n:::\n\nSolitamente, una variabile standardizzata viene denotata con la lettera $Z$.\n\n\n## Il teorema di Chebyshev\n\nIl *Teorema di Chebyshev* ci permette di stimare la probabilità che una variabile aleatoria si discosti dal suo valore atteso (media) di una certa quantità. In altre parole, ci fornisce un limite superiore alla probabilità che una variabile aleatoria assuma valori \"estremi\".\n\nIl teorema di Chebyshev afferma che, per qualsiasi variabile aleatoria X con media E(X) e varianza Var(X), e per qualsiasi numero reale k > 0, si ha:\n\n$$\nP(\\mid X - E(X)\\mid \\geq k \\sigma) \\leq 1/k^2,\n$$ {#eq-chebyshev-def}\n\ndove:\n\n* $P(\\mid X - E(X)\\mid \\geq k \\sigma)$ è la probabilità che lo scarto assoluto tra X e la sua media sia maggiore o uguale a k volte la deviazione standard (σ).\n* σ è la radice quadrata della varianza, ovvero la deviazione standard.\n\nCosa ci dice questo teorema?\n\n* **Limite superiore:** Il teorema ci fornisce un limite superiore alla probabilità che una variabile aleatoria si discosti dalla sua media di più di k deviazioni standard.\n* **Qualsiasi distribuzione:** La bellezza di questo teorema è che vale per qualsiasi distribuzione di probabilità, a patto che la media e la varianza esistano.\n* **Utilizzo:** Il teorema di Chebyshev è molto utile quando non conosciamo la distribuzione esatta di una variabile aleatoria, ma conosciamo la sua media e la sua varianza.\n\nIn sintesi, il teorema di Chebyshev ci fornisce un limite superiore alla probabilità che una variabile aleatoria si discosti dalla sua media di una certa quantità, in base alla sua varianza. Il teorema di Chebyshev ci permette quindi di fare inferenze sulla distribuzione di una variabile aleatoria anche quando abbiamo informazioni limitate.\n\n\n::: {.callout-note collapse=\"true\" title=\"Esercizio\"}\nSupponiamo di avere una variabile aleatoria $X$ con media 100 e varianza 25. Vogliamo stimare la probabilità che $X$ assuma valori al di fuori dell'intervallo [90, 110]. \n\nIn questo caso, $k$ = 2 (poiché 10 è uguale a 2 volte la deviazione standard, che è 5). Applicando il teorema di Chebyshev, otteniamo:\n\n$$\nP(\\mid X - 100 \\mid \\geq 10) \\leq \\left( \\frac{1}{2} \\right)^2 = 0.25\n$$\n\nQuindi, possiamo affermare con certezza che al massimo il 25% dei valori di X saranno al di fuori dell'intervallo [90, 110].\n\n:::\n\n\n## Momenti di variabili casuali\n\n::: {#def-}\nSi chiama *momento* di ordine $q$ di una v.c. $X$, dotata di densità $p(x)$, la quantità\n\n$$\n\\mathbb{E}(X^q) = \\int_{-\\infty}^{+\\infty} x^q p(x) \\; dx.\n$$ {#eq-moments-cont}\n\nSe $X$ è una v.c. discreta, i suoi momenti valgono:\n\n$$\n\\mathbb{E}(X^q) = \\sum_i x_i^q P(x_i),\n$$ {#eq-moments-discr}\n\ndove:\n\n- $E(X^q)$ rappresenta il valore atteso di $X$ elevato alla $q$-esima potenza.\n- $x_i$ sono i possibili valori della variabile discreta.\n- $P(x_i)$ è la probabilità associata a ciascun valore discreto.\n:::\n\nI momenti sono parametri statistici che forniscono informazioni importanti sulle caratteristiche di una variabile casuale. Tra questi, i più noti e utilizzati sono:\n\n1. Il momento del primo ordine ($q$ = 1): corrisponde al valore atteso (o media) della variabile casuale $X$.\n2. Il momento del secondo ordine ($q$ = 2): quando calcolato rispetto alla media, corrisponde alla varianza.\n\nPer i momenti di ordine superiore al primo, è comune calcolarli rispetto al valore medio di $X$. Questo si ottiene applicando una traslazione: $x_0 = x − \\mathbb{E}(X)$, dove $x_0$ rappresenta lo scarto dalla media. In particolare, il momento centrale del secondo ordine, calcolato con questa traslazione, corrisponde alla definizione di varianza.\n\n\n::: {.callout-note collapse=\"true\" title=\"Esercizio\"}\nIn R, possiamo calcolare il valore atteso e la varianza di variabili casuali discrete utilizzando vettori di valori e probabilità.\n\nConsideriamo una variabile casuale $X$ che rappresenta i valori ottenuti dal lancio di un dado non equilibrato, con valori possibili da 0 a 6, e con la seguente distribuzione di massa di probabilità: 0.1, 0.2, 0.3, 0.1, 0.1, 0.0, 0.2.\n\nIniziamo a definire un vettore che contiene i valori della v.c.:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nx <- 0:6\nprint(x)\n#> [1] 0 1 2 3 4 5 6\n```\n:::\n\n\nIl vettore `px` conterrà le probabilità associate ai valori `x`:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npx <- c(0.1, 0.2, 0.3, 0.1, 0.1, 0.0, 0.2)\nprint(px)\n#> [1] 0.1 0.2 0.3 0.1 0.1 0.0 0.2\n```\n:::\n\n\nControlliamo che la somma sia 1:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsum(px)\n#> [1] 1\n```\n:::\n\n\nCalcoliamo il valore atteso di $X$ implementando la formula del valore atteso utilizzando i vettori `x` e `px`:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nx_ev <- sum(x * px)\nx_ev\n#> [1] 2.7\n```\n:::\n\n\nCalcoliamo la varianza di $X$ usando i vettori `x` e `px`:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nx_var <- sum((x - x_ev)^2 * px)\nx_var\n#> [1] 3.81\n```\n:::\n\n\nCalcoliamo la deviazione standard di $X$ prendendo la radice quadrata della varianza:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nx_sd <- sqrt(x_var)\nx_sd\n#> [1] 1.95\n```\n:::\n\n\nPer rappresentare graficamente la distribuzione di massa, possiamo usare `ggplot2`:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndf <- data.frame(x = x, pmf = px)\nggplot(df, aes(x = x, y = pmf)) +\n  geom_point(color = \"#832F2B\", size = 3) +\n  geom_segment(aes(xend = x, yend = 0), linewidth = 1) +\n  labs(title = \"Distribuzione di massa di probabilità\", \n       x = \"Valori\", y = \"Probabilità\")\n```\n\n::: {.cell-output-display}\n![](08_expval_var_files/figure-html/unnamed-chunk-24-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\nQuesto codice calcola il valore atteso, la varianza e la deviazione standard di una variabile casuale discreta e rappresenta graficamente la distribuzione di massa, tutto in R.\n:::\n\n\n::: {.callout-note collapse=\"true\" title=\"Esercizio\"}\nUn esempio pratico dell'uso del **valore atteso** e della **varianza** in psicologia è rappresentato dagli studi sulla memoria episodica, in particolare attraverso il paradigma sperimentale delle risposte \"Remember-Know\". Questo paradigma permette di esplorare come le persone riconoscano eventi passati, distinguendo tra ricordi dettagliati e semplici sensazioni di familiarità. \n\n**Il Paradigma \"Remember-Know\"**  \n\nIn un tipico esperimento di memoria episodica:  \n\n1. Ai partecipanti viene presentata una lista di stimoli (es. parole o immagini).\n2. Dopo un intervallo di tempo, viene mostrata una nuova lista contenente elementi precedentemente visti (*old*) e elementi nuovi (*new*).  \n3. Per ogni stimolo *old* riconosciuto, i soggetti devono specificare se:  \n   - **Remember (R)**: Ricordano consapevolmente dettagli contestuali dell’episodio di encoding (es. \"Ricordo che questa parola era scritta in rosso\").\n   - **Know (K)**: Avvertono familiarità con lo stimolo, ma senza accesso a dettagli specifici (es. \"Sembra conosciuto, ma non so perché\").  \n   - **Miss**: Non riconoscono lo stimolo.  \n\nLa variabile in gioco è quindi **categorica e discreta**, con tre possibili esiti per gli stimoli *old*: {R, K, Miss}.  \n\n**Modelli Teorici e Previsioni Statistiche**  \n\nDue importanti teorie cercano di spiegare come avviene questo riconoscimento:  \n\n**Teoria del Processo Unico (Strength Theory)** [e.g., @wixted2010continuous]\n\n- **Ipotesi centrale**:  \n  C'è una sola dimensione continua (la \"forza mnemonica\") che determina il tipo di risposta.  \n  - Le risposte Remember derivano da tracce molto forti, quelle Know da tracce di forza intermedia, e i Miss da tracce troppo deboli.\n\n- **Implicazioni statistiche**: molte risposte Know, meno risposte Remember, bassa varianza.\n\n**Teoria del Doppio Processo (Dual-Process)** [e.g., @yonelinas2002nature]\n\n- **Ipotesi centrale**:  \n  Ci sono due processi indipendenti:  \n  1. **Recollection (R)**: Processo *qualitativo e binario* (presente/assente), legato al ricordo consapevole di dettagli contestuali.  \n  2. **Familiarità (K)**: Processo *continuo*, basato su una sensazione generica di familiarità.  \n\n- **Implicazioni statistiche**: numero simile di risposte Remember e Know, alta varianza. \n\nQui entrano in gioco i concetti statistici: ogni teoria formula previsioni diverse sul **valore atteso** (es. proporzione attesa di risposte R o K) e sulla **varianza** (dispersione dei dati attorno a questi valori). Confrontando le osservazioni sperimentali con le aspettative teoriche, è possibile testare quale modello sia più coerente con i dati empirici, illustrando come strumenti probabilistici possano chiarire meccanismi cognitivi complessi.\n\n**Confronto Statistico: Previsioni Teoriche**  \n\nPer confrontare quantitativamente le previsioni dei due modelli, consideriamo un esperimento ipotetico con 100 stimoli *old*. Assegniamo punteggi numerici alle categorie di risposta per trasformarle in una variabile discreta, facilitando il calcolo di valore atteso e varianza:  \n\n- **Remember (R) = 2**  \n- **Know (K) = 1**  \n- **Miss = 0**  \n\nQuesta codifica riflette l’intensità mnemonica associata a ciascuna risposta, permettendo di quantificare le differenze teoriche tra i modelli.  \n\n**1. Modello Single-Process (Forza continua)**  \n\nSecondo questa teoria, la distribuzione attesa delle risposte è:  \n\n| Categoria | R    | K    | Miss |  \n|-----------|------|------|------|  \n| % Prevista | 25%  | 60%  | 15%  |  \n\n**Calcoli statistici**:  \n- **Valore atteso** (media ponderata):  \n  $$ \n  E(X) = (2 \\cdot 0.25) + (1 \\cdot 0.60) + (0 \\cdot 0.15) = 1.10 \n  $$  \n- **Varianza** (dispersione attorno alla media):  \n  $$ \n  \\begin{aligned} \n  Var(X) &= (2-1.10)^2 \\cdot 0.25 + (1-1.10)^2 \\cdot 0.60 + (0-1.10)^2 \\cdot 0.15 \\\\ \n  &= 0.2025 + 0.006 + 0.1815 = 0.39 \n  \\end{aligned} \n  $$  \n\n\n**2. Modello Dual-Process (Recollection e Familiarità)** \n\nLa teoria prevede una distribuzione basata su due meccanismi indipendenti:  \n\n| Categoria | R    | K    | Miss |  \n|-----------|------|------|------|  \n| % Prevista | 40%  | 40%  | 20%  |  \n\n**Calcoli statistici**:  \n- **Valore atteso**:  \n  $$ \n  E(X) = (2 \\cdot 0.40) + (1 \\cdot 0.40) + (0 \\cdot 0.20) = 1.20 \n  $$  \n- **Varianza**:  \n  $$ \n  \\begin{aligned} \n  Var(X) &= (2-1.20)^2 \\cdot 0.40 + (1-1.20)^2 \\cdot 0.40 + (0-1.20)^2 \\cdot 0.20 \\\\ \n  &= 0.256 + 0.016 + 0.288 = 0.56 \n  \\end{aligned} \n  $$  \n\n**Sintesi del Confronto**  \n\nI due modelli generano previsioni distinte, riassunte nella tabella seguente:  \n\n| Modello          | Valore Atteso | Varianza | Interpretazione                     |  \n|------------------|---------------|----------|-------------------------------------|  \n| **Single-Process** | 1.10          | 0.39     | Media più bassa, varianza ridotta (distribuzione concentrata attorno a K). |  \n| **Dual-Process**   | 1.20          | 0.56     | Media più alta, varianza elevata (effetto della miscela tra due processi). |  \n\n- **Valore atteso**: Il modello dual-process predice una media superiore, coerente con la maggiore proporzione attesa di risposte *Remember*.  \n- **Varianza**: La differenza nella dispersione (0.39 vs. 0.56) riflette l’eterogeneità introdotta dalla separazione tra *recollection* e *familiarità* nel modello duale.  \n\n\n**Applicazione a Dati Empirici**  \n\nSupponiamo ora di aver raccolto dati reali da 100 soggetti che hanno prodotto questa distribuzione:\n\n| R  | K  | Miss |   \n |---------|---------|------------| \n| 38% | 42% | 20% |  \n\nCalcoliamo il valore atteso e la varianza empiriche:\n\n  $$ \n  E(X) = 2 \\cdot 0.38 + 1 \\cdot 0.42 + 0 \\cdot 0.20 = 1.18 \n  $$ \n  \n  $$ \n  Var(X) = (2-1.18)^2 \\cdot 0.38 + (1-1.18)^2 \\cdot 0.42 + (0-1.18)^2 \\cdot 0.20 = 0.55 \n  $$  \n\n**Risultati**:  \n\n| Dati          | Valore Atteso | Varianza |  \n|---------------|---------------|----------|  \n| Empirici      | 1.18          | 0.55     |  \n\nConfrontando questi risultati con le previsioni teoriche, notiamo che i dati empirici si avvicinano molto più al modello **dual-process** (valore atteso: 1.20 vs. 1.18; varianza: 0.56 vs. 0.55).\n\n**Implicazioni Psicologiche e Cliniche**  \n\n- **Teoriche**: Il confronto tra distribuzioni osservate e teoriche, usando valore atteso e varianza, consente di identificare quale teoria cognitiva spieghi meglio i dati.\n\n- **Cliniche**: In contesti clinici (es. valutazione di deficit cognitivi), questo approccio consente di identificare se un paziente mostra un profilo riconducibile a un danno selettivo della *recollection* (R ↓) o della *familiarità* (K ↓).  \n\nQuesto framework illustra come strumenti probabilistici di base possano tradurre ipotesi psicologiche complesse in predizioni quantitative verificabili, avanzando la comprensione dei meccanismi cognitivi.\n:::\n\n\n## Riflessioni conclusive {.unnumbered .unlisted}\n\nIn conclusione, i concetti di valore atteso e varianza sono fondamentali per comprendere il comportamento delle variabili casuali. Il valore atteso fornisce una misura centrale, rappresentando il \"valore tipico\" che ci si aspetta di osservare, mentre la varianza quantifica la dispersione dei valori attorno a questa media, offrendo una visione più completa della distribuzione. Questi strumenti sono essenziali per l'analisi e la modellizzazione statistica, fornendo le basi per valutare e interpretare la variabilità nei fenomeni aleatori.\n\n\n::: {.callout-important title=\"Problemi 1\" collapse=\"true\"}\n**Esercizio 1: Calcolo del Valore Atteso per Variabili Discrete**\n\nUtilizzando i dati raccolti dagli studenti sulla SWLS, calcola il valore atteso della soddisfazione con la vita ($X$). Organizza i dati come nell'esempio seguente e interpretalo come se fosse la distribuzione di probabilità **nella popolazione**:\n\n| SWLS Score | Probabilità $P(X)$ |\n|------------|-----------------------|\n| 5          | 0.05                  |\n| 10         | 0.10                  |\n| 15         | 0.20                  |\n| 20         | 0.30                  |\n| 25         | 0.20                  |\n| 30         | 0.10                  |\n| 35         | 0.05                  |\n\n1. Calcola il valore atteso di $X$, $\\mathbb{E}(X)$.\n2. Interpreta il risultato ottenuto.\n\n**Esercizio 2: Varianza e Deviazione Standard**\n\nData la stessa distribuzione della SWLS utilizzata nell'esercizio precedente:\n\n1. Calcola la varianza $\\mathbb{V}(X)$.\n2. Calcola la deviazione standard $\\sigma_X$.\n3. Commenta il significato della dispersione dei valori rispetto alla media.\n\n**Esercizio 3: Proprietà del Valore Atteso**\n\nUtilizzando la distribuzione della LSNS-6:\n\n1. Definisci una nuova variabile casuale $Y = 2X + 3$.\n2. Calcola il valore atteso di $Y$, $\\mathbb{E}(Y)$, utilizzando la linearità dell'operatore di aspettazione.\n3. Verifica il risultato calcolando direttamente $\\mathbb{E}(Y)$ dalla distribuzione di probabilità di $Y$.\n\nUtilizza una distribuzione della LSNS-6 organizzata come segue (sostituisci i valori presenti con quelli del campione):\n\n| LSNS-6 Score | Probabilità $P(Y)$ |\n|--------------|----------------------|\n| 5           | 0.10                 |\n| 10          | 0.15                 |\n| 15          | 0.25                 |\n| 20          | 0.25                 |\n| 25          | 0.15                 |\n| 30          | 0.10                 |\n\n\n**Esercizio 4: Applicazione del Teorema di Chebyshev**\n\nSia la soddisfazione con la vita (SWLS) distribuita con media $\\mu = 3.2$ e deviazione standard $\\sigma = 0.8$.\n\n1. Usa il teorema di Chebyshev per trovare un limite superiore alla probabilità che un valore di SWLS sia oltre due deviazioni standard dalla media.\n2. Confronta questo risultato con la probabilità empirica calcolata utilizzando i dati raccolti.\n\n**Esercizio 5: Standardizzazione e Distribuzione Normale**\n\n```r\n# Definizione dei dati osservati della LSNS-6 (sostituisci con i dati reali se disponibili)\nlsns6_scores <- c(5, 8, 10, 12, 15, 18, 20, 22, 25, 28)\n\n# Parametri della distribuzione\nmu <- 12   # Media della LSNS-6\nsigma <- 4  # Deviazione standard della LSNS-6\n\n# Standardizzazione dei valori osservati\nz_scores <- (lsns6_scores - mu) / sigma\n\n# Creazione dell'istogramma della distribuzione standardizzata\nhist(z_scores, \n     breaks = 10, \n     col = \"lightblue\", \n     main = \"Istogramma della distribuzione standardizzata di LSNS-6\", \n     xlab = \"Z-score\", \n     ylab = \"Frequenza\",\n     probability = TRUE)\n\n# Sovrapposizione della curva normale standard\ncurve(dnorm(x, mean = 0, sd = 1), col = \"red\", lwd = 2, add = TRUE)\n```\n\n1. **Standardizzazione**: La trasformazione dei punteggi della LSNS-6 in Z-score permette di esprimere ogni valore in termini di deviazioni standard rispetto alla media. Un valore $Z = 1$ significa che il punteggio di LSNS-6 è una deviazione standard sopra la media, mentre $Z = -1$ significa che è una deviazione standard sotto la media.\n\n2. **Istogramma della distribuzione standardizzata**: Il grafico mostra la distribuzione dei punteggi standardizzati. Se la distribuzione originale è simile a una normale, l'istogramma dei punteggi standardizzati dovrebbe assomigliare a una distribuzione normale standard.\n\n3. **Confronto con la distribuzione normale standard**: La curva rossa rappresenta la densità di una normale standard ($\\mathcal{N}(0,1)$). Se i dati sono approssimativamente normali, l'istogramma dei punteggi standardizzati dovrebbe seguire la forma della curva normale standard. Differenze marcate potrebbero indicare asimmetria o curtosi anomale nella distribuzione dei punteggi LSNS-6.\n:::\n\n::: {.callout-tip title=\"Soluzioni 1\" collapse=\"true\"}\n**Esercizio 1: Calcolo del Valore Atteso della SWLS**\n\nLa **Satisfaction With Life Scale (SWLS)** è composta da 5 item, ciascuno valutato su una scala Likert da 1 a 7. Supponiamo di avere la seguente distribuzione di probabilità per il punteggio totale della SWLS basata su un campione di studenti:\n\n| SWLS Score | Probabilità $P(X)$ |\n|------------|-----------------------|\n| 5          | 0.05                  |\n| 10         | 0.10                  |\n| 15         | 0.20                  |\n| 20         | 0.30                  |\n| 25         | 0.20                  |\n| 30         | 0.10                  |\n| 35         | 0.05                  |\n\n**Domanda:**  \nCalcola il valore atteso $\\mathbb{E}[X]$ del punteggio SWLS.\n\n**Soluzione:**\nIl valore atteso si calcola come:\n\n$$\n\\mathbb{E}[X] = \\sum x_i P(x_i)\n$$\n\nCalcoliamo in R:\n\n```r\n# Definizione dei valori SWLS e delle probabilità\nswls_scores <- c(5, 10, 15, 20, 25, 30, 35)\nprob_swls <- c(0.05, 0.10, 0.20, 0.30, 0.20, 0.10, 0.05)\n\n# Calcolo del valore atteso\nexpected_swls <- sum(swls_scores * prob_swls)\nexpected_swls\n```\n\n**Risultato:**  \n$$\n\\mathbb{E}[X] = 20\n$$\n\nIl valore atteso rappresenta la media teorica della soddisfazione con la vita nella popolazione, assumendo che la distribuzione dei punteggi SWLS segua esattamente le probabilità fornite. In altre parole, se prendessimo un numero molto grande di individui con questa distribuzione di probabilità, il punteggio medio atteso sarebbe 20. Questo suggerisce che, nella popolazione considerata, il livello medio di soddisfazione con la vita si colloca al centro della scala SWLS.\n\n**Esercizio 2: Calcolo della Varianza e Deviazione Standard della SWLS**\n\n```r\n# Definizione dei dati\nswls_scores <- c(5, 10, 15, 20, 25, 30, 35)\nprobabilities <- c(0.05, 0.10, 0.20, 0.30, 0.20, 0.10, 0.05)\n\n# Calcolo del valore atteso (media attesa)\nexpected_value <- sum(swls_scores * probabilities)\n\n# Calcolo della varianza\nvariance <- sum((swls_scores - expected_value)^2 * probabilities)\n\n# Calcolo della deviazione standard\nstd_deviation <- sqrt(variance)\n\n# Stampa dei risultati\ncat(\"Valore atteso (E[X]):\", expected_value, \"\\n\")\ncat(\"Varianza (Var[X]):\", variance, \"\\n\")\ncat(\"Deviazione standard (σ_X):\", std_deviation, \"\\n\")\n```\n\n- **Varianza**: Misura la dispersione dei punteggi SWLS rispetto alla media attesa. Se la varianza è alta, significa che i punteggi sono molto variabili; se è bassa, significa che i punteggi sono più concentrati attorno al valore atteso.\n- **Deviazione standard**: È la radice quadrata della varianza e ha la stessa unità di misura dei dati originali. Fornisce un'indicazione della dispersione media dei punteggi rispetto alla media.\n\nSe la deviazione standard è elevata, significa che nella popolazione ci sono sia individui con livelli di soddisfazione molto bassi sia individui con livelli molto alti. Se è bassa, i punteggi sono più omogenei intorno alla media.\n\n**Esercizio 3: Calcolo del Valore Atteso della Scala della Rete Sociale di Lubben (LSNS-6)**\n\n```r\n# Definizione dei dati della LSNS-6\nlsns_scores <- c(5, 10, 15, 20, 25, 30)\nprobabilities <- c(0.10, 0.15, 0.25, 0.25, 0.15, 0.10)\n\n# Definizione della trasformazione della variabile casuale Y = 2X + 3\ny_values <- 2 * lsns_scores + 3\n\n# Calcolo del valore atteso di X\nexpected_x <- sum(lsns_scores * probabilities)\n\n# Utilizzo della linearità dell'operatore di aspettazione: E[Y] = 2E[X] + 3\nexpected_y_from_x <- 2 * expected_x + 3\n\n# Calcolo diretto del valore atteso di Y\nexpected_y_direct <- sum(y_values * probabilities)\n\n# Stampa dei risultati\ncat(\"Valore atteso di X (E[X]):\", expected_x, \"\\n\")\ncat(\"Valore atteso di Y calcolato con la linearità (E[Y] = 2E[X] + 3):\", expected_y_from_x, \"\\n\")\ncat(\"Valore atteso di Y calcolato direttamente dalla distribuzione di probabilità di Y:\", expected_y_direct, \"\\n\")\n```\n\n1. **Linearità dell'operatore di aspettazione**: Questo principio afferma che se una variabile casuale $X$ viene trasformata linearmente in $Y = aX + b$, allora il valore atteso di $Y$ è dato da:\n\n   $$\n   \\mathbb{E}(Y) = a \\mathbb{E}(X) + b\n   $$\n   \n   Questo semplifica il calcolo senza dover ridefinire una nuova distribuzione di probabilità.\n\n2. **Verifica del risultato**: Dopo aver calcolato $\\mathbb{E}(Y)$ con la proprietà di linearità, lo confrontiamo con il calcolo diretto utilizzando la distribuzione trasformata. Se i due valori coincidono, confermiamo che la proprietà di linearità è rispettata.\n\n3. **Significato pratico**: La trasformazione lineare di una variabile casuale può rappresentare un'operazione reale come la conversione di punteggi da una scala all'altra. Il valore atteso si comporta linearmente, il che è utile per interpretare trasformazioni senza dover ricalcolare completamente la distribuzione.\n\n**Esercizio 4: Probabilità secondo il Teorema di Chebyshev**\n\nIl Teorema di Chebyshev afferma che per qualsiasi distribuzione, la probabilità che un valore sia oltre $k$ deviazioni standard dalla media è al massimo:\n\n$$\nP(|X - \\mu| \\geq k\\sigma) \\leq \\frac{1}{k^2}\n$$\n\nSostituendo $k = 2$:\n\n$$\nP(|X - 3.2| \\geq 2 \\cdot 0.8) \\leq \\frac{1}{2^2} = \\frac{1}{4} = 0.25\n$$\n\nQuindi, il Teorema di Chebyshev fornisce un limite superiore del 25% alla probabilità che un valore di SWLS sia oltre due deviazioni standard dalla media.\n\nPer confrontare questo risultato con la probabilità empirica, è necessaro usare i dati raccolti sulla SWLS.\n\n**Esercizio 5: Standardizzazione del Punteggio LSNS-6**\n\n**Domanda:**  \nStandardizza il punteggio **LSNS-6** trasformandolo nella variabile standardizzata $Z$.\n\n$$\nZ = \\frac{Y - \\mathbb{E}(Y)}{\\sigma_Y}\n$$\n\n**Soluzione:**\nCalcoliamo in R:\n\n```r\n# Standardizzazione dei punteggi LSNS-6\nz_lsns <- (lsns_scores - expected_lsns) / sd_lsns\nz_lsns\n```\n\n**Risultato:**  \n\n| LSNS-6 Score | Z-Score |\n|--------------|---------|\n| 5           | -2.23   |\n| 10          | -1.34   |\n| 15          | -0.45   |\n| 20          |  0.45   |\n| 25          |  1.34   |\n| 30          |  2.23   |\n:::\n\n::: {.callout-important title=\"Problemi 2\" collapse=\"true\"}\n**Esercizio 6: Personalizzazione degli Interventi Basati sulla Probabilità Condizionata**\n\nUno psicologo scolastico vuole identificare quali studenti potrebbero trarre maggiore beneficio da un programma di supporto psicologico. Dalla letteratura, si sa che la probabilità di avere livelli bassi di soddisfazione con la vita (SWLS ≤ 15) è più alta tra gli studenti che riportano elevati livelli di stress accademico.\n\nDai dati raccolti su un campione di studenti:\n\n- $P(\\text{SWLS} \\leq 15) = 0.35$\n- $P(\\text{Stress Alto}) = 0.40$\n- $P(\\text{SWLS} \\leq 15 \\mid \\text{Stress Alto}) = 0.60$\n\n**Domanda**\nSe uno studente è scelto a caso, qual è la probabilità che abbia un alto livello di stress dato che il suo punteggio SWLS è ≤ 15?\n\n**Esercizio 7: Prevedere il Successo di un Intervento Psicologico**\nUno psicologo clinico sta valutando l'efficacia di un intervento sulla riduzione dell'ansia. Ha raccolto i dati di 100 pazienti e ha osservato che il miglioramento medio nei punteggi di ansia (misurati con DASS-21) è di 5 punti con una deviazione standard di 2.5.\n\nSupponiamo che il miglioramento sia una variabile aleatoria normale con media 5 e deviazione standard 2.5.\n\n**Domanda**\nQual è la probabilità che un paziente scelto a caso migliori di almeno 7 punti?\n\n**Esercizio 8: Allocazione Ottimale delle Risorse in un Programma di Prevenzione**\nUno psicologo organizza un programma di sensibilizzazione sulla salute mentale in diverse scuole. Ha raccolto dati sulla frequenza con cui gli studenti si rivolgono allo sportello di ascolto, con la seguente distribuzione:\n\n| Numero di Visite | Probabilità |\n|-----------------|------------|\n| 0              | 0.40       |\n| 1              | 0.30       |\n| 2              | 0.15       |\n| 3+             | 0.15       |\n\n**Domanda**\nSe lo psicologo ha risorse per organizzare colloqui individuali solo per il 30% degli studenti, quale soglia può usare per selezionare gli studenti più bisognosi in base alla distribuzione delle visite?\n\n**Esercizio 9: Misurare la Variabilità della Risposta a un Trattamento**\nUno psicologo somministra un trattamento per la depressione e misura la variazione nei punteggi di depressione su un campione di pazienti prima e dopo l'intervento.\n\nLe variazioni seguono questa distribuzione:\n\n| Δ Punteggio DASS-21 | Probabilità |\n|--------------------|------------|\n| -10               | 0.10       |\n| -5                | 0.20       |\n| 0                 | 0.40       |\n| +5                | 0.20       |\n| +10               | 0.10       |\n\n**Domanda**\nQual è la deviazione standard della variazione nei punteggi di depressione?\n\n**Esercizio 10: Probabilità di un Fallimento in un Programma di Sensibilizzazione**\nUno psicologo organizza un programma per ridurre il pregiudizio sulla salute mentale. Dai dati precedenti, la probabilità di successo di ogni evento di sensibilizzazione è del 70%. Se organizza 5 eventi indipendenti, qual è la probabilità che almeno 1 fallisca?\n:::\n\n::: {.callout-tip title=\"Soluzioni 2\" collapse=\"true\"}\n**Esercizio 6: Personalizzazione degli Interventi Basati sulla Probabilità Condizionata**\n\nUtilizziamo la formula della probabilità condizionata:\n\n$$\nP(\\text{Stress Alto} \\mid \\text{SWLS} \\leq 15) = \\frac{P(\\text{SWLS} \\leq 15 \\mid \\text{Stress Alto}) P(\\text{Stress Alto})}{P(\\text{SWLS} \\leq 15)}\n$$\n\nCalcoliamo in R:\n\n```r\np_swls_low <- 0.35\np_stress_high <- 0.40\np_swls_given_stress <- 0.60\n\np_stress_given_swls <- (p_swls_given_stress * p_stress_high) / p_swls_low\np_stress_given_swls\n```\n\n**Risultato**\nLo psicologo può usare questa informazione per identificare studenti con alta probabilità di avere stress elevato, anche se non hanno segnalato direttamente il problema, e offrire supporto mirato.\n\n**Esercizio 7: Prevedere il Successo di un Intervento Psicologico**\n\nUsiamo la normalizzazione:\n\n$$\nZ = \\frac{X - \\mu}{\\sigma}\n$$\n\ne calcoliamo la probabilità corrispondente:\n\n```r\nmean_improvement <- 5\nsd_improvement <- 2.5\nthreshold <- 7\n\np_improve_7 <- 1 - pnorm(threshold, mean = mean_improvement, sd = sd_improvement)\np_improve_7\n```\n\n**Risultato**\nQuesto aiuta lo psicologo a comunicare ai pazienti la probabilità di ottenere miglioramenti significativi e ad adattare le aspettative dell'intervento.\n\n**Esercizio 8: Allocazione Ottimale delle Risorse in un Programma di Prevenzione**\n\n**Soluzione**\nCalcoliamo la probabilità cumulativa:\n\n```r\nvisits <- c(0, 1, 2, 3)\nprobabilities <- c(0.40, 0.30, 0.15, 0.15)\ncumulative_prob <- cumsum(probabilities)\n\n# Determinare la soglia per il 30% più bisognoso\nthreshold <- visits[min(which(cumulative_prob >= 0.70))]\nthreshold\n```\n\n**Risultato**\nLo psicologo può decidere di offrire supporto prioritario a studenti con almeno 2 visite, massimizzando l'impatto con risorse limitate.\n\n**Esercizio 9: Misurare la Variabilità della Risposta a un Trattamento**\n\n**Soluzione**\nCalcoliamo la varianza e la deviazione standard:\n\n```r\nscore_changes <- c(-10, -5, 0, 5, 10)\nprobabilities <- c(0.10, 0.20, 0.40, 0.20, 0.10)\n\n# Media attesa\nexpected_change <- sum(score_changes * probabilities)\n\n# Varianza\nvariance_change <- sum((score_changes - expected_change)^2 * probabilities)\n\n# Deviazione standard\nsd_change <- sqrt(variance_change)\nsd_change\n```\n\n**Risultato**\nSe la deviazione standard è grande, significa che l’effetto del trattamento è molto variabile e potrebbero essere necessarie strategie personalizzate.\n\n**Esercizio 10: Probabilità di un Fallimento in un Programma di Sensibilizzazione**\n\nUsiamo la distribuzione binomiale:\n\n```r\np_success <- 0.70\nn_events <- 5\n\np_failure_at_least_one <- 1 - dbinom(5, n_events, p_success)\np_failure_at_least_one\n```\n\n**Risultato**\nLo psicologo può pianificare strategie di miglioramento sapendo la probabilità di un fallimento.\n:::\n\n\n::: {.callout-important title=\"Problemi 3\" collapse=\"true\"}\n**Esercizio 3**\n\nConsiglio gli esercizi di base disponibili nella seguente [pagina web](https://stats.libretexts.org/Bookshelves/Introductory_Statistics/Introductory_Statistics_(Shafer_and_Zhang)/04%3A_Discrete_Random_Variables/4.E%3A_Discrete_Random_Variables_(Exercises)).\n:::\n\n\n::: {.callout-note collapse=true title=\"Informazioni sull'ambiente di sviluppo\"}\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.5.1 (2025-06-13)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.6.1\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#>  [4] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#>  [7] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#> [10] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#> [13] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#> [16] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#> [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#> [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#> [25] here_1.0.1           \n#> \n#> loaded via a namespace (and not attached):\n#>  [1] svUnit_1.0.8          tidyselect_1.2.1      farver_2.1.2         \n#>  [4] fastmap_1.2.0         TH.data_1.1-4         tensorA_0.36.2.1     \n#>  [7] digest_0.6.37         timechange_0.3.0      estimability_1.5.1   \n#> [10] lifecycle_1.0.4       survival_3.8-3        magrittr_2.0.3       \n#> [13] compiler_4.5.1        rlang_1.1.6           tools_4.5.1          \n#> [16] knitr_1.50            labeling_0.4.3        bridgesampling_1.1-2 \n#> [19] htmlwidgets_1.6.4     curl_7.0.0            pkgbuild_1.4.8       \n#> [22] RColorBrewer_1.1-3    abind_1.4-8           multcomp_1.4-28      \n#> [25] withr_3.0.2           purrr_1.1.0           grid_4.5.1           \n#> [28] stats4_4.5.1          colorspace_2.1-1      xtable_1.8-4         \n#> [31] inline_0.3.21         emmeans_1.11.2-8      scales_1.4.0         \n#> [34] MASS_7.3-65           cli_3.6.5             mvtnorm_1.3-3        \n#> [37] rmarkdown_2.29        ragg_1.5.0            generics_0.1.4       \n#> [40] RcppParallel_5.1.11-1 cachem_1.1.0          stringr_1.5.1        \n#> [43] splines_4.5.1         parallel_4.5.1        vctrs_0.6.5          \n#> [46] V8_7.0.0              Matrix_1.7-4          sandwich_3.1-1       \n#> [49] jsonlite_2.0.0        arrayhelpers_1.1-0    systemfonts_1.2.3    \n#> [52] glue_1.8.0            codetools_0.2-20      distributional_0.5.0 \n#> [55] lubridate_1.9.4       stringi_1.8.7         gtable_0.3.6         \n#> [58] QuickJSR_1.8.0        htmltools_0.5.8.1     Brobdingnag_1.2-9    \n#> [61] R6_2.6.1              textshaping_1.0.3     rprojroot_2.1.1      \n#> [64] evaluate_1.0.5        lattice_0.22-7        backports_1.5.0      \n#> [67] memoise_2.0.1         broom_1.0.9           snakecase_0.11.1     \n#> [70] rstantools_2.5.0      coda_0.19-4.1         gridExtra_2.3        \n#> [73] nlme_3.1-168          checkmate_2.3.3       xfun_0.53            \n#> [76] zoo_1.8-14            pkgconfig_2.0.3\n```\n:::\n\n:::\n\n\n## Bibliografia {.unnumbered .unlisted}\n\n",
    "supporting": [
      "08_expval_var_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}